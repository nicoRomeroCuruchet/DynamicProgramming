{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "b149d005",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nicoRomeroCuruchet/DynamicProgramming/blob/main/testing_bary.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "9c6a7123",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m2025-02-17 15:47:05.510\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m129\u001b[0m - \u001b[1mLower bounds: [-1.5707964   0.7        -0.34906584]\u001b[0m\n",
            "\u001b[32m2025-02-17 15:47:05.512\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m130\u001b[0m - \u001b[1mUpper bounds: [0.        4.        3.4906585]\u001b[0m\n",
            "\u001b[32m2025-02-17 15:47:05.514\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m149\u001b[0m - \u001b[1mNumber of states: 64000\u001b[0m\n",
            "\u001b[32m2025-02-17 15:47:05.515\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m150\u001b[0m - \u001b[1mTotal states:1600000\u001b[0m\n",
            "\u001b[32m2025-02-17 15:47:05.521\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mPolicy Iteration was correctly initialized.\u001b[0m\n",
            "\u001b[32m2025-02-17 15:47:05.522\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m164\u001b[0m - \u001b[1mThe enviroment name is: TimeLimit\u001b[0m\n",
            "\u001b[32m2025-02-17 15:47:05.531\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m387\u001b[0m - \u001b[1mCreating Delaunay triangulation over the state space...\u001b[0m\n",
            "\u001b[32m2025-02-17 15:47:12.562\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m389\u001b[0m - \u001b[1mDelaunay triangulation created.\u001b[0m\n",
            "\u001b[32m2025-02-17 15:47:12.563\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m399\u001b[0m - \u001b[1mGenerating transition and reward function table...\u001b[0m\n",
            "\u001b[32m2025-02-17 15:47:12.567\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m255\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-02-17 15:51:08.800\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m255\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-02-17 15:54:34.145\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m255\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-02-17 15:57:09.032\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m255\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-02-17 16:00:01.034\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m255\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-02-17 16:02:56.223\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m255\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-02-17 16:06:03.360\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m255\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-02-17 16:09:12.753\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m255\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-02-17 16:11:46.735\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m255\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-02-17 16:14:38.155\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m255\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-02-17 16:17:34.433\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m255\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-02-17 16:21:28.476\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m255\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-02-17 16:25:51.306\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m255\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-02-17 16:29:42.646\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m255\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-02-17 16:34:09.599\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m255\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-02-17 16:37:49.323\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m255\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-02-17 16:42:05.058\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m255\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-02-17 16:47:01.334\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m255\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-02-17 16:51:07.978\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m255\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-02-17 16:54:53.510\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m255\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-02-17 16:58:43.092\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m255\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-02-17 17:03:23.391\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m255\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-02-17 17:07:41.127\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m255\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-02-17 17:11:17.144\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m255\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-02-17 17:15:23.444\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m255\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-02-17 17:19:15.995\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m401\u001b[0m - \u001b[1mTransition and reward function table generated.\u001b[0m\n",
            "\u001b[32m2025-02-17 17:19:15.995\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m403\u001b[0m - \u001b[1msolving step 0\u001b[0m\n",
            "\u001b[32m2025-02-17 17:19:15.996\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m313\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-02-17 17:19:16.123\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.03999999910593033 | Avg Error: 0.014999999664723873 | 2761<0.001\u001b[0m\n",
            "\u001b[32m2025-02-17 17:19:35.902\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.008999999612569809 | Avg Error: 0.004000000189989805 | 3593<0.001\u001b[0m\n",
            "\u001b[32m2025-02-17 17:19:54.749\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.0020000000949949026 | Avg Error: 0.0010000000474974513 | 30482<0.001\u001b[0m\n",
            "\u001b[32m2025-02-17 17:20:14.064\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 64000<0.001\u001b[0m\n",
            "\u001b[32m2025-02-17 17:20:14.064\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m353\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-02-17 17:20:14.065\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-02-17 17:20:14.193\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m375\u001b[0m - \u001b[1mThe number of updated different actions: 1600000\u001b[0m\n",
            "\u001b[32m2025-02-17 17:20:14.193\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m378\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-02-17 17:20:14.194\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m403\u001b[0m - \u001b[1msolving step 1\u001b[0m\n",
            "\u001b[32m2025-02-17 17:20:14.194\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m313\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-02-17 17:20:14.411\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.08299999684095383 | Avg Error: 0.004000000189989805 | 18730<0.001\u001b[0m\n",
            "\u001b[32m2025-02-17 17:20:34.699\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.004000000189989805 | Avg Error: 0.0010000000474974513 | 39781<0.001\u001b[0m\n",
            "\u001b[32m2025-02-17 17:20:55.231\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.0010000000474974513 | Avg Error: 0.0 | 64000<0.001\u001b[0m\n",
            "\u001b[32m2025-02-17 17:21:17.815\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 64000<0.001\u001b[0m\n",
            "\u001b[32m2025-02-17 17:21:17.815\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m353\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-02-17 17:21:17.816\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-02-17 17:21:17.952\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m375\u001b[0m - \u001b[1mThe number of updated different actions: 44008\u001b[0m\n",
            "\u001b[32m2025-02-17 17:21:17.952\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m378\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-02-17 17:21:17.953\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m403\u001b[0m - \u001b[1msolving step 2\u001b[0m\n",
            "\u001b[32m2025-02-17 17:21:17.953\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m313\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-02-17 17:21:18.093\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.03400000184774399 | Avg Error: 0.0 | 56520<0.001\u001b[0m\n",
            "\u001b[32m2025-02-17 17:21:37.076\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.0010000000474974513 | Avg Error: 0.0 | 64000<0.001\u001b[0m\n",
            "\u001b[32m2025-02-17 17:21:56.345\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 64000<0.001\u001b[0m\n",
            "\u001b[32m2025-02-17 17:21:56.346\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m353\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-02-17 17:21:56.346\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-02-17 17:21:56.458\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m375\u001b[0m - \u001b[1mThe number of updated different actions: 12232\u001b[0m\n",
            "\u001b[32m2025-02-17 17:21:56.459\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m378\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-02-17 17:21:56.459\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m403\u001b[0m - \u001b[1msolving step 3\u001b[0m\n",
            "\u001b[32m2025-02-17 17:21:56.460\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m313\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-02-17 17:21:56.582\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.04699999839067459 | Avg Error: 0.0 | 62258<0.001\u001b[0m\n",
            "\u001b[32m2025-02-17 17:22:16.041\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 64000<0.001\u001b[0m\n",
            "\u001b[32m2025-02-17 17:22:16.042\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m353\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-02-17 17:22:16.042\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-02-17 17:22:16.158\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m375\u001b[0m - \u001b[1mThe number of updated different actions: 6886\u001b[0m\n",
            "\u001b[32m2025-02-17 17:22:16.159\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m378\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-02-17 17:22:16.159\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m403\u001b[0m - \u001b[1msolving step 4\u001b[0m\n",
            "\u001b[32m2025-02-17 17:22:16.160\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m313\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-02-17 17:22:16.291\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.028999999165534973 | Avg Error: 0.0 | 62624<0.001\u001b[0m\n",
            "\u001b[32m2025-02-17 17:22:35.661\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 64000<0.001\u001b[0m\n",
            "\u001b[32m2025-02-17 17:22:35.661\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m353\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-02-17 17:22:35.662\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-02-17 17:22:35.774\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m375\u001b[0m - \u001b[1mThe number of updated different actions: 3526\u001b[0m\n",
            "\u001b[32m2025-02-17 17:22:35.775\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m378\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-02-17 17:22:35.775\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m403\u001b[0m - \u001b[1msolving step 5\u001b[0m\n",
            "\u001b[32m2025-02-17 17:22:35.775\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m313\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-02-17 17:22:35.905\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.00800000037997961 | Avg Error: 0.0 | 63376<0.001\u001b[0m\n",
            "\u001b[32m2025-02-17 17:22:54.545\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 64000<0.001\u001b[0m\n",
            "\u001b[32m2025-02-17 17:22:54.546\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m353\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-02-17 17:22:54.546\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-02-17 17:22:54.709\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m375\u001b[0m - \u001b[1mThe number of updated different actions: 694\u001b[0m\n",
            "\u001b[32m2025-02-17 17:22:54.710\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m378\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-02-17 17:22:54.711\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m403\u001b[0m - \u001b[1msolving step 6\u001b[0m\n",
            "\u001b[32m2025-02-17 17:22:54.711\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m313\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-02-17 17:22:54.906\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.0020000000949949026 | Avg Error: 0.0 | 63982<0.001\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:15.079\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 64000<0.001\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:15.080\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m353\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:15.080\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:15.189\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m375\u001b[0m - \u001b[1mThe number of updated different actions: 128\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:15.190\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m378\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:15.190\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m403\u001b[0m - \u001b[1msolving step 7\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:15.191\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m313\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:15.320\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 64000<0.001\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:15.320\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m353\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:15.320\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:15.443\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m375\u001b[0m - \u001b[1mThe number of updated different actions: 12\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:15.443\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m378\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:15.444\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m403\u001b[0m - \u001b[1msolving step 8\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:15.444\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m313\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:15.565\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 64000<0.001\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:15.565\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m353\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:15.566\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:15.680\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m375\u001b[0m - \u001b[1mThe number of updated different actions: 6\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:15.681\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m378\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:15.681\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m403\u001b[0m - \u001b[1msolving step 9\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:15.682\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m313\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:15.813\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 64000<0.001\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:15.813\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m353\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:15.814\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:15.929\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m375\u001b[0m - \u001b[1mThe number of updated different actions: 6\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:15.929\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m378\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:15.929\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m403\u001b[0m - \u001b[1msolving step 10\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:15.930\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m313\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:16.066\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 64000<0.001\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:16.067\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m353\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:16.067\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:16.179\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m375\u001b[0m - \u001b[1mThe number of updated different actions: 8\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:16.180\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m378\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:16.180\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m403\u001b[0m - \u001b[1msolving step 11\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:16.181\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m313\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:16.305\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 64000<0.001\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:16.305\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m353\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:16.305\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:16.435\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m375\u001b[0m - \u001b[1mThe number of updated different actions: 6\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:16.435\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m378\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:16.436\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m403\u001b[0m - \u001b[1msolving step 12\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:16.436\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m313\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:16.563\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 64000<0.001\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:16.563\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m353\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:16.564\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:16.682\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m375\u001b[0m - \u001b[1mThe number of updated different actions: 6\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:16.683\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m378\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:16.683\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m403\u001b[0m - \u001b[1msolving step 13\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:16.683\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m313\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:16.810\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 64000<0.001\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:16.810\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m353\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:16.810\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:16.927\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m375\u001b[0m - \u001b[1mThe number of updated different actions: 2\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:16.928\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m378\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:16.928\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m403\u001b[0m - \u001b[1msolving step 14\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:16.929\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m313\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:17.059\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 64000<0.001\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:17.060\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m353\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:17.060\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:17.173\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m375\u001b[0m - \u001b[1mThe number of updated different actions: 2\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:17.174\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m378\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:17.174\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m403\u001b[0m - \u001b[1msolving step 15\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:17.175\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m313\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:17.306\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 64000<0.001\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:17.306\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m353\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:17.307\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:17.432\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m375\u001b[0m - \u001b[1mThe number of updated different actions: 4\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:17.433\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m378\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:17.433\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m403\u001b[0m - \u001b[1msolving step 16\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:17.434\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m313\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:17.558\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 64000<0.001\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:17.559\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m353\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:17.559\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:17.677\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m375\u001b[0m - \u001b[1mThe number of updated different actions: 2\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:17.677\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m378\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:17.678\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m403\u001b[0m - \u001b[1msolving step 17\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:17.678\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m313\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:17.801\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 64000<0.001\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:17.801\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m353\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:17.802\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:17.919\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m375\u001b[0m - \u001b[1mThe number of updated different actions: 4\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:17.919\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m378\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:17.920\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m403\u001b[0m - \u001b[1msolving step 18\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:17.920\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m313\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:18.058\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 64000<0.001\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:18.058\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m353\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:18.058\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:18.170\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m375\u001b[0m - \u001b[1mThe number of updated different actions: 10\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:18.170\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m378\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:18.170\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m403\u001b[0m - \u001b[1msolving step 19\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:18.171\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m313\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:18.300\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 64000<0.001\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:18.301\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m353\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:18.301\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:18.417\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m375\u001b[0m - \u001b[1mThe number of updated different actions: 2\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:18.418\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m378\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:18.419\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m403\u001b[0m - \u001b[1msolving step 20\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:18.419\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m313\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:18.547\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 64000<0.001\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:18.548\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m353\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:18.548\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:18.661\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m375\u001b[0m - \u001b[1mThe number of updated different actions: 6\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:18.662\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m378\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:18.662\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m403\u001b[0m - \u001b[1msolving step 21\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:18.662\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m313\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:18.793\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 64000<0.001\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:18.793\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m353\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:18.794\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:18.906\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m375\u001b[0m - \u001b[1mThe number of updated different actions: 6\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:18.907\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m378\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:18.907\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m403\u001b[0m - \u001b[1msolving step 22\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:18.907\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m313\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:19.044\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 64000<0.001\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:19.045\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m353\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:19.045\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:19.154\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m375\u001b[0m - \u001b[1mThe number of updated different actions: 4\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:19.155\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m378\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:19.155\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m403\u001b[0m - \u001b[1msolving step 23\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:19.155\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m313\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:19.287\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 64000<0.001\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:19.288\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m353\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:19.289\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:19.398\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m375\u001b[0m - \u001b[1mThe number of updated different actions: 6\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:19.398\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m378\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:19.399\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m403\u001b[0m - \u001b[1msolving step 24\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:19.399\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m313\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:19.526\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 64000<0.001\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:19.527\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m353\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:19.527\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:19.658\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m375\u001b[0m - \u001b[1mThe number of updated different actions: 6\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:19.659\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m378\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:19.660\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m403\u001b[0m - \u001b[1msolving step 25\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:19.660\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m313\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:19.788\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 64000<0.001\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:19.788\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m353\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:19.789\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:19.943\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m375\u001b[0m - \u001b[1mThe number of updated different actions: 4\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:19.943\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m378\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:19.944\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m403\u001b[0m - \u001b[1msolving step 26\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:19.944\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m313\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:20.070\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 64000<0.001\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:20.070\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m353\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:20.071\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:20.185\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m375\u001b[0m - \u001b[1mThe number of updated different actions: 6\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:20.186\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m378\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:20.186\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m403\u001b[0m - \u001b[1msolving step 27\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:20.186\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m313\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:20.315\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 64000<0.001\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:20.316\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m353\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:20.316\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:20.442\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m375\u001b[0m - \u001b[1mThe number of updated different actions: 6\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:20.443\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m378\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:20.443\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m403\u001b[0m - \u001b[1msolving step 28\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:20.443\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m313\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:20.568\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 64000<0.001\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:20.568\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m353\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:20.569\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:20.685\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m375\u001b[0m - \u001b[1mThe number of updated different actions: 6\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:20.685\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m378\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:20.686\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m403\u001b[0m - \u001b[1msolving step 29\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:20.686\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m313\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:20.810\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 64000<0.001\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:20.810\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m353\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:20.811\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:20.938\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m375\u001b[0m - \u001b[1mThe number of updated different actions: 2\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:20.939\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m378\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:20.939\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m403\u001b[0m - \u001b[1msolving step 30\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:20.940\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m313\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:21.068\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 64000<0.001\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:21.069\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m353\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:21.069\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:21.174\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m375\u001b[0m - \u001b[1mThe number of updated different actions: 4\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:21.175\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m378\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:21.176\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m403\u001b[0m - \u001b[1msolving step 31\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:21.176\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m313\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:21.310\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 64000<0.001\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:21.311\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m353\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:21.311\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:21.433\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m375\u001b[0m - \u001b[1mThe number of updated different actions: 4\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:21.434\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m378\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:21.435\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m403\u001b[0m - \u001b[1msolving step 32\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:21.435\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m313\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:21.563\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 64000<0.001\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:21.564\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m353\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:21.564\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:21.676\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m375\u001b[0m - \u001b[1mThe number of updated different actions: 6\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:21.676\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m378\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:21.677\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m403\u001b[0m - \u001b[1msolving step 33\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:21.677\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m313\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:21.801\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 64000<0.001\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:21.801\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m353\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:21.802\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:21.923\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m375\u001b[0m - \u001b[1mThe number of updated different actions: 10\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:21.923\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m378\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:21.924\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m403\u001b[0m - \u001b[1msolving step 34\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:21.924\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m313\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:22.059\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 64000<0.001\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:22.059\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m353\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:22.060\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:22.174\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m375\u001b[0m - \u001b[1mThe number of updated different actions: 2\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:22.174\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m378\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:22.175\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m403\u001b[0m - \u001b[1msolving step 35\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:22.175\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m313\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:22.304\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 64000<0.001\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:22.304\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m353\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:22.305\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:22.419\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m375\u001b[0m - \u001b[1mThe number of updated different actions: 2\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:22.420\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m378\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:22.420\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m403\u001b[0m - \u001b[1msolving step 36\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:22.420\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m313\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:22.550\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 64000<0.001\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:22.550\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m353\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:22.550\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:22.670\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m375\u001b[0m - \u001b[1mThe number of updated different actions: 2\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:22.670\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m378\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:22.671\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m403\u001b[0m - \u001b[1msolving step 37\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:22.671\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m313\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:22.800\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 64000<0.001\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:22.800\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m353\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:22.801\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:22.919\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m378\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-02-17 17:23:23.102\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36msave\u001b[0m:\u001b[36m422\u001b[0m - \u001b[1mPolicy and value function saved.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "import airplane\n",
        "import numpy as np\n",
        "import gymnasium as gym\n",
        "from utils.utils import test_enviroment\n",
        "from PolicyIteration import PolicyIteration\n",
        "\n",
        "glider = gym.make('ReducedBankedGliderPullout-v0')\n",
        "\n",
        "bins_space = {\n",
        "    \"flight_path_angle\": np.linspace(np.deg2rad(-90), np.deg2rad(0),    40,      dtype=np.float32),     # Flight Path Angle (γ)    (0)\n",
        "    \"airspeed_norm\":     np.linspace(0.7, 4.0,                          40,      dtype=np.float32),    # Air Speed         (V)    (1)\n",
        "    \"bank_angle\":        np.linspace( np.deg2rad(-20), np.deg2rad(200), 40,      dtype=np.float32),    # Bank Angle        (mu)   (2)\n",
        "}\n",
        "\n",
        "action_space= np.array(np.meshgrid(np.linspace(-0.4, 1.0, 5, dtype=np.float32), \n",
        "                                   np.linspace(np.deg2rad(-30), np.deg2rad(30), 5, dtype=np.float32))).T.reshape(-1, 2)\n",
        "\n",
        "pi = PolicyIteration(\n",
        "    env=glider, \n",
        "    bins_space=bins_space,\n",
        "    action_space= action_space,\n",
        "    gamma=0.99,\n",
        "    theta=1e-3,\n",
        ")\n",
        "\n",
        "\n",
        "pi.run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "5a2f30c2",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Action: [-0.4  0. ] | Reward: -0.011849143212344166 | State: [-1.3957323  1.2033064  3.1415927] | Terminated: False | Episode Length: 0.01\n",
            "Action: [-0.4  0. ] | Reward: -0.02372970564708082 | State: [-1.3951983  1.2066112  3.1415927] | Terminated: False | Episode Length: 0.02\n",
            "Action: [-0.4  0. ] | Reward: -0.035641656191802755 | State: [-1.3946618  1.2099144  3.1415927] | Terminated: False | Episode Length: 0.03\n",
            "Action: [-0.4  0. ] | Reward: -0.04758496357500507 | State: [-1.3941224  1.2132161  3.1415927] | Terminated: False | Episode Length: 0.04\n",
            "Action: [-0.4  0. ] | Reward: -0.05955959636559031 | State: [-1.3935803  1.216516   3.1415927] | Terminated: False | Episode Length: 0.05\n",
            "Action: [-0.4  0. ] | Reward: -0.07156552297237442 | State: [-1.3930354  1.2198144  3.1415927] | Terminated: False | Episode Length: 0.060000000000000005\n",
            "Action: [-0.4  0. ] | Reward: -0.0836027116435936 | State: [-1.3924879  1.2231112  3.1415927] | Terminated: False | Episode Length: 0.07\n",
            "Action: [-0.4  0. ] | Reward: -0.09567113046641201 | State: [-1.3919376  1.2264063  3.1415927] | Terminated: False | Episode Length: 0.08\n",
            "Action: [-0.4  0. ] | Reward: -0.10777074736643033 | State: [-1.3913846  1.2296997  3.1415927] | Terminated: False | Episode Length: 0.09\n",
            "Action: [-0.4  0. ] | Reward: -0.11990153010719533 | State: [-1.390829   1.2329917  3.1415927] | Terminated: False | Episode Length: 0.09999999999999999\n",
            "Action: [-0.4  0. ] | Reward: -0.13206344628971023 | State: [-1.3902707  1.2362819  3.1415927] | Terminated: False | Episode Length: 0.10999999999999999\n",
            "Action: [-0.4  0. ] | Reward: -0.1442564633519462 | State: [-1.3897097  1.2395705  3.1415927] | Terminated: False | Episode Length: 0.11999999999999998\n",
            "Action: [-0.4  0. ] | Reward: -0.1564805485683546 | State: [-1.389146   1.2428573  3.1415927] | Terminated: False | Episode Length: 0.12999999999999998\n",
            "Action: [-0.4  0. ] | Reward: -0.16873566904938048 | State: [-1.3885797  1.2461426  3.1415927] | Terminated: False | Episode Length: 0.13999999999999999\n",
            "Action: [-0.4  0. ] | Reward: -0.18102179174097674 | State: [-1.3880107  1.2494262  3.1415927] | Terminated: False | Episode Length: 0.15\n",
            "Action: [-0.4  0. ] | Reward: -0.1933388834241197 | State: [-1.3874391  1.2527082  3.1415927] | Terminated: False | Episode Length: 0.16\n",
            "Action: [-0.4  0. ] | Reward: -0.2056869107143254 | State: [-1.3868649  1.2559885  3.1415927] | Terminated: False | Episode Length: 0.17\n",
            "Action: [-0.4  0. ] | Reward: -0.21806584006116722 | State: [-1.386288   1.259267   3.1415927] | Terminated: False | Episode Length: 0.18000000000000002\n",
            "Action: [-0.4  0. ] | Reward: -0.23047563774779434 | State: [-1.3857086  1.2625439  3.1415927] | Terminated: False | Episode Length: 0.19000000000000003\n",
            "Action: [-0.4  0. ] | Reward: -0.2429162698904515 | State: [-1.3851265  1.2658191  3.1415927] | Terminated: False | Episode Length: 0.20000000000000004\n",
            "Action: [-0.4  0. ] | Reward: -0.2553877024379998 | State: [-1.3845417  1.2690926  3.1415927] | Terminated: False | Episode Length: 0.21000000000000005\n",
            "Action: [-0.4   -0.262] | Reward: -0.2678899011714386 | State: [-1.3839545  1.2723644  3.1389747] | Terminated: False | Episode Length: 0.22000000000000006\n",
            "Action: [-0.4   -0.262] | Reward: -0.28042283171250215 | State: [-1.3833647  1.2756344  3.1363566] | Terminated: False | Episode Length: 0.23000000000000007\n",
            "Action: [-0.4   -0.262] | Reward: -0.29298645953260866 | State: [-1.3827722  1.2789028  3.1337388] | Terminated: False | Episode Length: 0.24000000000000007\n",
            "Action: [-0.4   -0.262] | Reward: -0.3055807499529459 | State: [-1.3821772  1.2821695  3.1311207] | Terminated: False | Episode Length: 0.25000000000000006\n",
            "Action: [-0.4   -0.262] | Reward: -0.3182056681445658 | State: [-1.3815798  1.2854344  3.1285026] | Terminated: False | Episode Length: 0.26000000000000006\n",
            "Action: [-0.4   -0.262] | Reward: -0.33086117912848945 | State: [-1.3809798  1.2886976  3.1258848] | Terminated: False | Episode Length: 0.2700000000000001\n",
            "Action: [-0.4   -0.262] | Reward: -0.3435472477758213 | State: [-1.3803772  1.291959   3.1232667] | Terminated: False | Episode Length: 0.2800000000000001\n",
            "Action: [-0.4   -0.262] | Reward: -0.3562638388078737 | State: [-1.3797722  1.2952187  3.1206486] | Terminated: False | Episode Length: 0.2900000000000001\n",
            "Action: [-0.4   -0.262] | Reward: -0.36901091679630127 | State: [-1.3791647  1.2984767  3.1180308] | Terminated: False | Episode Length: 0.3000000000000001\n",
            "Action: [-0.4   -0.262] | Reward: -0.3817884461632452 | State: [-1.3785548  1.3017329  3.1154127] | Terminated: False | Episode Length: 0.3100000000000001\n",
            "Action: [-0.4   -0.262] | Reward: -0.39459639118148776 | State: [-1.3779424  1.3049873  3.1127946] | Terminated: False | Episode Length: 0.3200000000000001\n",
            "Action: [-0.4   -0.262] | Reward: -0.40743471597461683 | State: [-1.3773277  1.30824    3.1101768] | Terminated: False | Episode Length: 0.3300000000000001\n",
            "Action: [-0.4   -0.262] | Reward: -0.4203033845172009 | State: [-1.3767104  1.3114909  3.1075587] | Terminated: False | Episode Length: 0.34000000000000014\n",
            "Action: [-0.4   -0.262] | Reward: -0.4332023606349738 | State: [-1.3760908  1.3147401  3.1049407] | Terminated: False | Episode Length: 0.35000000000000014\n",
            "Action: [-0.4   -0.262] | Reward: -0.4461316080050305 | State: [-1.3754689  1.3179873  3.1023228] | Terminated: False | Episode Length: 0.36000000000000015\n",
            "Action: [-0.4   -0.262] | Reward: -0.4590910901560325 | State: [-1.3748444  1.3212329  3.0997047] | Terminated: False | Episode Length: 0.37000000000000016\n",
            "Action: [-0.4   -0.262] | Reward: -0.4720807704684244 | State: [-1.3742177  1.3244767  3.0970867] | Terminated: False | Episode Length: 0.38000000000000017\n",
            "Action: [-0.4   -0.262] | Reward: -0.48510061217466033 | State: [-1.3735887  1.3277186  3.0944688] | Terminated: False | Episode Length: 0.3900000000000002\n",
            "Action: [-0.4   -0.262] | Reward: -0.4981505783594414 | State: [-1.3729573  1.3309588  3.0918508] | Terminated: False | Episode Length: 0.4000000000000002\n",
            "Action: [-0.4   -0.262] | Reward: -0.5112306319599633 | State: [-1.3723236  1.3341972  3.0892327] | Terminated: False | Episode Length: 0.4100000000000002\n",
            "Action: [-0.4   -0.262] | Reward: -0.5243407357661755 | State: [-1.3716878  1.3374337  3.0866148] | Terminated: False | Episode Length: 0.4200000000000002\n",
            "Action: [-0.4   -0.262] | Reward: -0.5374808524210495 | State: [-1.3710495  1.3406684  3.0839968] | Terminated: False | Episode Length: 0.4300000000000002\n",
            "Action: [-0.4   -0.262] | Reward: -0.5506509444208598 | State: [-1.370409   1.3439013  3.0813787] | Terminated: False | Episode Length: 0.4400000000000002\n",
            "Action: [-0.4   -0.262] | Reward: -0.5638509741154745 | State: [-1.3697662  1.3471323  3.0787609] | Terminated: False | Episode Length: 0.45000000000000023\n",
            "Action: [-0.4   -0.262] | Reward: -0.5770809037086565 | State: [-1.3691213  1.3503615  3.0761428] | Terminated: False | Episode Length: 0.46000000000000024\n",
            "Action: [-0.4   -0.262] | Reward: -0.590340695258377 | State: [-1.3684741  1.3535889  3.0735247] | Terminated: False | Episode Length: 0.47000000000000025\n",
            "Action: [-0.4   -0.262] | Reward: -0.6036303106771385 | State: [-1.3678247  1.3568144  3.0709069] | Terminated: False | Episode Length: 0.48000000000000026\n",
            "Action: [-0.4   -0.262] | Reward: -0.6169497117323098 | State: [-1.3671731  1.360038   3.0682888] | Terminated: False | Episode Length: 0.49000000000000027\n",
            "Action: [-0.4   -0.262] | Reward: -0.630298860046472 | State: [-1.3665193  1.3632598  3.0656707] | Terminated: False | Episode Length: 0.5000000000000002\n",
            "Action: [-0.4   -0.262] | Reward: -0.6436777170977745 | State: [-1.3658634  1.3664798  3.063053 ] | Terminated: False | Episode Length: 0.5100000000000002\n",
            "Action: [-0.4   -0.262] | Reward: -0.6570862442203043 | State: [-1.3652054  1.3696978  3.0604348] | Terminated: False | Episode Length: 0.5200000000000002\n",
            "Action: [-0.4   -0.262] | Reward: -0.6705244026044641 | State: [-1.3645452  1.372914   3.0578167] | Terminated: False | Episode Length: 0.5300000000000002\n",
            "Action: [-0.4   -0.262] | Reward: -0.683992153297364 | State: [-1.363883   1.3761283  3.055199 ] | Terminated: False | Episode Length: 0.5400000000000003\n",
            "Action: [-0.4   -0.262] | Reward: -0.6974894572032222 | State: [-1.3632187  1.3793406  3.0525808] | Terminated: False | Episode Length: 0.5500000000000003\n",
            "Action: [-0.4   -0.262] | Reward: -0.7110162750837792 | State: [-1.3625522  1.3825512  3.0499628] | Terminated: False | Episode Length: 0.5600000000000003\n",
            "Action: [-0.4   -0.262] | Reward: -0.7245725675587219 | State: [-1.3618836  1.3857598  3.047345 ] | Terminated: False | Episode Length: 0.5700000000000003\n",
            "Action: [-0.4   -0.262] | Reward: -0.73815829510612 | State: [-1.3612131  1.3889666  3.0447268] | Terminated: False | Episode Length: 0.5800000000000003\n",
            "Action: [-0.4   -0.262] | Reward: -0.751773418062873 | State: [-1.3605405  1.3921714  3.0421088] | Terminated: False | Episode Length: 0.5900000000000003\n",
            "Action: [-0.4   -0.262] | Reward: -0.7654178966251702 | State: [-1.3598658  1.3953742  3.039491 ] | Terminated: False | Episode Length: 0.6000000000000003\n",
            "Action: [-0.4   -0.262] | Reward: -0.7790916908489605 | State: [-1.3591892  1.3985752  3.0368729] | Terminated: False | Episode Length: 0.6100000000000003\n",
            "Action: [-0.4    0.524] | Reward: -0.792794760650435 | State: [-1.3585106  1.4017742  3.0421088] | Terminated: False | Episode Length: 0.6200000000000003\n",
            "Action: [-0.4    0.524] | Reward: -0.8065270628520986 | State: [-1.357829   1.4049712  3.047345 ] | Terminated: False | Episode Length: 0.6300000000000003\n",
            "Action: [-0.4    0.524] | Reward: -0.8202885541511101 | State: [-1.3571445  1.4081664  3.0525808] | Terminated: False | Episode Length: 0.6400000000000003\n",
            "Action: [-0.4    0.524] | Reward: -0.834079191121351 | State: [-1.356457   1.4113597  3.0578167] | Terminated: False | Episode Length: 0.6500000000000004\n",
            "Action: [-0.4   -0.262] | Reward: -0.8478989302155362 | State: [-1.3557668  1.4145509  3.055199 ] | Terminated: False | Episode Length: 0.6600000000000004\n",
            "Action: [-0.4    0.524] | Reward: -0.8617477301986458 | State: [-1.3550744  1.4177402  3.0604348] | Terminated: False | Episode Length: 0.6700000000000004\n",
            "Action: [-0.4    0.524] | Reward: -0.8756255471641994 | State: [-1.3543793  1.4209275  3.0656707] | Terminated: False | Episode Length: 0.6800000000000004\n",
            "Action: [-0.4    0.524] | Reward: -0.8895323370880697 | State: [-1.3536813  1.4241129  3.0709069] | Terminated: False | Episode Length: 0.6900000000000004\n",
            "Action: [-0.4    0.524] | Reward: -0.9034680558307251 | State: [-1.3529807  1.4272963  3.0761428] | Terminated: False | Episode Length: 0.7000000000000004\n",
            "Action: [-0.4    0.524] | Reward: -0.9174326591395133 | State: [-1.3522773  1.4304777  3.0813787] | Terminated: False | Episode Length: 0.7100000000000004\n",
            "Action: [-0.4   -0.262] | Reward: -0.9314261026509869 | State: [-1.3515712  1.4336572  3.0787609] | Terminated: False | Episode Length: 0.7200000000000004\n",
            "Action: [-0.4    0.524] | Reward: -0.9454483437123353 | State: [-1.3508631  1.4368346  3.0839968] | Terminated: False | Episode Length: 0.7300000000000004\n",
            "Action: [-0.4   -0.262] | Reward: -0.9594993376065661 | State: [-1.3501523  1.44001    3.0813787] | Terminated: False | Episode Length: 0.7400000000000004\n",
            "Action: [-0.4    0.524] | Reward: -0.9735790412747712 | State: [-1.3494395  1.4431834  3.0866148] | Terminated: False | Episode Length: 0.7500000000000004\n",
            "Action: [-0.4   -0.262] | Reward: -0.9876874096464291 | State: [-1.348724   1.4463547  3.0839968] | Terminated: False | Episode Length: 0.7600000000000005\n",
            "Action: [-0.4    0.524] | Reward: -1.0018243992544233 | State: [-1.3480065  1.4495242  3.0892327] | Terminated: False | Episode Length: 0.7700000000000005\n",
            "Action: [-0.4    0.524] | Reward: -1.0159899646747768 | State: [-1.3472865  1.4526916  3.0944688] | Terminated: False | Episode Length: 0.7800000000000005\n",
            "Action: [-0.4    0.524] | Reward: -1.0301840603801198 | State: [-1.3465637  1.4558569  3.0997047] | Terminated: False | Episode Length: 0.7900000000000005\n",
            "Action: [-0.4    0.524] | Reward: -1.0444066407422534 | State: [-1.3458385  1.4590201  3.1049407] | Terminated: False | Episode Length: 0.8000000000000005\n",
            "Action: [-0.4    0.524] | Reward: -1.0586576600347533 | State: [-1.3451109  1.4621814  3.1101768] | Terminated: False | Episode Length: 0.8100000000000005\n",
            "Action: [-0.4    0.524] | Reward: -1.0729370724356158 | State: [-1.3443809  1.4653406  3.1154127] | Terminated: False | Episode Length: 0.8200000000000005\n",
            "Action: [-0.4    0.524] | Reward: -1.087244832029947 | State: [-1.3436483  1.4684979  3.1206486] | Terminated: False | Episode Length: 0.8300000000000005\n",
            "Action: [-0.4    0.524] | Reward: -1.1015808928126942 | State: [-1.3429135  1.4716529  3.1258848] | Terminated: False | Episode Length: 0.8400000000000005\n",
            "Action: [-0.4    0.524] | Reward: -1.1159452086914183 | State: [-1.3421763  1.474806   3.1311207] | Terminated: False | Episode Length: 0.8500000000000005\n",
            "Action: [-0.4    0.524] | Reward: -1.1303377334891094 | State: [-1.3414369  1.4779569  3.1363566] | Terminated: False | Episode Length: 0.8600000000000005\n",
            "Action: [-0.4    0.524] | Reward: -1.1447584209470436 | State: [-1.3406951  1.4811058  3.1415927] | Terminated: False | Episode Length: 0.8700000000000006\n",
            "Action: [-0.4    0.524] | Reward: -1.1592072247276826 | State: [-1.3399513  1.4842526  3.1468287] | Terminated: False | Episode Length: 0.8800000000000006\n",
            "Action: [-0.4    0.524] | Reward: -1.173684098417614 | State: [-1.3392051  1.4873973  3.1520646] | Terminated: False | Episode Length: 0.8900000000000006\n",
            "Action: [-0.4    0.524] | Reward: -1.1881889955305345 | State: [-1.338457   1.4905399  3.1573007] | Terminated: False | Episode Length: 0.9000000000000006\n",
            "Action: [-0.4    0.524] | Reward: -1.2027218695102733 | State: [-1.3377068  1.4936804  3.1625366] | Terminated: False | Episode Length: 0.9100000000000006\n",
            "Action: [-0.4    0.524] | Reward: -1.2172826737338585 | State: [-1.3369545  1.4968188  3.1677725] | Terminated: False | Episode Length: 0.9200000000000006\n",
            "Action: [-0.4   -0.524] | Reward: -1.231871361514624 | State: [-1.3362002  1.499955   3.1625366] | Terminated: False | Episode Length: 0.9300000000000006\n",
            "Action: [-0.4   -0.524] | Reward: -1.2464878848437233 | State: [-1.3354436  1.5030892  3.1573007] | Terminated: False | Episode Length: 0.9400000000000006\n",
            "Action: [-0.4   -0.524] | Reward: -1.261132195629821 | State: [-1.3346848  1.5062213  3.1520646] | Terminated: False | Episode Length: 0.9500000000000006\n",
            "Action: [-0.4   -0.524] | Reward: -1.2758042457021226 | State: [-1.3339237  1.5093513  3.1468287] | Terminated: False | Episode Length: 0.9600000000000006\n",
            "Action: [-0.4    0.524] | Reward: -1.2905039868134474 | State: [-1.3331604  1.512479   3.1520646] | Terminated: False | Episode Length: 0.9700000000000006\n",
            "Action: [-0.4    0.524] | Reward: -1.3052313709031858 | State: [-1.3323951  1.5156046  3.1573007] | Terminated: False | Episode Length: 0.9800000000000006\n",
            "Action: [-0.4   -0.524] | Reward: -1.3199863498457582 | State: [-1.3316277  1.5187281  3.1520646] | Terminated: False | Episode Length: 0.9900000000000007\n",
            "Action: [-0.4    0.524] | Reward: -1.3347688746629478 | State: [-1.3308581  1.5218494  3.1573007] | Terminated: False | Episode Length: 1.0000000000000007\n",
            "Action: [-0.4    0.524] | Reward: -1.3495788968336193 | State: [-1.3300865  1.5249686  3.1625366] | Terminated: False | Episode Length: 1.0100000000000007\n",
            "Action: [-0.4    0.524] | Reward: -1.3644163677762582 | State: [-1.3293128  1.5280856  3.1677725] | Terminated: False | Episode Length: 1.0200000000000007\n",
            "Action: [-0.4   -0.524] | Reward: -1.3792812388522997 | State: [-1.3285373  1.5312004  3.1625366] | Terminated: False | Episode Length: 1.0300000000000007\n",
            "Action: [-0.4    0.524] | Reward: -1.3941734600127416 | State: [-1.3277595  1.5343131  3.1677725] | Terminated: False | Episode Length: 1.0400000000000007\n",
            "Action: [-0.4    0.262] | Reward: -1.4090929822250404 | State: [-1.3269798  1.5374235  3.1703906] | Terminated: False | Episode Length: 1.0500000000000007\n",
            "Action: [-0.4    0.262] | Reward: -1.4240397560087403 | State: [-1.326198   1.5405319  3.1730087] | Terminated: False | Episode Length: 1.0600000000000007\n",
            "Action: [-0.4    0.262] | Reward: -1.439013731722973 | State: [-1.3254142  1.5436379  3.1756265] | Terminated: False | Episode Length: 1.0700000000000007\n",
            "Action: [-0.4    0.262] | Reward: -1.4540148595671392 | State: [-1.3246285  1.5467418  3.1782446] | Terminated: False | Episode Length: 1.0800000000000007\n",
            "Action: [-0.4    0.262] | Reward: -1.4690430895816027 | State: [-1.3238409  1.5498434  3.1808627] | Terminated: False | Episode Length: 1.0900000000000007\n",
            "Action: [-0.4    0.262] | Reward: -1.484098371648399 | State: [-1.3230512  1.5529429  3.1834805] | Terminated: False | Episode Length: 1.1000000000000008\n",
            "Action: [-0.4    0.262] | Reward: -1.4991806554919576 | State: [-1.3222597  1.5560402  3.1860986] | Terminated: False | Episode Length: 1.1100000000000008\n",
            "Action: [-0.4    0.262] | Reward: -1.514289890679837 | State: [-1.3214662  1.5591352  3.1887167] | Terminated: False | Episode Length: 1.1200000000000008\n",
            "Action: [-0.4    0.262] | Reward: -1.5294260266234754 | State: [-1.320671   1.562228   3.1913345] | Terminated: False | Episode Length: 1.1300000000000008\n",
            "Action: [-0.4    0.262] | Reward: -1.544589012578954 | State: [-1.3198737  1.5653185  3.1939526] | Terminated: False | Episode Length: 1.1400000000000008\n",
            "Action: [-0.4    0.262] | Reward: -1.5597787976477748 | State: [-1.3190746  1.5684068  3.1965706] | Terminated: False | Episode Length: 1.1500000000000008\n",
            "Action: [-0.4    0.262] | Reward: -1.5749953307776514 | State: [-1.3182737  1.5714929  3.1991885] | Terminated: False | Episode Length: 1.1600000000000008\n",
            "Action: [-0.4    0.262] | Reward: -1.590238560763315 | State: [-1.3174708  1.5745767  3.2018065] | Terminated: False | Episode Length: 1.1700000000000008\n",
            "Action: [-0.4    0.262] | Reward: -1.6055084362473337 | State: [-1.3166662  1.5776582  3.2044246] | Terminated: False | Episode Length: 1.1800000000000008\n",
            "Action: [-0.4    0.262] | Reward: -1.6208049057209462 | State: [-1.3158598  1.5807375  3.2070425] | Terminated: False | Episode Length: 1.1900000000000008\n",
            "Action: [-0.4    0.262] | Reward: -1.6361279175249084 | State: [-1.3150516  1.5838145  3.2096605] | Terminated: False | Episode Length: 1.2000000000000008\n",
            "Action: [-0.4    0.262] | Reward: -1.6514774198503557 | State: [-1.3142414  1.5868893  3.2122786] | Terminated: False | Episode Length: 1.2100000000000009\n",
            "Action: [-0.4    0.262] | Reward: -1.6668533607396783 | State: [-1.3134297  1.5899616  3.2148964] | Terminated: False | Episode Length: 1.2200000000000009\n",
            "Action: [-0.4    0.262] | Reward: -1.6822556880874109 | State: [-1.3126161  1.5930319  3.2175145] | Terminated: False | Episode Length: 1.2300000000000009\n",
            "Action: [-0.4    0.262] | Reward: -1.6976843496411362 | State: [-1.3118008  1.5960997  3.2201324] | Terminated: False | Episode Length: 1.2400000000000009\n",
            "Action: [-0.4    0.262] | Reward: -1.7131392930024028 | State: [-1.3109838  1.5991653  3.2227504] | Terminated: False | Episode Length: 1.2500000000000009\n",
            "Action: [-0.4    0.262] | Reward: -1.7286204656276574 | State: [-1.310165   1.6022285  3.2253685] | Terminated: False | Episode Length: 1.260000000000001\n",
            "Action: [-0.4    0.262] | Reward: -1.7441278148291908 | State: [-1.3093445  1.6052895  3.2279863] | Terminated: False | Episode Length: 1.270000000000001\n",
            "Action: [-0.4    0.262] | Reward: -1.7596612877760978 | State: [-1.3085225  1.6083481  3.2306044] | Terminated: False | Episode Length: 1.280000000000001\n",
            "Action: [-0.4    0.262] | Reward: -1.7752208314952522 | State: [-1.3076986  1.6114044  3.2332225] | Terminated: False | Episode Length: 1.290000000000001\n",
            "Action: [-0.4    0.262] | Reward: -1.7908063928722955 | State: [-1.3068732  1.6144584  3.2358403] | Terminated: False | Episode Length: 1.300000000000001\n",
            "Action: [-0.4    0.262] | Reward: -1.8064179186526386 | State: [-1.3060461  1.6175101  3.2384584] | Terminated: False | Episode Length: 1.310000000000001\n",
            "Action: [-0.4    0.262] | Reward: -1.8220553554424799 | State: [-1.3052174  1.6205593  3.2410765] | Terminated: False | Episode Length: 1.320000000000001\n",
            "Action: [-0.4    0.262] | Reward: -1.8377186497098361 | State: [-1.304387   1.6236063  3.2436943] | Terminated: False | Episode Length: 1.330000000000001\n",
            "Action: [-0.4    0.262] | Reward: -1.8534077477855875 | State: [-1.303555   1.6266509  3.2463124] | Terminated: False | Episode Length: 1.340000000000001\n",
            "Action: [-0.4    0.262] | Reward: -1.8691225958645377 | State: [-1.3027215  1.6296932  3.2489305] | Terminated: False | Episode Length: 1.350000000000001\n",
            "Action: [-0.4    0.262] | Reward: -1.8848631400064868 | State: [-1.3018864  1.6327331  3.2515483] | Terminated: False | Episode Length: 1.360000000000001\n",
            "Action: [-0.4    0.262] | Reward: -1.9006293261373206 | State: [-1.3010497  1.6357706  3.2541664] | Terminated: False | Episode Length: 1.370000000000001\n",
            "Action: [-0.4    0.262] | Reward: -1.9164211000501115 | State: [-1.3002115  1.6388057  3.2567844] | Terminated: False | Episode Length: 1.380000000000001\n",
            "Action: [-0.4    0.262] | Reward: -1.9322384074062355 | State: [-1.2993718  1.6418386  3.2594023] | Terminated: False | Episode Length: 1.390000000000001\n",
            "Action: [-0.4   -0.524] | Reward: -1.948081193736503 | State: [-1.2985306  1.6448689  3.2541664] | Terminated: False | Episode Length: 1.400000000000001\n",
            "Action: [-0.4   -0.524] | Reward: -1.9639493985992138 | State: [-1.2976866  1.6478969  3.2489305] | Terminated: False | Episode Length: 1.410000000000001\n",
            "Action: [-0.4   -0.524] | Reward: -1.9798429614493505 | State: [-1.2968397  1.6509225  3.2436943] | Terminated: False | Episode Length: 1.420000000000001\n",
            "Action: [-0.4    0.262] | Reward: -1.9957618216422577 | State: [-1.2959901  1.6539457  3.2463124] | Terminated: False | Episode Length: 1.430000000000001\n",
            "Action: [-0.4   -0.524] | Reward: -2.0117059235979315 | State: [-1.2951391  1.6569664  3.2410765] | Terminated: False | Episode Length: 1.440000000000001\n",
            "Action: [-0.4   -0.524] | Reward: -2.02767520627411 | State: [-1.2942853  1.6599848  3.2358403] | Terminated: False | Episode Length: 1.450000000000001\n",
            "Action: [-0.4   -0.524] | Reward: -2.043669608535569 | State: [-1.2934288  1.6630008  3.2306044] | Terminated: False | Episode Length: 1.460000000000001\n",
            "Action: [-0.4    0.262] | Reward: -2.0596890691579706 | State: [-1.2925698  1.6660143  3.2332225] | Terminated: False | Episode Length: 1.470000000000001\n",
            "Action: [-0.4   -0.524] | Reward: -2.0757335314449197 | State: [-1.2917091  1.6690254  3.2279863] | Terminated: False | Episode Length: 1.480000000000001\n",
            "Action: [-0.4   -0.524] | Reward: -2.091802933781834 | State: [-1.2908459  1.672034   3.2227504] | Terminated: False | Episode Length: 1.490000000000001\n",
            "Action: [-0.4   -0.524] | Reward: -2.107897214472061 | State: [-1.28998    1.6750401  3.2175145] | Terminated: False | Episode Length: 1.500000000000001\n",
            "Action: [-0.4   -0.524] | Reward: -2.124016311740896 | State: [-1.2891117  1.678044   3.2122786] | Terminated: False | Episode Length: 1.5100000000000011\n",
            "Action: [-0.4   -0.524] | Reward: -2.1401601637396515 | State: [-1.2882409  1.6810452  3.2070425] | Terminated: False | Episode Length: 1.5200000000000011\n",
            "Action: [-0.4   -0.524] | Reward: -2.1563287085497818 | State: [-1.2873678  1.684044   3.2018065] | Terminated: False | Episode Length: 1.5300000000000011\n",
            "Action: [-0.4   -0.524] | Reward: -2.1725218841870544 | State: [-1.2864922  1.6870403  3.1965706] | Terminated: False | Episode Length: 1.5400000000000011\n",
            "Action: [-0.4   -0.524] | Reward: -2.1887396286057785 | State: [-1.2856143  1.6900342  3.1913345] | Terminated: False | Episode Length: 1.5500000000000012\n",
            "Action: [-0.4   -0.524] | Reward: -2.204981879703082 | State: [-1.2847341  1.6930255  3.1860986] | Terminated: False | Episode Length: 1.5600000000000012\n",
            "Action: [-0.4   -0.524] | Reward: -2.22124857532324 | State: [-1.2838517  1.6960144  3.1808627] | Terminated: False | Episode Length: 1.5700000000000012\n",
            "Action: [-0.4   -0.524] | Reward: -2.2375396532620537 | State: [-1.2829671  1.6990007  3.1756265] | Terminated: False | Episode Length: 1.5800000000000012\n",
            "Action: [-0.4   -0.524] | Reward: -2.253855051271284 | State: [-1.2820803  1.7019845  3.1703906] | Terminated: False | Episode Length: 1.5900000000000012\n",
            "Action: [-0.4    0.524] | Reward: -2.270194707063128 | State: [-1.2811913  1.7049658  3.1756265] | Terminated: False | Episode Length: 1.6000000000000012\n",
            "Action: [-0.4   -0.524] | Reward: -2.286558560516436 | State: [-1.2803009  1.7079448  3.1703906] | Terminated: False | Episode Length: 1.6100000000000012\n",
            "Action: [-0.4   -0.524] | Reward: -2.302946548899793 | State: [-1.2794082  1.7109209  3.1651547] | Terminated: False | Episode Length: 1.6200000000000012\n",
            "Action: [-0.4    0.524] | Reward: -2.3193586094489205 | State: [-1.2785134  1.7138947  3.1703906] | Terminated: False | Episode Length: 1.6300000000000012\n",
            "Action: [-0.4   -0.524] | Reward: -2.335794681207993 | State: [-1.2776171  1.7168659  3.1651547] | Terminated: False | Episode Length: 1.6400000000000012\n",
            "Action: [-0.4   -0.524] | Reward: -2.352254700970701 | State: [-1.2767187  1.7198346  3.1599185] | Terminated: False | Episode Length: 1.6500000000000012\n",
            "Action: [-0.4    0.524] | Reward: -2.3687386055047592 | State: [-1.2758183  1.7228007  3.1651547] | Terminated: False | Episode Length: 1.6600000000000013\n",
            "Action: [-0.4   -0.524] | Reward: -2.3852463330130047 | State: [-1.2749163  1.7257643  3.1599185] | Terminated: False | Episode Length: 1.6700000000000013\n",
            "Action: [-0.4   -0.524] | Reward: -2.4017778198228674 | State: [-1.2740121  1.7287253  3.1546826] | Terminated: False | Episode Length: 1.6800000000000013\n",
            "Action: [-0.4    0.524] | Reward: -2.418333002242887 | State: [-1.2731061  1.7316837  3.1599185] | Terminated: False | Episode Length: 1.6900000000000013\n",
            "Action: [-0.4   -0.524] | Reward: -2.434911817627943 | State: [-1.2721983  1.7346395  3.1546826] | Terminated: False | Episode Length: 1.7000000000000013\n",
            "Action: [-0.4    0.524] | Reward: -2.4515142018482012 | State: [-1.2712886  1.7375928  3.1599185] | Terminated: False | Episode Length: 1.7100000000000013\n",
            "Action: [-0.4   -0.524] | Reward: -2.4681400918361627 | State: [-1.2703772  1.7405435  3.1546826] | Terminated: False | Episode Length: 1.7200000000000013\n",
            "Action: [-0.4   -0.524] | Reward: -2.484789423023214 | State: [-1.2694638  1.7434916  3.1494467] | Terminated: False | Episode Length: 1.7300000000000013\n",
            "Action: [-0.4    0.524] | Reward: -2.5014621308316105 | State: [-1.2685486  1.7464371  3.1546826] | Terminated: False | Episode Length: 1.7400000000000013\n",
            "Action: [-0.4   -0.524] | Reward: -2.5181581513361864 | State: [-1.2676315  1.74938    3.1494467] | Terminated: False | Episode Length: 1.7500000000000013\n",
            "Action: [-0.4   -0.524] | Reward: -2.5348774195225676 | State: [-1.2667127  1.7523203  3.1442106] | Terminated: False | Episode Length: 1.7600000000000013\n",
            "Action: [-0.4    0.524] | Reward: -2.551619870374818 | State: [-1.265792   1.7552578  3.1494467] | Terminated: False | Episode Length: 1.7700000000000014\n",
            "Action: [-0.4   -0.524] | Reward: -2.5683854391036074 | State: [-1.2648695  1.7581929  3.1442106] | Terminated: False | Episode Length: 1.7800000000000014\n",
            "Action: [-0.4   -0.524] | Reward: -2.585174060258686 | State: [-1.2639451  1.7611253  3.1389747] | Terminated: False | Episode Length: 1.7900000000000014\n",
            "Action: [-0.4   -0.524] | Reward: -2.601985668396007 | State: [-1.2630191  1.764055   3.1337388] | Terminated: False | Episode Length: 1.8000000000000014\n",
            "Action: [-0.4    0.262] | Reward: -2.6188201980829238 | State: [-1.2620912  1.7669822  3.1363566] | Terminated: False | Episode Length: 1.8100000000000014\n",
            "Action: [-0.4   -0.524] | Reward: -2.6356775833030746 | State: [-1.2611614  1.7699066  3.1311207] | Terminated: False | Episode Length: 1.8200000000000014\n",
            "Action: [-0.4    0.262] | Reward: -2.652557758310741 | State: [-1.2602301  1.7728285  3.1337388] | Terminated: False | Episode Length: 1.8300000000000014\n",
            "Action: [-0.4    0.262] | Reward: -2.6694606566000996 | State: [-1.2592969  1.7757475  3.1363566] | Terminated: False | Episode Length: 1.8400000000000014\n",
            "Action: [-0.4   -0.524] | Reward: -2.6863862115041273 | State: [-1.2583618  1.778664   3.1311207] | Terminated: False | Episode Length: 1.8500000000000014\n",
            "Action: [-0.4    0.262] | Reward: -2.703334356635487 | State: [-1.2574251  1.7815778  3.1337388] | Terminated: False | Episode Length: 1.8600000000000014\n",
            "Action: [-0.4   -0.524] | Reward: -2.720305024836456 | State: [-1.2564865  1.7844889  3.1285026] | Terminated: False | Episode Length: 1.8700000000000014\n",
            "Action: [-0.4    0.262] | Reward: -2.7372981494121347 | State: [-1.2555463  1.7873974  3.1311207] | Terminated: False | Episode Length: 1.8800000000000014\n",
            "Action: [-0.4   -0.524] | Reward: -2.7543136627132356 | State: [-1.2546042  1.7903031  3.1258848] | Terminated: False | Episode Length: 1.8900000000000015\n",
            "Action: [-0.4  0. ] | Reward: -2.771351497740871 | State: [-1.2536606  1.7932062  3.1258848] | Terminated: False | Episode Length: 1.9000000000000015\n",
            "Action: [-0.4  0. ] | Reward: -2.7884115866857555 | State: [-1.2527151  1.7961065  3.1258848] | Terminated: False | Episode Length: 1.9100000000000015\n",
            "Action: [-0.4  0. ] | Reward: -2.8054938615225367 | State: [-1.251768   1.7990041  3.1258848] | Terminated: False | Episode Length: 1.9200000000000015\n",
            "Action: [-0.4  0. ] | Reward: -2.8225982540097982 | State: [-1.250819   1.8018991  3.1258848] | Terminated: False | Episode Length: 1.9300000000000015\n",
            "Action: [-0.4  0. ] | Reward: -2.839724695690072 | State: [-1.2498683  1.8047912  3.1258848] | Terminated: False | Episode Length: 1.9400000000000015\n",
            "Action: [-0.4  0. ] | Reward: -2.856873117889852 | State: [-1.2489159  1.8076807  3.1258848] | Terminated: False | Episode Length: 1.9500000000000015\n",
            "Action: [-0.4  0. ] | Reward: -2.874043451719612 | State: [-1.2479618  1.8105674  3.1258848] | Terminated: False | Episode Length: 1.9600000000000015\n",
            "Action: [-0.4  0. ] | Reward: -2.89123562807383 | State: [-1.2470058  1.8134514  3.1258848] | Terminated: False | Episode Length: 1.9700000000000015\n",
            "Action: [-0.4  0. ] | Reward: -2.908449577631016 | State: [-1.2460482  1.8163326  3.1258848] | Terminated: False | Episode Length: 1.9800000000000015\n",
            "Action: [-0.4  0. ] | Reward: -2.9256852308537438 | State: [-1.2450888  1.8192111  3.1258848] | Terminated: False | Episode Length: 1.9900000000000015\n",
            "Action: [-0.4  0. ] | Reward: -2.9429425179886874 | State: [-1.2441278  1.8220868  3.1258848] | Terminated: False | Episode Length: 2.0000000000000013\n",
            "Action: [-0.4  0. ] | Reward: -2.960221369066663 | State: [-1.2431649  1.8249598  3.1258848] | Terminated: False | Episode Length: 2.010000000000001\n",
            "Action: [-0.4  0. ] | Reward: -2.977521713902674 | State: [-1.2422004  1.82783    3.1258848] | Terminated: False | Episode Length: 2.020000000000001\n",
            "Action: [-0.4  0. ] | Reward: -2.9948434820959617 | State: [-1.2412342  1.8306974  3.1258848] | Terminated: False | Episode Length: 2.0300000000000007\n",
            "Action: [-0.4  0. ] | Reward: -3.012186603030059 | State: [-1.2402662  1.833562   3.1258848] | Terminated: False | Episode Length: 2.0400000000000005\n",
            "Action: [-0.4  0. ] | Reward: -3.029551005872851 | State: [-1.2392966  1.8364239  3.1258848] | Terminated: False | Episode Length: 2.0500000000000003\n",
            "Action: [-0.4  0. ] | Reward: -3.046936619576639 | State: [-1.2383252  1.8392829  3.1258848] | Terminated: False | Episode Length: 2.06\n",
            "Action: [-0.4  0. ] | Reward: -3.0643433728782066 | State: [-1.2373523  1.8421391  3.1258848] | Terminated: False | Episode Length: 2.07\n",
            "Action: [-0.4  0. ] | Reward: -3.081771194298896 | State: [-1.2363775  1.8449925  3.1258848] | Terminated: False | Episode Length: 2.0799999999999996\n",
            "Action: [-0.4  0. ] | Reward: -3.099220012144683 | State: [-1.235401   1.847843   3.1258848] | Terminated: False | Episode Length: 2.0899999999999994\n",
            "Action: [-0.4  0. ] | Reward: -3.1166897545062606 | State: [-1.2344229  1.8506908  3.1258848] | Terminated: False | Episode Length: 2.099999999999999\n",
            "Action: [-0.4  0. ] | Reward: -3.1341803492591254 | State: [-1.233443   1.8535359  3.1258848] | Terminated: False | Episode Length: 2.109999999999999\n",
            "Action: [-0.4  0. ] | Reward: -3.1516917240636695 | State: [-1.2324616  1.856378   3.1258848] | Terminated: False | Episode Length: 2.1199999999999988\n",
            "Action: [-0.4  0. ] | Reward: -3.169223806365276 | State: [-1.2314785  1.8592173  3.1258848] | Terminated: False | Episode Length: 2.1299999999999986\n",
            "Action: [-0.4  0. ] | Reward: -3.1867765233944207 | State: [-1.2304935  1.8620536  3.1258848] | Terminated: False | Episode Length: 2.1399999999999983\n",
            "Action: [-0.4    0.262] | Reward: -3.2043498021667776 | State: [-1.2295071  1.8648872  3.1285026] | Terminated: False | Episode Length: 2.149999999999998\n",
            "Action: [-0.4    0.262] | Reward: -3.2219435690975504 | State: [-1.2285188  1.867718   3.1311207] | Terminated: False | Episode Length: 2.159999999999998\n",
            "Action: [-0.4    0.262] | Reward: -3.2395577504517674 | State: [-1.2275288  1.8705459  3.1337388] | Terminated: False | Episode Length: 2.1699999999999977\n",
            "Action: [-0.4    0.262] | Reward: -3.257192272345896 | State: [-1.2265371  1.8733709  3.1363566] | Terminated: False | Episode Length: 2.1799999999999975\n",
            "Action: [-0.4    0.262] | Reward: -3.274847060749473 | State: [-1.2255439  1.8761929  3.1389747] | Terminated: False | Episode Length: 2.1899999999999973\n",
            "Action: [-0.4    0.262] | Reward: -3.2925220414867544 | State: [-1.2245488  1.8790122  3.1415927] | Terminated: False | Episode Length: 2.199999999999997\n",
            "Action: [-0.4    0.262] | Reward: -3.3102171402383824 | State: [-1.2235521  1.8818285  3.1442106] | Terminated: False | Episode Length: 2.209999999999997\n",
            "Action: [-0.4    0.262] | Reward: -3.3279322825430677 | State: [-1.2225537  1.884642   3.1468287] | Terminated: False | Episode Length: 2.2199999999999966\n",
            "Action: [-0.4    0.262] | Reward: -3.3456673937992902 | State: [-1.2215538  1.8874525  3.1494467] | Terminated: False | Episode Length: 2.2299999999999964\n",
            "Action: [-0.4    0.262] | Reward: -3.363422399267017 | State: [-1.2205522  1.8902601  3.1520646] | Terminated: False | Episode Length: 2.239999999999996\n",
            "Action: [-0.4    0.262] | Reward: -3.3811972240694375 | State: [-1.2195491  1.8930649  3.1546826] | Terminated: False | Episode Length: 2.249999999999996\n",
            "Action: [-0.4    0.262] | Reward: -3.3989917931947145 | State: [-1.2185444  1.8958666  3.1573007] | Terminated: False | Episode Length: 2.259999999999996\n",
            "Action: [-0.4    0.262] | Reward: -3.416806031497754 | State: [-1.217538   1.8986655  3.1599185] | Terminated: False | Episode Length: 2.2699999999999956\n",
            "Action: [-0.4    0.262] | Reward: -3.4346398637019906 | State: [-1.2165302  1.9014615  3.1625366] | Terminated: False | Episode Length: 2.2799999999999954\n",
            "Action: [-0.4    0.262] | Reward: -3.4524932144011897 | State: [-1.2155207  1.9042544  3.1651547] | Terminated: False | Episode Length: 2.289999999999995\n",
            "Action: [-0.4    0.262] | Reward: -3.4703660080612684 | State: [-1.2145098  1.9070445  3.1677725] | Terminated: False | Episode Length: 2.299999999999995\n",
            "Action: [-0.4    0.262] | Reward: -3.4882581690221315 | State: [-1.2134974  1.9098316  3.1703906] | Terminated: False | Episode Length: 2.3099999999999947\n",
            "Action: [-0.4    0.262] | Reward: -3.506169621499524 | State: [-1.2124835  1.9126158  3.1730087] | Terminated: False | Episode Length: 2.3199999999999945\n",
            "Action: [-0.4    0.262] | Reward: -3.5241002895869036 | State: [-1.2114681  1.915397   3.1756265] | Terminated: False | Episode Length: 2.3299999999999943\n",
            "Action: [-0.4    0.262] | Reward: -3.542050097257325 | State: [-1.2104511  1.9181752  3.1782446] | Terminated: False | Episode Length: 2.339999999999994\n",
            "Action: [-0.4    0.262] | Reward: -3.560018968365345 | State: [-1.2094328  1.9209504  3.1808627] | Terminated: False | Episode Length: 2.349999999999994\n",
            "Action: [-0.4    0.262] | Reward: -3.578006826648942 | State: [-1.2084131  1.9237227  3.1834805] | Terminated: False | Episode Length: 2.3599999999999937\n",
            "Action: [-0.4   -0.524] | Reward: -3.5960135957314523 | State: [-1.207392   1.926492   3.1782446] | Terminated: False | Episode Length: 2.3699999999999934\n",
            "Action: [-0.4    0.262] | Reward: -3.6140391954286026 | State: [-1.2063688  1.9292583  3.1808627] | Terminated: False | Episode Length: 2.3799999999999932\n",
            "Action: [-0.4   -0.524] | Reward: -3.6320835488650096 | State: [-1.2053443  1.9320216  3.1756265] | Terminated: False | Episode Length: 2.389999999999993\n",
            "Action: [-0.4    0.262] | Reward: -3.650146575557634 | State: [-1.2043178  1.9347819  3.1782446] | Terminated: False | Episode Length: 2.399999999999993\n",
            "Action: [-0.4   -0.524] | Reward: -3.6682281981322036 | State: [-1.20329    1.9375391  3.1730087] | Terminated: False | Episode Length: 2.4099999999999926\n",
            "Action: [-0.4    0.262] | Reward: -3.6863283358118384 | State: [-1.2022601  1.9402934  3.1756265] | Terminated: False | Episode Length: 2.4199999999999924\n",
            "Action: [-0.4   -0.524] | Reward: -3.7044469107232474 | State: [-1.201229   1.9430447  3.1703906] | Terminated: False | Episode Length: 2.429999999999992\n",
            "Action: [-0.4    0.262] | Reward: -3.722583841800728 | State: [-1.2001959  1.9457929  3.1730087] | Terminated: False | Episode Length: 2.439999999999992\n",
            "Action: [-0.4   -0.524] | Reward: -3.7407390506718796 | State: [-1.1991614  1.9485381  3.1677725] | Terminated: False | Episode Length: 2.4499999999999917\n",
            "Action: [-0.4    0.262] | Reward: -3.758912455987291 | State: [-1.1981251  1.9512801  3.1703906] | Terminated: False | Episode Length: 2.4599999999999915\n",
            "Action: [-0.4   -0.524] | Reward: -3.7771039788753984 | State: [-1.1970874  1.9540192  3.1651547] | Terminated: False | Episode Length: 2.4699999999999913\n",
            "Action: [-0.4    0.262] | Reward: -3.795313537708289 | State: [-1.1960478  1.9567553  3.1677725] | Terminated: False | Episode Length: 2.479999999999991\n",
            "Action: [-0.4   -0.524] | Reward: -3.813541053115223 | State: [-1.1950068  1.9594883  3.1625366] | Terminated: False | Episode Length: 2.489999999999991\n",
            "Action: [-0.4    0.262] | Reward: -3.831786443195088 | State: [-1.1939641  1.9622182  3.1651547] | Terminated: False | Episode Length: 2.4999999999999907\n",
            "Action: [-0.4   -0.524] | Reward: -3.8500496280779926 | State: [-1.1929199  1.964945   3.1599185] | Terminated: False | Episode Length: 2.5099999999999905\n",
            "Action: [-0.4    0.262] | Reward: -3.8683305255950207 | State: [-1.1918739  1.9676687  3.1625366] | Terminated: False | Episode Length: 2.5199999999999902\n",
            "Action: [-0.4   -0.524] | Reward: -3.886629055377194 | State: [-1.1908265  1.9703894  3.1573007] | Terminated: False | Episode Length: 2.52999999999999\n",
            "Action: [-0.4    0.262] | Reward: -3.9049451349932833 | State: [-1.1897775  1.9731069  3.1599185] | Terminated: False | Episode Length: 2.53999999999999\n",
            "Action: [-0.4   -0.524] | Reward: -3.9232786835753273 | State: [-1.1887269  1.9758214  3.1546826] | Terminated: False | Episode Length: 2.5499999999999896\n",
            "Action: [-0.4    0.262] | Reward: -3.9416296184353676 | State: [-1.1876746  1.9785328  3.1573007] | Terminated: False | Episode Length: 2.5599999999999894\n",
            "Action: [-0.4   -0.524] | Reward: -3.9599978582066027 | State: [-1.186621   1.981241   3.1520646] | Terminated: False | Episode Length: 2.569999999999989\n",
            "Action: [-0.4    0.262] | Reward: -3.9783833199500243 | State: [-1.1855656  1.9839461  3.1546826] | Terminated: False | Episode Length: 2.579999999999989\n",
            "Action: [-0.4   -0.524] | Reward: -3.9967859218001727 | State: [-1.1845088  1.9866481  3.1494467] | Terminated: False | Episode Length: 2.5899999999999888\n",
            "Action: [-0.4    0.262] | Reward: -4.015205580572762 | State: [-1.1834503  1.989347   3.1520646] | Terminated: False | Episode Length: 2.5999999999999885\n",
            "Action: [-0.4   -0.524] | Reward: -4.033642213903897 | State: [-1.1823903  1.9920428  3.1468287] | Terminated: False | Episode Length: 2.6099999999999883\n",
            "Action: [-0.4    0.262] | Reward: -4.052095738369881 | State: [-1.1813289  1.9947354  3.1494467] | Terminated: False | Episode Length: 2.619999999999988\n",
            "Action: [-0.4   -0.524] | Reward: -4.070566071108643 | State: [-1.1802659  1.9974248  3.1442106] | Terminated: False | Episode Length: 2.629999999999988\n",
            "Action: [-0.4    0.262] | Reward: -4.089053128463038 | State: [-1.1792014  2.000111   3.1468287] | Terminated: False | Episode Length: 2.6399999999999877\n",
            "Action: [-0.4   -0.524] | Reward: -4.10755682707312 | State: [-1.1781354  2.0027943  3.1415927] | Terminated: False | Episode Length: 2.6499999999999875\n",
            "Action: [-0.4   -0.524] | Reward: -4.126077083054349 | State: [-1.1770678  2.0054743  3.1363566] | Terminated: False | Episode Length: 2.6599999999999873\n",
            "Action: [-0.4   -0.524] | Reward: -4.1446138126886565 | State: [-1.1759988  2.008151   3.1311207] | Terminated: False | Episode Length: 2.669999999999987\n",
            "Action: [-0.4   -0.262] | Reward: -4.163166932432092 | State: [-1.1749283  2.0108247  3.1285026] | Terminated: False | Episode Length: 2.679999999999987\n",
            "Action: [-0.4   -0.262] | Reward: -4.181736358405988 | State: [-1.1738564  2.0134952  3.1258848] | Terminated: False | Episode Length: 2.6899999999999866\n",
            "Action: [-0.4   -0.262] | Reward: -4.200322006630645 | State: [-1.1727831  2.0161624  3.1232667] | Terminated: False | Episode Length: 2.6999999999999864\n",
            "Action: [-0.4   -0.262] | Reward: -4.218923793027577 | State: [-1.1717085  2.0188265  3.1206486] | Terminated: False | Episode Length: 2.709999999999986\n",
            "Action: [-0.4  0. ] | Reward: -4.2375416334217855 | State: [-1.1706324  2.0214875  3.1206486] | Terminated: False | Episode Length: 2.719999999999986\n",
            "Action: [-0.4  0. ] | Reward: -4.256175442729069 | State: [-1.1695547  2.0241451  3.1206486] | Terminated: False | Episode Length: 2.7299999999999858\n",
            "Action: [-0.4  0. ] | Reward: -4.274825135665367 | State: [-1.1684757  2.0267994  3.1206486] | Terminated: False | Episode Length: 2.7399999999999856\n",
            "Action: [-0.4  0. ] | Reward: -4.293490626747166 | State: [-1.1673951  2.0294507  3.1206486] | Terminated: False | Episode Length: 2.7499999999999853\n",
            "Action: [-0.4  0. ] | Reward: -4.312171830291912 | State: [-1.1663132  2.0320988  3.1206486] | Terminated: False | Episode Length: 2.759999999999985\n",
            "Action: [-0.4  0. ] | Reward: -4.330868660418422 | State: [-1.1652297  2.0347435  3.1206486] | Terminated: False | Episode Length: 2.769999999999985\n",
            "Action: [-0.4  0. ] | Reward: -4.349581031047309 | State: [-1.1641448  2.037385   3.1206486] | Terminated: False | Episode Length: 2.7799999999999847\n",
            "Action: [-0.4  0. ] | Reward: -4.368308855901408 | State: [-1.1630584  2.0400233  3.1206486] | Terminated: False | Episode Length: 2.7899999999999845\n",
            "Action: [-0.4    0.262] | Reward: -4.387052048506205 | State: [-1.1619706  2.0426583  3.1232667] | Terminated: False | Episode Length: 2.7999999999999843\n",
            "Action: [-0.4    0.262] | Reward: -4.40581052144106 | State: [-1.1608812  2.04529    3.1258848] | Terminated: False | Episode Length: 2.809999999999984\n",
            "Action: [-0.4    0.262] | Reward: -4.424584187178789 | State: [-1.1597903  2.0479186  3.1285026] | Terminated: False | Episode Length: 2.819999999999984\n",
            "Action: [-0.4    0.262] | Reward: -4.443372958087975 | State: [-1.1586978  2.0505438  3.1311207] | Terminated: False | Episode Length: 2.8299999999999836\n",
            "Action: [-0.4    0.262] | Reward: -4.462176746435297 | State: [-1.157604   2.0531657  3.1337388] | Terminated: False | Episode Length: 2.8399999999999834\n",
            "Action: [-0.4    0.262] | Reward: -4.480995464387876 | State: [-1.1565086  2.0557845  3.1363566] | Terminated: False | Episode Length: 2.849999999999983\n",
            "Action: [-0.4    0.262] | Reward: -4.4998290240156384 | State: [-1.1554117  2.0584     3.1389747] | Terminated: False | Episode Length: 2.859999999999983\n",
            "Action: [-0.4    0.262] | Reward: -4.5186773372937 | State: [-1.1543133  2.061012   3.1415927] | Terminated: False | Episode Length: 2.869999999999983\n",
            "Action: [-0.4    0.262] | Reward: -4.537540316104758 | State: [-1.1532136  2.0636208  3.1442106] | Terminated: False | Episode Length: 2.8799999999999826\n",
            "Action: [-0.4    0.262] | Reward: -4.556417872241512 | State: [-1.1521125  2.0662262  3.1468287] | Terminated: False | Episode Length: 2.8899999999999824\n",
            "Action: [-0.4    0.262] | Reward: -4.575309917409089 | State: [-1.1510099  2.0688286  3.1494467] | Terminated: False | Episode Length: 2.899999999999982\n",
            "Action: [-0.4    0.262] | Reward: -4.594216363227499 | State: [-1.1499059  2.0714273  3.1520646] | Terminated: False | Episode Length: 2.909999999999982\n",
            "Action: [-0.4    0.262] | Reward: -4.613137121234094 | State: [-1.1488006  2.074023   3.1546826] | Terminated: False | Episode Length: 2.9199999999999817\n",
            "Action: [-0.4    0.262] | Reward: -4.632072102886053 | State: [-1.1476939  2.076615   3.1573007] | Terminated: False | Episode Length: 2.9299999999999815\n",
            "Action: [-0.4    0.262] | Reward: -4.651021219562881 | State: [-1.1465858  2.079204   3.1599185] | Terminated: False | Episode Length: 2.9399999999999813\n",
            "Action: [-0.4  0. ] | Reward: -4.669984382568919 | State: [-1.1454765  2.0817895  3.1599185] | Terminated: False | Episode Length: 2.949999999999981\n",
            "Action: [-0.4  0. ] | Reward: -4.688961502328254 | State: [-1.1443658  2.0843718  3.1599185] | Terminated: False | Episode Length: 2.959999999999981\n",
            "Action: [-0.4  0. ] | Reward: -4.707952489075749 | State: [-1.1432536  2.0869505  3.1599185] | Terminated: False | Episode Length: 2.9699999999999807\n",
            "Action: [-0.4  0. ] | Reward: -4.726957252857577 | State: [-1.14214    2.0895262  3.1599185] | Terminated: False | Episode Length: 2.9799999999999804\n",
            "Action: [-0.4  0. ] | Reward: -4.745975703531745 | State: [-1.1410251  2.0920982  3.1599185] | Terminated: False | Episode Length: 2.9899999999999802\n",
            "Action: [-0.4  0. ] | Reward: -4.765007750768637 | State: [-1.1399088  2.094667   3.1599185] | Terminated: False | Episode Length: 2.99999999999998\n",
            "Action: [-0.4  0. ] | Reward: -4.784053304051554 | State: [-1.1387911  2.0972323  3.1599185] | Terminated: False | Episode Length: 3.00999999999998\n",
            "Action: [-0.4  0. ] | Reward: -4.803112272677262 | State: [-1.137672   2.0997944  3.1599185] | Terminated: False | Episode Length: 3.0199999999999796\n",
            "Action: [-0.4  0. ] | Reward: -4.822184565756545 | State: [-1.1365515  2.1023529  3.1599185] | Terminated: False | Episode Length: 3.0299999999999794\n",
            "Action: [-0.4    0.262] | Reward: -4.841270092214764 | State: [-1.1354296  2.104908   3.1625366] | Terminated: False | Episode Length: 3.039999999999979\n",
            "Action: [-0.4    0.262] | Reward: -4.860368761636301 | State: [-1.1343064  2.1074598  3.1651547] | Terminated: False | Episode Length: 3.049999999999979\n",
            "Action: [-0.4    0.262] | Reward: -4.8794804835455095 | State: [-1.133182   2.1100082  3.1677725] | Terminated: False | Episode Length: 3.0599999999999787\n",
            "Action: [-0.4    0.262] | Reward: -4.898605167409374 | State: [-1.1320564  2.1125534  3.1703906] | Terminated: False | Episode Length: 3.0699999999999785\n",
            "Action: [-0.4    0.262] | Reward: -4.917742722640187 | State: [-1.1309295  2.115095   3.1730087] | Terminated: False | Episode Length: 3.0799999999999783\n",
            "Action: [-0.4    0.262] | Reward: -4.936893058598237 | State: [-1.1298014  2.1176329  3.1756265] | Terminated: False | Episode Length: 3.089999999999978\n",
            "Action: [-0.4    0.262] | Reward: -4.956056084594516 | State: [-1.1286721  2.1201677  3.1782446] | Terminated: False | Episode Length: 3.099999999999978\n",
            "Action: [-0.4    0.262] | Reward: -4.975231709893444 | State: [-1.1275417  2.122699   3.1808627] | Terminated: False | Episode Length: 3.1099999999999777\n",
            "Action: [-0.4  0. ] | Reward: -4.994419843715605 | State: [-1.12641    2.1252267  3.1808627] | Terminated: False | Episode Length: 3.1199999999999775\n",
            "Action: [-0.4    0.262] | Reward: -5.013620393428729 | State: [-1.125277   2.127751   3.1834805] | Terminated: False | Episode Length: 3.1299999999999772\n",
            "Action: [-0.4  0. ] | Reward: -5.032833268041571 | State: [-1.1241429  2.1302722  3.1834805] | Terminated: False | Episode Length: 3.139999999999977\n",
            "Action: [-0.4  0. ] | Reward: -5.052058374578858 | State: [-1.1230074  2.1327896  3.1834805] | Terminated: False | Episode Length: 3.149999999999977\n",
            "Action: [-0.4  0. ] | Reward: -5.071295619887227 | State: [-1.1218705  2.1353035  3.1834805] | Terminated: False | Episode Length: 3.1599999999999766\n",
            "Action: [-0.4  0. ] | Reward: -5.090544910635851 | State: [-1.1207324  2.137814   3.1834805] | Terminated: False | Episode Length: 3.1699999999999764\n",
            "Action: [-0.4  0. ] | Reward: -5.109806153317069 | State: [-1.1195929  2.1403213  3.1834805] | Terminated: False | Episode Length: 3.179999999999976\n",
            "Action: [-0.4  0. ] | Reward: -5.129079254247026 | State: [-1.1184521  2.1428246  3.1834805] | Terminated: False | Episode Length: 3.189999999999976\n",
            "Action: [-0.4  0. ] | Reward: -5.148364119566308 | State: [-1.1173099  2.145325   3.1834805] | Terminated: False | Episode Length: 3.1999999999999758\n",
            "Action: [-0.4  0. ] | Reward: -5.167660655240593 | State: [-1.1161665  2.1478214  3.1834805] | Terminated: False | Episode Length: 3.2099999999999755\n",
            "Action: [-0.4  0. ] | Reward: -5.186968767061302 | State: [-1.1150217  2.1503146  3.1834805] | Terminated: False | Episode Length: 3.2199999999999753\n",
            "Action: [-0.4  0. ] | Reward: -5.206288360646256 | State: [-1.1138756  2.1528041  3.1834805] | Terminated: False | Episode Length: 3.229999999999975\n",
            "Action: [-0.4  0. ] | Reward: -5.225619341440338 | State: [-1.1127282  2.1552901  3.1834805] | Terminated: False | Episode Length: 3.239999999999975\n",
            "Action: [-0.4  0. ] | Reward: -5.244961614716162 | State: [-1.1115795  2.1577728  3.1834805] | Terminated: False | Episode Length: 3.2499999999999747\n",
            "Action: [-0.4  0. ] | Reward: -5.2643150855747445 | State: [-1.1104295  2.1602519  3.1834805] | Terminated: False | Episode Length: 3.2599999999999745\n",
            "Action: [-0.4  0. ] | Reward: -5.283679658946181 | State: [-1.1092782  2.1627274  3.1834805] | Terminated: False | Episode Length: 3.2699999999999743\n",
            "Action: [-0.4  0. ] | Reward: -5.303055239590336 | State: [-1.1081256  2.1651993  3.1834805] | Terminated: False | Episode Length: 3.279999999999974\n",
            "Action: [-0.4  0. ] | Reward: -5.322441732097523 | State: [-1.1069716  2.1676676  3.1834805] | Terminated: False | Episode Length: 3.289999999999974\n",
            "Action: [-0.4  0. ] | Reward: -5.341839040889203 | State: [-1.1058164  2.1701326  3.1834805] | Terminated: False | Episode Length: 3.2999999999999736\n",
            "Action: [-0.4  0. ] | Reward: -5.361247070218687 | State: [-1.1046599  2.1725938  3.1834805] | Terminated: False | Episode Length: 3.3099999999999734\n",
            "Action: [-0.4  0. ] | Reward: -5.380665724171833 | State: [-1.1035022  2.1750517  3.1834805] | Terminated: False | Episode Length: 3.319999999999973\n",
            "Action: [-0.4  0. ] | Reward: -5.400094906667759 | State: [-1.1023431  2.177506   3.1834805] | Terminated: False | Episode Length: 3.329999999999973\n",
            "Action: [-0.4  0. ] | Reward: -5.419534521459559 | State: [-1.1011827  2.1799567  3.1834805] | Terminated: False | Episode Length: 3.3399999999999728\n",
            "Action: [-0.4  0. ] | Reward: -5.4389844721350205 | State: [-1.1000211  2.1824036  3.1834805] | Terminated: False | Episode Length: 3.3499999999999726\n",
            "Action: [-0.4  0. ] | Reward: -5.458444662117352 | State: [-1.0988582  2.184847   3.1834805] | Terminated: False | Episode Length: 3.3599999999999723\n",
            "Action: [-0.4  0. ] | Reward: -5.477914994665912 | State: [-1.097694   2.187287   3.1834805] | Terminated: False | Episode Length: 3.369999999999972\n",
            "Action: [-0.4  0. ] | Reward: -5.497395372876943 | State: [-1.0965286  2.1897233  3.1834805] | Terminated: False | Episode Length: 3.379999999999972\n",
            "Action: [-0.4  0. ] | Reward: -5.516885699684315 | State: [-1.095362   2.192156   3.1834805] | Terminated: False | Episode Length: 3.3899999999999717\n",
            "Action: [-0.4  0. ] | Reward: -5.536385877860273 | State: [-1.0941939  2.194585   3.1834805] | Terminated: False | Episode Length: 3.3999999999999715\n",
            "Action: [-0.4  0. ] | Reward: -5.555895810016181 | State: [-1.0930247  2.1970105  3.1834805] | Terminated: False | Episode Length: 3.4099999999999713\n",
            "Action: [-0.4  0. ] | Reward: -5.575415398603285 | State: [-1.0918543  2.1994324  3.1834805] | Terminated: False | Episode Length: 3.419999999999971\n",
            "Action: [-0.4  0. ] | Reward: -5.594944545913472 | State: [-1.0906826  2.2018507  3.1834805] | Terminated: False | Episode Length: 3.429999999999971\n",
            "Action: [-0.4  0. ] | Reward: -5.614483154080036 | State: [-1.0895096  2.2042654  3.1834805] | Terminated: False | Episode Length: 3.4399999999999706\n",
            "Action: [-0.4  0. ] | Reward: -5.63403112507845 | State: [-1.0883354  2.2066762  3.1834805] | Terminated: False | Episode Length: 3.4499999999999704\n",
            "Action: [-0.4  0. ] | Reward: -5.653588360727144 | State: [-1.08716    2.2090836  3.1834805] | Terminated: False | Episode Length: 3.45999999999997\n",
            "Action: [-0.4  0. ] | Reward: -5.673154762688286 | State: [-1.0859833  2.2114873  3.1834805] | Terminated: False | Episode Length: 3.46999999999997\n",
            "Action: [-0.4  0. ] | Reward: -5.692730232468569 | State: [-1.0848054  2.2138875  3.1834805] | Terminated: False | Episode Length: 3.47999999999997\n",
            "Action: [-0.4  0. ] | Reward: -5.7123146714200015 | State: [-1.0836263  2.2162838  3.1834805] | Terminated: False | Episode Length: 3.4899999999999696\n",
            "Action: [-0.4  0. ] | Reward: -5.731907980740709 | State: [-1.0824459  2.2186766  3.1834805] | Terminated: False | Episode Length: 3.4999999999999694\n",
            "Action: [-0.4  0. ] | Reward: -5.751510061475733 | State: [-1.0812643  2.2210655  3.1834805] | Terminated: False | Episode Length: 3.509999999999969\n",
            "Action: [-0.4  0. ] | Reward: -5.771120814517839 | State: [-1.0800815  2.223451   3.1834805] | Terminated: False | Episode Length: 3.519999999999969\n",
            "Action: [-0.4  0. ] | Reward: -5.790740140608331 | State: [-1.0788975  2.2258327  3.1834805] | Terminated: False | Episode Length: 3.5299999999999687\n",
            "Action: [-0.4  0. ] | Reward: -5.810367940337866 | State: [-1.0777122  2.2282107  3.1834805] | Terminated: False | Episode Length: 3.5399999999999685\n",
            "Action: [-0.4  0. ] | Reward: -5.830004114147279 | State: [-1.0765258  2.2305849  3.1834805] | Terminated: False | Episode Length: 3.5499999999999683\n",
            "Action: [-0.4  0. ] | Reward: -5.849648562328411 | State: [-1.0753381  2.2329557  3.1834805] | Terminated: False | Episode Length: 3.559999999999968\n",
            "Action: [-0.4  0. ] | Reward: -5.8693011850249395 | State: [-1.0741493  2.2353225  3.1834805] | Terminated: False | Episode Length: 3.569999999999968\n",
            "Action: [-0.4  0. ] | Reward: -5.888961882233219 | State: [-1.0729592  2.2376857  3.1834805] | Terminated: False | Episode Length: 3.5799999999999677\n",
            "Action: [-0.4  0. ] | Reward: -5.908630553803121 | State: [-1.0717679  2.2400453  3.1834805] | Terminated: False | Episode Length: 3.5899999999999674\n",
            "Action: [-0.4  0. ] | Reward: -5.928307099438885 | State: [-1.0705755  2.2424011  3.1834805] | Terminated: False | Episode Length: 3.5999999999999672\n",
            "Action: [-0.4  0. ] | Reward: -5.947991418699969 | State: [-1.0693818  2.2447531  3.1834805] | Terminated: False | Episode Length: 3.609999999999967\n",
            "Action: [-0.4  0. ] | Reward: -5.967683411001908 | State: [-1.068187   2.2471013  3.1834805] | Terminated: False | Episode Length: 3.619999999999967\n",
            "Action: [-0.4  0. ] | Reward: -5.9873829756171775 | State: [-1.066991   2.249446   3.1834805] | Terminated: False | Episode Length: 3.6299999999999666\n",
            "Action: [-0.4  0. ] | Reward: -6.007090011676061 | State: [-1.0657938  2.251787   3.1834805] | Terminated: False | Episode Length: 3.6399999999999664\n",
            "Action: [-0.4  0. ] | Reward: -6.026804418167522 | State: [-1.0645953  2.254124   3.1834805] | Terminated: False | Episode Length: 3.649999999999966\n",
            "Action: [-0.4  0. ] | Reward: -6.046526093940083 | State: [-1.0633959  2.2564573  3.1834805] | Terminated: False | Episode Length: 3.659999999999966\n",
            "Action: [-0.4  0. ] | Reward: -6.066254937702708 | State: [-1.0621952  2.258787   3.1834805] | Terminated: False | Episode Length: 3.6699999999999657\n",
            "Action: [-0.4  0. ] | Reward: -6.085990848025689 | State: [-1.0609932  2.2611127  3.1834805] | Terminated: False | Episode Length: 3.6799999999999655\n",
            "Action: [-0.4  0. ] | Reward: -6.1057337233415385 | State: [-1.0597901  2.263435   3.1834805] | Terminated: False | Episode Length: 3.6899999999999653\n",
            "Action: [-0.4  0. ] | Reward: -6.125483461945889 | State: [-1.058586   2.265753   3.1834805] | Terminated: False | Episode Length: 3.699999999999965\n",
            "Action: [-0.4  0. ] | Reward: -6.145239961998393 | State: [-1.0573806  2.2680676  3.1834805] | Terminated: False | Episode Length: 3.709999999999965\n",
            "Action: [-0.4  0. ] | Reward: -6.1650031215236325 | State: [-1.056174   2.2703784  3.1834805] | Terminated: False | Episode Length: 3.7199999999999647\n",
            "Action: [-0.4  0. ] | Reward: -6.184772838412028 | State: [-1.0549663  2.2726853  3.1834805] | Terminated: False | Episode Length: 3.7299999999999645\n",
            "Action: [-0.4  0. ] | Reward: -6.2045490104207595 | State: [-1.0537575  2.2749884  3.1834805] | Terminated: False | Episode Length: 3.7399999999999642\n",
            "Action: [-0.4  0. ] | Reward: -6.224331535174683 | State: [-1.0525476  2.2772877  3.1834805] | Terminated: False | Episode Length: 3.749999999999964\n",
            "Action: [-0.4  0. ] | Reward: -6.244120310167262 | State: [-1.0513365  2.2795832  3.1834805] | Terminated: False | Episode Length: 3.759999999999964\n",
            "Action: [-0.4  0. ] | Reward: -6.263915232761497 | State: [-1.0501243  2.281875   3.1834805] | Terminated: False | Episode Length: 3.7699999999999636\n",
            "Action: [-0.4  0. ] | Reward: -6.283716200190862 | State: [-1.0489109  2.2841628  3.1834805] | Terminated: False | Episode Length: 3.7799999999999634\n",
            "Action: [-0.4  0. ] | Reward: -6.303523109560244 | State: [-1.0476964  2.2864468  3.1834805] | Terminated: False | Episode Length: 3.789999999999963\n",
            "Action: [-0.4  0. ] | Reward: -6.323335857846891 | State: [-1.0464807  2.288727   3.1834805] | Terminated: False | Episode Length: 3.799999999999963\n",
            "Action: [-0.4  0. ] | Reward: -6.343154341901361 | State: [-1.0452639  2.2910035  3.1834805] | Terminated: False | Episode Length: 3.8099999999999627\n",
            "Action: [-0.4  0. ] | Reward: -6.362978458448479 | State: [-1.044046   2.2932758  3.1834805] | Terminated: False | Episode Length: 3.8199999999999625\n",
            "Action: [-0.4  0. ] | Reward: -6.382808104088296 | State: [-1.042827   2.2955446  3.1834805] | Terminated: False | Episode Length: 3.8299999999999623\n",
            "Action: [-0.4  0. ] | Reward: -6.402643175297052 | State: [-1.0416069  2.2978094  3.1834805] | Terminated: False | Episode Length: 3.839999999999962\n",
            "Action: [-0.4  0. ] | Reward: -6.42248356842815 | State: [-1.0403856  2.3000703  3.1834805] | Terminated: False | Episode Length: 3.849999999999962\n",
            "Action: [-0.4  0. ] | Reward: -6.442329179713124 | State: [-1.0391634  2.3023274  3.1834805] | Terminated: False | Episode Length: 3.8599999999999617\n",
            "Action: [-0.4  0. ] | Reward: -6.462179905262626 | State: [-1.0379399  2.3045807  3.1834805] | Terminated: False | Episode Length: 3.8699999999999615\n",
            "Action: [-0.4  0. ] | Reward: -6.482035641067399 | State: [-1.0367153  2.3068302  3.1834805] | Terminated: False | Episode Length: 3.8799999999999613\n",
            "Action: [-0.4  0. ] | Reward: -6.501896282999276 | State: [-1.0354897  2.3090756  3.1834805] | Terminated: False | Episode Length: 3.889999999999961\n",
            "Action: [-0.4  0. ] | Reward: -6.521761726812166 | State: [-1.0342629  2.3113172  3.1834805] | Terminated: False | Episode Length: 3.899999999999961\n",
            "Action: [-0.4  0. ] | Reward: -6.541631868143051 | State: [-1.033035   2.313555   3.1834805] | Terminated: False | Episode Length: 3.9099999999999606\n",
            "Action: [-0.4  0. ] | Reward: -6.561506602512995 | State: [-1.0318061  2.3157887  3.1834805] | Terminated: False | Episode Length: 3.9199999999999604\n",
            "Action: [-0.4  0. ] | Reward: -6.58138582532814 | State: [-1.0305761  2.3180187  3.1834805] | Terminated: False | Episode Length: 3.92999999999996\n",
            "Action: [-0.4  0. ] | Reward: -6.601269431880728 | State: [-1.029345   2.3202448  3.1834805] | Terminated: False | Episode Length: 3.93999999999996\n",
            "Action: [-0.4  0. ] | Reward: -6.621157317350108 | State: [-1.0281129  2.3224669  3.1834805] | Terminated: False | Episode Length: 3.9499999999999598\n",
            "Action: [-0.4  0. ] | Reward: -6.641049376803763 | State: [-1.0268797  2.3246849  3.1834805] | Terminated: False | Episode Length: 3.9599999999999596\n",
            "Action: [-0.4  0. ] | Reward: -6.660945505198328 | State: [-1.0256454  2.3268993  3.1834805] | Terminated: False | Episode Length: 3.9699999999999593\n",
            "Action: [-0.4  0. ] | Reward: -6.680845597380626 | State: [-1.0244099  2.3291094  3.1834805] | Terminated: False | Episode Length: 3.979999999999959\n",
            "Action: [-0.4  0. ] | Reward: -6.700749548088697 | State: [-1.0231735  2.331316   3.1834805] | Terminated: False | Episode Length: 3.989999999999959\n",
            "Action: [-0.4  0. ] | Reward: -6.720657251952838 | State: [-1.0219359  2.3335183  3.1834805] | Terminated: False | Episode Length: 3.9999999999999587\n",
            "Action: [-0.4  0. ] | Reward: -6.740568603496646 | State: [-1.0206974  2.335717   3.1834805] | Terminated: False | Episode Length: 4.009999999999959\n",
            "Action: [-0.4  0. ] | Reward: -6.760483497138064 | State: [-1.0194578  2.3379114  3.1834805] | Terminated: False | Episode Length: 4.019999999999959\n",
            "Action: [-0.4  0. ] | Reward: -6.780401827190433 | State: [-1.0182171  2.340102   3.1834805] | Terminated: False | Episode Length: 4.0299999999999585\n",
            "Action: [-0.4  0. ] | Reward: -6.800323487863548 | State: [-1.0169754  2.3422887  3.1834805] | Terminated: False | Episode Length: 4.039999999999958\n",
            "Action: [-0.4  0. ] | Reward: -6.820248373264719 | State: [-1.0157326  2.3444715  3.1834805] | Terminated: False | Episode Length: 4.049999999999958\n",
            "Action: [-0.4  0. ] | Reward: -6.840176377399834 | State: [-1.0144888  2.3466501  3.1834805] | Terminated: False | Episode Length: 4.059999999999958\n",
            "Action: [-0.4  0. ] | Reward: -6.8601073941744275 | State: [-1.0132439  2.3488247  3.1834805] | Terminated: False | Episode Length: 4.069999999999958\n",
            "Action: [-0.4  0. ] | Reward: -6.880041317394759 | State: [-1.011998   2.3509955  3.1834805] | Terminated: False | Episode Length: 4.079999999999957\n",
            "Action: [-0.4  0. ] | Reward: -6.899978040768882 | State: [-1.0107511  2.3531623  3.1834805] | Terminated: False | Episode Length: 4.089999999999957\n",
            "Action: [-0.4  0. ] | Reward: -6.919917457907735 | State: [-1.0095032  2.3553252  3.1834805] | Terminated: False | Episode Length: 4.099999999999957\n",
            "Action: [-0.4  0. ] | Reward: -6.939859462326218 | State: [-1.0082542  2.3574839  3.1834805] | Terminated: False | Episode Length: 4.109999999999957\n",
            "Action: [-0.4  0. ] | Reward: -6.9598039474442945 | State: [-1.0070043  2.3596387  3.1834805] | Terminated: False | Episode Length: 4.119999999999957\n",
            "Action: [-0.4  0. ] | Reward: -6.979750806588074 | State: [-1.0057533  2.3617895  3.1834805] | Terminated: False | Episode Length: 4.129999999999956\n",
            "Action: [-0.4  0. ] | Reward: -6.999699932990918 | State: [-1.0045012  2.3639362  3.1834805] | Terminated: False | Episode Length: 4.139999999999956\n",
            "Action: [-0.4  0. ] | Reward: -7.019651219794542 | State: [-1.0032481  2.3660789  3.1834805] | Terminated: False | Episode Length: 4.149999999999956\n",
            "Action: [-0.4  0. ] | Reward: -7.039604560050123 | State: [-1.0019941  2.3682177  3.1834805] | Terminated: False | Episode Length: 4.159999999999956\n",
            "Action: [-0.4  0. ] | Reward: -7.0595598467194085 | State: [-1.0007391  2.3703523  3.1834805] | Terminated: False | Episode Length: 4.1699999999999555\n",
            "Action: [-0.4  0. ] | Reward: -7.079516972675833 | State: [-0.999483   2.372483   3.1834805] | Terminated: False | Episode Length: 4.179999999999955\n",
            "Action: [-0.4  0. ] | Reward: -7.099475830705639 | State: [-0.9982259  2.3746095  3.1834805] | Terminated: False | Episode Length: 4.189999999999955\n",
            "Action: [-0.4  0. ] | Reward: -7.119436313508999 | State: [-0.9969679  2.376732   3.1834805] | Terminated: False | Episode Length: 4.199999999999955\n",
            "Action: [-0.4  0. ] | Reward: -7.139398313701141 | State: [-0.9957089  2.3788507  3.1834805] | Terminated: False | Episode Length: 4.209999999999955\n",
            "Action: [-0.4  0. ] | Reward: -7.159361723813487 | State: [-0.99444884  2.3809652   3.1834805 ] | Terminated: False | Episode Length: 4.2199999999999545\n",
            "Action: [-0.4  0. ] | Reward: -7.179326436294781 | State: [-0.99318784  2.3830755   3.1834805 ] | Terminated: False | Episode Length: 4.229999999999954\n",
            "Action: [-0.4  0. ] | Reward: -7.199292343512235 | State: [-0.99192584  2.385182    3.1834805 ] | Terminated: False | Episode Length: 4.239999999999954\n",
            "Action: [-0.4  0. ] | Reward: -7.219259337752668 | State: [-0.9906629  2.3872843  3.1834805] | Terminated: False | Episode Length: 4.249999999999954\n",
            "Action: [-0.4  0. ] | Reward: -7.239227311223654 | State: [-0.9893989  2.3893824  3.1834805] | Terminated: False | Episode Length: 4.259999999999954\n",
            "Action: [-0.4  0. ] | Reward: -7.259196156054677 | State: [-0.98813397  2.3914766   3.1834805 ] | Terminated: False | Episode Length: 4.269999999999953\n",
            "Action: [-0.4  0. ] | Reward: -7.279165764298284 | State: [-0.9868681  2.3935666  3.1834805] | Terminated: False | Episode Length: 4.279999999999953\n",
            "Action: [-0.4  0. ] | Reward: -7.299136027931246 | State: [-0.98560125  2.3956525   3.1834805 ] | Terminated: False | Episode Length: 4.289999999999953\n",
            "Action: [-0.4  0. ] | Reward: -7.319106838855717 | State: [-0.98433346  2.3977344   3.1834805 ] | Terminated: False | Episode Length: 4.299999999999953\n",
            "Action: [-0.4  0. ] | Reward: -7.339078088900407 | State: [-0.98306465  2.3998122   3.1834805 ] | Terminated: False | Episode Length: 4.3099999999999525\n",
            "Action: [-0.4  0. ] | Reward: -7.359049669821748 | State: [-0.98179495  2.4018857   3.1834805 ] | Terminated: False | Episode Length: 4.319999999999952\n",
            "Action: [-0.4  0. ] | Reward: -7.3790214733050705 | State: [-0.98052424  2.4039555   3.1834805 ] | Terminated: False | Episode Length: 4.329999999999952\n",
            "Action: [-0.4  0. ] | Reward: -7.398993390965783 | State: [-0.97925264  2.4060209   3.1834805 ] | Terminated: False | Episode Length: 4.339999999999952\n",
            "Action: [-0.4  0. ] | Reward: -7.418965314350554 | State: [-0.9779801  2.408082   3.1834805] | Terminated: False | Episode Length: 4.349999999999952\n",
            "Action: [-0.4  0. ] | Reward: -7.438937134938493 | State: [-0.97670656  2.4101393   3.1834805 ] | Terminated: False | Episode Length: 4.3599999999999515\n",
            "Action: [-0.4  0. ] | Reward: -7.458908744142349 | State: [-0.9754321  2.4121923  3.1834805] | Terminated: False | Episode Length: 4.369999999999951\n",
            "Action: [-0.4  0. ] | Reward: -7.478880033309695 | State: [-0.97415674  2.4142413   3.1834805 ] | Terminated: False | Episode Length: 4.379999999999951\n",
            "Action: [-0.4  0. ] | Reward: -7.49885089372413 | State: [-0.9728804  2.4162862  3.1834805] | Terminated: False | Episode Length: 4.389999999999951\n",
            "Action: [-0.4  0. ] | Reward: -7.51882121660648 | State: [-0.97160316  2.4183269   3.1834805 ] | Terminated: False | Episode Length: 4.399999999999951\n",
            "Action: [-0.4  0. ] | Reward: -7.538790893115998 | State: [-0.970325   2.4203632  3.1834805] | Terminated: False | Episode Length: 4.40999999999995\n",
            "Action: [-0.4  0. ] | Reward: -7.558759814351574 | State: [-0.96904594  2.4223957   3.1834805 ] | Terminated: False | Episode Length: 4.41999999999995\n",
            "Action: [-0.4  0. ] | Reward: -7.578727871352948 | State: [-0.9677659  2.424424   3.1834805] | Terminated: False | Episode Length: 4.42999999999995\n",
            "Action: [-0.4  0. ] | Reward: -7.598694955101922 | State: [-0.96648496  2.4264479   3.1834805 ] | Terminated: False | Episode Length: 4.43999999999995\n",
            "Action: [-0.4  0. ] | Reward: -7.61866095652358 | State: [-0.96520317  2.4284678   3.1834805 ] | Terminated: False | Episode Length: 4.4499999999999496\n",
            "Action: [-0.4  0. ] | Reward: -7.638625766487508 | State: [-0.9639204  2.4304833  3.1834805] | Terminated: False | Episode Length: 4.459999999999949\n",
            "Action: [-0.4  0. ] | Reward: -7.658589275809023 | State: [-0.96263677  2.4324949   3.1834805 ] | Terminated: False | Episode Length: 4.469999999999949\n",
            "Action: [-0.4  0. ] | Reward: -7.678551375250395 | State: [-0.9613522  2.4345024  3.1834805] | Terminated: False | Episode Length: 4.479999999999949\n",
            "Action: [-0.4  0. ] | Reward: -7.698511955522086 | State: [-0.9600668  2.4365053  3.1834805] | Terminated: False | Episode Length: 4.489999999999949\n",
            "Action: [-0.4  0. ] | Reward: -7.718470907283982 | State: [-0.95878047  2.4385045   3.1834805 ] | Terminated: False | Episode Length: 4.4999999999999485\n",
            "Action: [-0.4  0. ] | Reward: -7.738428121146631 | State: [-0.95749325  2.440499    3.1834805 ] | Terminated: False | Episode Length: 4.509999999999948\n",
            "Action: [-0.4  0. ] | Reward: -7.7583834876724875 | State: [-0.9562051  2.4424896  3.1834805] | Terminated: False | Episode Length: 4.519999999999948\n",
            "Action: [-0.4  0. ] | Reward: -7.778336897377156 | State: [-0.9549161  2.4444761  3.1834805] | Terminated: False | Episode Length: 4.529999999999948\n",
            "Action: [-0.4  0. ] | Reward: -7.798288240730639 | State: [-0.9536263  2.446458   3.1834805] | Terminated: False | Episode Length: 4.539999999999948\n",
            "Action: [-0.4   -0.524] | Reward: -7.818237408158592 | State: [-0.9523355  2.4484363  3.1782446] | Terminated: False | Episode Length: 4.549999999999947\n",
            "Action: [-0.4   -0.524] | Reward: -7.838184283772406 | State: [-0.9510434  2.45041    3.1730087] | Terminated: False | Episode Length: 4.559999999999947\n",
            "Action: [-0.4    0.262] | Reward: -7.858128752420972 | State: [-0.9497501  2.4523795  3.1756265] | Terminated: False | Episode Length: 4.569999999999947\n",
            "Action: [-0.4   -0.524] | Reward: -7.878070706964853 | State: [-0.9484561  2.4543445  3.1703906] | Terminated: False | Episode Length: 4.579999999999947\n",
            "Action: [-0.4    0.262] | Reward: -7.898010032541011 | State: [-0.9471609  2.4563057  3.1730087] | Terminated: False | Episode Length: 4.589999999999947\n",
            "Action: [-0.4   -0.524] | Reward: -7.91794662172419 | State: [-0.945865   2.4582624  3.1677725] | Terminated: False | Episode Length: 4.599999999999946\n",
            "Action: [-0.4   -0.524] | Reward: -7.937880359951445 | State: [-0.9445679  2.460215   3.1625366] | Terminated: False | Episode Length: 4.609999999999946\n",
            "Action: [-0.4    0.262] | Reward: -7.957811133433921 | State: [-0.94326967  2.4621632   3.1651547 ] | Terminated: False | Episode Length: 4.619999999999946\n",
            "Action: [-0.4   -0.524] | Reward: -7.977738833986424 | State: [-0.94197077  2.4641073   3.1599185 ] | Terminated: False | Episode Length: 4.629999999999946\n",
            "Action: [-0.4   -0.524] | Reward: -7.997663348144584 | State: [-0.9406707  2.466047   3.1546826] | Terminated: False | Episode Length: 4.6399999999999455\n",
            "Action: [-0.4    0.262] | Reward: -8.017584563242606 | State: [-0.93936974  2.4679825   3.1573007 ] | Terminated: False | Episode Length: 4.649999999999945\n",
            "Action: [-0.4   -0.524] | Reward: -8.037502370345255 | State: [-0.9380679  2.469914   3.1520646] | Terminated: False | Episode Length: 4.659999999999945\n",
            "Action: [-0.4    0.262] | Reward: -8.057416657135738 | State: [-0.93676513  2.4718409   3.1546826 ] | Terminated: False | Episode Length: 4.669999999999945\n",
            "Action: [-0.4   -0.524] | Reward: -8.07732731440654 | State: [-0.9354616  2.4737635  3.1494467] | Terminated: False | Episode Length: 4.679999999999945\n",
            "Action: [-0.4   -0.524] | Reward: -8.097234230202085 | State: [-0.93415713  2.475682    3.1442106 ] | Terminated: False | Episode Length: 4.689999999999944\n",
            "Action: [-0.4    0.262] | Reward: -8.117137293402326 | State: [-0.93285173  2.477596    3.1468287 ] | Terminated: False | Episode Length: 4.699999999999944\n",
            "Action: [-0.4   -0.524] | Reward: -8.137036394064836 | State: [-0.93154556  2.479506    3.1415927 ] | Terminated: False | Episode Length: 4.709999999999944\n",
            "Action: [-0.4   -0.524] | Reward: -8.156931421455472 | State: [-0.93023854  2.4814115   3.1363566 ] | Terminated: False | Episode Length: 4.719999999999944\n",
            "Action: [-0.4    0.262] | Reward: -8.176822265700286 | State: [-0.92893076  2.4833126   3.1389747 ] | Terminated: False | Episode Length: 4.729999999999944\n",
            "Action: [-0.4   -0.524] | Reward: -8.19670881613216 | State: [-0.92762214  2.4852097   3.1337388 ] | Terminated: False | Episode Length: 4.739999999999943\n",
            "Action: [-0.4  0. ] | Reward: -8.216590963287828 | State: [-0.92631274  2.4871023   3.1337388 ] | Terminated: False | Episode Length: 4.749999999999943\n",
            "Action: [-0.4  0. ] | Reward: -8.236468596800655 | State: [-0.9250026  2.4889905  3.1337388] | Terminated: False | Episode Length: 4.759999999999943\n",
            "Action: [-0.4  0. ] | Reward: -8.256341606288057 | State: [-0.9236916  2.4908745  3.1337388] | Terminated: False | Episode Length: 4.769999999999943\n",
            "Action: [-0.4  0. ] | Reward: -8.27620988135282 | State: [-0.9223798  2.4927542  3.1337388] | Terminated: False | Episode Length: 4.7799999999999425\n",
            "Action: [-0.4  0. ] | Reward: -8.29607331158443 | State: [-0.9210672  2.4946296  3.1337388] | Terminated: False | Episode Length: 4.789999999999942\n",
            "Action: [-0.4  0. ] | Reward: -8.315931786560398 | State: [-0.9197538  2.4965005  3.1337388] | Terminated: False | Episode Length: 4.799999999999942\n",
            "Action: [-0.4  0. ] | Reward: -8.33578519584759 | State: [-0.9184396  2.4983673  3.1337388] | Terminated: False | Episode Length: 4.809999999999942\n",
            "Action: [-0.4  0. ] | Reward: -8.35563342900356 | State: [-0.9171247  2.5002296  3.1337388] | Terminated: False | Episode Length: 4.819999999999942\n",
            "Action: [-0.4  0. ] | Reward: -8.375476375577886 | State: [-0.915809   2.5020876  3.1337388] | Terminated: False | Episode Length: 4.8299999999999415\n",
            "Action: [-0.4  0. ] | Reward: -8.395313925113504 | State: [-0.9144925  2.5039413  3.1337388] | Terminated: False | Episode Length: 4.839999999999941\n",
            "Action: [-0.4  0. ] | Reward: -8.415145967148053 | State: [-0.91317517  2.5057905   3.1337388 ] | Terminated: False | Episode Length: 4.849999999999941\n",
            "Action: [-0.4  0. ] | Reward: -8.434972391215215 | State: [-0.9118571  2.5076354  3.1337388] | Terminated: False | Episode Length: 4.859999999999941\n",
            "Action: [-0.4  0. ] | Reward: -8.454793086846058 | State: [-0.9105383  2.509476   3.1337388] | Terminated: False | Episode Length: 4.869999999999941\n",
            "Action: [-0.4  0. ] | Reward: -8.474607943570382 | State: [-0.9092187  2.5113122  3.1337388] | Terminated: False | Episode Length: 4.87999999999994\n",
            "Action: [-0.4  0. ] | Reward: -8.494416850918073 | State: [-0.9078984  2.513144   3.1337388] | Terminated: False | Episode Length: 4.88999999999994\n",
            "Action: [-0.4  0. ] | Reward: -8.51421969842045 | State: [-0.90657735  2.5149715   3.1337388 ] | Terminated: False | Episode Length: 4.89999999999994\n",
            "Action: [-0.4  0. ] | Reward: -8.534016375611618 | State: [-0.9052555  2.5167947  3.1337388] | Terminated: False | Episode Length: 4.90999999999994\n",
            "Action: [-0.4  0. ] | Reward: -8.553806772029828 | State: [-0.90393287  2.5186133   3.1337388 ] | Terminated: False | Episode Length: 4.9199999999999395\n",
            "Action: [-0.4  0. ] | Reward: -8.573590777218831 | State: [-0.9026095  2.5204277  3.1337388] | Terminated: False | Episode Length: 4.929999999999939\n",
            "Action: [-0.4  0. ] | Reward: -8.593368280729235 | State: [-0.90128547  2.5222375   3.1337388 ] | Terminated: False | Episode Length: 4.939999999999939\n",
            "Action: [-0.4  0. ] | Reward: -8.613139172119876 | State: [-0.89996064  2.524043    3.1337388 ] | Terminated: False | Episode Length: 4.949999999999939\n",
            "Action: [-0.4  0. ] | Reward: -8.632903340959171 | State: [-0.8986351  2.5258443  3.1337388] | Terminated: False | Episode Length: 4.959999999999939\n",
            "Action: [-0.4  0. ] | Reward: -8.652660676826493 | State: [-0.89730877  2.527641    3.1337388 ] | Terminated: False | Episode Length: 4.9699999999999385\n",
            "Action: [-0.4  0. ] | Reward: -8.672411069313533 | State: [-0.8959817  2.5294333  3.1337388] | Terminated: False | Episode Length: 4.979999999999938\n",
            "Action: [-0.4  0. ] | Reward: -8.692154408025674 | State: [-0.894654   2.5312214  3.1337388] | Terminated: False | Episode Length: 4.989999999999938\n",
            "Action: [-0.4  0. ] | Reward: -8.711890582583356 | State: [-0.8933255  2.5330048  3.1337388] | Terminated: False | Episode Length: 4.999999999999938\n",
            "Action: [-0.4  0. ] | Reward: -8.731619482623456 | State: [-0.8919963  2.5347838  3.1337388] | Terminated: False | Episode Length: 5.009999999999938\n",
            "Action: [-0.4  0. ] | Reward: -8.751340997800662 | State: [-0.8906664  2.5365586  3.1337388] | Terminated: False | Episode Length: 5.019999999999937\n",
            "Action: [-0.4  0. ] | Reward: -8.771055017788846 | State: [-0.8893358  2.5383286  3.1337388] | Terminated: False | Episode Length: 5.029999999999937\n",
            "Action: [-0.4  0. ] | Reward: -8.79076143228245 | State: [-0.8880045  2.5400946  3.1337388] | Terminated: False | Episode Length: 5.039999999999937\n",
            "Action: [-0.4  0. ] | Reward: -8.810460130997859 | State: [-0.88667244  2.541856    3.1337388 ] | Terminated: False | Episode Length: 5.049999999999937\n",
            "Action: [-0.4  0. ] | Reward: -8.83015100367479 | State: [-0.88533974  2.543613    3.1337388 ] | Terminated: False | Episode Length: 5.0599999999999365\n",
            "Action: [-0.4  0. ] | Reward: -8.849833940077668 | State: [-0.8840063  2.5453653  3.1337388] | Terminated: False | Episode Length: 5.069999999999936\n",
            "Action: [-0.4  0. ] | Reward: -8.869508829997018 | State: [-0.8826722  2.5471134  3.1337388] | Terminated: False | Episode Length: 5.079999999999936\n",
            "Action: [-0.4  0. ] | Reward: -8.889175563250856 | State: [-0.8813374  2.548857   3.1337388] | Terminated: False | Episode Length: 5.089999999999936\n",
            "Action: [-0.4  0. ] | Reward: -8.908834029686062 | State: [-0.8800019  2.5505962  3.1337388] | Terminated: False | Episode Length: 5.099999999999936\n",
            "Action: [-0.4  0. ] | Reward: -8.928484119179789 | State: [-0.8786657  2.5523307  3.1337388] | Terminated: False | Episode Length: 5.1099999999999355\n",
            "Action: [-0.4  0. ] | Reward: -8.948125721640839 | State: [-0.8773288  2.554061   3.1337388] | Terminated: False | Episode Length: 5.119999999999935\n",
            "Action: [-0.4  0. ] | Reward: -8.967758727011068 | State: [-0.8759913  2.5557868  3.1337388] | Terminated: False | Episode Length: 5.129999999999935\n",
            "Action: [-0.4  0. ] | Reward: -8.987383025266773 | State: [-0.87465304  2.557508    3.1337388 ] | Terminated: False | Episode Length: 5.139999999999935\n",
            "Action: [-0.4  0. ] | Reward: -9.006998506420093 | State: [-0.8733142  2.5592248  3.1337388] | Terminated: False | Episode Length: 5.149999999999935\n",
            "Action: [-0.4  0. ] | Reward: -9.0266050605204 | State: [-0.87197465  2.5609372   3.1337388 ] | Terminated: False | Episode Length: 5.159999999999934\n",
            "Action: [-0.4  0. ] | Reward: -9.046202577655704 | State: [-0.87063444  2.562645    3.1337388 ] | Terminated: False | Episode Length: 5.169999999999934\n",
            "Action: [-0.4  0. ] | Reward: -9.065790947954051 | State: [-0.8692936  2.5643485  3.1337388] | Terminated: False | Episode Length: 5.179999999999934\n",
            "Action: [-0.4  0. ] | Reward: -9.085370061584921 | State: [-0.867952   2.5660472  3.1337388] | Terminated: False | Episode Length: 5.189999999999934\n",
            "Action: [-0.4  0. ] | Reward: -9.104939808760635 | State: [-0.8666098  2.5677416  3.1337388] | Terminated: False | Episode Length: 5.199999999999934\n",
            "Action: [-0.4  0. ] | Reward: -9.124500079737755 | State: [-0.865267   2.5694315  3.1337388] | Terminated: False | Episode Length: 5.209999999999933\n",
            "Action: [-0.4  0. ] | Reward: -9.144050764818491 | State: [-0.86392355  2.571117    3.1337388 ] | Terminated: False | Episode Length: 5.219999999999933\n",
            "Action: [-0.4  0. ] | Reward: -9.163591754352106 | State: [-0.8625794  2.5727978  3.1337388] | Terminated: False | Episode Length: 5.229999999999933\n",
            "Action: [-0.4  0. ] | Reward: -9.183122938736322 | State: [-0.86123466  2.574474    3.1337388 ] | Terminated: False | Episode Length: 5.239999999999933\n",
            "Action: [-0.4  0. ] | Reward: -9.202644208418725 | State: [-0.85988927  2.5761461   3.1337388 ] | Terminated: False | Episode Length: 5.2499999999999325\n",
            "Action: [-0.4  0. ] | Reward: -9.222155453898186 | State: [-0.8585432  2.5778134  3.1337388] | Terminated: False | Episode Length: 5.259999999999932\n",
            "Action: [-0.4  0. ] | Reward: -9.241656565726252 | State: [-0.85719657  2.5794764   3.1337388 ] | Terminated: False | Episode Length: 5.269999999999932\n",
            "Action: [-0.4  0. ] | Reward: -9.261147434508576 | State: [-0.85584927  2.5811346   3.1337388 ] | Terminated: False | Episode Length: 5.279999999999932\n",
            "Action: [-0.4  0. ] | Reward: -9.280627950906315 | State: [-0.85450137  2.5827882   3.1337388 ] | Terminated: False | Episode Length: 5.289999999999932\n",
            "Action: [-0.4  0. ] | Reward: -9.300098005637546 | State: [-0.8531529  2.5844376  3.1337388] | Terminated: False | Episode Length: 5.299999999999931\n",
            "Action: [-0.4  0. ] | Reward: -9.319557489478683 | State: [-0.8518037  2.5860822  3.1337388] | Terminated: False | Episode Length: 5.309999999999931\n",
            "Action: [-0.4  0. ] | Reward: -9.33900629326589 | State: [-0.850454   2.5877225  3.1337388] | Terminated: False | Episode Length: 5.319999999999931\n",
            "Action: [-0.4  0. ] | Reward: -9.358444307896487 | State: [-0.8491036  2.589358   3.1337388] | Terminated: False | Episode Length: 5.329999999999931\n",
            "Action: [-0.4  0. ] | Reward: -9.377871424330385 | State: [-0.8477527  2.5909894  3.1337388] | Terminated: False | Episode Length: 5.339999999999931\n",
            "Action: [-0.4  0. ] | Reward: -9.397287533591479 | State: [-0.84640115  2.5926158   3.1337388 ] | Terminated: False | Episode Length: 5.34999999999993\n",
            "Action: [-0.4   -0.262] | Reward: -9.416692526769083 | State: [-0.84504896  2.5942378   3.1311207 ] | Terminated: False | Episode Length: 5.35999999999993\n",
            "Action: [-0.4    0.524] | Reward: -9.436086295959369 | State: [-0.8436963  2.5958552  3.1363566] | Terminated: False | Episode Length: 5.36999999999993\n",
            "Action: [-0.4   -0.262] | Reward: -9.455468730775394 | State: [-0.8423429  2.5974681  3.1337388] | Terminated: False | Episode Length: 5.37999999999993\n",
            "Action: [-0.4   -0.262] | Reward: -9.474839723183083 | State: [-0.840989   2.5990765  3.1311207] | Terminated: False | Episode Length: 5.3899999999999295\n",
            "Action: [-0.4    0.524] | Reward: -9.494199165495408 | State: [-0.83963454  2.6006804   3.1363566 ] | Terminated: False | Episode Length: 5.399999999999929\n",
            "Action: [-0.4   -0.262] | Reward: -9.513546947525304 | State: [-0.8382794  2.6022797  3.1337388] | Terminated: False | Episode Length: 5.409999999999929\n",
            "Action: [-0.4   -0.262] | Reward: -9.532882961461784 | State: [-0.8369238  2.6038742  3.1311207] | Terminated: False | Episode Length: 5.419999999999929\n",
            "Action: [-0.4    0.524] | Reward: -9.552207099847395 | State: [-0.8355676  2.6054642  3.1363566] | Terminated: False | Episode Length: 5.429999999999929\n",
            "Action: [-0.4   -0.262] | Reward: -9.571519252707734 | State: [-0.83421075  2.6070497   3.1337388 ] | Terminated: False | Episode Length: 5.4399999999999284\n",
            "Action: [-0.4    0.524] | Reward: -9.59081931246768 | State: [-0.8328534  2.6086307  3.1389747] | Terminated: False | Episode Length: 5.449999999999928\n",
            "Action: [-0.4   -0.262] | Reward: -9.610107169847629 | State: [-0.8314954  2.610207   3.1363566] | Terminated: False | Episode Length: 5.459999999999928\n",
            "Action: [-0.4   -0.262] | Reward: -9.629382717158832 | State: [-0.8301369  2.6117787  3.1337388] | Terminated: False | Episode Length: 5.469999999999928\n",
            "Action: [-0.4    0.524] | Reward: -9.648645847074844 | State: [-0.82877785  2.6133459   3.1389747 ] | Terminated: False | Episode Length: 5.479999999999928\n",
            "Action: [-0.4    0.524] | Reward: -9.667896450554522 | State: [-0.82741815  2.6149085   3.1442106 ] | Terminated: False | Episode Length: 5.489999999999927\n",
            "Action: [-0.4    0.524] | Reward: -9.687134419746737 | State: [-0.826058   2.6164665  3.1494467] | Terminated: False | Episode Length: 5.499999999999927\n",
            "Action: [-0.4    0.524] | Reward: -9.706359648003009 | State: [-0.8246973  2.6180198  3.1546826] | Terminated: False | Episode Length: 5.509999999999927\n",
            "Action: [-0.4    0.524] | Reward: -9.725572029890104 | State: [-0.8233362  2.6195686  3.1599185] | Terminated: False | Episode Length: 5.519999999999927\n",
            "Action: [-0.4    0.524] | Reward: -9.744771461202582 | State: [-0.82197475  2.6211128   3.1651547 ] | Terminated: False | Episode Length: 5.5299999999999265\n",
            "Action: [-0.4    0.524] | Reward: -9.763957838975289 | State: [-0.820613   2.6226523  3.1703906] | Terminated: False | Episode Length: 5.539999999999926\n",
            "Action: [-0.4    0.524] | Reward: -9.783131061495812 | State: [-0.81925106  2.6241872   3.1756265 ] | Terminated: False | Episode Length: 5.549999999999926\n",
            "Action: [-0.4  0. ] | Reward: -9.802291028316876 | State: [-0.817889   2.6257176  3.1756265] | Terminated: False | Episode Length: 5.559999999999926\n",
            "Action: [-0.4  0. ] | Reward: -9.821437632334453 | State: [-0.81652635  2.6272433   3.1756265 ] | Terminated: False | Episode Length: 5.569999999999926\n",
            "Action: [-0.4  0. ] | Reward: -9.84057076654097 | State: [-0.8151632  2.6287644  3.1756265] | Terminated: False | Episode Length: 5.5799999999999255\n",
            "Action: [-0.4  0. ] | Reward: -9.859690324026733 | State: [-0.81379956  2.630281    3.1756265 ] | Terminated: False | Episode Length: 5.589999999999925\n",
            "Action: [-0.4  0. ] | Reward: -9.878796197981337 | State: [-0.8124354  2.6317928  3.1756265] | Terminated: False | Episode Length: 5.599999999999925\n",
            "Action: [-0.4  0. ] | Reward: -9.89788828169509 | State: [-0.81107074  2.6333      3.1756265 ] | Terminated: False | Episode Length: 5.609999999999925\n",
            "Action: [-0.4  0. ] | Reward: -9.91696646856043 | State: [-0.80970556  2.6348026   3.1756265 ] | Terminated: False | Episode Length: 5.619999999999925\n",
            "Action: [-0.4  0. ] | Reward: -9.936030652073342 | State: [-0.80833983  2.6363006   3.1756265 ] | Terminated: False | Episode Length: 5.629999999999924\n",
            "Action: [-0.4  0. ] | Reward: -9.955080725834772 | State: [-0.80697364  2.6377938   3.1756265 ] | Terminated: False | Episode Length: 5.639999999999924\n",
            "Action: [-0.4  0. ] | Reward: -9.974116583552055 | State: [-0.80560696  2.6392825   3.1756265 ] | Terminated: False | Episode Length: 5.649999999999924\n",
            "Action: [-0.4  0. ] | Reward: -9.993138119040315 | State: [-0.8042398  2.6407666  3.1756265] | Terminated: False | Episode Length: 5.659999999999924\n",
            "Action: [-0.4  0. ] | Reward: -10.012145226223893 | State: [-0.8028721  2.642246   3.1756265] | Terminated: False | Episode Length: 5.6699999999999235\n",
            "Action: [-0.4  0. ] | Reward: -10.03113779913776 | State: [-0.801504   2.6437209  3.1756265] | Terminated: False | Episode Length: 5.679999999999923\n",
            "Action: [-0.4  0. ] | Reward: -10.050115731928924 | State: [-0.8001354  2.645191   3.1756265] | Terminated: False | Episode Length: 5.689999999999923\n",
            "Action: [-0.4  0. ] | Reward: -10.069078918857855 | State: [-0.79876626  2.6466563   3.1756265 ] | Terminated: False | Episode Length: 5.699999999999923\n",
            "Action: [-0.4  0. ] | Reward: -10.088027254299892 | State: [-0.7973967  2.648117   3.1756265] | Terminated: False | Episode Length: 5.709999999999923\n",
            "Action: [-0.4  0. ] | Reward: -10.106960632746656 | State: [-0.79602665  2.6495733   3.1756265 ] | Terminated: False | Episode Length: 5.7199999999999225\n",
            "Action: [-0.4  0. ] | Reward: -10.125878948807467 | State: [-0.7946561  2.6510248  3.1756265] | Terminated: False | Episode Length: 5.729999999999922\n",
            "Action: [-0.4  0. ] | Reward: -10.144782097210745 | State: [-0.79328513  2.6524715   3.1756265 ] | Terminated: False | Episode Length: 5.739999999999922\n",
            "Action: [-0.4  0. ] | Reward: -10.163669972805433 | State: [-0.7919137  2.6539137  3.1756265] | Terminated: False | Episode Length: 5.749999999999922\n",
            "Action: [-0.4  0. ] | Reward: -10.182542470562396 | State: [-0.7905418  2.6553512  3.1756265] | Terminated: False | Episode Length: 5.759999999999922\n",
            "Action: [-0.4   -0.524] | Reward: -10.201399485575836 | State: [-0.78916943  2.656784    3.1703906 ] | Terminated: False | Episode Length: 5.769999999999921\n",
            "Action: [-0.4   -0.524] | Reward: -10.22024090589194 | State: [-0.78779626  2.6582122   3.1651547 ] | Terminated: False | Episode Length: 5.779999999999921\n",
            "Action: [-0.4   -0.524] | Reward: -10.239066620832215 | State: [-0.7864223  2.6596355  3.1599185] | Terminated: False | Episode Length: 5.789999999999921\n",
            "Action: [-0.4   -0.524] | Reward: -10.25787652100624 | State: [-0.78504765  2.6610544   3.1546826 ] | Terminated: False | Episode Length: 5.799999999999921\n",
            "Action: [-0.4   -0.524] | Reward: -10.276670498324357 | State: [-0.7836724  2.6624684  3.1494467] | Terminated: False | Episode Length: 5.809999999999921\n",
            "Action: [-0.4   -0.524] | Reward: -10.295448446010324 | State: [-0.78229654  2.663878    3.1442106 ] | Terminated: False | Episode Length: 5.81999999999992\n",
            "Action: [-0.4  0. ] | Reward: -10.314210258613903 | State: [-0.7809202  2.6652827  3.1442106] | Terminated: False | Episode Length: 5.82999999999992\n",
            "Action: [-0.4  0. ] | Reward: -10.332955832023398 | State: [-0.77954346  2.6666827   3.1442106 ] | Terminated: False | Episode Length: 5.83999999999992\n",
            "Action: [-0.4  0. ] | Reward: -10.35168506226197 | State: [-0.7781663  2.668078   3.1442106] | Terminated: False | Episode Length: 5.84999999999992\n",
            "Action: [-0.4  0. ] | Reward: -10.370397845489041 | State: [-0.77678865  2.6694686   3.1442106 ] | Terminated: False | Episode Length: 5.8599999999999195\n",
            "Action: [-0.4  0. ] | Reward: -10.389094078001694 | State: [-0.77541065  2.6708546   3.1442106 ] | Terminated: False | Episode Length: 5.869999999999919\n",
            "Action: [-0.4  0. ] | Reward: -10.407773656236072 | State: [-0.77403224  2.6722357   3.1442106 ] | Terminated: False | Episode Length: 5.879999999999919\n",
            "Action: [-0.4  0. ] | Reward: -10.42643647676878 | State: [-0.77265334  2.6736124   3.1442106 ] | Terminated: False | Episode Length: 5.889999999999919\n",
            "Action: [-0.4  0. ] | Reward: -10.445082436318277 | State: [-0.7712741  2.674984   3.1442106] | Terminated: False | Episode Length: 5.899999999999919\n",
            "Action: [-0.4  0. ] | Reward: -10.463711431746272 | State: [-0.7698944  2.676351   3.1442106] | Terminated: False | Episode Length: 5.909999999999918\n",
            "Action: [-0.4  0. ] | Reward: -10.482323360059125 | State: [-0.7685144  2.6777136  3.1442106] | Terminated: False | Episode Length: 5.919999999999918\n",
            "Action: [-0.4  0. ] | Reward: -10.50091811840923 | State: [-0.76713395  2.6790712   3.1442106 ] | Terminated: False | Episode Length: 5.929999999999918\n",
            "Action: [-0.4  0. ] | Reward: -10.519495604096411 | State: [-0.7657531  2.6804242  3.1442106] | Terminated: False | Episode Length: 5.939999999999918\n",
            "Action: [-0.4  0. ] | Reward: -10.538055714569312 | State: [-0.7643719  2.6817725  3.1442106] | Terminated: False | Episode Length: 5.949999999999918\n",
            "Action: [-0.4  0. ] | Reward: -10.556598347426785 | State: [-0.76299024  2.683116    3.1442106 ] | Terminated: False | Episode Length: 5.959999999999917\n",
            "Action: [-0.4  0. ] | Reward: -10.575123400419272 | State: [-0.76160824  2.6844547   3.1442106 ] | Terminated: False | Episode Length: 5.969999999999917\n",
            "Action: [-0.4  0. ] | Reward: -10.593630771450197 | State: [-0.7602259  2.6857886  3.1442106] | Terminated: False | Episode Length: 5.979999999999917\n",
            "Action: [-0.4  0. ] | Reward: -10.612120358577343 | State: [-0.7588431  2.687118   3.1442106] | Terminated: False | Episode Length: 5.989999999999917\n",
            "Action: [-0.4  0. ] | Reward: -10.630592060014235 | State: [-0.75746    2.6884427  3.1442106] | Terminated: False | Episode Length: 5.9999999999999165\n",
            "Action: [-0.4  0. ] | Reward: -10.64904577413152 | State: [-0.7560765  2.6897626  3.1442106] | Terminated: False | Episode Length: 6.009999999999916\n",
            "Action: [-0.4  0. ] | Reward: -10.667481399458346 | State: [-0.7546926  2.6910777  3.1442106] | Terminated: False | Episode Length: 6.019999999999916\n",
            "Action: [-0.4  0. ] | Reward: -10.685898834683732 | State: [-0.7533084  2.692388   3.1442106] | Terminated: False | Episode Length: 6.029999999999916\n",
            "Action: [-0.4  0. ] | Reward: -10.70429797865795 | State: [-0.75192386  2.6936936   3.1442106 ] | Terminated: False | Episode Length: 6.039999999999916\n",
            "Action: [-0.4  0. ] | Reward: -10.722678730393893 | State: [-0.75053895  2.6949944   3.1442106 ] | Terminated: False | Episode Length: 6.0499999999999154\n",
            "Action: [-0.4  0. ] | Reward: -10.741040989068443 | State: [-0.7491537  2.6962907  3.1442106] | Terminated: False | Episode Length: 6.059999999999915\n",
            "Action: [-0.4  0. ] | Reward: -10.759384654023844 | State: [-0.74776804  2.697582    3.1442106 ] | Terminated: False | Episode Length: 6.069999999999915\n",
            "Action: [-0.4  0. ] | Reward: -10.777709624769063 | State: [-0.74638206  2.6988688   3.1442106 ] | Terminated: False | Episode Length: 6.079999999999915\n",
            "Action: [-0.4  0. ] | Reward: -10.796015800981156 | State: [-0.7449958  2.7001507  3.1442106] | Terminated: False | Episode Length: 6.089999999999915\n",
            "Action: [-0.4  0. ] | Reward: -10.814303082506632 | State: [-0.74360913  2.7014277   3.1442106 ] | Terminated: False | Episode Length: 6.099999999999914\n",
            "Action: [-0.4  0. ] | Reward: -10.832571369362809 | State: [-0.74222213  2.7027001   3.1442106 ] | Terminated: False | Episode Length: 6.109999999999914\n",
            "Action: [-0.4  0. ] | Reward: -10.850820561739173 | State: [-0.74083483  2.7039678   3.1442106 ] | Terminated: False | Episode Length: 6.119999999999914\n",
            "Action: [-0.4  0. ] | Reward: -10.869050559998737 | State: [-0.73944724  2.7052307   3.1442106 ] | Terminated: False | Episode Length: 6.129999999999914\n",
            "Action: [-0.4  0. ] | Reward: -10.887261264679386 | State: [-0.7380593  2.7064888  3.1442106] | Terminated: False | Episode Length: 6.1399999999999135\n",
            "Action: [-0.4  0. ] | Reward: -10.905452576495236 | State: [-0.73667103  2.7077422   3.1442106 ] | Terminated: False | Episode Length: 6.149999999999913\n",
            "Action: [-0.4  0. ] | Reward: -10.923624396337976 | State: [-0.7352824  2.7089908  3.1442106] | Terminated: False | Episode Length: 6.159999999999913\n",
            "Action: [-0.4  0. ] | Reward: -10.94177662527822 | State: [-0.7338936  2.7102346  3.1442106] | Terminated: False | Episode Length: 6.169999999999913\n",
            "Action: [-0.4  0. ] | Reward: -10.959909164566845 | State: [-0.73250437  2.7114737   3.1442106 ] | Terminated: False | Episode Length: 6.179999999999913\n",
            "Action: [-0.4  0. ] | Reward: -10.978021915636337 | State: [-0.73111486  2.712708    3.1442106 ] | Terminated: False | Episode Length: 6.1899999999999125\n",
            "Action: [-0.4  0. ] | Reward: -10.996114780102124 | State: [-0.72972506  2.7139375   3.1442106 ] | Terminated: False | Episode Length: 6.199999999999912\n",
            "Action: [-0.4  0. ] | Reward: -11.014187659763918 | State: [-0.72833496  2.7151623   3.1442106 ] | Terminated: False | Episode Length: 6.209999999999912\n",
            "Action: [-0.4  0. ] | Reward: -11.032240456607049 | State: [-0.72694457  2.7163823   3.1442106 ] | Terminated: False | Episode Length: 6.219999999999912\n",
            "Action: [-0.4  0. ] | Reward: -11.05027307280379 | State: [-0.72555393  2.7175975   3.1442106 ] | Terminated: False | Episode Length: 6.229999999999912\n",
            "Action: [-0.4  0. ] | Reward: -11.068285410714692 | State: [-0.72416294  2.718808    3.1442106 ] | Terminated: False | Episode Length: 6.239999999999911\n",
            "Action: [-0.4  0. ] | Reward: -11.086277372889906 | State: [-0.7227717  2.7200134  3.1442106] | Terminated: False | Episode Length: 6.249999999999911\n",
            "Action: [-0.4  0. ] | Reward: -11.104248862070508 | State: [-0.7213802  2.7212143  3.1442106] | Terminated: False | Episode Length: 6.259999999999911\n",
            "Action: [-0.4  0. ] | Reward: -11.122199781189815 | State: [-0.7199884  2.7224104  3.1442106] | Terminated: False | Episode Length: 6.269999999999911\n",
            "Action: [-0.4  0. ] | Reward: -11.140130033374714 | State: [-0.71859634  2.7236016   3.1442106 ] | Terminated: False | Episode Length: 6.2799999999999105\n",
            "Action: [-0.4  0. ] | Reward: -11.15803952194696 | State: [-0.717204   2.7247882  3.1442106] | Terminated: False | Episode Length: 6.28999999999991\n",
            "Action: [-0.4  0. ] | Reward: -11.17592815042451 | State: [-0.7158114  2.7259698  3.1442106] | Terminated: False | Episode Length: 6.29999999999991\n",
            "Action: [-0.4  0. ] | Reward: -11.193795822522805 | State: [-0.71441853  2.7271466   3.1442106 ] | Terminated: False | Episode Length: 6.30999999999991\n",
            "Action: [-0.4  0. ] | Reward: -11.211642442156105 | State: [-0.7130254  2.728319   3.1442106] | Terminated: False | Episode Length: 6.31999999999991\n",
            "Action: [-0.4  0. ] | Reward: -11.229467913438768 | State: [-0.7116321  2.7294862  3.1442106] | Terminated: False | Episode Length: 6.3299999999999095\n",
            "Action: [-0.4  0. ] | Reward: -11.247272140686567 | State: [-0.7102384  2.7306488  3.1442106] | Terminated: False | Episode Length: 6.339999999999909\n",
            "Action: [-0.4  0. ] | Reward: -11.26505502841798 | State: [-0.70884454  2.7318065   3.1442106 ] | Terminated: False | Episode Length: 6.349999999999909\n",
            "Action: [-0.4  0. ] | Reward: -11.282816481355484 | State: [-0.70745045  2.7329593   3.1442106 ] | Terminated: False | Episode Length: 6.359999999999909\n",
            "Action: [-0.4  0. ] | Reward: -11.30055640442685 | State: [-0.7060561  2.7341075  3.1442106] | Terminated: False | Episode Length: 6.369999999999909\n",
            "Action: [-0.4  0. ] | Reward: -11.318274702766429 | State: [-0.7046615  2.7352507  3.1442106] | Terminated: False | Episode Length: 6.379999999999908\n",
            "Action: [-0.4  0. ] | Reward: -11.335971281716436 | State: [-0.7032667  2.7363894  3.1442106] | Terminated: False | Episode Length: 6.389999999999908\n",
            "Action: [-0.4  0. ] | Reward: -11.353646046828235 | State: [-0.70187163  2.737523    3.1442106 ] | Terminated: False | Episode Length: 6.399999999999908\n",
            "Action: [-0.4  0. ] | Reward: -11.371298903863615 | State: [-0.7004764  2.738652   3.1442106] | Terminated: False | Episode Length: 6.409999999999908\n",
            "Action: [-0.4  0. ] | Reward: -11.388929758796065 | State: [-0.6990809  2.7397761  3.1442106] | Terminated: False | Episode Length: 6.419999999999908\n",
            "Action: [-0.4  0. ] | Reward: -11.40653851781205 | State: [-0.6976852  2.7408955  3.1442106] | Terminated: False | Episode Length: 6.429999999999907\n",
            "Action: [-0.4  0. ] | Reward: -11.424125087312275 | State: [-0.69628924  2.7420099   3.1442106 ] | Terminated: False | Episode Length: 6.439999999999907\n",
            "Action: [-0.4  0. ] | Reward: -11.441689373912952 | State: [-0.6948931  2.7431195  3.1442106] | Terminated: False | Episode Length: 6.449999999999907\n",
            "Action: [-0.4  0. ] | Reward: -11.459231284447066 | State: [-0.69349676  2.7442245   3.1442106 ] | Terminated: False | Episode Length: 6.459999999999907\n",
            "Action: [-0.4  0. ] | Reward: -11.476750725965626 | State: [-0.6921002  2.7453244  3.1442106] | Terminated: False | Episode Length: 6.4699999999999065\n",
            "Action: [-0.4  0. ] | Reward: -11.494247605738929 | State: [-0.6907035  2.7464197  3.1442106] | Terminated: False | Episode Length: 6.479999999999906\n",
            "Action: [-0.4  0. ] | Reward: -11.511721831257804 | State: [-0.68930656  2.7475102   3.1442106 ] | Terminated: False | Episode Length: 6.489999999999906\n",
            "Action: [-0.4  0. ] | Reward: -11.529173310234865 | State: [-0.6879094  2.7485957  3.1442106] | Terminated: False | Episode Length: 6.499999999999906\n",
            "Action: [-0.4  0. ] | Reward: -11.546601950605755 | State: [-0.6865121  2.7496765  3.1442106] | Terminated: False | Episode Length: 6.509999999999906\n",
            "Action: [-0.4  0. ] | Reward: -11.564007660530384 | State: [-0.6851146  2.7507524  3.1442106] | Terminated: False | Episode Length: 6.519999999999905\n",
            "Action: [-0.4  0. ] | Reward: -11.58139034839417 | State: [-0.6837169  2.7518237  3.1442106] | Terminated: False | Episode Length: 6.529999999999905\n",
            "Action: [-0.4  0. ] | Reward: -11.598749922809269 | State: [-0.68231905  2.75289     3.1442106 ] | Terminated: False | Episode Length: 6.539999999999905\n",
            "Action: [-0.4  0. ] | Reward: -11.616086292615812 | State: [-0.680921   2.7539515  3.1442106] | Terminated: False | Episode Length: 6.549999999999905\n",
            "Action: [-0.4  0. ] | Reward: -11.633399366883124 | State: [-0.6795228  2.7550082  3.1442106] | Terminated: False | Episode Length: 6.559999999999905\n",
            "Action: [-0.4  0. ] | Reward: -11.65068905491095 | State: [-0.6781244  2.7560601  3.1442106] | Terminated: False | Episode Length: 6.569999999999904\n",
            "Action: [-0.4  0. ] | Reward: -11.667955266230674 | State: [-0.67672586  2.757107    3.1442106 ] | Terminated: False | Episode Length: 6.579999999999904\n",
            "Action: [-0.4  0. ] | Reward: -11.685197910606531 | State: [-0.6753271  2.7581494  3.1442106] | Terminated: False | Episode Length: 6.589999999999904\n",
            "Action: [-0.4  0. ] | Reward: -11.702416898036823 | State: [-0.67392826  2.7591867   3.1442106 ] | Terminated: False | Episode Length: 6.599999999999904\n",
            "Action: [-0.4  0. ] | Reward: -11.719612138755123 | State: [-0.6725293  2.760219   3.1442106] | Terminated: False | Episode Length: 6.6099999999999035\n",
            "Action: [-0.4  0. ] | Reward: -11.736783543231478 | State: [-0.6711301  2.761247   3.1442106] | Terminated: False | Episode Length: 6.619999999999903\n",
            "Action: [-0.4  0. ] | Reward: -11.753931022173614 | State: [-0.6697308  2.7622697  3.1442106] | Terminated: False | Episode Length: 6.629999999999903\n",
            "Action: [-0.4  0. ] | Reward: -11.771054486528122 | State: [-0.6683313  2.7632878  3.1442106] | Terminated: False | Episode Length: 6.639999999999903\n",
            "Action: [-0.4  0. ] | Reward: -11.788153847481658 | State: [-0.66693175  2.764301    3.1442106 ] | Terminated: False | Episode Length: 6.649999999999903\n",
            "Action: [-0.4  0. ] | Reward: -11.805229016462123 | State: [-0.665532   2.7653096  3.1442106] | Terminated: False | Episode Length: 6.659999999999902\n",
            "Action: [-0.4  0. ] | Reward: -11.822279905139855 | State: [-0.6641321  2.766313   3.1442106] | Terminated: False | Episode Length: 6.669999999999902\n",
            "Action: [-0.4  0. ] | Reward: -11.8393064254288 | State: [-0.6627321  2.7673118  3.1442106] | Terminated: False | Episode Length: 6.679999999999902\n",
            "Action: [-0.4  0. ] | Reward: -11.856308489487693 | State: [-0.661332   2.7683055  3.1442106] | Terminated: False | Episode Length: 6.689999999999902\n",
            "Action: [-0.4  0. ] | Reward: -11.873286009721225 | State: [-0.6599318  2.7692947  3.1442106] | Terminated: False | Episode Length: 6.699999999999902\n",
            "Action: [-0.4  0. ] | Reward: -11.890238898781211 | State: [-0.6585314  2.770279   3.1442106] | Terminated: False | Episode Length: 6.709999999999901\n",
            "Action: [-0.4  0. ] | Reward: -11.907167069567754 | State: [-0.65713096  2.7712584   3.1442106 ] | Terminated: False | Episode Length: 6.719999999999901\n",
            "Action: [-0.4  0. ] | Reward: -11.9240704352304 | State: [-0.6557304  2.7722328  3.1442106] | Terminated: False | Episode Length: 6.729999999999901\n",
            "Action: [-0.4  0. ] | Reward: -11.940948909169297 | State: [-0.6543297  2.7732024  3.1442106] | Terminated: False | Episode Length: 6.739999999999901\n",
            "Action: [-0.4  0. ] | Reward: -11.957802405036338 | State: [-0.65292895  2.7741673   3.1442106 ] | Terminated: False | Episode Length: 6.7499999999999005\n",
            "Action: [-0.4  0. ] | Reward: -11.974630836736312 | State: [-0.65152806  2.7751274   3.1442106 ] | Terminated: False | Episode Length: 6.7599999999999\n",
            "Action: [-0.4   -0.262] | Reward: -11.99143411842804 | State: [-0.65012705  2.7760825   3.1415927 ] | Terminated: False | Episode Length: 6.7699999999999\n",
            "Action: [-0.4  0. ] | Reward: -12.00821216434122 | State: [-0.648726   2.7770329  3.1415927] | Terminated: False | Episode Length: 6.7799999999999\n",
            "Action: [-0.4  0. ] | Reward: -12.024964889145567 | State: [-0.6473248  2.7779784  3.1415927] | Terminated: False | Episode Length: 6.7899999999999\n",
            "Action: [-0.4  0. ] | Reward: -12.041692207768234 | State: [-0.6459235  2.778919   3.1415927] | Terminated: False | Episode Length: 6.7999999999998995\n",
            "Action: [-0.4  0. ] | Reward: -12.058394035394928 | State: [-0.6445222  2.7798548  3.1415927] | Terminated: False | Episode Length: 6.809999999999899\n",
            "Action: [-0.4   -0.262] | Reward: -12.07507028747103 | State: [-0.64312077  2.7807858   3.1389747 ] | Terminated: False | Episode Length: 6.819999999999899\n",
            "Action: [-0.4  0. ] | Reward: -12.091720879888614 | State: [-0.6417193  2.7817118  3.1389747] | Terminated: False | Episode Length: 6.829999999999899\n",
            "Action: [-0.4  0. ] | Reward: -12.108345728616325 | State: [-0.64031774  2.782633    3.1389747 ] | Terminated: False | Episode Length: 6.839999999999899\n",
            "Action: [-0.4  0. ] | Reward: -12.124944749885804 | State: [-0.6389161  2.7835495  3.1389747] | Terminated: False | Episode Length: 6.849999999999898\n",
            "Action: [-0.4  0. ] | Reward: -12.141517860192799 | State: [-0.6375144  2.7844613  3.1389747] | Terminated: False | Episode Length: 6.859999999999898\n",
            "Action: [-0.4   -0.262] | Reward: -12.15806497629825 | State: [-0.63611263  2.785368    3.1363566 ] | Terminated: False | Episode Length: 6.869999999999898\n",
            "Action: [-0.4  0. ] | Reward: -12.174586015791835 | State: [-0.63471085  2.78627     3.1363566 ] | Terminated: False | Episode Length: 6.879999999999898\n",
            "Action: [-0.4  0. ] | Reward: -12.191080895969856 | State: [-0.633309   2.7871668  3.1363566] | Terminated: False | Episode Length: 6.8899999999998975\n",
            "Action: [-0.4    0.524] | Reward: -12.207549534397062 | State: [-0.63190717  2.788059    3.1415927 ] | Terminated: False | Episode Length: 6.899999999999897\n",
            "Action: [-0.4   -0.262] | Reward: -12.223991848154023 | State: [-0.6305052  2.7889464  3.1389747] | Terminated: False | Episode Length: 6.909999999999897\n",
            "Action: [-0.4  0. ] | Reward: -12.240407755532082 | State: [-0.6291032  2.7898288  3.1389747] | Terminated: False | Episode Length: 6.919999999999897\n",
            "Action: [-0.4  0. ] | Reward: -12.256797174906081 | State: [-0.62770116  2.7907066   3.1389747 ] | Terminated: False | Episode Length: 6.929999999999897\n",
            "Action: [-0.4  0. ] | Reward: -12.27316002492359 | State: [-0.6262991  2.7915792  3.1389747] | Terminated: False | Episode Length: 6.9399999999998965\n",
            "Action: [-0.4  0. ] | Reward: -12.289496224505964 | State: [-0.62489694  2.7924473   3.1389747 ] | Terminated: False | Episode Length: 6.949999999999896\n",
            "Action: [-0.4  0. ] | Reward: -12.305805692849402 | State: [-0.6234948  2.7933104  3.1389747] | Terminated: False | Episode Length: 6.959999999999896\n",
            "Action: [-0.4  0. ] | Reward: -12.32208834942599 | State: [-0.62209266  2.7941687   3.1389747 ] | Terminated: False | Episode Length: 6.969999999999896\n",
            "Action: [-0.4  0. ] | Reward: -12.338344113984737 | State: [-0.62069046  2.795022    3.1389747 ] | Terminated: False | Episode Length: 6.979999999999896\n",
            "Action: [-0.4  0. ] | Reward: -12.354572906552626 | State: [-0.61928827  2.7958708   3.1389747 ] | Terminated: False | Episode Length: 6.989999999999895\n",
            "Action: [-0.4  0. ] | Reward: -12.370774647435633 | State: [-0.61788607  2.7967143   3.1389747 ] | Terminated: False | Episode Length: 6.999999999999895\n",
            "Action: [-0.4  0. ] | Reward: -12.38694925721976 | State: [-0.61648387  2.7975533   3.1389747 ] | Terminated: False | Episode Length: 7.009999999999895\n",
            "Action: [-0.4  0. ] | Reward: -12.403096656772055 | State: [-0.6150816  2.7983873  3.1389747] | Terminated: False | Episode Length: 7.019999999999895\n",
            "Action: [-0.4  0. ] | Reward: -12.419216767241632 | State: [-0.6136794  2.7992165  3.1389747] | Terminated: False | Episode Length: 7.0299999999998946\n",
            "Action: [-0.4  0. ] | Reward: -12.435309510060682 | State: [-0.61227715  2.8000407   3.1389747 ] | Terminated: False | Episode Length: 7.039999999999894\n",
            "Action: [-0.4  0. ] | Reward: -12.451374806945473 | State: [-0.61087495  2.8008602   3.1389747 ] | Terminated: False | Episode Length: 7.049999999999894\n",
            "Action: [-0.4  0. ] | Reward: -12.467412579897362 | State: [-0.6094727  2.8016748  3.1389747] | Terminated: False | Episode Length: 7.059999999999894\n",
            "Action: [-0.4  0. ] | Reward: -12.483422751203781 | State: [-0.6080705  2.8024848  3.1389747] | Terminated: False | Episode Length: 7.069999999999894\n",
            "Action: [-0.4  0. ] | Reward: -12.499405243439234 | State: [-0.6066683  2.8032897  3.1389747] | Terminated: False | Episode Length: 7.0799999999998935\n",
            "Action: [-0.4  0. ] | Reward: -12.515359979466284 | State: [-0.60526615  2.8040898   3.1389747 ] | Terminated: False | Episode Length: 7.089999999999893\n",
            "Action: [-0.4  0. ] | Reward: -12.531286882436527 | State: [-0.60386395  2.804885    3.1389747 ] | Terminated: False | Episode Length: 7.099999999999893\n",
            "Action: [-0.4  0. ] | Reward: -12.54718587579157 | State: [-0.6024619  2.8056753  3.1389747] | Terminated: False | Episode Length: 7.109999999999893\n",
            "Action: [-0.4  0. ] | Reward: -12.563056883264004 | State: [-0.60105973  2.8064609   3.1389747 ] | Terminated: False | Episode Length: 7.119999999999893\n",
            "Action: [-0.4  0. ] | Reward: -12.578899828878363 | State: [-0.59965765  2.8072414   3.1389747 ] | Terminated: False | Episode Length: 7.129999999999892\n",
            "Action: [-0.4  0. ] | Reward: -12.594714636952087 | State: [-0.59825563  2.8080173   3.1389747 ] | Terminated: False | Episode Length: 7.139999999999892\n",
            "Action: [-0.4  0. ] | Reward: -12.610501232096473 | State: [-0.5968537  2.8087883  3.1389747] | Terminated: False | Episode Length: 7.149999999999892\n",
            "Action: [-0.4  0. ] | Reward: -12.626259539217623 | State: [-0.5954517  2.8095546  3.1389747] | Terminated: False | Episode Length: 7.159999999999892\n",
            "Action: [-0.4  0. ] | Reward: -12.641989483517388 | State: [-0.5940498  2.8103158  3.1389747] | Terminated: False | Episode Length: 7.169999999999892\n",
            "Action: [-0.4  0. ] | Reward: -12.657690990494308 | State: [-0.59264797  2.8110723   3.1389747 ] | Terminated: False | Episode Length: 7.179999999999891\n",
            "Action: [-0.4  0. ] | Reward: -12.673363985944533 | State: [-0.5912461  2.8118238  3.1389747] | Terminated: False | Episode Length: 7.189999999999891\n",
            "Action: [-0.4  0. ] | Reward: -12.689008395962762 | State: [-0.5898444  2.8125706  3.1389747] | Terminated: False | Episode Length: 7.199999999999891\n",
            "Action: [-0.4  0. ] | Reward: -12.704624146943159 | State: [-0.58844274  2.8133125   3.1389747 ] | Terminated: False | Episode Length: 7.209999999999891\n",
            "Action: [-0.4  0. ] | Reward: -12.72021116558026 | State: [-0.5870411  2.8140497  3.1389747] | Terminated: False | Episode Length: 7.2199999999998905\n",
            "Action: [-0.4  0. ] | Reward: -12.735769378869895 | State: [-0.58563954  2.814782    3.1389747 ] | Terminated: False | Episode Length: 7.22999999999989\n",
            "Action: [-0.4  0. ] | Reward: -12.751298714110085 | State: [-0.58423805  2.8155093   3.1389747 ] | Terminated: False | Episode Length: 7.23999999999989\n",
            "Action: [-0.4  0. ] | Reward: -12.76679909890194 | State: [-0.5828367  2.8162317  3.1389747] | Terminated: False | Episode Length: 7.24999999999989\n",
            "Action: [-0.4  0. ] | Reward: -12.782270461150553 | State: [-0.5814354  2.8169494  3.1389747] | Terminated: False | Episode Length: 7.25999999999989\n",
            "Action: [-0.4  0. ] | Reward: -12.797712729065884 | State: [-0.58003414  2.8176622   3.1389747 ] | Terminated: False | Episode Length: 7.269999999999889\n",
            "Action: [-0.4  0. ] | Reward: -12.813125831163648 | State: [-0.57863295  2.8183703   3.1389747 ] | Terminated: False | Episode Length: 7.279999999999889\n",
            "Action: [-0.4  0. ] | Reward: -12.82850969626618 | State: [-0.5772319  2.8190734  3.1389747] | Terminated: False | Episode Length: 7.289999999999889\n",
            "Action: [-0.4  0. ] | Reward: -12.843864253503314 | State: [-0.57583094  2.8197718   3.1389747 ] | Terminated: False | Episode Length: 7.299999999999889\n",
            "Action: [-0.4  0. ] | Reward: -12.859189432313244 | State: [-0.57443005  2.8204653   3.1389747 ] | Terminated: False | Episode Length: 7.309999999999889\n",
            "Action: [-0.4  0. ] | Reward: -12.874485162443376 | State: [-0.5730293  2.8211539  3.1389747] | Terminated: False | Episode Length: 7.319999999999888\n",
            "Action: [-0.4  0. ] | Reward: -12.889751373951189 | State: [-0.5716286  2.8218377  3.1389747] | Terminated: False | Episode Length: 7.329999999999888\n",
            "Action: [-0.4  0. ] | Reward: -12.904987997205076 | State: [-0.57022804  2.8225167   3.1389747 ] | Terminated: False | Episode Length: 7.339999999999888\n",
            "Action: [-0.4  0. ] | Reward: -12.920194962885187 | State: [-0.56882757  2.823191    3.1389747 ] | Terminated: False | Episode Length: 7.349999999999888\n",
            "Action: [-0.4  0. ] | Reward: -12.935372201984261 | State: [-0.5674272  2.8238602  3.1389747] | Terminated: False | Episode Length: 7.3599999999998875\n",
            "Action: [-0.4  0. ] | Reward: -12.95051964580846 | State: [-0.56602705  2.8245246   3.1389747 ] | Terminated: False | Episode Length: 7.369999999999887\n",
            "Action: [-0.4  0. ] | Reward: -12.965637225978186 | State: [-0.56462693  2.8251843   3.1389747 ] | Terminated: False | Episode Length: 7.379999999999887\n",
            "Action: [-0.4  0. ] | Reward: -12.9807248744289 | State: [-0.56322694  2.825839    3.1389747 ] | Terminated: False | Episode Length: 7.389999999999887\n",
            "Action: [-0.4  0. ] | Reward: -12.99578252341193 | State: [-0.5618271  2.826489   3.1389747] | Terminated: False | Episode Length: 7.399999999999887\n",
            "Action: [-0.4  0. ] | Reward: -13.010810105495288 | State: [-0.56042737  2.8271341   3.1389747 ] | Terminated: False | Episode Length: 7.4099999999998865\n",
            "Action: [-0.4  0. ] | Reward: -13.025807553564453 | State: [-0.5590278  2.8277745  3.1389747] | Terminated: False | Episode Length: 7.419999999999886\n",
            "Action: [-0.4  0. ] | Reward: -13.040774800823172 | State: [-0.55762833  2.82841     3.1389747 ] | Terminated: False | Episode Length: 7.429999999999886\n",
            "Action: [-0.4  0. ] | Reward: -13.05571178079425 | State: [-0.55622905  2.8290405   3.1389747 ] | Terminated: False | Episode Length: 7.439999999999886\n",
            "Action: [-0.4  0. ] | Reward: -13.070618427320323 | State: [-0.5548299  2.8296664  3.1389747] | Terminated: False | Episode Length: 7.449999999999886\n",
            "Action: [-0.4  0. ] | Reward: -13.08549467456464 | State: [-0.5534309  2.8302872  3.1389747] | Terminated: False | Episode Length: 7.459999999999885\n",
            "Action: [-0.4  0. ] | Reward: -13.100340457011827 | State: [-0.55203205  2.8309035   3.1389747 ] | Terminated: False | Episode Length: 7.469999999999885\n",
            "Action: [-0.4  0. ] | Reward: -13.115155709468652 | State: [-0.5506334  2.8315148  3.1389747] | Terminated: False | Episode Length: 7.479999999999885\n",
            "Action: [-0.4  0. ] | Reward: -13.129940367064783 | State: [-0.54923487  2.8321214   3.1389747 ] | Terminated: False | Episode Length: 7.489999999999885\n",
            "Action: [-0.4  0. ] | Reward: -13.144694365253537 | State: [-0.5478365  2.832723   3.1389747] | Terminated: False | Episode Length: 7.4999999999998845\n",
            "Action: [-0.4  0. ] | Reward: -13.15941763981262 | State: [-0.5464383  2.83332    3.1389747] | Terminated: False | Episode Length: 7.509999999999884\n",
            "Action: [-0.4  0. ] | Reward: -13.174110126844873 | State: [-0.54504025  2.833912    3.1389747 ] | Terminated: False | Episode Length: 7.519999999999884\n",
            "Action: [-0.4  0. ] | Reward: -13.188771762779 | State: [-0.5436424  2.8344991  3.1389747] | Terminated: False | Episode Length: 7.529999999999884\n",
            "Action: [-0.4  0. ] | Reward: -13.203402484370294 | State: [-0.54224473  2.8350813   3.1389747 ] | Terminated: False | Episode Length: 7.539999999999884\n",
            "Action: [-0.4  0. ] | Reward: -13.218002228701355 | State: [-0.54084724  2.835659    3.1389747 ] | Terminated: False | Episode Length: 7.5499999999998835\n",
            "Action: [-0.4  0. ] | Reward: -13.232570933182808 | State: [-0.53944993  2.8362317   3.1389747 ] | Terminated: False | Episode Length: 7.559999999999883\n",
            "Action: [-0.4  0. ] | Reward: -13.247108535554005 | State: [-0.5380528  2.8367996  3.1389747] | Terminated: False | Episode Length: 7.569999999999883\n",
            "Action: [-0.4  0. ] | Reward: -13.26161497388373 | State: [-0.5366559  2.8373628  3.1389747] | Terminated: False | Episode Length: 7.579999999999883\n",
            "Action: [-0.4  0. ] | Reward: -13.276090186570892 | State: [-0.5352591  2.8379211  3.1389747] | Terminated: False | Episode Length: 7.589999999999883\n",
            "Action: [-0.4  0. ] | Reward: -13.29053411234521 | State: [-0.5338626  2.8384745  3.1389747] | Terminated: False | Episode Length: 7.599999999999882\n",
            "Action: [-0.4  0. ] | Reward: -13.304946690267903 | State: [-0.5324663  2.8390234  3.1389747] | Terminated: False | Episode Length: 7.609999999999882\n",
            "Action: [-0.4  0. ] | Reward: -13.319327859732356 | State: [-0.5310702  2.8395672  3.1389747] | Terminated: False | Episode Length: 7.619999999999882\n",
            "Action: [-0.4  0. ] | Reward: -13.333677560464798 | State: [-0.52967423  2.8401062   3.1389747 ] | Terminated: False | Episode Length: 7.629999999999882\n",
            "Action: [-0.4  0. ] | Reward: -13.34799573252496 | State: [-0.5282786  2.8406405  3.1389747] | Terminated: False | Episode Length: 7.6399999999998816\n",
            "Action: [-0.4  0. ] | Reward: -13.362282316306736 | State: [-0.52688307  2.8411698   3.1389747 ] | Terminated: False | Episode Length: 7.649999999999881\n",
            "Action: [-0.4  0. ] | Reward: -13.376537252538824 | State: [-0.52548784  2.8416946   3.1389747 ] | Terminated: False | Episode Length: 7.659999999999881\n",
            "Action: [-0.4  0. ] | Reward: -13.390760482285383 | State: [-0.5240928  2.8422143  3.1389747] | Terminated: False | Episode Length: 7.669999999999881\n",
            "Action: [-0.4  0. ] | Reward: -13.404951946946662 | State: [-0.522698   2.8427293  3.1389747] | Terminated: False | Episode Length: 7.679999999999881\n",
            "Action: [-0.4  0. ] | Reward: -13.419111588259632 | State: [-0.5213034  2.8432395  3.1389747] | Terminated: False | Episode Length: 7.6899999999998805\n",
            "Action: [-0.4  0. ] | Reward: -13.433239348298612 | State: [-0.5199091  2.843745   3.1389747] | Terminated: False | Episode Length: 7.69999999999988\n",
            "Action: [-0.4  0. ] | Reward: -13.447335169475888 | State: [-0.51851493  2.8442457   3.1389747 ] | Terminated: False | Episode Length: 7.70999999999988\n",
            "Action: [-0.4  0. ] | Reward: -13.461398994542325 | State: [-0.5171211  2.8447416  3.1389747] | Terminated: False | Episode Length: 7.71999999999988\n",
            "Action: [-0.4  0. ] | Reward: -13.475430766587971 | State: [-0.51572746  2.8452325   3.1389747 ] | Terminated: False | Episode Length: 7.72999999999988\n",
            "Action: [-0.4  0. ] | Reward: -13.489430429042654 | State: [-0.51433414  2.8457189   3.1389747 ] | Terminated: False | Episode Length: 7.739999999999879\n",
            "Action: [-0.4  0. ] | Reward: -13.50339792567658 | State: [-0.512941   2.8462002  3.1389747] | Terminated: False | Episode Length: 7.749999999999879\n",
            "Action: [-0.4  0. ] | Reward: -13.517333200600916 | State: [-0.51154816  2.846677    3.1389747 ] | Terminated: False | Episode Length: 7.759999999999879\n",
            "Action: [-0.4  0. ] | Reward: -13.531236198268367 | State: [-0.51015556  2.847149    3.1389747 ] | Terminated: False | Episode Length: 7.769999999999879\n",
            "Action: [-0.4  0. ] | Reward: -13.545106863473752 | State: [-0.5087632  2.847616   3.1389747] | Terminated: False | Episode Length: 7.779999999999879\n",
            "Action: [-0.4  0. ] | Reward: -13.55894514135457 | State: [-0.5073711  2.8480783  3.1389747] | Terminated: False | Episode Length: 7.789999999999878\n",
            "Action: [-0.4  0. ] | Reward: -13.57275097739156 | State: [-0.50597936  2.8485358   3.1389747 ] | Terminated: False | Episode Length: 7.799999999999878\n",
            "Action: [-0.4  0. ] | Reward: -13.586524317409253 | State: [-0.5045878  2.8489885  3.1389747] | Terminated: False | Episode Length: 7.809999999999878\n",
            "Action: [-0.4  0. ] | Reward: -13.600265107576522 | State: [-0.50319654  2.8494365   3.1389747 ] | Terminated: False | Episode Length: 7.819999999999878\n",
            "Action: [-0.4  0. ] | Reward: -13.613973294407117 | State: [-0.5018056  2.8498797  3.1389747] | Terminated: False | Episode Length: 7.8299999999998775\n",
            "Action: [-0.4  0. ] | Reward: -13.627648824760202 | State: [-0.5004149  2.8503182  3.1389747] | Terminated: False | Episode Length: 7.839999999999877\n",
            "Action: [-0.4  0. ] | Reward: -13.641291645840884 | State: [-0.4990245  2.8507519  3.1389747] | Terminated: False | Episode Length: 7.849999999999877\n",
            "Action: [-0.4  0. ] | Reward: -13.654901705200729 | State: [-0.4976344  2.8511806  3.1389747] | Terminated: False | Episode Length: 7.859999999999877\n",
            "Action: [-0.4  0. ] | Reward: -13.66847895073828 | State: [-0.4962446  2.8516047  3.1389747] | Terminated: False | Episode Length: 7.869999999999877\n",
            "Action: [-0.4  0. ] | Reward: -13.68202333069956 | State: [-0.49485508  2.852024    3.1389747 ] | Terminated: False | Episode Length: 7.879999999999876\n",
            "Action: [-0.4  0. ] | Reward: -13.695534793678576 | State: [-0.49346587  2.8524387   3.1389747 ] | Terminated: False | Episode Length: 7.889999999999876\n",
            "Action: [-0.4  0. ] | Reward: -13.709013288617813 | State: [-0.49207696  2.8528485   3.1389747 ] | Terminated: False | Episode Length: 7.899999999999876\n",
            "Action: [-0.4  0. ] | Reward: -13.72245876480872 | State: [-0.49068838  2.8532534   3.1389747 ] | Terminated: False | Episode Length: 7.909999999999876\n",
            "Action: [-0.4  0. ] | Reward: -13.735871171892192 | State: [-0.48930007  2.8536537   3.1389747 ] | Terminated: False | Episode Length: 7.919999999999876\n",
            "Action: [-0.4  0. ] | Reward: -13.74925045985904 | State: [-0.48791212  2.8540492   3.1389747 ] | Terminated: False | Episode Length: 7.929999999999875\n",
            "Action: [-0.4  0. ] | Reward: -13.762596579050465 | State: [-0.48652446  2.85444     3.1389747 ] | Terminated: False | Episode Length: 7.939999999999875\n",
            "Action: [-0.4  0. ] | Reward: -13.775909480158514 | State: [-0.48513713  2.854826    3.1389747 ] | Terminated: False | Episode Length: 7.949999999999875\n",
            "Action: [-0.4  0. ] | Reward: -13.789189114226536 | State: [-0.48375013  2.8552072   3.1389747 ] | Terminated: False | Episode Length: 7.959999999999875\n",
            "Action: [-0.4  0. ] | Reward: -13.80243543264963 | State: [-0.48236346  2.8555837   3.1389747 ] | Terminated: False | Episode Length: 7.9699999999998745\n",
            "Action: [-0.4  0. ] | Reward: -13.815648387175084 | State: [-0.48097715  2.8559556   3.1389747 ] | Terminated: False | Episode Length: 7.979999999999874\n",
            "Action: [-0.4  0. ] | Reward: -13.82882792990281 | State: [-0.47959113  2.8563225   3.1389747 ] | Terminated: False | Episode Length: 7.989999999999874\n",
            "Action: [-0.4  0. ] | Reward: -13.841974013285771 | State: [-0.47820547  2.8566847   3.1389747 ] | Terminated: False | Episode Length: 7.999999999999874\n",
            "Action: [-0.4  0. ] | Reward: -13.855086590130403 | State: [-0.47682014  2.8570423   3.1389747 ] | Terminated: False | Episode Length: 8.009999999999874\n",
            "Action: [-0.4  0. ] | Reward: -13.868165613597029 | State: [-0.4754352  2.8573952  3.1389747] | Terminated: False | Episode Length: 8.019999999999873\n",
            "Action: [-0.4  0. ] | Reward: -13.881211037200261 | State: [-0.47405058  2.857743    3.1389747 ] | Terminated: False | Episode Length: 8.029999999999873\n",
            "Action: [-0.4  0. ] | Reward: -13.894222814809408 | State: [-0.4726663  2.8580863  3.1389747] | Terminated: False | Episode Length: 8.039999999999873\n",
            "Action: [-0.4  0. ] | Reward: -13.907200900648867 | State: [-0.4712824  2.858425   3.1389747] | Terminated: False | Episode Length: 8.049999999999873\n",
            "Action: [-0.4  0. ] | Reward: -13.920145249298509 | State: [-0.46989885  2.858759    3.1389747 ] | Terminated: False | Episode Length: 8.059999999999873\n",
            "Action: [-0.4  0. ] | Reward: -13.93305581569406 | State: [-0.46851566  2.859088    3.1389747 ] | Terminated: False | Episode Length: 8.069999999999872\n",
            "Action: [-0.4  0. ] | Reward: -13.945932555127474 | State: [-0.46713287  2.8594124   3.1389747 ] | Terminated: False | Episode Length: 8.079999999999872\n",
            "Action: [-0.4  0. ] | Reward: -13.958775423247303 | State: [-0.46575043  2.859732    3.1389747 ] | Terminated: False | Episode Length: 8.089999999999872\n",
            "Action: [-0.4  0. ] | Reward: -13.971584376059052 | State: [-0.46436834  2.8600469   3.1389747 ] | Terminated: False | Episode Length: 8.099999999999872\n",
            "Action: [-0.4  0. ] | Reward: -13.984359369925537 | State: [-0.46298668  2.8603573   3.1389747 ] | Terminated: False | Episode Length: 8.109999999999872\n",
            "Action: [-0.4  0. ] | Reward: -13.99710036156723 | State: [-0.46160537  2.8606627   3.1389747 ] | Terminated: False | Episode Length: 8.119999999999871\n",
            "Action: [-0.4  0. ] | Reward: -14.009807308062594 | State: [-0.46022445  2.8609633   3.1389747 ] | Terminated: False | Episode Length: 8.129999999999871\n",
            "Action: [-0.4  0. ] | Reward: -14.02248016684843 | State: [-0.45884392  2.8612595   3.1389747 ] | Terminated: False | Episode Length: 8.139999999999871\n",
            "Action: [-0.4  0. ] | Reward: -14.035118895720188 | State: [-0.45746377  2.8615508   3.1389747 ] | Terminated: False | Episode Length: 8.14999999999987\n",
            "Action: [-0.4  0. ] | Reward: -14.047723452832296 | State: [-0.45608404  2.8618376   3.1389747 ] | Terminated: False | Episode Length: 8.15999999999987\n",
            "Action: [-0.4  0. ] | Reward: -14.060293796698467 | State: [-0.4547047  2.8621194  3.1389747] | Terminated: False | Episode Length: 8.16999999999987\n",
            "Action: [-0.4  0. ] | Reward: -14.07282988619201 | State: [-0.45332575  2.8623967   3.1389747 ] | Terminated: False | Episode Length: 8.17999999999987\n",
            "Action: [-0.4  0. ] | Reward: -14.085331680546126 | State: [-0.4519472  2.8626692  3.1389747] | Terminated: False | Episode Length: 8.18999999999987\n",
            "Action: [-0.4  0. ] | Reward: -14.097799139354207 | State: [-0.4505691  2.8629372  3.1389747] | Terminated: False | Episode Length: 8.19999999999987\n",
            "Action: [-0.4  0. ] | Reward: -14.11023222257011 | State: [-0.4491914  2.8632004  3.1389747] | Terminated: False | Episode Length: 8.20999999999987\n",
            "Action: [-0.4  0. ] | Reward: -14.122630890508447 | State: [-0.4478141  2.8634589  3.1389747] | Terminated: False | Episode Length: 8.21999999999987\n",
            "Action: [-0.4  0. ] | Reward: -14.134995103844853 | State: [-0.4464372  2.8637125  3.1389747] | Terminated: False | Episode Length: 8.229999999999869\n",
            "Action: [-0.4  0. ] | Reward: -14.14732482361625 | State: [-0.4450608  2.8639617  3.1389747] | Terminated: False | Episode Length: 8.239999999999869\n",
            "Action: [-0.4  0. ] | Reward: -14.15962001122111 | State: [-0.44368476  2.864206    3.1389747 ] | Terminated: False | Episode Length: 8.249999999999869\n",
            "Action: [-0.4  0. ] | Reward: -14.171880628419702 | State: [-0.44230917  2.864446    3.1389747 ] | Terminated: False | Episode Length: 8.259999999999868\n",
            "Action: [-0.4  0. ] | Reward: -14.184106637334343 | State: [-0.440934   2.8646808  3.1389747] | Terminated: False | Episode Length: 8.269999999999868\n",
            "Action: [-0.4  0. ] | Reward: -14.196298000449632 | State: [-0.43955928  2.8649113   3.1389747 ] | Terminated: False | Episode Length: 8.279999999999868\n",
            "Action: [-0.4  0. ] | Reward: -14.20845468061268 | State: [-0.438185   2.8651369  3.1389747] | Terminated: False | Episode Length: 8.289999999999868\n",
            "Action: [-0.4  0. ] | Reward: -14.220576641033341 | State: [-0.43681118  2.8653579   3.1389747 ] | Terminated: False | Episode Length: 8.299999999999867\n",
            "Action: [-0.4  0. ] | Reward: -14.232663845284428 | State: [-0.4354378  2.8655744  3.1389747] | Terminated: False | Episode Length: 8.309999999999867\n",
            "Action: [-0.4  0. ] | Reward: -14.24471625730192 | State: [-0.43406487  2.865786    3.1389747 ] | Terminated: False | Episode Length: 8.319999999999867\n",
            "Action: [-0.4  0. ] | Reward: -14.256733841385174 | State: [-0.43269238  2.865993    3.1389747 ] | Terminated: False | Episode Length: 8.329999999999867\n",
            "Action: [-0.4  0. ] | Reward: -14.268716562197115 | State: [-0.43132037  2.8661954   3.1389747 ] | Terminated: False | Episode Length: 8.339999999999867\n",
            "Action: [-0.4  0. ] | Reward: -14.280664384764433 | State: [-0.4299488  2.866393   3.1389747] | Terminated: False | Episode Length: 8.349999999999866\n",
            "Action: [-0.4  0. ] | Reward: -14.292577274477768 | State: [-0.42857772  2.8665862   3.1389747 ] | Terminated: False | Episode Length: 8.359999999999866\n",
            "Action: [-0.4  0. ] | Reward: -14.304455197091881 | State: [-0.4272071  2.8667746  3.1389747] | Terminated: False | Episode Length: 8.369999999999866\n",
            "Action: [-0.4  0. ] | Reward: -14.31629811872583 | State: [-0.42583695  2.8669584   3.1389747 ] | Terminated: False | Episode Length: 8.379999999999866\n",
            "Action: [-0.4  0. ] | Reward: -14.328106005863136 | State: [-0.42446727  2.8671374   3.1389747 ] | Terminated: False | Episode Length: 8.389999999999866\n",
            "Action: [-0.4  0. ] | Reward: -14.339878825351931 | State: [-0.4230981  2.867312   3.1389747] | Terminated: False | Episode Length: 8.399999999999865\n",
            "Action: [-0.4  0. ] | Reward: -14.351616544405122 | State: [-0.4217294  2.867482   3.1389747] | Terminated: False | Episode Length: 8.409999999999865\n",
            "Action: [-0.4  0. ] | Reward: -14.363319130600523 | State: [-0.42036116  2.8676472   3.1389747 ] | Terminated: False | Episode Length: 8.419999999999865\n",
            "Action: [-0.4  0. ] | Reward: -14.374986551881 | State: [-0.4189934  2.8678076  3.1389747] | Terminated: False | Episode Length: 8.429999999999865\n",
            "Action: [-0.4  0. ] | Reward: -14.386618776554595 | State: [-0.41762617  2.8679636   3.1389747 ] | Terminated: False | Episode Length: 8.439999999999864\n",
            "Action: [-0.4  0. ] | Reward: -14.398215773294659 | State: [-0.4162594  2.868115   3.1389747] | Terminated: False | Episode Length: 8.449999999999864\n",
            "Action: [-0.4  0. ] | Reward: -14.409777511139957 | State: [-0.41489318  2.8682616   3.1389747 ] | Terminated: False | Episode Length: 8.459999999999864\n",
            "Action: [-0.4  0. ] | Reward: -14.421303959494788 | State: [-0.41352743  2.8684037   3.1389747 ] | Terminated: False | Episode Length: 8.469999999999864\n",
            "Action: [-0.4  0. ] | Reward: -14.432795088129081 | State: [-0.41216218  2.8685412   3.1389747 ] | Terminated: False | Episode Length: 8.479999999999864\n",
            "Action: [-0.4  0. ] | Reward: -14.4442508671785 | State: [-0.41079745  2.868674    3.1389747 ] | Terminated: False | Episode Length: 8.489999999999863\n",
            "Action: [-0.4  0. ] | Reward: -14.455671267144528 | State: [-0.40943325  2.8688023   3.1389747 ] | Terminated: False | Episode Length: 8.499999999999863\n",
            "Action: [-0.4  0. ] | Reward: -14.46705625889455 | State: [-0.40806955  2.8689258   3.1389747 ] | Terminated: False | Episode Length: 8.509999999999863\n",
            "Action: [-0.4  0. ] | Reward: -14.478405813661935 | State: [-0.40670636  2.8690448   3.1389747 ] | Terminated: False | Episode Length: 8.519999999999863\n",
            "Action: [-0.4  0. ] | Reward: -14.489719903046101 | State: [-0.4053437  2.8691592  3.1389747] | Terminated: False | Episode Length: 8.529999999999863\n",
            "Action: [-0.4  0. ] | Reward: -14.500998499012583 | State: [-0.4039816  2.8692691  3.1389747] | Terminated: False | Episode Length: 8.539999999999862\n",
            "Action: [-0.4  0. ] | Reward: -14.512241573893084 | State: [-0.40262    2.8693743  3.1389747] | Terminated: False | Episode Length: 8.549999999999862\n",
            "Action: [-0.4  0. ] | Reward: -14.523449100385527 | State: [-0.40125895  2.8694751   3.1389747 ] | Terminated: False | Episode Length: 8.559999999999862\n",
            "Action: [-0.4  0. ] | Reward: -14.534621051554103 | State: [-0.3998984  2.869571   3.1389747] | Terminated: False | Episode Length: 8.569999999999862\n",
            "Action: [-0.4  0. ] | Reward: -14.545757400829302 | State: [-0.39853844  2.8696625   3.1389747 ] | Terminated: False | Episode Length: 8.579999999999862\n",
            "Action: [-0.4  0. ] | Reward: -14.556858122007945 | State: [-0.397179   2.8697495  3.1389747] | Terminated: False | Episode Length: 8.589999999999861\n",
            "Action: [-0.4  0. ] | Reward: -14.567923189253207 | State: [-0.3958201  2.8698318  3.1389747] | Terminated: False | Episode Length: 8.599999999999861\n",
            "Action: [-0.4  0. ] | Reward: -14.578952577094634 | State: [-0.39446178  2.8699095   3.1389747 ] | Terminated: False | Episode Length: 8.60999999999986\n",
            "Action: [-0.4  0. ] | Reward: -14.589946260428155 | State: [-0.393104   2.8699827  3.1389747] | Terminated: False | Episode Length: 8.61999999999986\n",
            "Action: [-0.4  0. ] | Reward: -14.600904214516083 | State: [-0.39174676  2.8700511   3.1389747 ] | Terminated: False | Episode Length: 8.62999999999986\n",
            "Action: [-0.4  0. ] | Reward: -14.611826414987112 | State: [-0.3903901  2.8701153  3.1389747] | Terminated: False | Episode Length: 8.63999999999986\n",
            "Action: [-0.4  0. ] | Reward: -14.622712837836309 | State: [-0.389034   2.870175   3.1389747] | Terminated: False | Episode Length: 8.64999999999986\n",
            "Action: [-0.4  0. ] | Reward: -14.633563459425094 | State: [-0.38767847  2.8702297   3.1389747 ] | Terminated: False | Episode Length: 8.65999999999986\n",
            "Action: [-0.4  0. ] | Reward: -14.644378256481225 | State: [-0.3863235  2.87028    3.1389747] | Terminated: False | Episode Length: 8.66999999999986\n",
            "Action: [-0.4  0. ] | Reward: -14.65515720609876 | State: [-0.38496912  2.8703258   3.1389747 ] | Terminated: False | Episode Length: 8.67999999999986\n",
            "Action: [-0.4  0. ] | Reward: -14.665900285738024 | State: [-0.38361531  2.870367    3.1389747 ] | Terminated: False | Episode Length: 8.68999999999986\n",
            "Action: [-0.4  0. ] | Reward: -14.676607473225568 | State: [-0.38226208  2.8704038   3.1389747 ] | Terminated: False | Episode Length: 8.699999999999859\n",
            "Action: [-0.4  0. ] | Reward: -14.687278746754119 | State: [-0.38090944  2.8704362   3.1389747 ] | Terminated: False | Episode Length: 8.709999999999859\n",
            "Action: [-0.4  0. ] | Reward: -14.697914084882525 | State: [-0.3795574  2.8704638  3.1389747] | Terminated: False | Episode Length: 8.719999999999859\n",
            "Action: [-0.4  0. ] | Reward: -14.708513466535688 | State: [-0.37820596  2.870487    3.1389747 ] | Terminated: False | Episode Length: 8.729999999999858\n",
            "Action: [-0.4  0. ] | Reward: -14.719076871004503 | State: [-0.37685508  2.8705056   3.1389747 ] | Terminated: False | Episode Length: 8.739999999999858\n",
            "Action: [-0.4  0. ] | Reward: -14.729604277945779 | State: [-0.37550482  2.8705196   3.1389747 ] | Terminated: False | Episode Length: 8.749999999999858\n",
            "Action: [-0.4  0. ] | Reward: -14.740095667382155 | State: [-0.37415516  2.8705292   3.1389747 ] | Terminated: False | Episode Length: 8.759999999999858\n",
            "Action: [-0.4  0. ] | Reward: -14.750551019702016 | State: [-0.3728061  2.8705342  3.1389747] | Terminated: False | Episode Length: 8.769999999999857\n",
            "Action: [-0.4  0. ] | Reward: -14.760970315659394 | State: [-0.37145764  2.8705347   3.1389747 ] | Terminated: False | Episode Length: 8.779999999999857\n",
            "Action: [-0.4  0. ] | Reward: -14.771353536373873 | State: [-0.37010983  2.8705306   3.1389747 ] | Terminated: False | Episode Length: 8.789999999999857\n",
            "Action: [-0.4  0. ] | Reward: -14.781700663330474 | State: [-0.36876258  2.8705223   3.1389747 ] | Terminated: False | Episode Length: 8.799999999999857\n",
            "Action: [-0.4  0. ] | Reward: -14.792011678379547 | State: [-0.367416   2.8705091  3.1389747] | Terminated: False | Episode Length: 8.809999999999857\n",
            "Action: [-0.4  0. ] | Reward: -14.802286563736647 | State: [-0.36607003  2.8704917   3.1389747 ] | Terminated: False | Episode Length: 8.819999999999856\n",
            "Action: [-0.4  0. ] | Reward: -14.81252530198241 | State: [-0.36472467  2.8704698   3.1389747 ] | Terminated: False | Episode Length: 8.829999999999856\n",
            "Action: [-0.4  0. ] | Reward: -14.822727876062416 | State: [-0.36337996  2.870443    3.1389747 ] | Terminated: False | Episode Length: 8.839999999999856\n",
            "Action: [-0.4  0. ] | Reward: -14.832894269287051 | State: [-0.36203587  2.8704123   3.1389747 ] | Terminated: False | Episode Length: 8.849999999999856\n",
            "Action: [-0.4  0. ] | Reward: -14.843024465331364 | State: [-0.3606924  2.8703768  3.1389747] | Terminated: False | Episode Length: 8.859999999999856\n",
            "Action: [-0.4  0. ] | Reward: -14.85311844823491 | State: [-0.35934958  2.8703368   3.1389747 ] | Terminated: False | Episode Length: 8.869999999999855\n",
            "Action: [-0.4  0. ] | Reward: -14.863176202401593 | State: [-0.35800743  2.8702924   3.1389747 ] | Terminated: False | Episode Length: 8.879999999999855\n",
            "Action: [-0.4  0. ] | Reward: -14.873197712599502 | State: [-0.35666588  2.8702435   3.1389747 ] | Terminated: False | Episode Length: 8.889999999999855\n",
            "Action: [-0.4  0. ] | Reward: -14.883182963960737 | State: [-0.355325   2.8701904  3.1389747] | Terminated: False | Episode Length: 8.899999999999855\n",
            "Action: [-0.4  0. ] | Reward: -14.893131941981231 | State: [-0.3539848  2.8701324  3.1389747] | Terminated: False | Episode Length: 8.909999999999854\n",
            "Action: [-0.4  0. ] | Reward: -14.903044632520574 | State: [-0.35264522  2.8700702   3.1389747 ] | Terminated: False | Episode Length: 8.919999999999854\n",
            "Action: [-0.4  0. ] | Reward: -14.91292102180181 | State: [-0.35130632  2.8700035   3.1389747 ] | Terminated: False | Episode Length: 8.929999999999854\n",
            "Action: [-0.4  0. ] | Reward: -14.922761096411246 | State: [-0.34996808  2.8699324   3.1389747 ] | Terminated: False | Episode Length: 8.939999999999854\n",
            "Action: [-0.4  0. ] | Reward: -14.932564843298257 | State: [-0.3486305  2.8698568  3.1389747] | Terminated: False | Episode Length: 8.949999999999854\n",
            "Action: [-0.4  0. ] | Reward: -14.942332249775061 | State: [-0.3472936  2.8697767  3.1389747] | Terminated: False | Episode Length: 8.959999999999853\n",
            "Action: [-0.4  0. ] | Reward: -14.952063303516518 | State: [-0.34595737  2.8696923   3.1389747 ] | Terminated: False | Episode Length: 8.969999999999853\n",
            "Action: [-0.4  0. ] | Reward: -14.961757992559896 | State: [-0.3446218  2.8696034  3.1389747] | Terminated: False | Episode Length: 8.979999999999853\n",
            "Action: [-0.4  0. ] | Reward: -14.971416305304658 | State: [-0.34328693  2.86951     3.1389747 ] | Terminated: False | Episode Length: 8.989999999999853\n",
            "Action: [-0.4  0. ] | Reward: -14.981038230512212 | State: [-0.3419527  2.8694122  3.1389747] | Terminated: False | Episode Length: 8.999999999999853\n",
            "Action: [-0.4  0. ] | Reward: -14.990623757305682 | State: [-0.3406192  2.86931    3.1389747] | Terminated: False | Episode Length: 9.009999999999852\n",
            "Action: [-0.4  0. ] | Reward: -15.000172875169659 | State: [-0.3392864  2.8692033  3.1389747] | Terminated: False | Episode Length: 9.019999999999852\n",
            "Action: [-0.4  0. ] | Reward: -15.009685573949943 | State: [-0.33795428  2.8690925   3.1389747 ] | Terminated: False | Episode Length: 9.029999999999852\n",
            "Action: [-0.4  0. ] | Reward: -15.019161843853292 | State: [-0.33662283  2.8689768   3.1389747 ] | Terminated: False | Episode Length: 9.039999999999852\n",
            "Action: [-0.4  0. ] | Reward: -15.028601675447154 | State: [-0.3352921  2.8688571  3.1389747] | Terminated: False | Episode Length: 9.049999999999851\n",
            "Action: [-0.4  0. ] | Reward: -15.038005059659396 | State: [-0.33396208  2.868733    3.1389747 ] | Terminated: False | Episode Length: 9.059999999999851\n",
            "Action: [-0.4  0. ] | Reward: -15.047371987778027 | State: [-0.33263275  2.8686042   3.1389747 ] | Terminated: False | Episode Length: 9.069999999999851\n",
            "Action: [-0.4  0. ] | Reward: -15.056702451450915 | State: [-0.33130416  2.8684711   3.1389747 ] | Terminated: False | Episode Length: 9.07999999999985\n",
            "Action: [-0.4  0. ] | Reward: -15.0659964426855 | State: [-0.32997626  2.8683338   3.1389747 ] | Terminated: False | Episode Length: 9.08999999999985\n",
            "Action: [-0.4  0. ] | Reward: -15.075253953848497 | State: [-0.32864907  2.868192    3.1389747 ] | Terminated: False | Episode Length: 9.09999999999985\n",
            "Action: [-0.4  0. ] | Reward: -15.084474977665591 | State: [-0.3273226  2.8680458  3.1389747] | Terminated: False | Episode Length: 9.10999999999985\n",
            "Action: [-0.4  0. ] | Reward: -15.093659507221139 | State: [-0.32599688  2.8678951   3.1389747 ] | Terminated: False | Episode Length: 9.11999999999985\n",
            "Action: [-0.4  0. ] | Reward: -15.102807535957849 | State: [-0.32467186  2.8677404   3.1389747 ] | Terminated: False | Episode Length: 9.12999999999985\n",
            "Action: [-0.4  0. ] | Reward: -15.111919057676467 | State: [-0.32334757  2.8675811   3.1389747 ] | Terminated: False | Episode Length: 9.13999999999985\n",
            "Action: [-0.4  0. ] | Reward: -15.120994066535445 | State: [-0.32202402  2.8674173   3.1389747 ] | Terminated: False | Episode Length: 9.14999999999985\n",
            "Action: [-0.4  0. ] | Reward: -15.130032557050617 | State: [-0.3207012  2.8672493  3.1389747] | Terminated: False | Episode Length: 9.15999999999985\n",
            "Action: [-0.4  0. ] | Reward: -15.139034524094859 | State: [-0.31937915  2.867077    3.1389747 ] | Terminated: False | Episode Length: 9.169999999999849\n",
            "Action: [-0.4  0. ] | Reward: -15.147999962897746 | State: [-0.3180578  2.8669002  3.1389747] | Terminated: False | Episode Length: 9.179999999999849\n",
            "Action: [-0.4  0. ] | Reward: -15.156928869045203 | State: [-0.31673723  2.8667192   3.1389747 ] | Terminated: False | Episode Length: 9.189999999999849\n",
            "Action: [-0.4  0. ] | Reward: -15.165821238479152 | State: [-0.3154174  2.8665338  3.1389747] | Terminated: False | Episode Length: 9.199999999999848\n",
            "Action: [-0.4  0. ] | Reward: -15.174677067497154 | State: [-0.31409833  2.8663442   3.1389747 ] | Terminated: False | Episode Length: 9.209999999999848\n",
            "Action: [-0.4  0. ] | Reward: -15.183496352752035 | State: [-0.31278    2.8661501  3.1389747] | Terminated: False | Episode Length: 9.219999999999848\n",
            "Action: [-0.4  0. ] | Reward: -15.192279091251525 | State: [-0.31146243  2.8659518   3.1389747 ] | Terminated: False | Episode Length: 9.229999999999848\n",
            "Action: [-0.4  0. ] | Reward: -15.201025280357868 | State: [-0.31014562  2.8657491   3.1389747 ] | Terminated: False | Episode Length: 9.239999999999847\n",
            "Action: [-0.4  0. ] | Reward: -15.20973491778745 | State: [-0.30882958  2.865542    3.1389747 ] | Terminated: False | Episode Length: 9.249999999999847\n",
            "Action: [-0.4  0. ] | Reward: -15.218408001610404 | State: [-0.3075143  2.8653307  3.1389747] | Terminated: False | Episode Length: 9.259999999999847\n",
            "Action: [-0.4  0. ] | Reward: -15.227044530250215 | State: [-0.30619982  2.8651152   3.1389747 ] | Terminated: False | Episode Length: 9.269999999999847\n",
            "Action: [-0.4  0. ] | Reward: -15.23564450248332 | State: [-0.3048861  2.864895   3.1389747] | Terminated: False | Episode Length: 9.279999999999847\n",
            "Action: [-0.4  0. ] | Reward: -15.244207917438704 | State: [-0.30357316  2.864671    3.1389747 ] | Terminated: False | Episode Length: 9.289999999999846\n",
            "Action: [-0.4  0. ] | Reward: -15.252734774597483 | State: [-0.30226102  2.8644423   3.1389747 ] | Terminated: False | Episode Length: 9.299999999999846\n",
            "Action: [-0.4  0. ] | Reward: -15.261225073792493 | State: [-0.30094963  2.8642097   3.1389747 ] | Terminated: False | Episode Length: 9.309999999999846\n",
            "Action: [-0.4  0. ] | Reward: -15.269678815207861 | State: [-0.29963908  2.8639724   3.1389747 ] | Terminated: False | Episode Length: 9.319999999999846\n",
            "Action: [-0.4  0. ] | Reward: -15.278095999378579 | State: [-0.29832926  2.8637311   3.1389747 ] | Terminated: False | Episode Length: 9.329999999999846\n",
            "Action: [-0.4  0. ] | Reward: -15.286476627190066 | State: [-0.2970203  2.8634856  3.1389747] | Terminated: False | Episode Length: 9.339999999999845\n",
            "Action: [-0.4  0. ] | Reward: -15.294820699877734 | State: [-0.29571208  2.8632355   3.1389747 ] | Terminated: False | Episode Length: 9.349999999999845\n",
            "Action: [-0.4  0. ] | Reward: -15.303128219026538 | State: [-0.2944047  2.8629813  3.1389747] | Terminated: False | Episode Length: 9.359999999999845\n",
            "Action: [-0.4  0. ] | Reward: -15.311399186570528 | State: [-0.29309812  2.8627229   3.1389747 ] | Terminated: False | Episode Length: 9.369999999999845\n",
            "Action: [-0.4  0. ] | Reward: -15.319633604792386 | State: [-0.29179233  2.8624604   3.1389747 ] | Terminated: False | Episode Length: 9.379999999999844\n",
            "Action: [-0.4  0. ] | Reward: -15.327831476322974 | State: [-0.29048738  2.8621933   3.1389747 ] | Terminated: False | Episode Length: 9.389999999999844\n",
            "Action: [-0.4  0. ] | Reward: -15.335992804140854 | State: [-0.28918323  2.8619223   3.1389747 ] | Terminated: False | Episode Length: 9.399999999999844\n",
            "Action: [-0.4  0. ] | Reward: -15.34411759157183 | State: [-0.28787988  2.8616467   3.1389747 ] | Terminated: False | Episode Length: 9.409999999999844\n",
            "Action: [-0.4  0. ] | Reward: -15.352205842288456 | State: [-0.28657737  2.861367    3.1389747 ] | Terminated: False | Episode Length: 9.419999999999844\n",
            "Action: [-0.4  0. ] | Reward: -15.360257560309558 | State: [-0.2852757  2.8610833  3.1389747] | Terminated: False | Episode Length: 9.429999999999843\n",
            "Action: [-0.4  0. ] | Reward: -15.368272749999747 | State: [-0.28397486  2.860795    3.1389747 ] | Terminated: False | Episode Length: 9.439999999999843\n",
            "Action: [-0.4  0. ] | Reward: -15.37625141606892 | State: [-0.28267482  2.8605027   3.1389747 ] | Terminated: False | Episode Length: 9.449999999999843\n",
            "Action: [-0.4  0. ] | Reward: -15.384193563571761 | State: [-0.28137562  2.8602061   3.1389747 ] | Terminated: False | Episode Length: 9.459999999999843\n",
            "Action: [-0.4  0. ] | Reward: -15.392099197907239 | State: [-0.28007728  2.8599055   3.1389747 ] | Terminated: False | Episode Length: 9.469999999999843\n",
            "Action: [-0.4  0. ] | Reward: -15.399968324818095 | State: [-0.27877977  2.8596005   3.1389747 ] | Terminated: False | Episode Length: 9.479999999999842\n",
            "Action: [-0.4  0. ] | Reward: -15.407800950390326 | State: [-0.2774831  2.8592913  3.1389747] | Terminated: False | Episode Length: 9.489999999999842\n",
            "Action: [-0.4  0. ] | Reward: -15.415597081052665 | State: [-0.2761873  2.858978   3.1389747] | Terminated: False | Episode Length: 9.499999999999842\n",
            "Action: [-0.4  0. ] | Reward: -15.423356723576052 | State: [-0.27489233  2.8586605   3.1389747 ] | Terminated: False | Episode Length: 9.509999999999842\n",
            "Action: [-0.4  0. ] | Reward: -15.43107988507311 | State: [-0.27359822  2.8583388   3.1389747 ] | Terminated: False | Episode Length: 9.519999999999841\n",
            "Action: [-0.4  0. ] | Reward: -15.438766572997599 | State: [-0.27230495  2.858013    3.1389747 ] | Terminated: False | Episode Length: 9.529999999999841\n",
            "Action: [-0.4  0. ] | Reward: -15.44641679514388 | State: [-0.27101257  2.8576827   3.1389747 ] | Terminated: False | Episode Length: 9.539999999999841\n",
            "Action: [-0.4  0. ] | Reward: -15.454030559646368 | State: [-0.26972106  2.8573484   3.1389747 ] | Terminated: False | Episode Length: 9.54999999999984\n",
            "Action: [-0.4  0. ] | Reward: -15.461607874978977 | State: [-0.26843038  2.8570101   3.1389747 ] | Terminated: False | Episode Length: 9.55999999999984\n",
            "Action: [-0.4  0. ] | Reward: -15.469148749954565 | State: [-0.2671406  2.8566675  3.1389747] | Terminated: False | Episode Length: 9.56999999999984\n",
            "Action: [-0.4  0. ] | Reward: -15.47665319372437 | State: [-0.26585168  2.8563209   3.1389747 ] | Terminated: False | Episode Length: 9.57999999999984\n",
            "Action: [-0.4  0. ] | Reward: -15.484121215777447 | State: [-0.26456365  2.85597     3.1389747 ] | Terminated: False | Episode Length: 9.58999999999984\n",
            "Action: [-0.4  0. ] | Reward: -15.491552825940094 | State: [-0.2632765  2.855615   3.1389747] | Terminated: False | Episode Length: 9.59999999999984\n",
            "Action: [-0.4  0. ] | Reward: -15.49894803437527 | State: [-0.26199022  2.8552556   3.1389747 ] | Terminated: False | Episode Length: 9.60999999999984\n",
            "Action: [-0.4  0. ] | Reward: -15.506306851582018 | State: [-0.26070485  2.8548925   3.1389747 ] | Terminated: False | Episode Length: 9.61999999999984\n",
            "Action: [-0.4  0. ] | Reward: -15.513629288394878 | State: [-0.25942034  2.854525    3.1389747 ] | Terminated: False | Episode Length: 9.62999999999984\n",
            "Action: [-0.4  0. ] | Reward: -15.520915355983293 | State: [-0.25813672  2.8541534   3.1389747 ] | Terminated: False | Episode Length: 9.639999999999839\n",
            "Action: [-0.4  0. ] | Reward: -15.528165065851013 | State: [-0.25685403  2.853778    3.1389747 ] | Terminated: False | Episode Length: 9.649999999999839\n",
            "Action: [-0.4  0. ] | Reward: -15.535378429835491 | State: [-0.25557223  2.853398    3.1389747 ] | Terminated: False | Episode Length: 9.659999999999838\n",
            "Action: [-0.4  0. ] | Reward: -15.542555460107282 | State: [-0.25429133  2.8530142   3.1389747 ] | Terminated: False | Episode Length: 9.669999999999838\n",
            "Action: [-0.4  0. ] | Reward: -15.549696169169422 | State: [-0.25301132  2.852626    3.1389747 ] | Terminated: False | Episode Length: 9.679999999999838\n",
            "Action: [-0.4  0. ] | Reward: -15.556800569856824 | State: [-0.25173223  2.8522341   3.1389747 ] | Terminated: False | Episode Length: 9.689999999999838\n",
            "Action: [-0.4  0. ] | Reward: -15.563868675335645 | State: [-0.25045407  2.8518379   3.1389747 ] | Terminated: False | Episode Length: 9.699999999999838\n",
            "Action: [-0.4  0. ] | Reward: -15.570900499102668 | State: [-0.2491768  2.8514376  3.1389747] | Terminated: False | Episode Length: 9.709999999999837\n",
            "Action: [-0.4  0. ] | Reward: -15.57789605498467 | State: [-0.24790046  2.8510332   3.1389747 ] | Terminated: False | Episode Length: 9.719999999999837\n",
            "Action: [-0.4  0. ] | Reward: -15.584855357137783 | State: [-0.24662504  2.8506248   3.1389747 ] | Terminated: False | Episode Length: 9.729999999999837\n",
            "Action: [-0.4  0. ] | Reward: -15.59177842004686 | State: [-0.24535054  2.8502123   3.1389747 ] | Terminated: False | Episode Length: 9.739999999999837\n",
            "Action: [-0.4  0. ] | Reward: -15.598665258524823 | State: [-0.24407698  2.8497958   3.1389747 ] | Terminated: False | Episode Length: 9.749999999999837\n",
            "Action: [-0.4  0. ] | Reward: -15.605515887712025 | State: [-0.24280435  2.8493752   3.1389747 ] | Terminated: False | Episode Length: 9.759999999999836\n",
            "Action: [-0.4  0. ] | Reward: -15.612330323075582 | State: [-0.24153265  2.8489506   3.1389747 ] | Terminated: False | Episode Length: 9.769999999999836\n",
            "Action: [-0.4  0. ] | Reward: -15.619108580408728 | State: [-0.2402619  2.848522   3.1389747] | Terminated: False | Episode Length: 9.779999999999836\n",
            "Action: [-0.4  0. ] | Reward: -15.62585067583014 | State: [-0.23899208  2.8480892   3.1389747 ] | Terminated: False | Episode Length: 9.789999999999836\n",
            "Action: [-0.4  0. ] | Reward: -15.632556625783282 | State: [-0.2377232  2.8476524  3.1389747] | Terminated: False | Episode Length: 9.799999999999836\n",
            "Action: [-0.4  0. ] | Reward: -15.639226447035725 | State: [-0.23645528  2.8472116   3.1389747 ] | Terminated: False | Episode Length: 9.809999999999835\n",
            "Action: [-0.4  0. ] | Reward: -15.645860156678472 | State: [-0.2351883  2.8467667  3.1389747] | Terminated: False | Episode Length: 9.819999999999835\n",
            "Action: [-0.4  0. ] | Reward: -15.652457772125281 | State: [-0.23392227  2.8463178   3.1389747 ] | Terminated: False | Episode Length: 9.829999999999835\n",
            "Action: [-0.4  0. ] | Reward: -15.659019311111978 | State: [-0.23265722  2.845865    3.1389747 ] | Terminated: False | Episode Length: 9.839999999999835\n",
            "Action: [-0.4  0. ] | Reward: -15.665544791695762 | State: [-0.23139311  2.8454082   3.1389747 ] | Terminated: False | Episode Length: 9.849999999999834\n",
            "Action: [-0.4  0. ] | Reward: -15.672034232254518 | State: [-0.23012997  2.8449473   3.1389747 ] | Terminated: False | Episode Length: 9.859999999999834\n",
            "Action: [-0.4  0. ] | Reward: -15.678487651486114 | State: [-0.2288678  2.8444824  3.1389747] | Terminated: False | Episode Length: 9.869999999999834\n",
            "Action: [-0.4  0. ] | Reward: -15.684905068407703 | State: [-0.22760661  2.8440135   3.1389747 ] | Terminated: False | Episode Length: 9.879999999999834\n",
            "Action: [-0.4  0. ] | Reward: -15.69128650235501 | State: [-0.22634637  2.8435407   3.1389747 ] | Terminated: False | Episode Length: 9.889999999999834\n",
            "Action: [-0.4  0. ] | Reward: -15.697631972981627 | State: [-0.22508712  2.8430638   3.1389747 ] | Terminated: False | Episode Length: 9.899999999999833\n",
            "Action: [-0.4  0. ] | Reward: -15.70394150025829 | State: [-0.22382885  2.842583    3.1389747 ] | Terminated: False | Episode Length: 9.909999999999833\n",
            "Action: [-0.4  0. ] | Reward: -15.710215104472166 | State: [-0.22257155  2.8420982   3.1389747 ] | Terminated: False | Episode Length: 9.919999999999833\n",
            "Action: [-0.4  0. ] | Reward: -15.716452806226126 | State: [-0.22131525  2.8416095   3.1389747 ] | Terminated: False | Episode Length: 9.929999999999833\n",
            "Action: [-0.4  0. ] | Reward: -15.722654626438018 | State: [-0.22005995  2.8411167   3.1389747 ] | Terminated: False | Episode Length: 9.939999999999833\n",
            "Action: [-0.4  0. ] | Reward: -15.728820586339934 | State: [-0.21880561  2.84062     3.1389747 ] | Terminated: False | Episode Length: 9.949999999999832\n",
            "Action: [-0.4  0. ] | Reward: -15.734950707477472 | State: [-0.21755229  2.8401194   3.1389747 ] | Terminated: False | Episode Length: 9.959999999999832\n",
            "Action: [-0.4  0. ] | Reward: -15.741045011708998 | State: [-0.21629997  2.8396149   3.1389747 ] | Terminated: False | Episode Length: 9.969999999999832\n",
            "Action: [-0.4  0. ] | Reward: -15.747103521204902 | State: [-0.21504863  2.8391063   3.1389747 ] | Terminated: False | Episode Length: 9.979999999999832\n",
            "Action: [-0.4  0. ] | Reward: -15.753126258446848 | State: [-0.21379831  2.838594    3.1389747 ] | Terminated: False | Episode Length: 9.989999999999831\n",
            "Action: [-0.4  0. ] | Reward: -15.759113246227018 | State: [-0.212549   2.8380778  3.1389747] | Terminated: False | Episode Length: 9.999999999999831\n",
            "Action: [-0.4  0. ] | Reward: -15.765064507647365 | State: [-0.21130069  2.8375573   3.1389747 ] | Terminated: False | Episode Length: 10.009999999999831\n",
            "Action: [-0.4  0. ] | Reward: -15.770980066118842 | State: [-0.2100534  2.8370333  3.1389747] | Terminated: False | Episode Length: 10.01999999999983\n",
            "Action: [-0.4  0. ] | Reward: -15.776859945360645 | State: [-0.20880713  2.8365052   3.1389747 ] | Terminated: False | Episode Length: 10.02999999999983\n",
            "Action: [-0.4  0. ] | Reward: -15.782704169399441 | State: [-0.20756188  2.8359733   3.1389747 ] | Terminated: False | Episode Length: 10.03999999999983\n",
            "Action: [-0.4  0. ] | Reward: -15.788512762568597 | State: [-0.20631765  2.8354373   3.1389747 ] | Terminated: False | Episode Length: 10.04999999999983\n",
            "Action: [-0.4  0. ] | Reward: -15.794285749507404 | State: [-0.20507446  2.8348975   3.1389747 ] | Terminated: False | Episode Length: 10.05999999999983\n",
            "Action: [-0.4  0. ] | Reward: -15.800023155160297 | State: [-0.20383228  2.834354    3.1389747 ] | Terminated: False | Episode Length: 10.06999999999983\n",
            "Action: [-0.4  0. ] | Reward: -15.80572500477607 | State: [-0.20259114  2.8338065   3.1389747 ] | Terminated: False | Episode Length: 10.07999999999983\n",
            "Action: [-0.4  0. ] | Reward: -15.811391323907094 | State: [-0.20135105  2.833255    3.1389747 ] | Terminated: False | Episode Length: 10.08999999999983\n",
            "Action: [-0.4  0. ] | Reward: -15.817022138408516 | State: [-0.20011199  2.8326998   3.1389747 ] | Terminated: False | Episode Length: 10.09999999999983\n",
            "Action: [-0.4  0. ] | Reward: -15.822617474437477 | State: [-0.19887395  2.8321407   3.1389747 ] | Terminated: False | Episode Length: 10.109999999999829\n",
            "Action: [-0.4  0. ] | Reward: -15.828177358452301 | State: [-0.19763699  2.8315778   3.1389747 ] | Terminated: False | Episode Length: 10.119999999999829\n",
            "Action: [-0.4  0. ] | Reward: -15.833701817211702 | State: [-0.19640106  2.8310108   3.1389747 ] | Terminated: False | Episode Length: 10.129999999999828\n",
            "Action: [-0.4  0. ] | Reward: -15.839190877773975 | State: [-0.19516619  2.8304403   3.1389747 ] | Terminated: False | Episode Length: 10.139999999999828\n",
            "Action: [-0.4  0. ] | Reward: -15.844644567496184 | State: [-0.19393237  2.8298657   3.1389747 ] | Terminated: False | Episode Length: 10.149999999999828\n",
            "Action: [-0.4  0. ] | Reward: -15.850062914033353 | State: [-0.19269961  2.8292875   3.1389747 ] | Terminated: False | Episode Length: 10.159999999999828\n",
            "Action: [-0.4  0. ] | Reward: -15.855445945337651 | State: [-0.19146791  2.8287053   3.1389747 ] | Terminated: False | Episode Length: 10.169999999999828\n",
            "Action: [-0.4  0. ] | Reward: -15.860793689657564 | State: [-0.19023727  2.8281193   3.1389747 ] | Terminated: False | Episode Length: 10.179999999999827\n",
            "Action: [-0.4  0. ] | Reward: -15.86610617553708 | State: [-0.1890077  2.8275297  3.1389747] | Terminated: False | Episode Length: 10.189999999999827\n",
            "Action: [-0.4  0. ] | Reward: -15.87138343181486 | State: [-0.1877792  2.826936   3.1389747] | Terminated: False | Episode Length: 10.199999999999827\n",
            "Action: [-0.4  0. ] | Reward: -15.876625487623404 | State: [-0.18655178  2.8263388   3.1389747 ] | Terminated: False | Episode Length: 10.209999999999827\n",
            "Action: [-0.4   -0.524] | Reward: -15.881832372388219 | State: [-0.18532543  2.8257375   3.1337388 ] | Terminated: False | Episode Length: 10.219999999999827\n",
            "Action: [-0.4  0. ] | Reward: -15.887004117710578 | State: [-0.18410023  2.8251326   3.1337388 ] | Terminated: False | Episode Length: 10.229999999999826\n",
            "Action: [-0.4  0. ] | Reward: -15.892140753599127 | State: [-0.18287611  2.8245237   3.1337388 ] | Terminated: False | Episode Length: 10.239999999999826\n",
            "Action: [-0.4  0. ] | Reward: -15.89724231035297 | State: [-0.18165308  2.8239112   3.1337388 ] | Terminated: False | Episode Length: 10.249999999999826\n",
            "Action: [-0.4  0. ] | Reward: -15.902308818560815 | State: [-0.18043114  2.823295    3.1337388 ] | Terminated: False | Episode Length: 10.259999999999826\n",
            "Action: [-0.4  0. ] | Reward: -15.907340309100128 | State: [-0.17921029  2.822675    3.1337388 ] | Terminated: False | Episode Length: 10.269999999999825\n",
            "Action: [-0.4  0. ] | Reward: -15.91233681313628 | State: [-0.17799053  2.8220513   3.1337388 ] | Terminated: False | Episode Length: 10.279999999999825\n",
            "Action: [-0.4    0.262] | Reward: -15.917298362121688 | State: [-0.17677188  2.8214235   3.1363566 ] | Terminated: False | Episode Length: 10.289999999999825\n",
            "Action: [-0.4    0.262] | Reward: -15.922224986619492 | State: [-0.17555428  2.8207924   3.1389747 ] | Terminated: False | Episode Length: 10.299999999999825\n",
            "Action: [-0.4    0.262] | Reward: -15.927116717948794 | State: [-0.17433776  2.8201573   3.1415927 ] | Terminated: False | Episode Length: 10.309999999999825\n",
            "Action: [-0.4    0.262] | Reward: -15.931973588183482 | State: [-0.17312233  2.8195186   3.1442106 ] | Terminated: False | Episode Length: 10.319999999999824\n",
            "Action: [-0.4   -0.524] | Reward: -15.936795630151039 | State: [-0.17190804  2.818876    3.1389747 ] | Terminated: False | Episode Length: 10.329999999999824\n",
            "Action: [-0.4    0.262] | Reward: -15.94158287672671 | State: [-0.17069486  2.81823     3.1415927 ] | Terminated: False | Episode Length: 10.339999999999824\n",
            "Action: [-0.4    0.262] | Reward: -15.946335360832801 | State: [-0.16948277  2.81758     3.1442106 ] | Terminated: False | Episode Length: 10.349999999999824\n",
            "Action: [-0.4    0.262] | Reward: -15.951053116142242 | State: [-0.16827182  2.8169262   3.1468287 ] | Terminated: False | Episode Length: 10.359999999999824\n",
            "Action: [-0.4   -0.524] | Reward: -15.95573617707732 | State: [-0.16706201  2.816269    3.1415927 ] | Terminated: False | Episode Length: 10.369999999999823\n",
            "Action: [-0.4    0.262] | Reward: -15.96038457669678 | State: [-0.1658533  2.815608   3.1442106] | Terminated: False | Episode Length: 10.379999999999823\n",
            "Action: [-0.4    0.262] | Reward: -15.964998349511049 | State: [-0.16464573  2.8149433   3.1468287 ] | Terminated: False | Episode Length: 10.389999999999823\n",
            "Action: [-0.4    0.262] | Reward: -15.969577530776862 | State: [-0.16343932  2.814275    3.1494467 ] | Terminated: False | Episode Length: 10.399999999999823\n",
            "Action: [-0.4   -0.524] | Reward: -15.974122156495952 | State: [-0.16223408  2.813603    3.1442106 ] | Terminated: False | Episode Length: 10.409999999999823\n",
            "Action: [-0.4  0. ] | Reward: -15.97863225989824 | State: [-0.16102992  2.812927    3.1442106 ] | Terminated: False | Episode Length: 10.419999999999822\n",
            "Action: [-0.4  0. ] | Reward: -15.983107876363933 | State: [-0.15982689  2.8122478   3.1442106 ] | Terminated: False | Episode Length: 10.429999999999822\n",
            "Action: [-0.4  0. ] | Reward: -15.987549041547094 | State: [-0.158625   2.8115647  3.1442106] | Terminated: False | Episode Length: 10.439999999999822\n",
            "Action: [-0.4  0. ] | Reward: -15.991955791374751 | State: [-0.15742427  2.810878    3.1442106 ] | Terminated: False | Episode Length: 10.449999999999822\n",
            "Action: [-0.4  0. ] | Reward: -15.99632816204598 | State: [-0.15622468  2.8101876   3.1442106 ] | Terminated: False | Episode Length: 10.459999999999821\n",
            "Action: [-0.4  0. ] | Reward: -16.000666190030998 | State: [-0.15502626  2.8094935   3.1442106 ] | Terminated: False | Episode Length: 10.469999999999821\n",
            "Action: [-0.4  0. ] | Reward: -16.004969912070255 | State: [-0.15382898  2.808796    3.1442106 ] | Terminated: False | Episode Length: 10.479999999999821\n",
            "Action: [-0.4  0. ] | Reward: -16.00923936517351 | State: [-0.15263288  2.8080947   3.1442106 ] | Terminated: False | Episode Length: 10.48999999999982\n",
            "Action: [-0.4  0. ] | Reward: -16.013474586618923 | State: [-0.15143792  2.80739     3.1442106 ] | Terminated: False | Episode Length: 10.49999999999982\n",
            "Action: [-0.4  0. ] | Reward: -16.01767561395213 | State: [-0.15024413  2.8066814   3.1442106 ] | Terminated: False | Episode Length: 10.50999999999982\n",
            "Action: [-0.4  0. ] | Reward: -16.021842484985317 | State: [-0.14905152  2.8059695   3.1442106 ] | Terminated: False | Episode Length: 10.51999999999982\n",
            "Action: [-0.4  0. ] | Reward: -16.025975237796306 | State: [-0.14786007  2.8052537   3.1442106 ] | Terminated: False | Episode Length: 10.52999999999982\n",
            "Action: [-0.4  0. ] | Reward: -16.030073910727616 | State: [-0.14666979  2.8045344   3.1442106 ] | Terminated: False | Episode Length: 10.53999999999982\n",
            "Action: [-0.4  0. ] | Reward: -16.034138542385534 | State: [-0.1454807  2.8038116  3.1442106] | Terminated: False | Episode Length: 10.54999999999982\n",
            "Action: [-0.4  0. ] | Reward: -16.038169171639193 | State: [-0.14429279  2.803085    3.1442106 ] | Terminated: False | Episode Length: 10.55999999999982\n",
            "Action: [-0.4  0. ] | Reward: -16.04216583761962 | State: [-0.14310606  2.8023553   3.1442106 ] | Terminated: False | Episode Length: 10.569999999999819\n",
            "Action: [-0.4  0. ] | Reward: -16.046128579718815 | State: [-0.14192052  2.8016217   3.1442106 ] | Terminated: False | Episode Length: 10.579999999999819\n",
            "Action: [-0.4  0. ] | Reward: -16.050057437588798 | State: [-0.14073616  2.8008845   3.1442106 ] | Terminated: False | Episode Length: 10.589999999999819\n",
            "Action: [-0.4  0. ] | Reward: -16.053952451140677 | State: [-0.13955301  2.8001437   3.1442106 ] | Terminated: False | Episode Length: 10.599999999999818\n",
            "Action: [-0.4  0. ] | Reward: -16.0578136605437 | State: [-0.13837105  2.7993996   3.1442106 ] | Terminated: False | Episode Length: 10.609999999999818\n",
            "Action: [-0.4  0. ] | Reward: -16.061641106224304 | State: [-0.13719028  2.7986517   3.1442106 ] | Terminated: False | Episode Length: 10.619999999999818\n",
            "Action: [-0.4  0. ] | Reward: -16.06543482886517 | State: [-0.13601072  2.7979004   3.1442106 ] | Terminated: False | Episode Length: 10.629999999999818\n",
            "Action: [-0.4  0. ] | Reward: -16.06919486940427 | State: [-0.13483237  2.7971456   3.1442106 ] | Terminated: False | Episode Length: 10.639999999999818\n",
            "Action: [-0.4  0. ] | Reward: -16.072921269033927 | State: [-0.1336552  2.7963872  3.1442106] | Terminated: False | Episode Length: 10.649999999999817\n",
            "Action: [-0.4  0. ] | Reward: -16.07661406919983 | State: [-0.13247927  2.7956254   3.1442106 ] | Terminated: False | Episode Length: 10.659999999999817\n",
            "Action: [-0.4  0. ] | Reward: -16.08027331160011 | State: [-0.13130455  2.7948601   3.1442106 ] | Terminated: False | Episode Length: 10.669999999999817\n",
            "Action: [-0.4  0. ] | Reward: -16.083899038184352 | State: [-0.13013104  2.7940912   3.1442106 ] | Terminated: False | Episode Length: 10.679999999999817\n",
            "Action: [-0.4  0. ] | Reward: -16.087491291152652 | State: [-0.12895875  2.7933187   3.1442106 ] | Terminated: False | Episode Length: 10.689999999999817\n",
            "Action: [-0.4  0. ] | Reward: -16.091050112954644 | State: [-0.12778768  2.792543    3.1442106 ] | Terminated: False | Episode Length: 10.699999999999816\n",
            "Action: [-0.4  0. ] | Reward: -16.094575546288535 | State: [-0.12661785  2.7917635   3.1442106 ] | Terminated: False | Episode Length: 10.709999999999816\n",
            "Action: [-0.4   -0.262] | Reward: -16.098067634100143 | State: [-0.12544924  2.7909808   3.1415927 ] | Terminated: False | Episode Length: 10.719999999999816\n",
            "Action: [-0.4  0. ] | Reward: -16.101526419350098 | State: [-0.12428185  2.7901945   3.1415927 ] | Terminated: False | Episode Length: 10.729999999999816\n",
            "Action: [-0.4  0. ] | Reward: -16.104951945476643 | State: [-0.1231157  2.7894049  3.1415927] | Terminated: False | Episode Length: 10.739999999999815\n",
            "Action: [-0.4   -0.262] | Reward: -16.108344256162724 | State: [-0.12195078  2.7886117   3.1389747 ] | Terminated: False | Episode Length: 10.749999999999815\n",
            "Action: [-0.4  0. ] | Reward: -16.111703395566533 | State: [-0.12078712  2.7878149   3.1389747 ] | Terminated: False | Episode Length: 10.759999999999815\n",
            "Action: [-0.4  0. ] | Reward: -16.11502940785734 | State: [-0.1196247  2.7870147  3.1389747] | Terminated: False | Episode Length: 10.769999999999815\n",
            "Action: [-0.4   -0.262] | Reward: -16.118322337446166 | State: [-0.11846352  2.7862113   3.1363566 ] | Terminated: False | Episode Length: 10.779999999999815\n",
            "Action: [-0.4    0.524] | Reward: -16.121582229678502 | State: [-0.11730362  2.7854044   3.1415927 ] | Terminated: False | Episode Length: 10.789999999999814\n",
            "Action: [-0.4   -0.262] | Reward: -16.12480912852104 | State: [-0.11614495  2.784594    3.1389747 ] | Terminated: False | Episode Length: 10.799999999999814\n",
            "Action: [-0.4   -0.262] | Reward: -16.128003079335343 | State: [-0.11498753  2.78378     3.1363566 ] | Terminated: False | Episode Length: 10.809999999999814\n",
            "Action: [-0.4    0.524] | Reward: -16.13116412818239 | State: [-0.1138314  2.782963   3.1415927] | Terminated: False | Episode Length: 10.819999999999814\n",
            "Action: [-0.4   -0.262] | Reward: -16.13429231974358 | State: [-0.1126765  2.7821424  3.1389747] | Terminated: False | Episode Length: 10.829999999999814\n",
            "Action: [-0.4    0.524] | Reward: -16.13738770009067 | State: [-0.11152287  2.7813184   3.1442106 ] | Terminated: False | Episode Length: 10.839999999999813\n",
            "Action: [-0.4   -0.262] | Reward: -16.140450315299425 | State: [-0.11037051  2.780491    3.1415927 ] | Terminated: False | Episode Length: 10.849999999999813\n",
            "Action: [-0.4   -0.262] | Reward: -16.14348021144899 | State: [-0.10921941  2.7796602   3.1389747 ] | Terminated: False | Episode Length: 10.859999999999813\n",
            "Action: [-0.4    0.524] | Reward: -16.146477435312384 | State: [-0.10806959  2.7788262   3.1442106 ] | Terminated: False | Episode Length: 10.869999999999813\n",
            "Action: [-0.4    0.524] | Reward: -16.149442033663984 | State: [-0.10692105  2.7779887   3.1494467 ] | Terminated: False | Episode Length: 10.879999999999812\n",
            "Action: [-0.4    0.524] | Reward: -16.152374055350286 | State: [-0.10577385  2.7771478   3.1546826 ] | Terminated: False | Episode Length: 10.889999999999812\n",
            "Action: [-0.4    0.524] | Reward: -16.155273551285838 | State: [-0.10462807  2.7763035   3.1599185 ] | Terminated: False | Episode Length: 10.899999999999812\n",
            "Action: [-0.4    0.524] | Reward: -16.158140574449046 | State: [-0.10348377  2.775456    3.1651547 ] | Terminated: False | Episode Length: 10.909999999999812\n",
            "Action: [-0.4   -0.262] | Reward: -16.160975179877852 | State: [-0.10234104  2.774605    3.1625366 ] | Terminated: False | Episode Length: 10.919999999999812\n",
            "Action: [-0.4   -0.262] | Reward: -16.163777411573466 | State: [-0.10119945  2.7737508   3.1599185 ] | Terminated: False | Episode Length: 10.929999999999811\n",
            "Action: [-0.4   -0.262] | Reward: -16.16654731422644 | State: [-0.10005902  2.7728932   3.1573007 ] | Terminated: False | Episode Length: 10.939999999999811\n",
            "Action: [-0.4   -0.262] | Reward: -16.16928493321501 | State: [-0.09891979  2.7720325   3.1546826 ] | Terminated: False | Episode Length: 10.949999999999811\n",
            "Action: [-0.4   -0.262] | Reward: -16.171990314603377 | State: [-0.09778177  2.7711682   3.1520646 ] | Terminated: False | Episode Length: 10.95999999999981\n",
            "Action: [-0.4   -0.262] | Reward: -16.174663505140018 | State: [-0.09664498  2.7703006   3.1494467 ] | Terminated: False | Episode Length: 10.96999999999981\n",
            "Action: [-0.4   -0.262] | Reward: -16.177304552255936 | State: [-0.09550942  2.76943     3.1468287 ] | Terminated: False | Episode Length: 10.97999999999981\n",
            "Action: [-0.4    0.524] | Reward: -16.179913504062903 | State: [-0.09437515  2.7685559   3.1520646 ] | Terminated: False | Episode Length: 10.98999999999981\n",
            "Action: [-0.4    0.524] | Reward: -16.18249041278484 | State: [-0.09324228  2.7676785   3.1573007 ] | Terminated: False | Episode Length: 10.99999999999981\n",
            "Action: [-0.4   -0.262] | Reward: -16.185035332690926 | State: [-0.09211089  2.7667978   3.1546826 ] | Terminated: False | Episode Length: 11.00999999999981\n",
            "Action: [-0.4    0.524] | Reward: -16.187548311174673 | State: [-0.09098073  2.765914    3.1599185 ] | Terminated: False | Episode Length: 11.01999999999981\n",
            "Action: [-0.4    0.524] | Reward: -16.190029403847163 | State: [-0.08985209  2.7650268   3.1651547 ] | Terminated: False | Episode Length: 11.02999999999981\n",
            "Action: [-0.4   -0.262] | Reward: -16.192478668354784 | State: [-0.08872504  2.7641363   3.1625366 ] | Terminated: False | Episode Length: 11.039999999999809\n",
            "Action: [-0.4    0.524] | Reward: -16.194896151364734 | State: [-0.08759917  2.7632427   3.1677725 ] | Terminated: False | Episode Length: 11.049999999999809\n",
            "Action: [-0.4   -0.262] | Reward: -16.19728191185312 | State: [-0.08647493  2.7623458   3.1651547 ] | Terminated: False | Episode Length: 11.059999999999809\n",
            "Action: [-0.4    0.524] | Reward: -16.199635996458007 | State: [-0.08535186  2.7614455   3.1703906 ] | Terminated: False | Episode Length: 11.069999999999808\n",
            "Action: [-0.4   -0.524] | Reward: -16.20195846547843 | State: [-0.08423047  2.7605422   3.1651547 ] | Terminated: False | Episode Length: 11.079999999999808\n",
            "Action: [-0.4    0.524] | Reward: -16.204249361192844 | State: [-0.08311007  2.7596354   3.1703906 ] | Terminated: False | Episode Length: 11.089999999999808\n",
            "Action: [-0.4   -0.524] | Reward: -16.206508744309662 | State: [-0.08199135  2.7587256   3.1651547 ] | Terminated: False | Episode Length: 11.099999999999808\n",
            "Action: [-0.4   -0.524] | Reward: -16.20873665753517 | State: [-0.08087365  2.7578127   3.1599185 ] | Terminated: False | Episode Length: 11.109999999999808\n",
            "Action: [-0.4   -0.524] | Reward: -16.21093314561391 | State: [-0.07975702  2.7568965   3.1546826 ] | Terminated: False | Episode Length: 11.119999999999807\n",
            "Action: [-0.4    0.524] | Reward: -16.21309825532451 | State: [-0.07864155  2.755977    3.1599185 ] | Terminated: False | Episode Length: 11.129999999999807\n",
            "Action: [-0.4   -0.524] | Reward: -16.215232044559293 | State: [-0.07752763  2.7550545   3.1546826 ] | Terminated: False | Episode Length: 11.139999999999807\n",
            "Action: [-0.4   -0.524] | Reward: -16.217334560512988 | State: [-0.07641486  2.7541287   3.1494467 ] | Terminated: False | Episode Length: 11.149999999999807\n",
            "Action: [-0.4   -0.524] | Reward: -16.219405852406 | State: [-0.07530332  2.7531996   3.1442106 ] | Terminated: False | Episode Length: 11.159999999999807\n",
            "Action: [-0.4    0.524] | Reward: -16.221445971479902 | State: [-0.07419308  2.7522676   3.1494467 ] | Terminated: False | Episode Length: 11.169999999999806\n",
            "Action: [-0.4   -0.524] | Reward: -16.223454972805403 | State: [-0.07308426  2.7513323   3.1442106 ] | Terminated: False | Episode Length: 11.179999999999806\n",
            "Action: [-0.4   -0.524] | Reward: -16.22543290802801 | State: [-0.07197675  2.7503939   3.1389747 ] | Terminated: False | Episode Length: 11.189999999999806\n",
            "Action: [-0.4   -0.524] | Reward: -16.227379830805603 | State: [-0.07087061  2.749452    3.1337388 ] | Terminated: False | Episode Length: 11.199999999999806\n",
            "Action: [-0.4  0. ] | Reward: -16.229295796803637 | State: [-0.0697659  2.7485075  3.1337388] | Terminated: False | Episode Length: 11.209999999999805\n",
            "Action: [-0.4  0. ] | Reward: -16.231180860074 | State: [-0.06866258  2.7475595   3.1337388 ] | Terminated: False | Episode Length: 11.219999999999805\n",
            "Action: [-0.4  0. ] | Reward: -16.233035074864812 | State: [-0.06756063  2.7466087   3.1337388 ] | Terminated: False | Episode Length: 11.229999999999805\n",
            "Action: [-0.4  0. ] | Reward: -16.23485849561938 | State: [-0.06646007  2.7456546   3.1337388 ] | Terminated: False | Episode Length: 11.239999999999805\n",
            "Action: [-0.4  0. ] | Reward: -16.23665117697518 | State: [-0.06536088  2.7446973   3.1337388 ] | Terminated: False | Episode Length: 11.249999999999805\n",
            "Action: [-0.4  0. ] | Reward: -16.2384131737628 | State: [-0.06426309  2.743737    3.1337388 ] | Terminated: False | Episode Length: 11.259999999999804\n",
            "Action: [-0.4  0. ] | Reward: -16.240144541004938 | State: [-0.06316669  2.7427735   3.1337388 ] | Terminated: False | Episode Length: 11.269999999999804\n",
            "Action: [-0.4  0. ] | Reward: -16.24184533391533 | State: [-0.06207167  2.7418072   3.1337388 ] | Terminated: False | Episode Length: 11.279999999999804\n",
            "Action: [-0.4  0. ] | Reward: -16.243515607897738 | State: [-0.06097806  2.7408376   3.1337388 ] | Terminated: False | Episode Length: 11.289999999999804\n",
            "Action: [-0.4  0. ] | Reward: -16.24515541854491 | State: [-0.05988584  2.7398648   3.1337388 ] | Terminated: False | Episode Length: 11.299999999999804\n",
            "Action: [-0.4  0. ] | Reward: -16.246764821637537 | State: [-0.05879503  2.7388892   3.1337388 ] | Terminated: False | Episode Length: 11.309999999999803\n",
            "Action: [-0.4  0. ] | Reward: -16.248343873143213 | State: [-0.05770562  2.7379103   3.1337388 ] | Terminated: False | Episode Length: 11.319999999999803\n",
            "Action: [-0.4  0. ] | Reward: -16.249892629215406 | State: [-0.05661762  2.7369285   3.1337388 ] | Terminated: False | Episode Length: 11.329999999999803\n",
            "Action: [-0.4  0. ] | Reward: -16.251411146192417 | State: [-0.05553103  2.7359436   3.1337388 ] | Terminated: False | Episode Length: 11.339999999999803\n",
            "Action: [-0.4  0. ] | Reward: -16.252899480596337 | State: [-0.05444585  2.7349558   3.1337388 ] | Terminated: False | Episode Length: 11.349999999999802\n",
            "Action: [-0.4  0. ] | Reward: -16.254357689132014 | State: [-0.05336209  2.7339647   3.1337388 ] | Terminated: False | Episode Length: 11.359999999999802\n",
            "Action: [-0.4  0. ] | Reward: -16.255785828686015 | State: [-0.05227975  2.7329707   3.1337388 ] | Terminated: False | Episode Length: 11.369999999999802\n",
            "Action: [-0.4  0. ] | Reward: -16.25718395632558 | State: [-0.05119883  2.731974    3.1337388 ] | Terminated: False | Episode Length: 11.379999999999802\n",
            "Action: [-0.4  0. ] | Reward: -16.258552129297588 | State: [-0.05011934  2.7309737   3.1337388 ] | Terminated: False | Episode Length: 11.389999999999802\n",
            "Action: [-0.4  0. ] | Reward: -16.259890405027512 | State: [-0.04904127  2.7299707   3.1337388 ] | Terminated: False | Episode Length: 11.399999999999801\n",
            "Action: [-0.4  0. ] | Reward: -16.261198841118393 | State: [-0.04796463  2.7289648   3.1337388 ] | Terminated: False | Episode Length: 11.409999999999801\n",
            "Action: [-0.4  0. ] | Reward: -16.262477495349778 | State: [-0.04688943  2.7279558   3.1337388 ] | Terminated: False | Episode Length: 11.419999999999801\n",
            "Action: [-0.4  0. ] | Reward: -16.263726425676698 | State: [-0.04581566  2.7269437   3.1337388 ] | Terminated: False | Episode Length: 11.4299999999998\n",
            "Action: [-0.4  0. ] | Reward: -16.264945690228622 | State: [-0.04474333  2.7259288   3.1337388 ] | Terminated: False | Episode Length: 11.4399999999998\n",
            "Action: [-0.4  0. ] | Reward: -16.266135347308417 | State: [-0.04367245  2.724911    3.1337388 ] | Terminated: False | Episode Length: 11.4499999999998\n",
            "Action: [-0.4  0. ] | Reward: -16.26729545539131 | State: [-0.04260301  2.72389     3.1337388 ] | Terminated: False | Episode Length: 11.4599999999998\n",
            "Action: [-0.4  0. ] | Reward: -16.268426073123837 | State: [-0.04153501  2.7228663   3.1337388 ] | Terminated: False | Episode Length: 11.4699999999998\n",
            "Action: [-0.4  0. ] | Reward: -16.26952725932282 | State: [-0.04046847  2.7218394   3.1337388 ] | Terminated: False | Episode Length: 11.4799999999998\n",
            "Action: [-0.4  0. ] | Reward: -16.270599072974317 | State: [-0.03940338  2.7208097   3.1337388 ] | Terminated: False | Episode Length: 11.4899999999998\n",
            "Action: [-0.4  0. ] | Reward: -16.27164157323258 | State: [-0.03833975  2.719777    3.1337388 ] | Terminated: False | Episode Length: 11.4999999999998\n",
            "Action: [-0.4  0. ] | Reward: -16.272654819419014 | State: [-0.03727758  2.7187414   3.1337388 ] | Terminated: False | Episode Length: 11.509999999999799\n",
            "Action: [-0.4  0. ] | Reward: -16.273638871021152 | State: [-0.03621686  2.717703    3.1337388 ] | Terminated: False | Episode Length: 11.519999999999799\n",
            "Action: [-0.4  0. ] | Reward: -16.274593787691597 | State: [-0.03515761  2.7166617   3.1337388 ] | Terminated: False | Episode Length: 11.529999999999799\n",
            "Action: [-0.4    0.262] | Reward: -16.275519629246986 | State: [-0.03409983  2.7156174   3.1363566 ] | Terminated: False | Episode Length: 11.539999999999798\n",
            "Action: [-0.4    0.262] | Reward: -16.27641645456179 | State: [-0.03304349  2.71457     3.1389747 ] | Terminated: False | Episode Length: 11.549999999999798\n",
            "Action: [-0.4    0.262] | Reward: -16.277284323116195 | State: [-0.03198858  2.71352     3.1415927 ] | Terminated: False | Episode Length: 11.559999999999798\n",
            "Action: [-0.4  0. ] | Reward: -16.278123294993957 | State: [-0.03093515  2.7124672   3.1415927 ] | Terminated: False | Episode Length: 11.569999999999798\n",
            "Action: [-0.4  0. ] | Reward: -16.278933430659695 | State: [-0.02988319  2.7114112   3.1415927 ] | Terminated: False | Episode Length: 11.579999999999798\n",
            "Action: [-0.4  0. ] | Reward: -16.279714790736886 | State: [-0.02883272  2.7103527   3.1415927 ] | Terminated: False | Episode Length: 11.589999999999797\n",
            "Action: [-0.4  0. ] | Reward: -16.280467436006848 | State: [-0.02778373  2.709291    3.1415927 ] | Terminated: False | Episode Length: 11.599999999999797\n",
            "Action: [-0.4  0. ] | Reward: -16.281191427407684 | State: [-0.02673623  2.7082267   3.1415927 ] | Terminated: False | Episode Length: 11.609999999999797\n",
            "Action: [-0.4  0. ] | Reward: -16.281886826033254 | State: [-0.02569022  2.7071593   3.1415927 ] | Terminated: False | Episode Length: 11.619999999999797\n",
            "Action: [-0.4  0. ] | Reward: -16.282553693132137 | State: [-0.0246457  2.7060893  3.1415927] | Terminated: False | Episode Length: 11.629999999999797\n",
            "Action: [-0.4  0. ] | Reward: -16.283192090106585 | State: [-0.02360268  2.7050164   3.1415927 ] | Terminated: False | Episode Length: 11.639999999999796\n",
            "Action: [-0.4  0. ] | Reward: -16.2838020785115 | State: [-0.02256115  2.7039406   3.1415927 ] | Terminated: False | Episode Length: 11.649999999999796\n",
            "Action: [-0.4  0. ] | Reward: -16.284383720053388 | State: [-0.02152113  2.702862    3.1415927 ] | Terminated: False | Episode Length: 11.659999999999796\n",
            "Action: [-0.4  0. ] | Reward: -16.284937076589326 | State: [-0.02048261  2.7017808   3.1415927 ] | Terminated: False | Episode Length: 11.669999999999796\n",
            "Action: [-0.4  0. ] | Reward: -16.285462210125928 | State: [-0.0194456  2.7006965  3.1415927] | Terminated: False | Episode Length: 11.679999999999795\n",
            "Action: [-0.4  0. ] | Reward: -16.28595918281831 | State: [-0.0184101  2.6996095  3.1415927] | Terminated: False | Episode Length: 11.689999999999795\n",
            "Action: [-0.4  0. ] | Reward: -16.286428056969047 | State: [-0.01737611  2.69852     3.1415927 ] | Terminated: False | Episode Length: 11.699999999999795\n",
            "Action: [-0.4  0. ] | Reward: -16.286868895027155 | State: [-0.01634363  2.6974273   3.1415927 ] | Terminated: False | Episode Length: 11.709999999999795\n",
            "Action: [-0.4  0. ] | Reward: -16.287281759587042 | State: [-0.01531268  2.696332    3.1415927 ] | Terminated: False | Episode Length: 11.719999999999795\n",
            "Action: [-0.4  0. ] | Reward: -16.287666713387488 | State: [-0.01428325  2.695234    3.1415927 ] | Terminated: False | Episode Length: 11.729999999999794\n",
            "Action: [-0.4  0. ] | Reward: -16.288023819310602 | State: [-0.01325534  2.6941333   3.1415927 ] | Terminated: False | Episode Length: 11.739999999999794\n",
            "Action: [-0.4  0. ] | Reward: -16.288353140380803 | State: [-0.01222895  2.6930296   3.1415927 ] | Terminated: False | Episode Length: 11.749999999999794\n",
            "Action: [-0.4  0. ] | Reward: -16.288654739763775 | State: [-0.0112041  2.6919234  3.1415927] | Terminated: False | Episode Length: 11.759999999999794\n",
            "Action: [-0.4  0. ] | Reward: -16.288928680765444 | State: [-0.01018077  2.6908143   3.1415927 ] | Terminated: False | Episode Length: 11.769999999999794\n",
            "Action: [-0.4  0. ] | Reward: -16.289175026830954 | State: [-0.00915899  2.6897025   3.1415927 ] | Terminated: False | Episode Length: 11.779999999999793\n",
            "Action: [-0.4  0. ] | Reward: -16.289393841543625 | State: [-0.00813874  2.6885881   3.1415927 ] | Terminated: False | Episode Length: 11.789999999999793\n",
            "Action: [-0.4  0. ] | Reward: -16.28958518862393 | State: [-0.00712003  2.687471    3.1415927 ] | Terminated: False | Episode Length: 11.799999999999793\n",
            "Action: [-0.4    0.262] | Reward: -16.289749131928485 | State: [-0.00610286  2.686351    3.1442106 ] | Terminated: False | Episode Length: 11.809999999999793\n",
            "Action: [-0.4    0.262] | Reward: -16.28988573566539 | State: [-0.00508725  2.6852283   3.1468287 ] | Terminated: False | Episode Length: 11.819999999999792\n",
            "Action: [-0.4    0.262] | Reward: -16.289995064608835 | State: [-0.00407321  2.6841033   3.1494467 ] | Terminated: False | Episode Length: 11.829999999999792\n",
            "Action: [-0.4    0.262] | Reward: -16.29007718409678 | State: [-3.0607670e-03  2.6829753e+00  3.1520646e+00] | Terminated: False | Episode Length: 11.839999999999792\n",
            "Action: [-0.4    0.262] | Reward: -16.29013216002865 | State: [-2.0499313e-03  2.6818445e+00  3.1546826e+00] | Terminated: False | Episode Length: 11.849999999999792\n",
            "Action: [-0.4    0.262] | Reward: -16.290160058863002 | State: [-1.0407253e-03  2.6807113e+00  3.1573007e+00] | Terminated: False | Episode Length: 11.859999999999792\n",
            "Action: [-0.4    0.262] | Reward: -16.290160947615178 | State: [-3.3167649e-05  2.6795752e+00  3.1599185e+00] | Terminated: False | Episode Length: 11.869999999999791\n",
            "Action: [-0.4    0.262] | Reward: -16.290134893854955 | State: [9.7272277e-04 2.6784368e+00 3.1625366e+00] | Terminated: True | Episode Length: 11.879999999999791\n"
          ]
        }
      ],
      "source": [
        "STALL_AIRSPEED = 27.331231856346\n",
        "from utils.utils import get_optimal_action\n",
        "\n",
        "state = np.array([np.deg2rad(-80), 1.2, np.deg2rad(180)])\n",
        "\n",
        "glider.airplane.flight_path_angle = state[0]\n",
        "glider.airplane.airspeed_norm     = state[1]\n",
        "glider.airplane.bank_angle        = state[2]\n",
        "\n",
        "total_heigh_lost   = 0\n",
        "episode_length = 0\n",
        "terminated     = False\n",
        "\n",
        "while episode_length <10000:\n",
        "    action = get_optimal_action(state, pi)\n",
        "    prev_state  = state.copy()\n",
        "    state, reward, terminated, _, _ = glider.step(action)\n",
        "    state = state[0]\n",
        "    total_heigh_lost += reward\n",
        "    episode_length += 0.01\n",
        "    print(f\"Action: {np.round(action,3)} | Reward: {total_heigh_lost} | State: {state} | Terminated: {terminated} | Episode Length: {episode_length}\")\n",
        "    if terminated: break\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "e08a7e16",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_46979/2236598453.py:33: UserWarning: The input coordinates to pcolormesh are interpreted as cell centers, but are not monotonically increasing or decreasing. This may lead to incorrectly calculated cell edges, in which case, please supply explicit cell edges to pcolormesh.\n",
            "  c = ax.pcolormesh(X, Y, norm_values, cmap='gray', shading='auto',\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhwAAAGJCAYAAADBveoRAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABeUklEQVR4nO3dd1gUV/s38O+CVJGiVBUFLBgVLKA8GLsoNiwpGlEBNRrzEBtEwVgQE0Wxl0RNYk2M+sSW2EXUqBEbitiwohCVFhUUlTrvH77Mz5Xi7LLLUr6f65rrYs+cOXMvSZg7Z06RCYIggIiIiEiNtDQdABEREVV+TDiIiIhI7ZhwEBERkdox4SAiIiK1Y8JBREREaseEg4iIiNSOCQcRERGpHRMOIiIiUjsmHERERKR2TDiIlLRhwwbIZDLcv3+/ytzbzs4Ofn5+4ufjx49DJpPh+PHjZRoHAISHh6NJkybIz89X2z0OHjwIIyMjpKamqu0eRFUFEw6qNK5du4Zhw4ahTp060NPTQ+3atTF06FBcu3atVO3OnTsXu3fvVk2QZWzWrFmQyWTiYWhoiKZNm2L69OnIyMjQdHhKy8jIwPz58xEUFAQtLfk/Y69fv8aSJUvg5uYGExMT6Ovro3Hjxvjqq69w69YtsV7B7yYtLa3Y+/Ts2RMNGzZEWFiY2r4LUVXBhIMqhZ07d6J169aIjIzEiBEj8MMPP2DUqFE4duwYWrdujV27dinddnEJx/Dhw/Hq1SvUr1+/FJGXjVWrVuGXX37B4sWL0aRJE8yZMwc9e/ZEabdS6tixI169eoWOHTuqKFJp1q1bh9zcXAwZMkSuPC0tDe3bt0dAQAAsLS0xe/ZsfP/99xgwYAD+/PNPNG/eXOF7ffHFF1izZg2eP3+uqvCJqqRqmg6AqLTu3r2L4cOHw8HBASdOnICFhYV4bsKECejQoQOGDx+O2NhYODg4qOy+2tra0NbWVll76vTJJ5/A3NwcADB27Fh8/PHH2LlzJ86cOQN3d3el29XS0oK+vr6qwpRs/fr16NevX6F7+/n54dKlS9i+fTs+/vhjuXPffvstpk2bpvC9Pv74Y4wbNw6///47Ro4cWaq4iaoy9nBQhbdgwQK8fPkSP/74o1yyAQDm5uZYs2YNMjMzER4eLpYXdKfHxcVh0KBBMDY2Rq1atTBhwgS8fv1arCeTyZCZmYmNGzeKryUKxjAUNY7Czs4Offv2xfHjx+Hq6goDAwM4OTmJYxx27twJJycn6Ovrw8XFBZcuXZKLNzY2Fn5+fnBwcIC+vj6sra0xcuRI/Pvvvyr9nXXt2hUAEB8fDwDIzMxEYGAgbG1toaenB0dHRyxcuPC9PSDFjeE4e/YsevfuDTMzM1SvXh3Ozs5YtmwZgDfJgkwmK/TdgTe9Sdra2nj48GGx94yPj0dsbCw8PDwK3XPfvn0YNWpUoWQDAPT09LBw4cISv09RLC0t4ezsjD/++EPha4no/zDhoApvz549sLOzQ4cOHYo837FjR9jZ2WHfvn2Fzg0aNAivX79GWFgYevfujeXLl2PMmDHi+V9++QV6enro0KEDfvnlF/zyyy/44osvSoznzp078Pb2hpeXF8LCwvD06VN4eXlh8+bNmDRpEoYNG4bQ0FDcvXsXgwYNkhv0GBERgXv37mHEiBFYsWIFPvvsM2zduhW9e/cu9euPt929excAUKtWLQiCgH79+mHJkiXo2bMnFi9eDEdHR0yePBkBAQEKtx0REYGOHTvi+vXrmDBhAhYtWoQuXbpg7969AN70thgYGGDz5s2Frt28eTM6d+6MOnXqFNv+6dOnAQCtW7eWK//zzz8BvHnVpWouLi7ifYlISQJRBfbs2TMBgNC/f/8S6/Xr108AIGRkZAiCIAghISECAKFfv35y9f773/8KAITLly+LZdWrVxd8fX0Ltbl+/XoBgBAfHy+W1a9fXwAgnD59Wiw7dOiQAEAwMDAQHjx4IJavWbNGACAcO3ZMLHv58mWh+2zZskUAIJw4caLEexel4HvevHlTSE1NFeLj44U1a9YIenp6gpWVlZCZmSns3r1bACB89913ctd+8skngkwmE+7cuSP3/d7+XRw7dkzuO+Tm5gr29vZC/fr1hadPn8q1l5+fL/48ZMgQoXbt2kJeXp5YdvHiRQGAsH79+hK/0/Tp0wUAwvPnz+XKBw4cKAAodN/iFPxuUlNT31t37ty5AgAhOTlZUttEVBh7OKhCKxjIV6NGjRLrFZx/d2aGv7+/3Odx48YBAPbv3690TE2bNpUbF+Hm5gbgzWuMevXqFSq/d++eWGZgYCD+/Pr1a6SlpeE///kPAODixYtKx+To6AgLCwvY29vjiy++QMOGDbFv3z4YGhpi//790NbWxvjx4+WuCQwMhCAIOHDggOT7XLp0CfHx8Zg4cSJMTU3lzslkMvFnHx8fPHr0CMeOHRPLNm/eDAMDgyJfh7zt33//RbVq1WBkZCRXXvDP9n3/LijDzMwMAEqc0UJEJeOgUarQCh4u75tBUFxi0qhRI7nPDRo0gJaWVqnWt3g7qQAAExMTAICtrW2R5U+fPhXLnjx5gtDQUGzduhUpKSly9dPT05WOaceOHTA2NoaOjg7q1q2LBg0aiOcePHiA2rVrF/rdfPDBB+J5qQpe1bxvNkj37t1hY2ODzZs3o1u3bsjPz8eWLVvQv39/pRMGY2NjAG/+Wb+b7JSW8P9fZ72dNBGRYphwUIVmYmICGxsbxMbGllgvNjYWderUER9KxVHFA6W4mSvFlQtvjc0YNGgQTp8+jcmTJ6Nly5YwMjJCfn4+evbsWaoFrjp27CjOUikPtLW14e3tjZ9++gk//PAD/v77bzx69AjDhg1777W1atVCbm4unj9/LpecNGnSBABw5cqVYsfzKKsgKSxPv0OiioavVKjC69u3L+Lj43Hq1Kkiz588eRL3799H3759C527ffu23Oc7d+4gPz8fdnZ2YllZ/V/t06dPERkZieDgYISGhmLgwIHo3r27SqfyFqV+/fp49OhRoV6iuLg48bxUBT0nV69efW9dHx8fZGRkYM+ePdi8eTMsLCzg6en53usKEouCGTYFvLy8AAC//vqr5Hilio+Ph7m5eaFZUEQkHRMOqvAmT54MAwMDfPHFF4Wmjz558gRjx46FoaEhJk+eXOja77//Xu7zihUrAAC9evUSy6pXr45nz56pPvB3FPSACO/MRlm6dKla79u7d2/k5eVh5cqVcuVLliyBTCaT+128T+vWrWFvb4+lS5cW+p29+72cnZ3h7OyMn3/+GTt27MBnn32GatXe3+laMD7mwoULhcp79uyJn3/+uciF2rKzs/H1119L/i5vi46OLtV6JUTEVypUCTRq1AgbN27E0KFD4eTkhFGjRsHe3h7379/H2rVrkZaWhi1btsiNWygQHx+Pfv36oWfPnoiKisKvv/4Kb29vtGjRQqzj4uKCI0eOYPHixahduzbs7e3FAZ+qZGxsjI4dOyI8PBw5OTmoU6cODh8+XOj/5FXNy8sLXbp0wbRp03D//n20aNEChw8fxh9//IGJEycW+XsrjpaWFlatWgUvLy+0bNkSI0aMgI2NDeLi4nDt2jUcOnRIrr6Pj4+YBEh5nQIADg4OaN68OY4cOVJoIa5NmzahR48e+Oijj+Dl5YVu3bqhevXquH37NrZu3YrHjx8XWotj8eLFMDQ0LPQ9vvnmGwBASkoKYmNjCw0wJiIFaXSODJEKxcbGCkOGDBFsbGwEHR0dwdraWhgyZIhw5cqVQnULpkRev35d+OSTT4QaNWoIZmZmwldffSW8evVKrm5cXJzQsWNHwcDAQAAgTgstblpsnz59Ct0PgODv7y9XFh8fLwAQFixYIJb9888/wsCBAwVTU1PBxMRE+PTTT4VHjx4JAISQkBCxnqLTYt839fP58+fCpEmThNq1aws6OjpCo0aNhAULFshNZS34fiVNiy1w6tQpoXv37kKNGjWE6tWrC87OzsKKFSsK3ffx48eCtra20Lhx4xLje9fixYsFIyOjIqcRv3z5Uli4cKHQpk0bwcjISNDV1RUaNWokjBs3Tm6Kb8HvpqhDW1tbrLdq1SrB0NBQnFJNRMqRCYIKVxMiqiBmzZqF0NBQpKamciCgBqWlpcHGxgYzZ87EjBkzJF+Xnp4OBwcHhIeHY9SoUWqMEGjVqhU6d+6MJUuWqPU+RJUdx3AQkcZs2LABeXl5Cq8OamJigilTpmDBggVq357+9u3bmDp1qtruQVRVcAwHEZW5o0eP4vr165gzZw4GDBggNytIqqCgIAQFBak+uLf07NkTL168UOs9iKoKJhxEVOZmz56N06dP48MPPxRnBhFR5VYpX6l8//33sLOzg76+Ptzc3HDu3DlNh0TlzKxZsyAIAsdvaMjx48eRnZ2NY8eOlbhRGxEBJ06cgJeXF2rXrg2ZTFbktO93HT9+HK1bt4aenh4aNmyIDRs2qD3O96l0Cce2bdsQEBCAkJAQXLx4ES1atICnp2ehZaKJiIgqgszMTLRo0aLQukHFiY+PR58+fdClSxfExMRg4sSJ+PzzzwtNSy9rlW6WipubG9q0aSMuYpSfnw9bW1uMGzcOwcHBGo6OiIhIeTKZDLt27cKAAQOKrRMUFIR9+/bJrfj72Wef4dmzZzh48GAZRFm0SjWGIzs7G9HR0XIjyrW0tODh4YGoqKgir8nKykJWVpb4OT8/H0+ePEGtWrW4URMRUQUmCAKeP3+O2rVrQ0tL9R36r1+/RnZ2tlLXCoJQ6Bmjp6cHPT29UscVFRUFDw8PuTJPT09MnDix1G2XRqVKONLS0pCXlwcrKyu5cisrK3FfiHeFhYUhNDS0LMIjIiINSExMRN26dVXa5uvXr2Fvb4+kpCSlrjcyMio0AyokJASzZs0qdWxJSUlFPgczMjLw6tUrGBgYlPoeyqhUCYcypk6dioCAAPFzeno66tWrh8TExPfuLEpEqmViYqLpEKgSentXYVXJzs5GUlISEhISFH5WZGRkFPmcUUXvRnlWqRIOc3NzaGtrIzk5Wa48OTkZ1tbWRV5TXBeWsbExEw4iokpAna/Ha9SooXBCUzB0Ul3PGWtr6yKfg8bGxhrr3QAq2SwVXV1duLi4IDIyUizLz89HZGQkd3okIiKVEwRBqUOd3N3d5Z6DABAREaHx52ClSjgAICAgAD/99BM2btyIGzdu4Msvv0RmZiZGjBih6dCIiIgU9uLFC8TExCAmJgbAm2mvMTExSEhIAPBmaICPj49Yf+zYsbh37x6mTJmCuLg4/PDDD/jf//6HSZMmaSJ8UaV6pQIAgwcPRmpqKmbOnImkpCS0bNkSBw8eLDSAhoiIqLSU6bFQtP6FCxfQpUsX8XPBuENfX19s2LABjx8/FpMPALC3t8e+ffswadIkLFu2DHXr1sXPP/8MT09Phe6rapVuHY7SysjIgImJCdLT0zmGg6iMcSo6qYM6/p4XPCvS0tKUGjRqbm5e5Z4zla6Hg4iIqKyURQ9HZcGEg4iISElMOKRjwkFERKQkJhzSVbpZKkRERFT+sIeDiIhISezhkI4JBxERkZKYcEjHhIOIiEhJTDikY8JBRESkJCYc0jHhICIiUhITDuk4S4WIiIjUjj0cRERESmIPh3RMOIiIiJTEhEM6JhxERERKYsIhHRMOIiIiJTHhkI4JBxERkZKYcEjHWSpERESkduzhICIiKoWq2mOhKCYcRERESuIrFemYcBARESmJCYd0TDiIiIiUxIRDOiYcRERESmLCIR1nqRAREZHasYeDiIhISezhkK7C9HDMmTMH7dq1g6GhIUxNTYusk5CQgD59+sDQ0BCWlpaYPHkycnNzyzZQIiKqMgoSDkWPqqjC9HBkZ2fj008/hbu7O9auXVvofF5eHvr06QNra2ucPn0ajx8/ho+PD3R0dDB37lwNRExERJUdezikqzAJR2hoKABgw4YNRZ4/fPgwrl+/jiNHjsDKygotW7bEt99+i6CgIMyaNQu6urplGC0REVUFTDikqzCvVN4nKioKTk5OsLKyEss8PT2RkZGBa9euFXtdVlYWMjIy5A4iIiIp+EpFukqTcCQlJcklGwDEz0lJScVeFxYWBhMTE/GwtbVVa5xERERVkUYTjuDgYMhkshKPuLg4tcYwdepUpKeni0diYqJa70dERJUHezik0+gYjsDAQPj5+ZVYx8HBQVJb1tbWOHfunFxZcnKyeK44enp60NPTk3QPIiKit3EMh3QaTTgsLCxgYWGhkrbc3d0xZ84cpKSkwNLSEgAQEREBY2NjNG3aVCX3ICIiehsTDukqzCyVhIQEPHnyBAkJCcjLy0NMTAwAoGHDhjAyMkKPHj3QtGlTDB8+HOHh4UhKSsL06dPh7+/PHgwiIlILJhzSVZiEY+bMmdi4caP4uVWrVgCAY8eOoXPnztDW1sbevXvx5Zdfwt3dHdWrV4evry9mz56tqZCJiKiSY8IhnUyoqt+8GBkZGTAxMUF6ejqMjY01HQ5RlSKTyTQdAlVC6vh7XvCsuHz5MmrUqKHQtc+fP0eLFi2q3HOmwvRwEBERlTfs4ZCOCQcREZGSmHBIx4SDiIhISUw4pGPCQUREVApVNYFQFBMOIiIiJbGHQ7pKs5cKERERlV/s4SAiIlISezikY8JBRESkJCYc0jHhICIiUhITDumYcBARESmJCYd0TDiIiIiUxIRDOs5SISIiIrVjDwcREZGS2MMhHRMOIiIiJTHhkI4JBxERkZKYcEjHhIOIiEhJTDik46BRIiIiJRUkHIoeyvj+++9hZ2cHfX19uLm54dy5cyXWX7p0KRwdHWFgYABbW1tMmjQJr1+/VureqsCEg4iIqJzbtm0bAgICEBISgosXL6JFixbw9PRESkpKkfV/++03BAcHIyQkBDdu3MDatWuxbds2fPPNN2Uc+f9hwkFERKSksurhWLx4MUaPHo0RI0agadOmWL16NQwNDbFu3boi658+fRoffvghvL29YWdnhx49emDIkCHv7RVRJyYcRERESipNwpGRkSF3ZGVlFXmP7OxsREdHw8PDQyzT0tKCh4cHoqKiirymXbt2iI6OFhOMe/fuYf/+/ejdu7eKfwPScdAoERGRkkozaNTW1lauPCQkBLNmzSpUPy0tDXl5ebCyspIrt7KyQlxcXJH38Pb2RlpaGtq3bw9BEJCbm4uxY8dq9JUKEw4iIiIllSbhSExMhLGxsViup6ensriOHz+OuXPn4ocffoCbmxvu3LmDCRMm4Ntvv8WMGTNUdh9FMOEgIiJSUmkSDmNjY7mEozjm5ubQ1tZGcnKyXHlycjKsra2LvGbGjBkYPnw4Pv/8cwCAk5MTMjMzMWbMGEybNg1aWmU/oqJCjOG4f/8+Ro0aBXt7exgYGKBBgwYICQlBdna2XL3Y2Fh06NAB+vr6sLW1RXh4uIYiJiIiUg1dXV24uLggMjJSLMvPz0dkZCTc3d2LvObly5eFkgptbW0AmlsHpEL0cMTFxSE/Px9r1qxBw4YNcfXqVYwePRqZmZlYuHAhgDeDb3r06AEPDw+sXr0aV65cwciRI2FqaooxY8Zo+BsQEVFlVFYLfwUEBMDX1xeurq5o27Ytli5diszMTIwYMQIA4OPjgzp16iAsLAwA4OXlhcWLF6NVq1biK5UZM2bAy8tLTDzKWoVIOHr27ImePXuKnx0cHHDz5k2sWrVKTDg2b96M7OxsrFu3Drq6umjWrBliYmKwePFiJhxERKQ2ZdFjMHjwYKSmpmLmzJlISkpCy5YtcfDgQXEgaUJCglyPxvTp0yGTyTB9+nQ8fPgQFhYW8PLywpw5c9Qea3FkQgVdY3X69Ok4ePAgLly4AOBNdpeRkYHdu3eLdY4dO4auXbviyZMnMDMzK7KdrKwsualIGRkZsLW1RXp6uqR3a0SkOjKZTNMhUCWkjr/nGRkZMDExwZEjR1C9enWFrs3MzISHh0eVe85UiDEc77pz5w5WrFiBL774QixLSkoqcspQwbnihIWFwcTERDzenaZERERUnLJc2ryi02jCERwcDJlMVuLx7hzjhw8fomfPnvj0008xevToUscwdepUpKeni0diYmKp2yQiIiJ5Gh3DERgYCD8/vxLrODg4iD8/evQIXbp0Qbt27fDjjz/K1bO2ti5yylDBueLo6empdO4zERFVHdwtVjqNJhwWFhawsLCQVPfhw4fo0qULXFxcsH79+kLTfdzd3TFt2jTk5ORAR0cHABAREQFHR8dix28QERGVBhMO6SrEGI6HDx+ic+fOqFevHhYuXIjU1FQkJSXJjc3w9vaGrq4uRo0ahWvXrmHbtm1YtmwZAgICNBg5ERFVZhzDIV2FmBYbERGBO3fu4M6dO6hbt67cuYJ/cCYmJjh8+DD8/f3h4uICc3NzzJw5k1NiiYhIbdjDIV2FSDj8/PzeO9YDAJydnXHy5En1B0RERAQmHIqoEK9UiIiIqGIrVQ9HVlYWZ3gQEVGVxR4O6RTq4Thw4AB8fX3h4OAAHR0dGBoawtjYGJ06dcKcOXPw6NEjdcVJRERU7nDQqHSSEo5du3ahcePGGDlyJKpVq4agoCDs3LkThw4dws8//4xOnTrhyJEjcHBwwNixY5GamqruuImIiDSOCYd0kl6phIeHY8mSJejVq1eh9S8AYNCgQQDeTF9dsWIFfv31V0yaNEm1kRIREZUzfKUinaSEIyoqSlJjderUwbx580oVEBERUUXBhEM6zlIhIiIitVN4lkpxK3fKZDLo6+ujYcOG6N+/P2rWrFnq4IiIiMoz9nBIp3DCcenSJVy8eBF5eXlwdHQEANy6dQva2tpo0qQJfvjhBwQGBuLUqVNo2rSpygMmIiIqL5hwSKfwK5X+/fvDw8MDjx49QnR0NKKjo/HPP/+ge/fuGDJkCB4+fIiOHTty0CgREVV6nKUincIJx4IFC/Dtt9/C2NhYLDMxMcGsWbMQHh4OQ0NDzJw5E9HR0SoNlIiIqLxhwiGdwglHeno6UlJSCpWnpqYiIyMDAGBqaors7OzSR0dERFSOMeGQTqlXKiNHjsSuXbvwzz//4J9//sGuXbswatQoDBgwAABw7tw5NG7cWNWxEhERUQWl8KDRNWvWYNKkSfjss8+Qm5v7ppFq1eDr64slS5YAAJo0aYKff/5ZtZESERGVQ1W1x0JRCiccRkZG+Omnn7BkyRLcu3cPAODg4AAjIyOxTsuWLVUWIBERUXnFWSrSKb3wV1JSEh4/foxGjRrByMioyv4CiYio6uIYDukUTjj+/fdfdOvWDY0bN0bv3r3x+PFjAMCoUaMQGBio8gCJiIjKKyYc0imccEyaNAk6OjpISEiAoaGhWD548GAcPHhQpcERERGVZ0w4pFN4DMfhw4dx6NAh1K1bV668UaNGePDggcoCIyIiospD4YQjMzNTrmejwJMnT6Cnp6eSoIiIiCoCDhqVTuFXKh06dMCmTZvEzzKZDPn5+QgPD0eXLl1UGhwREVF5xlcq0incwxEeHo5u3brhwoULyM7OxpQpU3Dt2jU8efIEf//9tzpiJCIiKpfYwyGdwj0czZs3x61bt9C+fXv0798fmZmZ+Oijj3Dp0iU0aNBAHTESERGVS+zhkE7hHg7gzWZt06ZNU3UsJerXrx9iYmKQkpICMzMzeHh4YP78+ahdu7ZYJzY2Fv7+/jh//jwsLCwwbtw4TJkypUzjJCKiqoM9HNJJSjhiY2MlN+js7Kx0MCXp0qULvvnmG9jY2ODhw4f4+uuv8cknn+D06dMAgIyMDPTo0QMeHh5YvXo1rly5gpEjR8LU1BRjxoxRS0xEREQkjaSEo2XLlpDJZBAEATKZTCwvyNLeLsvLy1NxiG9MmjRJ/Ll+/foIDg7GgAEDkJOTAx0dHWzevBnZ2dlYt24ddHV10axZM8TExGDx4sVMOIiISC3YwyGdpDEc8fHxuHfvHuLj47Fjxw7Y29vjhx9+QExMDGJiYvDDDz+gQYMG2LFjh7rjBfBmCu7mzZvRrl076OjoAACioqLQsWNH6OrqivU8PT1x8+ZNPH36tNi2srKykJGRIXcQERFJwTEc0knq4ahfv77486efforly5ejd+/eYpmzszNsbW0xY8YMcYt6dQgKCsLKlSvx8uVL/Oc//8HevXvFc0lJSbC3t5erb2VlJZ4zMzMrss2wsDCEhoaqLWYiIqq82MMhncKzVK5cuVLowQ4A9vb2uH79ukJtBQcHQyaTlXjExcWJ9SdPnoxLly7h8OHD0NbWho+PT6n/wU2dOhXp6enikZiYWKr2iIio6mAPh3QKz1L54IMPEBYWhp9//ll8fZGdnY2wsDB88MEHCrUVGBgIPz+/Eus4ODiIP5ubm8Pc3ByNGzfGBx98AFtbW5w5cwbu7u6wtrZGcnKy3LUFn62trYttX09PjyukEhGRUtjDIZ3CCcfq1avh5eWFunXrijNSYmNjIZPJsGfPHoXasrCwgIWFhaIhAADy8/MBvBmDAQDu7u6YNm2aOIgUACIiIuDo6Fjs6xQiIiKS5t69exg7diwOHz6s1PUKJxxt27bFvXv3sHnzZvF1x+DBg+Ht7Y3q1asrFcT7nD17FufPn0f79u1hZmaGu3fvYsaMGWjQoAHc3d0BAN7e3ggNDcWoUaMQFBSEq1evYtmyZViyZIlaYiIiIqpKPRzPnz9HZGSk0tcrtfBX9erVy3SqqaGhIXbu3ImQkBBkZmbCxsYGPXv2xPTp08XXISYmJjh8+DD8/f3h4uICc3NzzJw5k1NiiYhIbapSwlFakhKOM2fO4D//+Y+kBl++fIn4+Hg0a9asVIG9zcnJCUePHn1vPWdnZ5w8eVJl9yUiIioJEw7pJM1SGT58ODw9PfH7778jMzOzyDrXr1/HN998gwYNGiA6OlqlQRIREZVHnKUinaQejuvXr2PVqlWYPn06vL290bhxY9SuXRv6+vp4+vQp4uLi8OLFCwwcOBCHDx+Gk5OTuuMmIiIqFypLAtGqVSu5lcPf9fLly1K1Lynh0NHRwfjx4zF+/HhcuHABp06dwoMHD/Dq1Su0aNECkyZNQpcuXVCzZs1SBUNERESaoc6FOwElBo26urrC1dVVHbEQERFVKJVpDEdISIha21d4pVEiIiJ6ozKN4Xj9+jX+/PNPPH/+vNC5jIwM/Pnnn+LaV8pgwkFERKSkypRwrFmzBsuWLUONGjUKnTM2Nsby5cvx008/Kd0+Ew4iIiIlVaaEY/PmzZg4cWKx5ydOnIhNmzYp3b5SC38RERFR5RrDcfv2bbRo0aLY887Ozrh9+7bS7Zeqh+P169eluZyIiIjKidzcXKSmphZ7PjU1Fbm5uUq3r3DCkZ+fj2+//RZ16tSBkZER7t27BwCYMWMG1q5dq3QgREREFU1leqXSrFkzHDlypNjzhw8fLtUq4gonHN999x02bNiA8PBwcXt6AGjevDl+/vlnpQMhIiKqaMoy4fj+++9hZ2cHfX19uLm54dy5cyXWf/bsGfz9/WFjYwM9PT00btwY+/fvL7b+yJEj8e2332Lv3r2Fzu3Zswdz5szByJEjlYodUGIMx6ZNm/Djjz+iW7duGDt2rFjeokULcfdYIiKiqqCsxnBs27YNAQEBWL16Ndzc3LB06VJ4enri5s2bsLS0LFQ/Ozsb3bt3h6WlJbZv3446dergwYMHMDU1LfYeY8aMwYkTJ9CvXz80adIEjo6OAIC4uDjcunULgwYNKtWGqAonHA8fPkTDhg0Llefn5yMnJ0fpQIiIiCqasko4Fi9ejNGjR2PEiBEAgNWrV2Pfvn1Yt24dgoODC9Vft24dnjx5gtOnT0NHRwcAYGdn9977/Prrr+jXrx9+++033Lp1C4IgwNHREaGhoRg0aJDCcb9N4YSjadOmOHnyJOrXry9Xvn37drRq1apUwRAREVUkpUk4MjIy5Mr19PSgp6dXqH52djaio6MxdepUsUxLSwseHh6Iiooq8h5//vkn3N3d4e/vjz/++AMWFhbw9vZGUFAQtLW1S4xv0KBBpU4uiqJwwjFz5kz4+vri4cOHyM/Px86dO3Hz5k1s2rSpyPc+REREVJitra3c55CQEMyaNatQvbS0NOTl5cHKykqu3MrKqtihDPfu3cPRo0cxdOhQ7N+/H3fu3MF///tf5OTkqH0J8+IonHD0798fe/bswezZs1G9enXMnDkTrVu3xp49e9C9e3d1xEhERFQulaaHIzExEcbGxmJ5Ub0bysrPz4elpSV+/PFHaGtrw8XFBQ8fPsSCBQsqTsIBAB06dEBERISqYyEiIqpQSpNwGBsbyyUcxTE3N4e2tjaSk5PlypOTk2FtbV3kNTY2NtDR0ZF7ffLBBx8gKSkJ2dnZcrNMywqXNiciIlJSWUyL1dXVhYuLCyIjI8Wy/Px8REZGwt3dvchrPvzwQ9y5cwf5+fli2a1bt2BjY6ORZAOQ2MNhZmYGmUwmqcEnT56UKiAiIqKKoqxmqQQEBMDX1xeurq5o27Ytli5diszMTHHWio+PD+rUqYOwsDAAwJdffomVK1diwoQJGDduHG7fvo25c+di/PjxCt9bVSQlHEuXLlVzGERERBVPWSUcgwcPRmpqKmbOnImkpCS0bNkSBw8eFAeSJiQkQEvr/15a2Nra4tChQ5g0aRKcnZ1Rp04dTJgwAUFBQUW2/9FHH0mOZefOnQrHD0hMOHx9fZVqnIiIiFTjq6++wldffVXkuePHjxcqc3d3x5kzZyS1bWJiIv4sCAJ27doFExMTuLq6AgCio6Px7NkzhRKTdyk8aPTdecMFZDIZ9PT0NPZuiIiIqKxVlt1i169fL/4cFBSEQYMGYfXq1eKg07y8PPz3v/+VNMi1OAonHKampiWO56hbty78/PwQEhIi171DRERU2VSWhONt69atw6lTp+RmuGhrayMgIADt2rXDggULlGpX4YRjw4YNmDZtGvz8/NC2bVsAwLlz57Bx40ZMnz4dqampWLhwIfT09PDNN98oFRQREVFFUd4TCEXl5uYiLi5O3EulQFxcnNysF0UpnHBs3LgRixYtklv21MvLC05OTlizZg0iIyNRr149zJkzRy0JR1ZWFtzc3HD58mVcunQJLVu2FM/FxsbC398f58+fh4WFBcaNG4cpU6aoPAYiIiKgcvZwjBgxAqNGjcLdu3fFjoWzZ89i3rx54qwYZSiccJw+fRqrV68uVN6qVStxTff27dsjISFB6aBKMmXKFNSuXRuXL1+WK8/IyECPHj3g4eGB1atX48qVKxg5ciRMTU1LtbsdERFRcSpjwrFw4UJYW1tj0aJFePz4MYA3C4lNnjwZgYGBSrer8CALW1tbrF27tlD52rVrxXXh//33X5iZmSkdVHEOHDiAw4cPY+HChYXObd68GdnZ2Vi3bh2aNWuGzz77DOPHj8fixYtVHgcREVFlpaWlhSlTpuDhw4d49uwZnj17hocPH2LKlCnv3fitJAr3cCxcuBCffvopDhw4gDZt2gAALly4gLi4OGzfvh0AcP78eQwePFjpoIqSnJyM0aNHY/fu3TA0NCx0PioqCh07dpSbJePp6Yn58+fj6dOnxSZAWVlZyMrKEj8XNwuHiIjoXZWxhwN4M47j+PHjuHv3Lry9vQEAjx49grGxMYyMjJRqU+GEo1+/foiLi8OaNWtw69YtAECvXr2we/du2NnZAXizwpkqCYIAPz8/jB07Fq6urrh//36hOklJSbC3t5crK1gQJSkpqdiEIywsDKGhoSqNl4iIqobKmHA8ePAAPXv2REJCArKystC9e3fUqFED8+fPR1ZWVpHDKqRQavM2e3t7zJs3T6kbvi04OBjz588vsc6NGzdw+PBhPH/+HFOnTi31Pd81depUBAQEiJ8zMjIKbRlMRERUlMqYcEyYMAGurq64fPkyatWqJZYPHDgQo0ePVrpdpRKOZ8+e4dy5c0hJSSk0RcbHx0dyO4GBgfDz8yuxjoODA44ePYqoqKhCW/e6urpi6NCh2LhxI6ytrYvcSQ9AsbvpAW+2A1bllsBERFR1VMaE4+TJkzh9+nShhTzt7Ozw8OFDpdtVOOHYs2cPhg4dihcvXsDY2FhuETCZTKZQwmFhYQELC4v31lu+fDm+++478fOjR4/g6emJbdu2wc3NDcCbJVynTZuGnJwc6OjoAAAiIiLg6OiolgGsRERElTHhyM/PR15eXqHyf/75BzVq1FC6XYVnqQQGBmLkyJF48eIFnj17hqdPn4qHunaKrVevHpo3by4ejRs3BgA0aNAAdevWBQB4e3tDV1cXo0aNwrVr17Bt2zYsW7ZM7nUJERERlaxHjx5ym7bKZDK8ePECISEh6N27t9LtKtzD8fDhQ4wfP77ImSKaZGJigsOHD8Pf3x8uLi4wNzfHzJkzuQYHERGpTWXs4Vi0aBE8PT3RtGlTvH79Gt7e3rh9+zbMzc2xZcsWpdtVOOHw9PTEhQsX4ODgoPRNS8vOzq7If2DOzs44efKkBiIiIqKqqDImHHXr1sXly5exbds2XL58GS9evMCoUaMwdOhQGBgYKN2uwglHnz59MHnyZFy/fh1OTk7ieIkC/fr1UzoYIiKiiqQyJhwAUK1aNQwdOhRDhw5VXZuKXlAwJWb27NmFzslksiIHmhAREVVGlTHh0NbWRseOHbFjxw7UrFlTLE9OTkbt2rWVfs4rPGg0Pz+/2IPJBhERUcUmCAKysrLg6uqKa9euFTqnLIUTjuI8e/YMK1euVFVzRERE5V5BD4eiR3kmk8mwY8cOeHl5wd3dHX/88YfcOWWVOuGIjIyEt7c3bGxsEBISUtrmiIiIKozKmHAIggBtbW0sW7YMCxcuxODBg/Hdd9+VOm6lEo7ExETMnj0b9vb26NGjB2QyGXbt2oWkpKRSBUNERFSRVMaE421jxozBgQMHsHTpUoUW9iyK5IQjJycHv//+Ozw9PeHo6IiYmBgsWLAAWlpamDZtGnr27FloxgoREVFlVhkTjvr168ttQ9+lSxecOXMGiYmJpWpX8iyVOnXqoEmTJhg2bBi2bt0qLhc+ZMiQUgVARERUUVXGWSrx8fGFyho2bIhLly4V2rNMEZJ7OHJzcyGTySCTyeQyHyIiIqr89PX1Ub9+faWvl9zD8ejRI+zYsQNr167FhAkT0KtXLwwbNqxUI1aJiIgqssrSw1GzZk3cunUL5ubmMDMzK/HZruy+aZITDn19fXHVsbt372L9+vUYP348cnNzMWfOHPj5+aFr167s/SAioiqlPCYQilqyZIm4E+zbG7epkkwoxW8qPz8fhw4dwtq1a7Fnzx7UqFEDaWlpqoyvzGVkZMDExATp6ekwNjbWdDhEVQp7TEkd1PH3vOBZERQUBD09PYWuzcrKwvz586vcc0bhpc3fpqWlhV69eqFXr15ITU3FL7/8oqq4iIiIyr3K8kolIyNDcl1lk6RSJRxvs7CwQEBAgKqaIyIiKvcqS8Jhamr63h5GQRBKtWeayhIOIiIiqpiOHTum9nsw4SAiIlJSZenh6NSpk9rvwYSDiIhISZUl4SjKy5cvkZCQgOzsbLlyZ2dnpdpjwkFERKSkyphwpKamYsSIEThw4ECR58tsDEdeXh42bNiAyMhIpKSkID8/X+780aNHlQqEiIiooqmMCcfEiRPx7NkznD17Fp07d8auXbuQnJyM7777DosWLVK6XYUTjgkTJmDDhg3o06cPmjdvznnzRERUZVXGhOPo0aP4448/4OrqCi0tLdSvXx/du3eHsbExwsLC0KdPH6XaVTjh2Lp1K/73v/+hd+/eSt2QiIiIyq/MzExYWloCAMzMzJCamorGjRvDyckJFy9eVLpdyZu3FdDV1UXDhg2VviEREVFlURm3p3d0dMTNmzcBAC1atMCaNWvw8OFDrF69GjY2Nkq3q3DCERgYiGXLlpX7XxgREZG6VcaEY8KECXj8+DEAICQkBAcOHEC9evWwfPlyzJ07V+l2Jb1S+eijj+Q+Hz16FAcOHECzZs2go6Mjd27nzp1KB1MSOzs7PHjwQK4sLCwMwcHB4ufY2Fj4+/vj/PnzsLCwwLhx4zBlyhS1xENERFQZx3AMGzZM/NnFxQUPHjxAXFwc6tWrB3Nzc6XblZRwmJiYyH0eOHCg0jcsjdmzZ2P06NHi54Kd7YA368D36NEDHh4eWL16Na5cuYKRI0fC1NQUY8aM0US4RERUyVXGhONdhoaGaN26danbkZRwrF+/vtQ3UoUaNWrA2tq6yHObN29GdnY21q1bB11dXTRr1gwxMTFYvHgxEw4iIlKLyphwCIKA7du349ixY0Uuf6HsmwyFx3B07doVz549K1SekZGBrl27KhWEVPPmzUOtWrXQqlUrLFiwALm5ueK5qKgodOzYEbq6umKZp6cnbt68iadPnxbbZlZWFjIyMuQOIiKiqmrixIkYPnw44uPjYWRkBBMTE7lDWQpPiz1+/HihZU4B4PXr1zh58qTSgbzP+PHj0bp1a9SsWROnT5/G1KlT8fjxYyxevBgAkJSUBHt7e7lrrKysxHNmZmZFthsWFobQ0FC1xU1ERJVXZezh+OWXX7Bz506VL38hOeGIjY0Vf75+/TqSkpLEz3l5eTh48CDq1Kmj0M2Dg4Mxf/78EuvcuHEDTZo0QUBAgFjm7OwMXV1dfPHFFwgLC4Oenp5C933b1KlT5drOyMiAra2t0u0REVHVURkTDhMTEzg4OKi8XckJR8uWLSGTySCTyYp8dWJgYIAVK1YodPPAwED4+fmVWKe4L+3m5obc3Fzcv38fjo6OsLa2RnJyslydgs/FjfsAAD09vVIlLEREVHVVxoRj1qxZCA0Nxbp162BgYKCydiUnHPHx8RAEAQ4ODjh37hwsLCzEc7q6urC0tIS2trZCN7ewsJBrRxExMTHQ0tISV0Nzd3fHtGnTkJOTI07VjYiIgKOjY7GvU4iIiEqjMiYcgwYNwpYtW2BpaQk7O7tCy18ou9qo5ISjfv36AFBotGpZiIqKwtmzZ9GlSxfUqFEDUVFRmDRpEoYNGyYmE97e3ggNDcWoUaMQFBSEq1evYtmyZViyZEmZx0tERFVHeU8gFOXr64vo6GgMGzYMVlZWKtszTent6a9fv46EhIRCA0j79etX6qDepaenh61bt2LWrFnIysqCvb09Jk2aJDf2wsTEBIcPH4a/vz9cXFxgbm6OmTNnckosERGRAvbt24dDhw6hffv2Km1X4YTj3r17GDhwIK5cuQKZTCZmdgUZUF5enkoDBIDWrVvjzJkz763n7Oys1pkyREREb6uMr1RsbW1hbGys8nYVXodjwoQJsLe3R0pKCgwNDXHt2jWcOHECrq6uOH78uMoDJCIiKq8q414qixYtwpQpU3D//n2VtqtwD0dUVBSOHj0Kc3NzaGlpQUtLC+3bt0dYWBjGjx+PS5cuqTRAIiKi8qoy9nAMGzYML1++RIMGDWBoaFho0OiTJ0+UalfhhCMvL0/cw8Tc3ByPHj2Co6Mj6tevL25nS0REVBVUxoRj6dKlamlX4YSjefPmuHz5Muzt7eHm5obw8HDo6urixx9/VMtCIUREROVVWSYc33//PRYsWICkpCS0aNECK1asQNu2bd973datWzFkyBD0798fu3fvLrFuTk4O/vrrL8yYMaPQ6t2lpfAYjunTp4tTY2fPno34+Hh06NAB+/fvx/Lly1UaHBEREQHbtm1DQEAAQkJCcPHiRbRo0QKenp5ISUkp8br79+/j66+/RocOHSTdR0dHBzt27FBFyIUonHB07twZnp6eAICGDRsiLi4OaWlpSElJUfvmbUREROVJWQ0aXbx4MUaPHo0RI0agadOmWL16NQwNDbFu3bpir8nLy8PQoUMRGhqq0BuIAQMGvLcnRBmSX6mkpqbCx8cHR44cQX5+Ptq0aYNff/0VDRs2RM2aNVUeGBERUXlXmlcq7+5OXtxWG9nZ2YiOjsbUqVPFMi0tLXh4eCAqKqrY+8yePRuWlpYYNWqUQktGNGrUCLNnz8bff/8NFxcXVK9eXe78+PHjJbf1NskJR1BQEGJiYjB79mzo6+tjzZo1GD16NI4dO6bUjYmIiCq60iQc724UGhISglmzZhWqn5aWhry8PHEH9AJWVlaIi4sr8h6nTp3C2rVrERMTo1BsALB27VqYmpoiOjoa0dHRcudkMpn6E46IiAhs2LBBfJ3St29ffPDBB8jKyuLmZ0REVCWVJuFITEyUW2BLVc/S58+fY/jw4fjpp59gbm6u8PXx8fEqieNdkhOOR48eoUWLFuLnRo0aQU9PD48fP4adnZ06YiMiIirXSpNwGBsbS1rR09zcHNra2kXuiF7Ubuh3797F/fv34eXlJZYVTPaoVq0abt68iQYNGigUqyr2U1Fo0Oi7u8Fqa2uX+/nEREREFZmuri5cXFwQGRkpluXn5yMyMhLu7u6F6jdp0gRXrlxBTEyMePTr1w9dunRBTExMoVc5Rdm0aROcnJxgYGAAAwMDODs745dffinV95DcwyEIAho3biyX5bx48QKtWrWCltb/5S3KrkBGRERU0ZTVOhwBAQHw9fWFq6sr2rZti6VLlyIzMxMjRowAAPj4+KBOnToICwuDvr4+mjdvLne9qakpABQqL8rixYsxY8YMfPXVV/jwww8BvBkTMnbsWKSlpWHSpEkKxw8okHCsX79eqRsQERFVVmWVcAwePBipqamYOXMmkpKS0LJlSxw8eFAcSJqQkCD3P/+lsWLFCqxatQo+Pj5iWb9+/dCsWTPMmjVL6YRDJvCdiJyMjAyYmJggPT1dLbvlEVHxVPGemOhd6vh7XvCs8Pb2hq6urkLXZmdn47fffiu3zxl9fX1cvXoVDRs2lCu/ffs2nJyc8Pr1a6XaVU06REREVAVVxt1iGzZsiP/973+Fyrdt24ZGjRop3a7Ce6kQERHRG5Vx87bQ0FAMHjwYJ06cEMdw/P3334iMjCwyEZGKPRxEREQk+vjjj3H27FmYm5tj9+7d2L17N8zNzXHu3DkMHDhQ6XbZw0FERKSkytjDAQAuLi749ddfVdqmwj0cs2fPxsuXLwuVv3r1CrNnz1ZJUERERBVBZRzDoS4KJxyhoaF48eJFofKXL18iNDRUJUERERFVFJUl2dDS0oK2tnaJR7Vqyr8YUfhKQRCKnLp2+fJl7hpLRERVSmV6pbJr165iz0VFRWH58uXiEunKkJxwmJmZQSaTQSaTFVpxNC8vDy9evMDYsWOVDoSIiKiiqUwJR//+/QuV3bx5E8HBwdizZw+GDh1aqqETkhOOpUuXQhAEjBw5EqGhoTAxMRHP6erqws7Orsg13YmIiKhiefToEUJCQrBx40Z4enoiJiZG0rLoJZGccPj6+gIA7O3t0a5dO+jo6JTqxsrYt28fZs+ejdjYWOjr66NTp07YvXu3eD4hIQFffvkljh07BiMjI/j6+iIsLKxU75yIiIiKU5l6OIA3q7LOnTsXK1asQMuWLREZGYkOHTqopG2Fn8SdOnVCfn4+bt26hZSUlELvczp27KiSwN61Y8cOjB49GnPnzkXXrl2Rm5uLq1eviufz8vLQp08fWFtb4/Tp03j8+DF8fHygo6ODuXPnqiUmIiKq2ipTwhEeHo758+fD2toaW7ZsKfIVS2kovJfKmTNn4O3tjQcPHhT6pclkMuTl5ak0QADIzc2FnZ0dQkNDMWrUqCLrHDhwAH379sWjR4/EzWxWr16NoKAgpKamSl7rnnupEGkO91IhdVDnXioDBw5UuMc/JycHu3btKnfPGS0tLRgYGMDDwwPa2trF1tu5c6dS7SvcwzF27Fi4urpi3759sLGxKZM/EBcvXsTDhw+hpaWFVq1aiTvlLViwQHynFBUVBScnJzHZAABPT098+eWXuHbtGlq1alVk21lZWcjKyhI/Z2RkqPfLEBFRpVGZejh8fHzU+kxXOOG4ffs2tm/fXmgXOXW6d+8eAGDWrFlYvHgx7OzssGjRInTu3Bm3bt1CzZo1kZSUJJdsABA/JyUlFdt2WFgY1w8hIiKlVKaEY8OGDWptX+GFv9zc3HDnzh2V3Dw4OFicalvcERcXJ44TmTZtGj7++GO4uLhg/fr1kMlk+P3330sVw9SpU5Geni4eiYmJqvhqRERE9BZJPRyxsbHiz+PGjUNgYCCSkpLg5ORU6N2Vs7Oz5JsHBgbCz8+vxDoODg54/PgxAKBp06ZiuZ6eHhwcHJCQkAAAsLa2xrlz5+SuTU5OFs8VR09PD3p6epJjJiIiKlCZejjUTVLC0bJlS8hkMrlf0siRI8WfC84pOmjUwsICFhYW763n4uICPT093Lx5E+3btwfwZtDN/fv3Ub9+fQCAu7s75syZg5SUFFhaWgIAIiIiYGxsLJeoEBERqQoTDukkJRzx8fHqjqNExsbGGDt2LEJCQmBra4v69etjwYIFAIBPP/0UANCjRw80bdoUw4cPR3h4OJKSkjB9+nT4+/uzB4OIiNSCCYd0khKOgl4ETVqwYAGqVauG4cOH49WrV3Bzc8PRo0dhZmYGANDW1sbevXvx5Zdfwt3dHdWrV4evry93sCUiIrVhwiGdwutw/Pnnn0U3JJNBX18fDRs2hL29vUqC0wSuw0GkOVyHg9RBnetw9O7dW6l1OPbv31/lnjMKT4sdMGBAofEcgPw4jvbt22P37t1i7wMRERFVbQpPi42IiECbNm0QEREhTiWNiIiAm5sb9u7dixMnTuDff//F119/rY54iYiIyo2CVyqKHlWRwj0cEyZMwI8//oh27dqJZd26dYO+vj7GjBmDa9euYenSpXKzWIiIiCojjuGQTuGE4+7du0W+czI2NhZXBG3UqBHS0tJKHx0REVE5xoRDOoVfqbi4uGDy5MlITU0Vy1JTUzFlyhS0adMGwJvlz21tbVUXJRERUTnEVyrSKdzDsXbtWvTv3x9169YVk4rExEQ4ODjgjz/+AAC8ePEC06dPV22kRERE5Qx7OKRTOOFwdHTE9evXcfjwYdy6dUss6969O7S03nSYDBgwQKVBEhERUcWmcMIBAFpaWujZsyd69uyp6niIiIgqDPZwSCcp4Vi+fDnGjBkDfX19LF++vMS648ePV0lgREREFUFVTSAUJSnhWLJkCYYOHQp9fX0sWbKk2HoymYwJBxERVRns4ZBO4c3bNL2RGxERUXnBhEM6hafFEhERESlKUg9HQECA5AYXL16sdDBEREQVCXs4pJOUcFy6dElSY9zpkYiIqhImHNJJSjiOHTum7jiIiIgqHCYc0kkew3Hv3r0q+0siIiIqCpc2l05ywtGoUSO5/VMGDx6M5ORktQRFRERUETDhkE5ywvHuL2j//v3IzMxUeUBERERU+Si1tDkRERFxDIciJCccMpms0CwUzkohIqKqjAmHdJITDkEQ4OfnBz09PQDA69evMXbsWFSvXl2u3s6dO1UbIRERUTnFhEM6yQmHr6+v3Odhw4apPBgiIqKKhAmHdJITjvXr16szDiIiogqHCYd0FWIvlePHj4tjSN49zp8/L9aLjY1Fhw4doK+vD1tbW4SHh2swaiJSlLJTDDnlkKj8qxCzVNq1a4fHjx/Llc2YMQORkZFwdXUFAGRkZKBHjx7w8PDA6tWrceXKFYwcORKmpqYYM2aMJsImIqJKjj0c0lWIhENXVxfW1tbi55ycHPzxxx8YN26cOFNm8+bNyM7Oxrp166Crq4tmzZohJiYGixcvZsJBRERqwYRDugrxSuVdf/75J/7991+MGDFCLIuKikLHjh2hq6srlnl6euLmzZt4+vRpsW1lZWUhIyND7iAiIpKCr/2kq5AJx9q1a+Hp6Ym6deuKZUlJSbCyspKrV/A5KSmp2LbCwsJgYmIiHra2tuoJmoiIKh0mHNJpNOEIDg4udjBowREXFyd3zT///INDhw5h1KhRKolh6tSpSE9PF4/ExESVtEtERJUfEw7pNDqGIzAwEH5+fiXWcXBwkPu8fv161KpVC/369ZMrt7a2LrSZXMHnt8d/vEtPT09czIyIiIjUQ6M9HBYWFmjSpEmJx9tjMgRBwPr16+Hj4wMdHR25ttzd3XHixAnk5OSIZREREXB0dISZmVmZfSciIqpayqp34/vvv4ednR309fXh5uaGc+fOFVv3p59+QocOHWBmZgYzMzN4eHiUWL8sVKgxHEePHkV8fDw+//zzQue8vb2hq6uLUaNG4dq1a9i2bRuWLVuGgIAADURKRERVQVm9Utm2bRsCAgIQEhKCixcvokWLFvD09ERKSkqR9Y8fP44hQ4bg2LFjiIqKgq2tLXr06IGHDx+W9isrTSZUoJdJ3t7eePDgAf7+++8iz8fGxsLf3x/nz5+Hubk5xo0bh6CgIIXukZGRARMTE6Snp8PY2FgVYRNRGePGkvQ2dfw9L3hWtGrVCtra2gpdm5eXh0uXLikUl5ubG9q0aYOVK1cCAPLz82Fra4tx48YhODhY0j3NzMywcuVK+Pj4KBSvqlSIdTgK/PbbbyWed3Z2xsmTJ8soGiIiqupKsw7Hu8swFDemMDs7G9HR0Zg6dapYpqWlBQ8PD0RFRUm658uXL5GTk4OaNWsqFKsqVahXKkREROVJaV6p2Nrayi3LEBYWVuQ90tLSkJeXV+TSDyUt+/C2oKAg1K5dGx4eHqX7wqVQoXo4iIiIKovExES5VyrqmjE5b948bN26FcePH4e+vr5a7iEFEw4iIiIlleaVirGxsaQxHObm5tDW1i5y6YeSln0AgIULF2LevHk4cuQInJ2dFYpT1fhKhYiISEllMUtFV1cXLi4uiIyMFMvy8/MRGRkJd3f3Yq8LDw/Ht99+i4MHD4obnWoSeziIiIiUVFabtwUEBMDX1xeurq5o27Ytli5diszMTHFPMR8fH9SpU0ccBzJ//nzMnDkTv/32G+zs7MSxHkZGRjAyMlL4/qrAhIOIiEhJZZVwDB48GKmpqZg5cyaSkpLQsmVLHDx4UBxImpCQAC2t/3tpsWrVKmRnZ+OTTz6RayckJASzZs1S+P6qUKHW4SgLXIeDqOLjOhz0NnWuw9G0aVOl1uG4fv16lXvOcAwHERERqR1fqRARESmprF6pVAZMOIiIiJTEhEM6JhxERERKYsIhHRMOIiIiJTHhkI4JBxERkZKYcEjHWSpERESkduzhICIiUhJ7OKRjwkFERKQkJhzSMeEgIiJSEhMO6ZhwEBERlUJVTSAUxYSDiIhISezhkI6zVIiIiEjt2MNBRESkJPZwSMeEg4iISElMOKRjwkFERKQkJhzSMeEgIiJSEhMO6SrMoNFbt26hf//+MDc3h7GxMdq3b49jx47J1UlISECfPn1gaGgIS0tLTJ48Gbm5uRqKmIiIKruChEPRoyqqMAlH3759kZubi6NHjyI6OhotWrRA3759kZSUBADIy8tDnz59kJ2djdOnT2Pjxo3YsGEDZs6cqeHIiYiISCZUgFQrLS0NFhYWOHHiBDp06AAAeP78OYyNjREREQEPDw8cOHAAffv2xaNHj2BlZQUAWL16NYKCgpCamgpdXV1J98rIyICJiQnS09NhbGystu9EROojk8k0HQKVI+r4e17wrKhTpw60tBT7f/f8/Hw8fPiwyj1nKkQPR61ateDo6IhNmzYhMzMTubm5WLNmDSwtLeHi4gIAiIqKgpOTk5hsAICnpycyMjJw7dq1YtvOyspCRkaG3EFERCQFX6lIVyEGjcpkMhw5cgQDBgxAjRo1oKWlBUtLSxw8eBBmZmYAgKSkJLlkA4D4ueC1S1HCwsIQGhqqvuCJiKjS4qBR6TTawxEcHAyZTFbiERcXB0EQ4O/vD0tLS5w8eRLnzp3DgAED4OXlhcePH5cqhqlTpyI9PV08EhMTVfTtiIiosmMPh3Qa7eEIDAyEn59fiXUcHBxw9OhR7N27F0+fPhXfd/3www+IiIjAxo0bERwcDGtra5w7d07u2uTkZACAtbV1se3r6elBT0+vdF+EiIiqJPZwSKfRhMPCwgIWFhbvrffy5UsAKDQwR0tLC/n5+QAAd3d3zJkzBykpKbC0tAQAREREwNjYGE2bNlVx5ERERKSICjFo1N3dHWZmZvD19cXly5dx69YtTJ48GfHx8ejTpw8AoEePHmjatCmGDx+Oy5cv49ChQ5g+fTr8/f3Zg0FERGrBVyrSVYiEw9zcHAcPHsSLFy/QtWtXuLq64tSpU/jjjz/QokULAIC2tjb27t0LbW1tuLu7Y9iwYfDx8cHs2bM1HD0REVVWTDikqxDrcJQlrsNBVPFxHQ56mzrX4TA3N1dqHY60tLQq95ypENNiiYiIyiMOGpWOCQcREZGSmHBIVyHGcBAREVHFxh4OIiIiJbGHQzomHERERKVQVRMIRTHhICIiUpIyyUZVTVCYcBARESmJCYd0TDiIiIiUxIRDOs5SISIiIrVjDwcREZGS2MMhHRMOIiIiJTHhkI4JBxERkZKYcEjHhIOIiEhJTDikY8JBRESkJCYc0nGWChEREakdeziIiIiUxB4O6ZhwEBERKYkJh3RMOIiIiJTEhEM6JhxERERKYsIhHRMOIqp0quofdJKXkZEBExMTTYdB/x8TDiIiIiWxh0M6JhxERERKYsIhHRMOIiIiJTHhkK7CLPx18eJFdO/eHaampqhVqxbGjBmDFy9eyNVJSEhAnz59YGhoCEtLS0yePBm5ubkaipiIiCo7QRCUOpTx/fffw87ODvr6+nBzc8O5c+dKrP/777+jSZMm0NfXh5OTE/bv36/UfVWlQiQcjx49goeHBxo2bIizZ8/i4MGDuHbtGvz8/MQ6eXl56NOnD7Kzs3H69Gls3LgRGzZswMyZMzUXOBERVWpllXBs27YNAQEBCAkJwcWLF9GiRQt4enoiJSWlyPqnT5/GkCFDMGrUKFy6dAkDBgzAgAEDcPXq1dJ+ZeUJFcCaNWsES0tLIS8vTyyLjY0VAAi3b98WBEEQ9u/fL2hpaQlJSUlinVWrVgnGxsZCVlaW5Hulp6cLAIT09HTVfQEiIipz6vx7XtA2AEEmkyl0FFynSFxt27YV/P39xc95eXlC7dq1hbCwsCLrDxo0SOjTp49cmZubm/DFF18o94VVoEKM4cjKyoKuri60tP6vQ8bAwAAAcOrUKTRs2BBRUVFwcnKClZWVWMfT0xNffvklrl27hlatWhXbdlZWlvg5PT0dwJvpVEREVHEV/B0X1DxmQtn2333O6OnpQU9Pr1C97OxsREdHY+rUqWKZlpYWPDw8EBUVVWTbUVFRCAgIkCvz9PTE7t27lYpVFSpEwtG1a1cEBARgwYIFmDBhAjIzMxEcHAwAePz4MQAgKSlJLtkAIH5OSkoqtu2wsDCEhoYWKre1tVVV+EREpEHPnz9X+Xocurq6sLa2LvH5UhIjI6NCz5mQkBDMmjWrUN20tDTk5eUV+YyLi4srsv3inonKxqsKGk04goODMX/+/BLr3LhxA82aNcPGjRsREBCAqVOnQltbG+PHj4eVlZVcr4cypk6dKpcF5ufn48mTJ6hVqxZkMlmR12RkZMDW1haJiYkwNjYu1f3LGmPXDMauGRU5dqBix18eYhcEAc+fP0ft2rVV3ra+vj7i4+ORnZ2t1PWCIBR6xhTVu1GZaDThCAwMlBv4WRQHBwcAgLe3N7y9vZGcnIzq1atDJpNh8eLF4nlra+tCI3aTk5PFc8UpqgvL1NRUUvzGxsYV7o9AAcauGYxdMypy7EDFjl/TsatzpVF9fX3o6+urrf0C5ubm0NbWFp9pBZKTk4t9vllbWytUvyxodJaKhYUFmjRpUuKhq6srd42VlRWMjIywbds26Ovro3v37gAAd3d3XLlyRW7EbkREBIyNjdG0adMy/V5ERESqoqurCxcXF0RGRopl+fn5iIyMhLu7e5HXuLu7y9UH3jwTi6tfFirEGA4AWLlyJdq1awcjIyNERERg8uTJmDdvntgb0aNHDzRt2hTDhw9HeHg4kpKSMH36dPj7+1f6bioiIqrcAgIC4OvrC1dXV7Rt2xZLly5FZmYmRowYAQDw8fFBnTp1EBYWBgCYMGECOnXqhEWLFqFPnz7YunUrLly4gB9//FFzX0Jj82MUNHz4cKFmzZqCrq6u4OzsLGzatKlQnfv37wu9evUSDAwMBHNzcyEwMFDIyclReSyvX78WQkJChNevX6u8bXVj7JrB2DWjIscuCBU7/ooce3m1YsUKoV69eoKurq7Qtm1b4cyZM+K5Tp06Cb6+vnL1//e//wmNGzcWdHV1hWbNmgn79u0r44jlyQShiq6xSkRERGWmQqw0SkRERBUbEw4iIiJSOyYcREREpHZMOIiIiEjtmHAoSNHtgTUhLCwMbdq0QY0aNWBpaYkBAwbg5s2bcnVev34Nf39/1KpVC0ZGRvj4448LLRJTHsybNw8ymQwTJ04Uy8pz7A8fPsSwYcNQq1YtGBgYwMnJCRcuXBDPC4KAmTNnwsbGBgYGBvDw8MDt27c1GPEbeXl5mDFjBuzt7WFgYIAGDRrg22+/ldsjojzFfuLECXh5eaF27dqQyWSF9oeQEuuTJ08wdOhQGBsbw9TUFKNGjcKLFy80GntOTg6CgoLg5OSE6tWro3bt2vDx8cGjR4/KfezvGjt2LGQyGZYuXSpXrqnYSfOYcChA0e2BNeWvv/6Cv78/zpw5g4iICOTk5KBHjx7IzMwU60yaNAl79uzB77//jr/++guPHj3CRx99pMGoCzt//jzWrFkDZ2dnufLyGvvTp0/x4YcfQkdHBwcOHMD169exaNEimJmZiXXCw8OxfPlyrF69GmfPnkX16tXh6emJ169fazByYP78+Vi1ahVWrlyJGzduYP78+QgPD8eKFSvEOuUp9szMTLRo0QLff/99keelxDp06FBcu3YNERER2Lt3L06cOIExY8ZoNPaXL1/i4sWLmDFjBi5evIidO3fi5s2b6Nevn1y98hj723bt2oUzZ84UuaS4pmKnckCTc3IrGkW3By4vUlJSBADCX3/9JQiCIDx79kzQ0dERfv/9d7HOjRs3BABCVFSUpsKU8/z5c6FRo0ZCRESE0KlTJ2HChAmCIJTv2IOCgoT27dsXez4/P1+wtrYWFixYIJY9e/ZM0NPTE7Zs2VIWIRarT58+wsiRI+XKPvroI2Ho0KGCIJTv2AEIu3btEj9LifX69esCAOH8+fNinQMHDggymUx4+PChxmIvyrlz5wQAwoMHDwRBKP+x//PPP0KdOnWEq1evCvXr1xeWLFkinisvsZNmsIdDooLtgT08PMSy920PXF6kp6cDAGrWrAkAiI6ORk5Ojtx3adKkCerVq1duvou/vz/69OkjFyNQvmP/888/4erqik8//RSWlpZo1aoVfvrpJ/F8fHw8kpKS5GI3MTGBm5ubxmNv164dIiMjcevWLQDA5cuXcerUKfTq1QtA+Y79XVJijYqKgqmpKVxdXcU6Hh4e0NLSwtmzZ8s85pKkp6dDJpOJqyqX59jz8/MxfPhwTJ48Gc2aNSt0vjzHTupXYZY21zRltgcuD/Lz8zFx4kR8+OGHaN68OYA32xbr6uoW2qRO01sXF9i6dSsuXryI8+fPFzpXnmO/d+8eVq1ahYCAAHzzzTc4f/48xo8fD11dXfj6+orxlbcto4E3OzdnZGSgSZMm0NbWRl5eHubMmYOhQ4cCQLmO/V1SYk1KSoKlpaXc+WrVqqFmzZrl6vu8fv0aQUFBGDJkiLgBWnmOff78+ahWrRrGjx9f5PnyHDupHxOOSs7f3x9Xr17FqVOnNB2KJImJiZgwYQIiIiLKZBdGVcrPz4erqyvmzp0LAGjVqhWuXr2K1atXw9fXV8PRlex///sfNm/ejN9++w3NmjVDTEwMJk6ciNq1a5f72CurnJwcDBo0CIIgYNWqVZoO572io6OxbNkyXLx4sdC260QAB41Kpsz2wJr21VdfYe/evTh27Bjq1q0rlltbWyM7OxvPnj2Tq18evkt0dDRSUlLQunVrVKtWDdWqVcNff/2F5cuXo1q1arCysiq3sdvY2BTamfiDDz5AQkICAIjxlcd/hyZPnozg4GB89tlncHJywvDhwzFp0iRxI6jyHPu7pMRqbW1daLB3bm4unjx5Ui6+T0Gy8eDBA3HX6wLlNfaTJ08iJSUF9erVE//bffDgAQIDA2FnZweg/MZOZYMJh0TKbA+sKYIg4KuvvsKuXbtw9OhR2Nvby513cXGBjo6O3He5efMmEhISNP5dunXrhitXriAmJkY8XF1dMXToUPHn8hr7hx9+WGj68a1bt1C/fn0AgL29PaytreViz8jIwNmzZzUe+8uXL6GlJf/nQFtbG/n5+QDKd+zvkhKru7s7nj17hujoaLHO0aNHkZ+fDzc3tzKP+W0Fycbt27dx5MgR1KpVS+58eY19+PDhiI2Nlftvt3bt2pg8eTIOHToEoPzGTmVE06NWK5KtW7cKenp6woYNG4Tr168LY8aMEUxNTYWkpCRNhybnyy+/FExMTITjx48Ljx8/Fo+XL1+KdcaOHSvUq1dPOHr0qHDhwgXB3d1dcHd312DUxXt7looglN/Yz507J1SrVk2YM2eOcPv2bWHz5s2CoaGh8Ouvv4p15s2bJ5iamgp//PGHEBsbK/Tv31+wt7cXXr16pcHIBcHX11eoU6eOsHfvXiE+Pl7YuXOnYG5uLkyZMkWsU55if/78uXDp0iXh0qVLAgBh8eLFwqVLl8SZHFJi7dmzp9CqVSvh7NmzwqlTp4RGjRoJQ4YM0Wjs2dnZQr9+/YS6desKMTExcv/9ZmVllevYi/LuLBVNxk6ax4RDQSVtD1xeACjyWL9+vVjn1atXwn//+1/BzMxMMDQ0FAYOHCg8fvxYc0GX4N2EozzHvmfPHqF58+aCnp6e0KRJE+HHH3+UO5+fny/MmDFDsLKyEvT09IRu3boJN2/e1FC0/ycjI0OYMGGCUK9ePUFfX19wcHAQpk2bJveQK0+xHzt2rMh/xwu255YS67///isMGTJEMDIyEoyNjYURI0YIz58/12js8fHxxf73e+zYsXIde1GKSjg0FTtpHrenJyIiIrXjGA4iIiJSOyYcREREpHZMOIiIiEjtmHAQERGR2jHhICIiIrVjwkFERERqx4SDiIiI1I4JBxEREakdEw4iDejcuTMmTpyo6TCKdP/+fchkMsTExJS6reHDh4u75xbHzs4OS5cuLfW93hYcHIxx48aptE0iKh0mHET/n5+fH2QymXjUqlULPXv2RGxsrKZDk+Pp6QltbW2cP39e06GU6PLly9i/fz/Gjx9f5vf++uuvsXHjRty7d6/M701ERWPCQfSWnj174vHjx3j8+DEiIyNRrVo19O3bV9NhiRISEnD69Gl89dVXWLdunabDKdGKFSvw6aefwsjIqMzvbW5uDk9PT6xatarM701ERWPCQfQWPT09WFtbw9raGi1btkRwcDASExORmpoq1gkKCkLjxo1haGgIBwcHzJgxAzk5OeL5WbNmoWXLlvjll19gZ2cHExMTfPbZZ3j+/Hmx9923bx9MTEywefPmEuNbv349+vbtiy+//BJbtmzBq1ev5M537twZ48ePx5QpU1CzZk1YW1tj1qxZcnXi4uLQvn176Ovro2nTpjhy5AhkMhl2795d7H2vXr2KXr16wcjICFZWVhg+fDjS0tKKrZ+Xl4ft27fDy8tLrjwlJQVeXl4wMDCAvb19kd/32bNn+Pzzz2FhYQFjY2N07doVly9flqvz3XffwdLSEjVq1MDnn3+O4OBgtGzZUq6Ol5cXtm7dWmyMRFS2mHAQFePFixf49ddf0bBhQ9SqVUssr1GjBjZs2IDr169j2bJl+Omnn7BkyRK5a+/evYvdu3dj79692Lt3L/766y/MmzevyPv89ttvGDJkCDZv3oyhQ4cWG48gCFi/fj2GDRuGJk2aoGHDhti+fXuhehs3bkT16tVx9uxZhIeHY/bs2YiIiADwJhEYMGAADA0NcfbsWfz444+YNm1aib+HZ8+eoWvXrmjVqhUuXLiAgwcPIjk5GYMGDSr2mtjYWKSnp8PV1VWu3M/PD4mJiTh27Bi2b9+OH374ASkpKXJ1Pv30U6SkpODAgQOIjo5G69at0a1bNzx58gQAsHnzZsyZMwfz589HdHQ06tWrV2RPRtu2bfHPP//g/v37JX4/IiojGt6tlqjc8PX1FbS1tYXq1asL1atXFwAINjY2QnR0dInXLViwQHBxcRE/h4SECIaGhkJGRoZYNnnyZMHNzU383KlTJ2HChAnCypUrBRMTE+H48ePvje/w4cOChYWFkJOTIwiCICxZskTo1KmTXJ1OnToJ7du3lytr06aNEBQUJAiCIBw4cECoVq2a8PjxY/F8RESEAEDYtWuXIAiCuEX6pUuXBEEQhG+//Vbo0aOHXJuJiYkCgGK3p9+1a5egra0t5Ofni2U3b94UAAjnzp0Ty27cuCEAELcwP3nypGBsbCy8fv1arr0GDRoIa9asEQRBENzc3AR/f3+58x9++KHQokULubL09HQBgKTfLRGpH3s4iN7SpUsXxMTEICYmBufOnYOnpyd69eqFBw8eiHW2bduGDz/8ENbW1jAyMsL06dORkJAg146dnR1q1KghfraxsSn0f/Lbt2/HpEmTEBERgU6dOr03tnXr1mHw4MGoVq0aAGDIkCH4+++/cffuXbl6zs7Ocp/fvvfNmzdha2sLa2tr8Xzbtm1LvO/ly5dx7NgxGBkZiUeTJk0AoNC9C7x69Qp6enqQyWRi2Y0bN1CtWjW4uLiIZU2aNIGpqancvV68eIFatWrJ3S8+Pl68182bNwvFXNR3MDAwAAC8fPmyxO9HRGWjmqYDICpPqlevjoYNG4qff/75Z5iYmOCnn37Cd999h6ioKAwdOhShoaHw9PSEiYkJtm7dikWLFsm1o6OjI/dZJpMhPz9frqxVq1a4ePEi1q1bB1dXV7mH87uePHmCXbt2IScnR+71QV5eHtatW4c5c+YodG9FvHjxAl5eXpg/f36hczY2NkVeY25ujpcvXyI7Oxu6uroK3cvGxgbHjx8vdO7txESKglcwFhYWCl1HROrBhIOoBDKZDFpaWuLgzNOnT6N+/fpy4x7e7v1QRIMGDbBo0SJ07twZ2traWLlyZbF1N2/ejLp16xYa2Hn48GEsWrQIs2fPhra29nvv6ejoiMTERCQnJ8PKygoA3ju9tnXr1tixYwfs7OzE3pX3KRjAef36dfHnJk2aIDc3F9HR0WjTpg2AN70Vz549k7tXUlISqlWrBjs7u2K/w/nz5+Hj4yOWFfUdrl69Ch0dHTRr1kxSzESkXnylQvSWrKwsJCUlISkpCTdu3MC4cePE/8MHgEaNGiEhIQFbt27F3bt3sXz5cuzatUvp+zVu3BjHjh3Djh07SlwIbO3atfjkk0/QvHlzuWPUqFFIS0vDwYMHJd2ve/fuaNCgAXx9fREbG4u///4b06dPB4Bie1j8/f3x5MkTDBkyBOfPn8fdu3dx6NAhjBgxAnl5eUVeY2FhgdatW+PUqVNimaOjI3r27IkvvvgCZ8+eRXR0ND7//HPx1QcAeHh4wN3dHQMGDMDhw4dx//59nD59GtOmTcOFCxcAAOPGjcPatWuxceNG3L59G9999x1iY2MLxX/y5El06NBBrn0i0hwmHERvOXjwIGxsbGBjYwM3NzecP38ev//+Ozp37gwA6NevHyZNmoSvvvoKLVu2xOnTpzFjxoxS3dPR0RFHjx7Fli1bEBgYWOh8dHQ0Ll++jI8//rjQORMTE3Tr1g1r166VdC9tbW3s3r0bL168QJs2bfD555+LvTX6+vpFXlO7dm38/fffyMvLQ48ePeDk5ISJEyfC1NQUWlrF/wn5/PPPC017Xb9+PWrXro1OnTrho48+wpgxY2BpaSmel8lk2L9/Pzp27IgRI0agcePG+Oyzz/DgwQOxR2bo0KGYOnUqvv76a7Ru3Rrx8fHw8/MrFP/WrVsxevRoSb8XIlI/mSAIgqaDICLN+fvvv9G+fXvcuXMHDRo0UFm7r169gqOjI7Zt2wZ3d3eVtVuU7t27w9raGr/88gsA4MCBAwgMDERsbKzk10BEpF78L5Goitm1axeMjIzQqFEj3LlzBxMmTMCHH36o0mQDeDNLZNOmTSUuEKaMly9fYvXq1eIS71u2bMGRI0fEtUYAIDMzE+vXr2eyQVSOsIeDqIrZtGkTvvvuOyQkJMDc3BweHh5YtGiR3OJm5dmrV6/g5eWFS5cu4fXr13B0dMT06dPx0UcfaTo0IioBEw4iIiJSOw4aJSIiIrVjwkFERERqx4SDiIiI1I4JBxEREakdEw4iIiJSOyYcREREpHZMOIiIiEjtmHAQERGR2v0/tWGOKjkvLkUAAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 600x400 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.colors as mcolors\n",
        "\n",
        "\n",
        "bins_space = {\n",
        "    \"flight_path_angle\": np.linspace(-90, 0,   20,      dtype=np.float32),     # Flight Path Angle (γ)    (0)\n",
        "    \"bank_angle\":        np.linspace(0, 150,   20,      dtype=np.float32),     # Bank Angle        (mu)   (2)\n",
        "}\n",
        "\n",
        "grid = np.meshgrid(*bins_space.values(), indexing='ij')\n",
        "states_space = np.vstack([g.ravel() for g in grid], dtype=np.float32).T\n",
        "flight_path_angles = states_space[:,0]\n",
        "bank_angles = states_space[:,1]\n",
        "policy_values = np.zeros((len(flight_path_angles), len(bank_angles)))\n",
        "\n",
        "for i, gamma in enumerate(flight_path_angles):\n",
        "    for j, mu in enumerate(bank_angles):\n",
        "        state = (np.deg2rad(gamma), 1.2,np.deg2rad(mu))\n",
        "        action = get_optimal_action(state, pi)  # or pass your real policy object\n",
        "        cl = action[0]  # If the first element of action is CL\n",
        "        policy_values[i, j] = cl\n",
        "\n",
        "# Normalize the policy values (0 to 1) for grayscale plotting\n",
        "vmin, vmax = policy_values.min(), policy_values.max()\n",
        "norm_values = policy_values #- vmin) / (vmax - vmin + 1e-8)\n",
        "\n",
        "# Create a mesh for plotting\n",
        "X, Y = np.meshgrid(bank_angles, flight_path_angles)\n",
        "\n",
        "# Plot using pcolormesh (grayscale)\n",
        "fig, ax = plt.subplots(figsize=(6, 4))\n",
        "c = ax.pcolormesh(X, Y, norm_values, cmap='gray', shading='auto',\n",
        "                  norm=mcolors.Normalize(vmin=0, vmax=1))\n",
        "\n",
        "# Labels and title\n",
        "ax.set_xlabel(\"Bank Angle (deg)\")\n",
        "ax.set_ylabel(\"Flight Path Angle (deg)\")\n",
        "ax.set_title(\"Optimal Policy (CL)\")\n",
        "\n",
        "# Optional: colorbar\n",
        "plt.colorbar(c, ax=ax, label=\"Normalized CL\")\n",
        "\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e954bd11",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from utils.utils import get_optimal_action\n",
        "\n",
        "# initial state\n",
        "state = np.array([np.deg2rad(-60), 1.2, np.deg2rad(30)])\n",
        "glider.airplane.flight_path_angle = state[0]\n",
        "glider.airplane.airspeed_norm     = state[1]\n",
        "glider.airplane.bank_angle        = state[2]\n",
        "\n",
        "total_height_lost = 0\n",
        "episode_length    = 0\n",
        "terminated        = False\n",
        "\n",
        "time_history = []\n",
        "height_lost_history = []\n",
        "\n",
        "while episode_length < 20:\n",
        "    action = get_optimal_action(state, pi)\n",
        "    prev_state = state.copy()\n",
        "    state, reward, terminated, _, _ = glider.step(action)\n",
        "    state = state[0] \n",
        "    total_height_lost += reward\n",
        "    episode_length += 0.01\n",
        "\n",
        "    time_history.append(episode_length)  # for plotting!\n",
        "    height_lost_history.append(total_height_lost)\n",
        "\n",
        "    #print(f\"Action: {np.round(action,3)} | Lost Height: {total_height_lost:.3f} | State: {state} | Terminated: {terminated} | Time: {episode_length:.2f}\")\n",
        "    if terminated:\n",
        "        break\n",
        "\n",
        "# Plotting the results\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(time_history, height_lost_history, label=\"Height Lost\")\n",
        "plt.xlabel(\"Time (s)\")\n",
        "plt.ylabel(\"Height Lost (m)\")\n",
        "plt.title(\"Height Lost Over Time\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5cd13daf",
      "metadata": {},
      "outputs": [],
      "source": [
        "STALL_AIRSPEED = 27.331231856346\n",
        "from utils.utils import get_optimal_action\n",
        "from tqdm import tqdm\n",
        "with open(glider.__class__.__name__ + \".pkl\", \"rb\") as f:\n",
        "    pi: PolicyIteration = pickle.load(f)\n",
        "\n",
        "prom_episode_lenght = 0\n",
        "dict_result = {}\n",
        "dict_episode_length = {}\n",
        "state_spaces = [v for v in pi.states_space if v[0] > -np.pi/2]\n",
        "for state in tqdm(state_spaces):\n",
        "    initial_state = state.copy()\n",
        "    prev_state = state.copy()\n",
        "    glider.reset()\n",
        "    glider.airplane.flight_path_angle = state[0]\n",
        "    glider.airplane.airspeed_norm = state[1]\n",
        "    glider.airplane.bank_angle = state[2]\n",
        "    done = False\n",
        "    episode_length = 0\n",
        "    total_reward = 0\n",
        "    while not done:\n",
        "        action = get_optimal_action(state, pi)\n",
        "        prev_state  = state.copy()\n",
        "        state, reward, done, _, _ = glider.step(action)\n",
        "        done  = bool(done)\n",
        "        if done:\n",
        "            break\n",
        "        state = state[0]\n",
        "        # check if our state is in the state space\n",
        "        index = pi.triangulation.find_simplex(state)\n",
        "        if not done:\n",
        "            total_reward -= reward#*STALL_AIRSPEED\n",
        "        if (index ==-1) or episode_length > 70: \n",
        "            done = True\n",
        "        episode_length += 1\n",
        "        \n",
        "    dict_result[tuple(initial_state)] = total_reward\n",
        "    dict_episode_length[tuple(initial_state)] = episode_length\n",
        "    prom_episode_lenght += episode_length / len(pi.states_space)\n",
        "    #print(f\"Initial state: {initial_state} - Total reward: {total_reward}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab055601",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "epsilon = 1*1e-1\n",
        "#dict_result = dict_episode_length\n",
        "# Your dictionary with keys as coordinates (x, y) and values as the color intensity (z)\n",
        "# Extracting the x, y and z values\n",
        "x = [np.degrees(coord[0]) for coord in dict_result.keys() if 0.05 >= coord[0] >= -np.pi/2 - epsilon and coord[1] > 0.7]\n",
        "#convert x to grad\n",
        "y = [coord[1] for coord in dict_result.keys() if 0.05 >= coord[0] >= -np.pi/2 - epsilon and coord[1] > 0.7]\n",
        "#convert y to Vs\n",
        "keys_list = list(dict_result.keys())\n",
        "values_list = list(dict_result.values())\n",
        "z = [v for e,v in zip(keys_list, values_list) if 0.05 >= e[0] >= -np.pi/2 - epsilon and e[1] > 0.7]\n",
        "\n",
        "# Creating a 2D scatter plot\n",
        "cmap = plt.get_cmap('viridis', 2048)\n",
        "plt.tricontourf(y, x, z, cmap=cmap, levels=18)   # Change 'viridis' to any other colormap you like\n",
        "plt.colorbar(label='', shrink=0.8,  )  # Add color bar for the z values\n",
        "\n",
        "# Add labels and a title\n",
        "plt.ylabel('Flight Path Angle (γ) [deg]')\n",
        "plt.xlabel('V/Vs')\n",
        "\n",
        "x_min, x_max = min(x), max(x)\n",
        "y_min, y_max = min(y), max(y)\n",
        "\n",
        "# Set the minor ticks for the grid, keeping the dense grid with smaller squares\n",
        "ax = plt.gca()  # Get current axes\n",
        "ax.set_yticks(np.linspace(x_min, x_max, 60), minor=True)  # 20 minor ticks for grid\n",
        "ax.set_xticks(np.linspace(y_min, y_max, 60), minor=True)  # 20 minor ticks for grid\n",
        "# put line x = 1\n",
        "plt.axvline(x=1, color='r', linestyle='--', linewidth=0.5)\n",
        "# put line y = 0\n",
        "#plt.axhline(y=0, color='k', linestyle='--')\n",
        "\n",
        "# Show the plot\n",
        "vals = np.round(np.linspace(-90, 0,6))\n",
        "plt.yticks(vals)  # Only 5 labels on x-axis\n",
        "plt.xticks(np.linspace(round(y_min), round(y_max), 6))  # Only 5 labels on y-axis\n",
        "# Enable the minor grid lines\n",
        "ax.grid(which='minor', color='gray', linestyle='-', linewidth=0.5)\n",
        "\n",
        "# Habilitar la cuadrícula en las marcas menores\n",
        "ax.grid(which='minor', color='gray', linestyle='-', linewidth=0.5)\n",
        "\n",
        "# Guardar la imagen sin borde blanco\n",
        "plt.savefig('output.png', bbox_inches='tight')\n",
        "\n",
        "# set size of the plot\n",
        "plt.gcf().set_size_inches(9, 5)\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8416867",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.interpolate import griddata\n",
        "\n",
        "# Your dictionary with keys as coordinates (x, y) and values as the color intensity (z)\n",
        "# Extracting the x, y and z values\n",
        "x = [np.degrees(coord[0]) for coord in dict_result.keys() if 5 >= coord[0] >= -np.pi/2 and coord[1] > 0.7]\n",
        "y = [coord[1] for coord in dict_result.keys() if 5 >= coord[0] >= -np.pi/2 and coord[1] > 0.7]\n",
        "keys_list = list(dict_result.keys())\n",
        "values_list = list(dict_result.values())\n",
        "z = [v for e,v in zip(keys_list, values_list) if 5 >= e[0] >= -np.pi/2 and e[1] > 0.7]\n",
        "\n",
        "# Create a grid for interpolation\n",
        "x_grid = np.linspace(min(x), max(x), 100)\n",
        "y_grid = np.linspace(min(y), max(y), 100)\n",
        "X, Y = np.meshgrid(x_grid, y_grid)\n",
        "\n",
        "# Interpolate the scattered data into the grid\n",
        "Z = griddata((y, x), z, (Y, X), method='linear')\n",
        "\n",
        "# Create the scatter plot\n",
        "cmap = plt.get_cmap('viridis', 2048)\n",
        "plt.scatter(y, x, c=z, cmap=cmap)\n",
        "\n",
        "# Add color bar\n",
        "plt.colorbar(label='', shrink=0.8)\n",
        "contour_levels = np.linspace(np.min(z), np.max(z), 10)  # 10 levels\n",
        "contour_levels = contour_levels[contour_levels != 0]    # Remove zero from levels\n",
        "\n",
        "# Add contour lines on top of the scatter plot\n",
        "contour = plt.contour(Y, X, Z, levels=contour_levels, colors='black', linewidths=0.75)\n",
        "plt.clabel(contour, inline=True, fontsize=8)  # Optional: add labels to the contours\n",
        "\n",
        "# Add labels and a title\n",
        "plt.ylabel('Flight Path Angle (γ) [deg]')\n",
        "plt.xlabel('V/Vs')\n",
        "\n",
        "# Plot vertical line at x=1\n",
        "plt.axvline(x=1, color='k', linestyle='--')\n",
        "\n",
        "# Configure the minor ticks and grid\n",
        "x_min, x_max = min(x), max(x)\n",
        "y_min, y_max = min(y), max(y)\n",
        "ax = plt.gca()  # Get current axes\n",
        "ax.set_yticks(np.linspace(x_min, x_max, 60), minor=True)\n",
        "ax.set_xticks(np.linspace(y_min, y_max, 60), minor=True)\n",
        "plt.yticks(np.linspace(x_min, x_max, 6))  # Major ticks on y-axis\n",
        "plt.xticks(np.linspace(y_min, y_max, 4))  # Major ticks on x-axis\n",
        "\n",
        "# Set size of the plot\n",
        "plt.gcf().set_size_inches(9, 5)\n",
        "\n",
        "# Enable the minor grid lines\n",
        "ax.grid(which='minor', color='white', linestyle='-', linewidth=0.25)\n",
        "\n",
        "# Habilitar la cuadrícula en las marcas menores\n",
        "ax.grid(which='minor', color='white', linestyle='-', linewidth=0.25)\n",
        "\n",
        "# Save the image\n",
        "plt.savefig('output_with_contours.png', bbox_inches='tight')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "204e0318",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "3c8fe4a4",
      "metadata": {},
      "source": [
        "# CartPoleEnv \n",
        "\n",
        "### Observation Space\n",
        "\n",
        "The observation is a `ndarray` with shape `(4,)` with the values corresponding to the following positions and velocities:\n",
        "\n",
        "| Num | Observation           | Min                 | Max               |\n",
        "|-----|-----------------------|---------------------|-------------------|\n",
        "| 0   | Cart Position         | -4.8                | 4.8               |\n",
        "| 1   | Cart Velocity         | -Inf                | Inf               |\n",
        "| 2   | Pole Angle            | ~ -0.418 rad (-24°) | ~ 0.418 rad (24°) |\n",
        "| 3   | Pole Angular Velocity | -Inf                | Inf               |\n",
        "\n",
        "### Action Space\n",
        "\n",
        "The action is a `ndarray` with shape `(1,)` which can take values `{0, 1}` indicating the direction\n",
        "of the fixed force the cart is pushed with.\n",
        "\n",
        "- 0: Push cart to the left\n",
        "- 1: Push cart to the right"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1c04b7b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train cartpole environment:\n",
        "from classic_control.cartpole import CartPoleEnv\n",
        "# CartPole environment:\n",
        "env = CartPoleEnv(sutton_barto_reward=True)\n",
        "# position thresholds:\n",
        "x_lim         = 2.4\n",
        "theta_lim     = 0.418 \n",
        "# velocity thresholds:\n",
        "x_dot_lim     = 3.1\n",
        "theta_dot_lim = 3.1\n",
        "\n",
        "bins_space = {\n",
        "    \"x_space\"         : np.linspace(-x_lim, x_lim, 10,  dtype=np.float32),                     # position space          (0)\n",
        "    \"x_dot_space\"     : np.linspace(-x_dot_lim, x_dot_lim, 10,  dtype=np.float32),             # velocity space          (1)\n",
        "    \"theta_space\"     : np.linspace(-theta_lim, theta_lim, 10, dtype=np.float32),              # angle space             (2)\n",
        "    \"theta_dot_space\" : np.linspace(-theta_dot_lim, theta_dot_lim, 10, dtype=np.float32),      # angular velocity space  (3)\n",
        "}\n",
        "\n",
        "pi = PolicyIteration(\n",
        "    env=env, \n",
        "    bins_space=bins_space,\n",
        "    action_space=np.array([0, 1], dtype=np.int32),\n",
        "    gamma=0.99,\n",
        "    theta=1e-3\n",
        ")\n",
        "\n",
        "pi.run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0462a904",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test cartpole environment:\n",
        "\n",
        "with open(env.__class__.__name__ + \".pkl\", \"rb\") as f:\n",
        "    pi = pickle.load(f)\n",
        "\n",
        "test_enviroment(CartPoleEnv(sutton_barto_reward=True, render_mode=\"human\"), pi)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "063b6002",
      "metadata": {},
      "source": [
        "## Observation Space\n",
        "\n",
        "The observation is a `ndarray` with shape `(2,)` where the elements correspond to the following:\n",
        "\n",
        "| Num | Observation                          | Min   | Max  | Unit         |\n",
        "|-----|--------------------------------------|-------|------|--------------|\n",
        "| 0   | position of the car along the x-axis | -1.2  | 0.6  | position (m) |\n",
        "| 1   | velocity of the car                  | -0.07 | 0.07 | velocity (v) |\n",
        "\n",
        "## Action Space\n",
        "\n",
        "There are 3 discrete deterministic actions:\n",
        "\n",
        "- 0: Accelerate to the left\n",
        "- 1: Don't accelerate\n",
        "- 2: Accelerate to the right\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d617686",
      "metadata": {},
      "outputs": [],
      "source": [
        "from classic_control.continuous_mountain_car import Continuous_MountainCarEnv\n",
        "\n",
        "env=Continuous_MountainCarEnv()\n",
        "\n",
        "bins_space = {\n",
        "    \"x_space\":     np.linspace(env.min_position, env.max_position, 100,      dtype=np.float32),    # position space    (0)\n",
        "    \"x_dot_space\": np.linspace(-abs(env.max_speed), abs(env.max_speed), 100, dtype=np.float32),    # velocity space    (1)\n",
        "}\n",
        "\n",
        "pi = PolicyIteration(\n",
        "    env=env, \n",
        "    bins_space=bins_space,\n",
        "    action_space=np.linspace(-1.0, +1.0, 9, dtype=np.float32),\n",
        "    gamma=0.99,\n",
        "    theta=1e-3,\n",
        ")\n",
        "pi.run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f556b5a",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test mountain car environment:\n",
        "with open(env.__class__.__name__ + \".pkl\", \"rb\") as f:\n",
        "    pi: PolicyIteration = pickle.load(f)\n",
        "\n",
        "test_enviroment(Continuous_MountainCarEnv(render_mode=\"human\"), pi)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "DynamicProgramming",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
