{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "b149d005",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nicoRomeroCuruchet/DynamicProgramming/blob/main/testing_bary.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "9c6a7123",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m2025-03-06 18:26:22.073\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m131\u001b[0m - \u001b[1mLower bounds: [-3.1415927   0.9        -0.34906584]\u001b[0m\n",
            "\u001b[32m2025-03-06 18:26:22.075\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m132\u001b[0m - \u001b[1mUpper bounds: [0.        4.5       3.4906585]\u001b[0m\n",
            "\u001b[32m2025-03-06 18:26:22.076\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m151\u001b[0m - \u001b[1mNumber of states: 27000\u001b[0m\n",
            "\u001b[32m2025-03-06 18:26:22.077\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m152\u001b[0m - \u001b[1mTotal states:1944000\u001b[0m\n",
            "\u001b[32m2025-03-06 18:26:22.085\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m165\u001b[0m - \u001b[1mPolicy Iteration was correctly initialized.\u001b[0m\n",
            "\u001b[32m2025-03-06 18:26:22.085\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m166\u001b[0m - \u001b[1mThe enviroment name is: TimeLimit\u001b[0m\n",
            "\u001b[32m2025-03-06 18:26:22.086\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m389\u001b[0m - \u001b[1mCreating Delaunay triangulation over the state space...\u001b[0m\n",
            "\u001b[32m2025-03-06 18:26:24.573\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m391\u001b[0m - \u001b[1mDelaunay triangulation created.\u001b[0m\n",
            "\u001b[32m2025-03-06 18:26:24.574\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m401\u001b[0m - \u001b[1mGenerating transition and reward function table...\u001b[0m\n",
            "/home/nromero/anaconda3/envs/DynamicProgramming/lib/python3.11/site-packages/gymnasium/utils/passive_env_checker.py:159: UserWarning: \u001b[33mWARN: The obs returned by the `reset()` method is not within the observation space.\u001b[0m\n",
            "  logger.warn(f\"{pre} is not within the observation space.\")\n",
            "/home/nromero/anaconda3/envs/DynamicProgramming/lib/python3.11/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.airplane to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.airplane` for environment variables or `env.get_wrapper_attr('airplane')` that will search the reminding wrappers.\u001b[0m\n",
            "  logger.warn(\n",
            "/home/nromero/anaconda3/envs/DynamicProgramming/lib/python3.11/site-packages/gymnasium/utils/passive_env_checker.py:228: UserWarning: \u001b[33mWARN: Expects `terminated` signal to be a boolean, actual type: <class 'numpy.ndarray'>\u001b[0m\n",
            "  logger.warn(\n",
            "/home/nromero/anaconda3/envs/DynamicProgramming/lib/python3.11/site-packages/gymnasium/utils/passive_env_checker.py:159: UserWarning: \u001b[33mWARN: The obs returned by the `step()` method is not within the observation space.\u001b[0m\n",
            "  logger.warn(f\"{pre} is not within the observation space.\")\n",
            "/home/nromero/anaconda3/envs/DynamicProgramming/lib/python3.11/site-packages/gymnasium/utils/passive_env_checker.py:246: UserWarning: \u001b[33mWARN: The reward returned by `step()` must be a float, int, np.integer or np.floating, actual type: <class 'numpy.ndarray'>\u001b[0m\n",
            "  logger.warn(\n",
            "\u001b[32m2025-03-06 18:26:24.576\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m257\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-03-06 18:27:07.318\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m257\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-03-06 18:27:46.705\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m257\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-03-06 18:28:28.361\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m257\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-03-06 18:29:07.880\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m257\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-03-06 18:29:48.196\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m257\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-03-06 18:30:25.373\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m257\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-03-06 18:31:03.106\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m257\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-03-06 18:31:39.069\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m257\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-03-06 18:32:20.970\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m257\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-03-06 18:33:00.309\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m257\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-03-06 18:33:41.139\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m257\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-03-06 18:34:20.662\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m257\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-03-06 18:35:02.086\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m257\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-03-06 18:35:43.456\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m257\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-03-06 18:36:25.773\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m257\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-03-06 18:37:11.641\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m257\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-03-06 18:37:50.072\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m257\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-03-06 18:38:27.360\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m257\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-03-06 18:39:02.107\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m257\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-03-06 18:39:36.465\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m257\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-03-06 18:40:13.443\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m257\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-03-06 18:40:50.160\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m257\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-03-06 18:41:33.689\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m257\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-03-06 18:42:10.394\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m257\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-03-06 18:42:48.073\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m257\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-03-06 18:43:42.317\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m257\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-03-06 18:44:28.744\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m257\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-03-06 18:45:15.004\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m257\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-03-06 18:45:55.166\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m257\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-03-06 18:46:34.370\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m257\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-03-06 18:47:11.967\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m257\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-03-06 18:47:48.308\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m257\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-03-06 18:48:26.673\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m257\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-03-06 18:49:06.032\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m257\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-03-06 18:49:43.990\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m257\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-03-06 18:50:21.095\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m257\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-03-06 18:51:02.311\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m257\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-03-06 18:51:41.995\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m257\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-03-06 18:52:26.851\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m257\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-03-06 18:53:05.311\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m257\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-03-06 18:53:46.218\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m257\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-03-06 18:54:28.658\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m257\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-03-06 18:55:02.697\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m257\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-03-06 18:55:37.431\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m257\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-03-06 18:56:12.999\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m257\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-03-06 18:56:48.991\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m257\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-03-06 18:57:28.545\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m257\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-03-06 18:58:04.178\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m257\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-03-06 18:58:46.187\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m257\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-03-06 18:59:33.927\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m257\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:00:09.851\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m257\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:00:45.082\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m257\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:01:23.067\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m257\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:02:07.417\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m257\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:02:45.044\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m257\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:03:19.029\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m257\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:04:01.262\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m257\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:04:44.981\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m257\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:05:21.260\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m257\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:06:04.732\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m257\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:06:42.542\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m257\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:07:22.066\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m257\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:07:59.633\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m257\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:08:35.425\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m257\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:09:10.458\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m257\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:09:46.252\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m257\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:10:13.826\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m257\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:10:42.238\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m257\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:11:17.887\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m257\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:11:54.420\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m257\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:12:32.637\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m257\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:13:05.159\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m403\u001b[0m - \u001b[1mTransition and reward function table generated.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:13:05.160\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m405\u001b[0m - \u001b[1msolving step 0\u001b[0m\n",
            "\u001b[32m2025-03-06 19:13:05.160\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m315\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-03-06 19:13:05.291\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m338\u001b[0m - \u001b[1mMax Error: 0.04500000178813934 | Avg Error: 0.017000000923871994 | 1800<0.001\u001b[0m\n",
            "\u001b[32m2025-03-06 19:13:25.404\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m338\u001b[0m - \u001b[1mMax Error: 0.009999999776482582 | Avg Error: 0.004000000189989805 | 1759<0.001\u001b[0m\n",
            "\u001b[32m2025-03-06 19:13:47.819\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m338\u001b[0m - \u001b[1mMax Error: 0.0020000000949949026 | Avg Error: 0.0010000000474974513 | 11916<0.001\u001b[0m\n",
            "\u001b[32m2025-03-06 19:14:12.123\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m338\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 27000<0.001\u001b[0m\n",
            "\u001b[32m2025-03-06 19:14:12.124\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m355\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:14:12.125\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m364\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-03-06 19:14:12.248\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mThe number of updated different actions: 1944000\u001b[0m\n",
            "\u001b[32m2025-03-06 19:14:12.249\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m380\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:14:12.250\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m405\u001b[0m - \u001b[1msolving step 1\u001b[0m\n",
            "\u001b[32m2025-03-06 19:14:12.250\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m315\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-03-06 19:14:12.391\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m338\u001b[0m - \u001b[1mMax Error: 0.06199999898672104 | Avg Error: 0.006000000052154064 | 5387<0.001\u001b[0m\n",
            "\u001b[32m2025-03-06 19:14:33.430\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m338\u001b[0m - \u001b[1mMax Error: 0.004999999888241291 | Avg Error: 0.0010000000474974513 | 13986<0.001\u001b[0m\n",
            "\u001b[32m2025-03-06 19:14:55.974\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m338\u001b[0m - \u001b[1mMax Error: 0.0010000000474974513 | Avg Error: 0.0 | 27000<0.001\u001b[0m\n",
            "\u001b[32m2025-03-06 19:15:15.996\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m338\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 27000<0.001\u001b[0m\n",
            "\u001b[32m2025-03-06 19:15:15.996\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m355\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:15:15.996\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m364\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-03-06 19:15:16.109\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mThe number of updated different actions: 20438\u001b[0m\n",
            "\u001b[32m2025-03-06 19:15:16.110\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m380\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:15:16.110\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m405\u001b[0m - \u001b[1msolving step 2\u001b[0m\n",
            "\u001b[32m2025-03-06 19:15:16.111\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m315\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-03-06 19:15:16.236\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m338\u001b[0m - \u001b[1mMax Error: 0.035999998450279236 | Avg Error: 0.0010000000474974513 | 22452<0.001\u001b[0m\n",
            "\u001b[32m2025-03-06 19:15:34.763\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m338\u001b[0m - \u001b[1mMax Error: 0.0010000000474974513 | Avg Error: 0.0 | 27000<0.001\u001b[0m\n",
            "\u001b[32m2025-03-06 19:15:53.190\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m338\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 27000<0.001\u001b[0m\n",
            "\u001b[32m2025-03-06 19:15:53.191\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m355\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:15:53.191\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m364\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-03-06 19:15:53.300\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mThe number of updated different actions: 5690\u001b[0m\n",
            "\u001b[32m2025-03-06 19:15:53.301\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m380\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:15:53.301\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m405\u001b[0m - \u001b[1msolving step 3\u001b[0m\n",
            "\u001b[32m2025-03-06 19:15:53.302\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m315\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-03-06 19:15:53.429\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m338\u001b[0m - \u001b[1mMax Error: 0.020999999716877937 | Avg Error: 0.0 | 26235<0.001\u001b[0m\n",
            "\u001b[32m2025-03-06 19:16:13.535\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m338\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 27000<0.001\u001b[0m\n",
            "\u001b[32m2025-03-06 19:16:13.535\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m355\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:16:13.536\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m364\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-03-06 19:16:13.645\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mThe number of updated different actions: 2466\u001b[0m\n",
            "\u001b[32m2025-03-06 19:16:13.645\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m380\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:16:13.646\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m405\u001b[0m - \u001b[1msolving step 4\u001b[0m\n",
            "\u001b[32m2025-03-06 19:16:13.646\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m315\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-03-06 19:16:13.772\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m338\u001b[0m - \u001b[1mMax Error: 0.010999999940395355 | Avg Error: 0.0 | 26552<0.001\u001b[0m\n",
            "\u001b[32m2025-03-06 19:16:35.140\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m338\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 27000<0.001\u001b[0m\n",
            "\u001b[32m2025-03-06 19:16:35.141\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m355\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:16:35.141\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m364\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-03-06 19:16:35.249\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mThe number of updated different actions: 574\u001b[0m\n",
            "\u001b[32m2025-03-06 19:16:35.250\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m380\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:16:35.250\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m405\u001b[0m - \u001b[1msolving step 5\u001b[0m\n",
            "\u001b[32m2025-03-06 19:16:35.250\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m315\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-03-06 19:16:35.381\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m338\u001b[0m - \u001b[1mMax Error: 0.003000000026077032 | Avg Error: 0.0 | 26991<0.001\u001b[0m\n",
            "\u001b[32m2025-03-06 19:16:55.773\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m338\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 27000<0.001\u001b[0m\n",
            "\u001b[32m2025-03-06 19:16:55.774\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m355\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:16:55.774\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m364\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-03-06 19:16:55.939\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mThe number of updated different actions: 60\u001b[0m\n",
            "\u001b[32m2025-03-06 19:16:55.939\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m380\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:16:55.940\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m405\u001b[0m - \u001b[1msolving step 6\u001b[0m\n",
            "\u001b[32m2025-03-06 19:16:55.940\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m315\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-03-06 19:16:56.193\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m338\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 27000<0.001\u001b[0m\n",
            "\u001b[32m2025-03-06 19:16:56.194\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m355\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:16:56.194\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m364\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-03-06 19:16:56.386\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mThe number of updated different actions: 12\u001b[0m\n",
            "\u001b[32m2025-03-06 19:16:56.386\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m380\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:16:56.387\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m405\u001b[0m - \u001b[1msolving step 7\u001b[0m\n",
            "\u001b[32m2025-03-06 19:16:56.387\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m315\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-03-06 19:16:56.616\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m338\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 27000<0.001\u001b[0m\n",
            "\u001b[32m2025-03-06 19:16:56.617\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m355\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:16:56.617\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m364\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-03-06 19:16:56.752\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mThe number of updated different actions: 12\u001b[0m\n",
            "\u001b[32m2025-03-06 19:16:56.752\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m380\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:16:56.753\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m405\u001b[0m - \u001b[1msolving step 8\u001b[0m\n",
            "\u001b[32m2025-03-06 19:16:56.753\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m315\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-03-06 19:16:56.980\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m338\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 27000<0.001\u001b[0m\n",
            "\u001b[32m2025-03-06 19:16:56.980\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m355\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:16:56.981\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m364\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-03-06 19:16:57.134\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mThe number of updated different actions: 14\u001b[0m\n",
            "\u001b[32m2025-03-06 19:16:57.135\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m380\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:16:57.135\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m405\u001b[0m - \u001b[1msolving step 9\u001b[0m\n",
            "\u001b[32m2025-03-06 19:16:57.136\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m315\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-03-06 19:16:57.274\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m338\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 27000<0.001\u001b[0m\n",
            "\u001b[32m2025-03-06 19:16:57.275\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m355\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:16:57.275\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m364\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-03-06 19:16:57.388\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mThe number of updated different actions: 10\u001b[0m\n",
            "\u001b[32m2025-03-06 19:16:57.389\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m380\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:16:57.389\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m405\u001b[0m - \u001b[1msolving step 10\u001b[0m\n",
            "\u001b[32m2025-03-06 19:16:57.389\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m315\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-03-06 19:16:57.522\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m338\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 27000<0.001\u001b[0m\n",
            "\u001b[32m2025-03-06 19:16:57.522\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m355\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:16:57.523\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m364\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-03-06 19:16:57.654\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mThe number of updated different actions: 6\u001b[0m\n",
            "\u001b[32m2025-03-06 19:16:57.655\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m380\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:16:57.655\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m405\u001b[0m - \u001b[1msolving step 11\u001b[0m\n",
            "\u001b[32m2025-03-06 19:16:57.655\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m315\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-03-06 19:16:57.782\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m338\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 27000<0.001\u001b[0m\n",
            "\u001b[32m2025-03-06 19:16:57.783\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m355\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:16:57.783\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m364\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-03-06 19:16:57.892\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mThe number of updated different actions: 8\u001b[0m\n",
            "\u001b[32m2025-03-06 19:16:57.893\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m380\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:16:57.893\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m405\u001b[0m - \u001b[1msolving step 12\u001b[0m\n",
            "\u001b[32m2025-03-06 19:16:57.893\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m315\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-03-06 19:16:58.036\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m338\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 27000<0.001\u001b[0m\n",
            "\u001b[32m2025-03-06 19:16:58.036\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m355\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:16:58.037\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m364\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-03-06 19:16:58.146\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mThe number of updated different actions: 6\u001b[0m\n",
            "\u001b[32m2025-03-06 19:16:58.146\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m380\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:16:58.147\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m405\u001b[0m - \u001b[1msolving step 13\u001b[0m\n",
            "\u001b[32m2025-03-06 19:16:58.147\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m315\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-03-06 19:16:58.285\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m338\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 27000<0.001\u001b[0m\n",
            "\u001b[32m2025-03-06 19:16:58.285\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m355\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:16:58.286\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m364\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-03-06 19:16:58.402\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mThe number of updated different actions: 8\u001b[0m\n",
            "\u001b[32m2025-03-06 19:16:58.402\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m380\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:16:58.403\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m405\u001b[0m - \u001b[1msolving step 14\u001b[0m\n",
            "\u001b[32m2025-03-06 19:16:58.403\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m315\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-03-06 19:16:58.564\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m338\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 27000<0.001\u001b[0m\n",
            "\u001b[32m2025-03-06 19:16:58.564\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m355\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:16:58.565\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m364\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-03-06 19:16:58.673\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mThe number of updated different actions: 10\u001b[0m\n",
            "\u001b[32m2025-03-06 19:16:58.674\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m380\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:16:58.674\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m405\u001b[0m - \u001b[1msolving step 15\u001b[0m\n",
            "\u001b[32m2025-03-06 19:16:58.675\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m315\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-03-06 19:16:58.808\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m338\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 27000<0.001\u001b[0m\n",
            "\u001b[32m2025-03-06 19:16:58.808\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m355\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:16:58.809\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m364\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-03-06 19:16:58.918\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mThe number of updated different actions: 8\u001b[0m\n",
            "\u001b[32m2025-03-06 19:16:58.919\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m380\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:16:58.919\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m405\u001b[0m - \u001b[1msolving step 16\u001b[0m\n",
            "\u001b[32m2025-03-06 19:16:58.920\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m315\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-03-06 19:16:59.054\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m338\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 27000<0.001\u001b[0m\n",
            "\u001b[32m2025-03-06 19:16:59.055\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m355\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:16:59.055\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m364\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-03-06 19:16:59.212\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mThe number of updated different actions: 8\u001b[0m\n",
            "\u001b[32m2025-03-06 19:16:59.213\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m380\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:16:59.214\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m405\u001b[0m - \u001b[1msolving step 17\u001b[0m\n",
            "\u001b[32m2025-03-06 19:16:59.214\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m315\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-03-06 19:16:59.354\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m338\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 27000<0.001\u001b[0m\n",
            "\u001b[32m2025-03-06 19:16:59.354\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m355\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:16:59.354\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m364\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-03-06 19:16:59.465\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mThe number of updated different actions: 12\u001b[0m\n",
            "\u001b[32m2025-03-06 19:16:59.466\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m380\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:16:59.466\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m405\u001b[0m - \u001b[1msolving step 18\u001b[0m\n",
            "\u001b[32m2025-03-06 19:16:59.466\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m315\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-03-06 19:16:59.680\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m338\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 27000<0.001\u001b[0m\n",
            "\u001b[32m2025-03-06 19:16:59.680\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m355\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:16:59.681\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m364\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-03-06 19:16:59.799\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mThe number of updated different actions: 12\u001b[0m\n",
            "\u001b[32m2025-03-06 19:16:59.799\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m380\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:16:59.800\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m405\u001b[0m - \u001b[1msolving step 19\u001b[0m\n",
            "\u001b[32m2025-03-06 19:16:59.800\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m315\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-03-06 19:16:59.937\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m338\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 27000<0.001\u001b[0m\n",
            "\u001b[32m2025-03-06 19:16:59.938\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m355\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:16:59.938\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m364\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:00.103\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mThe number of updated different actions: 12\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:00.104\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m380\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:00.104\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m405\u001b[0m - \u001b[1msolving step 20\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:00.104\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m315\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:00.272\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m338\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 27000<0.001\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:00.273\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m355\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:00.273\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m364\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:00.388\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mThe number of updated different actions: 6\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:00.389\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m380\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:00.389\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m405\u001b[0m - \u001b[1msolving step 21\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:00.389\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m315\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:00.562\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m338\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 27000<0.001\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:00.562\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m355\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:00.562\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m364\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:00.675\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mThe number of updated different actions: 10\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:00.675\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m380\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:00.675\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m405\u001b[0m - \u001b[1msolving step 22\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:00.676\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m315\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:00.806\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m338\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 27000<0.001\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:00.806\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m355\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:00.807\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m364\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:00.922\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mThe number of updated different actions: 6\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:00.923\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m380\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:00.923\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m405\u001b[0m - \u001b[1msolving step 23\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:00.924\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m315\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:01.143\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m338\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 27000<0.001\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:01.144\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m355\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:01.144\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m364\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:01.340\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mThe number of updated different actions: 4\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:01.341\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m380\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:01.341\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m405\u001b[0m - \u001b[1msolving step 24\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:01.341\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m315\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:01.553\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m338\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 27000<0.001\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:01.554\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m355\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:01.554\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m364\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:01.783\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mThe number of updated different actions: 10\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:01.784\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m380\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:01.784\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m405\u001b[0m - \u001b[1msolving step 25\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:01.784\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m315\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:01.981\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m338\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 27000<0.001\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:01.981\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m355\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:01.982\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m364\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:02.180\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mThe number of updated different actions: 8\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:02.181\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m380\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:02.181\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m405\u001b[0m - \u001b[1msolving step 26\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:02.182\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m315\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:02.354\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m338\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 27000<0.001\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:02.355\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m355\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:02.355\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m364\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:02.496\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mThe number of updated different actions: 12\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:02.496\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m380\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:02.497\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m405\u001b[0m - \u001b[1msolving step 27\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:02.497\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m315\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:02.799\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m338\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 27000<0.001\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:02.799\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m355\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:02.800\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m364\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:02.976\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mThe number of updated different actions: 10\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:02.976\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m380\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:02.977\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m405\u001b[0m - \u001b[1msolving step 28\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:02.977\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m315\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:03.172\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m338\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 27000<0.001\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:03.172\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m355\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:03.173\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m364\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:03.342\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mThe number of updated different actions: 12\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:03.343\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m380\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:03.343\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m405\u001b[0m - \u001b[1msolving step 29\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:03.343\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m315\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:03.555\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m338\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 27000<0.001\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:03.556\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m355\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:03.557\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m364\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:03.722\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mThe number of updated different actions: 6\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:03.723\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m380\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:03.724\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m405\u001b[0m - \u001b[1msolving step 30\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:03.724\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m315\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:03.922\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m338\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 27000<0.001\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:03.923\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m355\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:03.923\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m364\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:04.065\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mThe number of updated different actions: 4\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:04.065\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m380\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:04.066\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m405\u001b[0m - \u001b[1msolving step 31\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:04.066\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m315\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:04.201\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m338\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 27000<0.001\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:04.202\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m355\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:04.202\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m364\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:04.316\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mThe number of updated different actions: 8\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:04.316\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m380\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:04.316\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m405\u001b[0m - \u001b[1msolving step 32\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:04.317\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m315\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:04.451\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m338\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 27000<0.001\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:04.451\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m355\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:04.451\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m364\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:04.565\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mThe number of updated different actions: 14\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:04.565\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m380\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:04.566\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m405\u001b[0m - \u001b[1msolving step 33\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:04.566\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m315\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:04.694\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m338\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 27000<0.001\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:04.695\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m355\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:04.695\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m364\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:04.815\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mThe number of updated different actions: 6\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:04.815\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m380\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:04.816\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m405\u001b[0m - \u001b[1msolving step 34\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:04.816\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m315\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:04.942\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m338\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 27000<0.001\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:04.943\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m355\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:04.943\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m364\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:05.055\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mThe number of updated different actions: 6\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:05.055\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m380\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:05.056\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m405\u001b[0m - \u001b[1msolving step 35\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:05.056\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m315\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:05.182\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m338\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 27000<0.001\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:05.182\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m355\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:05.183\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m364\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:05.302\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mThe number of updated different actions: 4\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:05.303\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m380\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:05.303\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m405\u001b[0m - \u001b[1msolving step 36\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:05.303\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m315\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:05.431\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m338\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 27000<0.001\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:05.431\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m355\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:05.431\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m364\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:05.540\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mThe number of updated different actions: 2\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:05.540\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m380\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:05.541\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m405\u001b[0m - \u001b[1msolving step 37\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:05.541\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m315\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:05.665\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m338\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 27000<0.001\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:05.666\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m355\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:05.666\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m364\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:05.784\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mThe number of updated different actions: 8\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:05.784\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m380\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:05.784\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m405\u001b[0m - \u001b[1msolving step 38\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:05.785\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m315\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:05.909\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m338\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 27000<0.001\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:05.909\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m355\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:05.910\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m364\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:06.019\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mThe number of updated different actions: 6\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:06.019\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m380\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:06.019\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m405\u001b[0m - \u001b[1msolving step 39\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:06.020\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m315\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:06.145\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m338\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 27000<0.001\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:06.145\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m355\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:06.145\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m364\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:06.259\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mThe number of updated different actions: 8\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:06.259\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m380\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:06.259\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m405\u001b[0m - \u001b[1msolving step 40\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:06.260\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m315\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:06.384\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m338\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 27000<0.001\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:06.385\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m355\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:06.385\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m364\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:06.494\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mThe number of updated different actions: 8\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:06.494\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m380\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:06.495\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m405\u001b[0m - \u001b[1msolving step 41\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:06.495\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m315\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:06.619\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m338\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 27000<0.001\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:06.620\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m355\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:06.620\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m364\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:06.734\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mThe number of updated different actions: 14\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:06.735\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m380\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:06.735\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m405\u001b[0m - \u001b[1msolving step 42\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:06.735\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m315\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:06.860\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m338\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 27000<0.001\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:06.860\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m355\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:06.860\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m364\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:06.971\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mThe number of updated different actions: 10\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:06.972\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m380\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:06.972\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m405\u001b[0m - \u001b[1msolving step 43\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:06.972\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m315\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:07.104\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m338\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 27000<0.001\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:07.105\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m355\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:07.105\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m364\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:07.214\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mThe number of updated different actions: 14\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:07.215\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m380\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:07.215\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m405\u001b[0m - \u001b[1msolving step 44\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:07.215\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m315\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:07.350\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m338\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 27000<0.001\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:07.350\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m355\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:07.350\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m364\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:07.486\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mThe number of updated different actions: 4\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:07.486\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m380\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:07.486\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m405\u001b[0m - \u001b[1msolving step 45\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:07.487\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m315\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:07.614\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m338\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 27000<0.001\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:07.614\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m355\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:07.615\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m364\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:07.731\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mThe number of updated different actions: 6\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:07.732\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m380\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:07.732\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m405\u001b[0m - \u001b[1msolving step 46\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:07.733\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m315\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:07.862\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m338\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 27000<0.001\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:07.862\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m355\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:07.862\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m364\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:07.972\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mThe number of updated different actions: 10\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:07.972\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m380\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:07.972\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m405\u001b[0m - \u001b[1msolving step 47\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:07.973\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m315\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:08.105\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m338\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 27000<0.001\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:08.105\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m355\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:08.106\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m364\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:08.214\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mThe number of updated different actions: 6\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:08.215\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m380\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:08.215\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m405\u001b[0m - \u001b[1msolving step 48\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:08.216\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m315\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:08.344\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m338\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 27000<0.001\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:08.344\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m355\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:08.345\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m364\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:08.455\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mThe number of updated different actions: 10\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:08.455\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m380\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:08.456\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m405\u001b[0m - \u001b[1msolving step 49\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:08.456\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m315\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:08.581\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m338\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 27000<0.001\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:08.582\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m355\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:08.582\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m364\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:08.690\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mThe number of updated different actions: 8\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:08.691\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m380\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:08.691\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m405\u001b[0m - \u001b[1msolving step 50\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:08.692\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m315\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:08.815\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m338\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 27000<0.001\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:08.816\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m355\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:08.816\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m364\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:08.925\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mThe number of updated different actions: 2\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:08.925\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m380\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:08.925\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m405\u001b[0m - \u001b[1msolving step 51\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:08.926\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m315\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:09.055\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m338\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 27000<0.001\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:09.055\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m355\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:09.055\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m364\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:09.171\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mThe number of updated different actions: 4\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:09.171\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m380\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:09.171\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m405\u001b[0m - \u001b[1msolving step 52\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:09.172\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m315\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:09.304\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m338\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 27000<0.001\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:09.305\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m355\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:09.305\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m364\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:09.457\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mThe number of updated different actions: 4\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:09.457\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m380\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:09.458\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m405\u001b[0m - \u001b[1msolving step 53\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:09.459\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m315\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:09.646\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m338\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 27000<0.001\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:09.646\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m355\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:09.647\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m364\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:09.808\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mThe number of updated different actions: 8\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:09.809\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m380\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:09.809\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m405\u001b[0m - \u001b[1msolving step 54\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:09.809\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m315\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:10.001\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m338\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 27000<0.001\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:10.002\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m355\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:10.002\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m364\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:10.182\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mThe number of updated different actions: 14\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:10.183\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m380\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:10.183\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m405\u001b[0m - \u001b[1msolving step 55\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:10.183\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m315\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:10.368\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m338\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 27000<0.001\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:10.369\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m355\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:10.369\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m364\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:10.546\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mThe number of updated different actions: 8\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:10.547\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m380\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:10.547\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m405\u001b[0m - \u001b[1msolving step 56\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:10.548\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m315\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:10.761\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m338\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 27000<0.001\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:10.761\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m355\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:10.762\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m364\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:10.909\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mThe number of updated different actions: 6\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:10.910\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m380\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:10.910\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m405\u001b[0m - \u001b[1msolving step 57\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:10.911\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m315\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:11.067\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m338\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 27000<0.001\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:11.067\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m355\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:11.068\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m364\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:11.181\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mThe number of updated different actions: 6\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:11.181\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m380\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:11.182\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m405\u001b[0m - \u001b[1msolving step 58\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:11.182\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m315\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:11.311\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m338\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 27000<0.001\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:11.311\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m355\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:11.312\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m364\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:11.424\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mThe number of updated different actions: 8\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:11.424\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m380\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:11.425\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m405\u001b[0m - \u001b[1msolving step 59\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:11.425\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m315\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:11.553\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m338\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 27000<0.001\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:11.554\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m355\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:11.554\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m364\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:11.672\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mThe number of updated different actions: 6\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:11.672\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m380\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:11.673\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m405\u001b[0m - \u001b[1msolving step 60\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:11.673\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m315\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:11.812\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m338\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 27000<0.001\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:11.813\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m355\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:11.813\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m364\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:11.926\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mThe number of updated different actions: 6\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:11.927\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m380\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:11.927\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m405\u001b[0m - \u001b[1msolving step 61\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:11.928\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m315\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:12.055\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m338\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 27000<0.001\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:12.055\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m355\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:12.055\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m364\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:12.173\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mThe number of updated different actions: 6\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:12.174\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m380\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:12.174\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m405\u001b[0m - \u001b[1msolving step 62\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:12.174\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m315\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:12.299\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m338\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 27000<0.001\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:12.300\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m355\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:12.300\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m364\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:12.410\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mThe number of updated different actions: 4\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:12.411\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m380\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:12.411\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m405\u001b[0m - \u001b[1msolving step 63\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:12.412\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m315\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:12.537\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m338\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 27000<0.001\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:12.538\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m355\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:12.538\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m364\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:12.649\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mThe number of updated different actions: 2\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:12.650\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m380\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:12.650\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m405\u001b[0m - \u001b[1msolving step 64\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:12.650\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m315\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:12.774\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m338\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 27000<0.001\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:12.775\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m355\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:12.775\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m364\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:12.886\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mThe number of updated different actions: 4\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:12.887\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m380\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:12.887\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m405\u001b[0m - \u001b[1msolving step 65\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:12.887\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m315\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:13.018\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m338\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 27000<0.001\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:13.018\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m355\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:13.018\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m364\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:13.138\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mThe number of updated different actions: 8\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:13.138\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m380\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:13.139\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m405\u001b[0m - \u001b[1msolving step 66\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:13.139\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m315\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:13.270\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m338\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 27000<0.001\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:13.270\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m355\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:13.270\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m364\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:13.384\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mThe number of updated different actions: 2\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:13.384\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m380\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:13.385\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m405\u001b[0m - \u001b[1msolving step 67\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:13.385\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m315\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:13.509\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m338\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 27000<0.001\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:13.509\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m355\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:13.510\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m364\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:13.619\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mThe number of updated different actions: 2\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:13.619\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m380\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:13.620\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m405\u001b[0m - \u001b[1msolving step 68\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:13.620\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m315\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:13.745\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m338\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 27000<0.001\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:13.746\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m355\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:13.746\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m364\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:13.857\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mThe number of updated different actions: 6\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:13.857\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m380\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:13.858\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m405\u001b[0m - \u001b[1msolving step 69\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:13.858\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m315\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:13.983\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m338\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 27000<0.001\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:13.984\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m355\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:13.984\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m364\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:14.094\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mThe number of updated different actions: 4\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:14.094\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m380\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:14.094\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m405\u001b[0m - \u001b[1msolving step 70\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:14.095\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m315\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:14.219\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m338\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 27000<0.001\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:14.219\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m355\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:14.220\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m364\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:14.329\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mThe number of updated different actions: 4\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:14.329\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m380\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:14.330\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m405\u001b[0m - \u001b[1msolving step 71\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:14.330\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m315\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:14.460\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m338\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 27000<0.001\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:14.460\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m355\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:14.461\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m364\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:14.638\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mThe number of updated different actions: 4\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:14.639\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m380\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:14.640\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m405\u001b[0m - \u001b[1msolving step 72\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:14.640\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m315\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:14.785\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m338\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 27000<0.001\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:14.786\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m355\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:14.786\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m364\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:14.902\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mThe number of updated different actions: 4\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:14.902\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m380\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:14.903\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m405\u001b[0m - \u001b[1msolving step 73\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:14.903\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m315\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:15.041\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m338\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 27000<0.001\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:15.042\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m355\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:15.042\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m364\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:15.210\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mThe number of updated different actions: 10\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:15.211\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m380\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:15.211\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m405\u001b[0m - \u001b[1msolving step 74\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:15.212\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m315\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:15.397\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m338\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 27000<0.001\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:15.397\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m355\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:15.398\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m364\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:15.509\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mThe number of updated different actions: 2\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:15.509\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m380\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:15.510\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m405\u001b[0m - \u001b[1msolving step 75\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:15.510\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m315\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:15.640\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m338\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 27000<0.001\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:15.640\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m355\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:15.641\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m364\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:15.760\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mThe number of updated different actions: 4\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:15.760\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m380\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:15.761\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m405\u001b[0m - \u001b[1msolving step 76\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:15.761\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m315\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:15.897\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m338\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 27000<0.001\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:15.897\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m355\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:15.898\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m364\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:16.023\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mThe number of updated different actions: 6\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:16.024\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m380\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:16.024\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m405\u001b[0m - \u001b[1msolving step 77\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:16.024\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m315\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:16.162\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m338\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 27000<0.001\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:16.162\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m355\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:16.163\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m364\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:16.342\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mThe number of updated different actions: 6\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:16.343\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m380\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:16.343\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m405\u001b[0m - \u001b[1msolving step 78\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:16.343\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m315\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:16.498\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m338\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 27000<0.001\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:16.499\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m355\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:16.499\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m364\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:16.610\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mThe number of updated different actions: 6\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:16.611\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m380\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:16.611\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m405\u001b[0m - \u001b[1msolving step 79\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:16.612\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m315\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:16.738\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m338\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 27000<0.001\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:16.738\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m355\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:16.739\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m364\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:16.855\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mThe number of updated different actions: 6\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:16.856\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m380\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:16.856\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m405\u001b[0m - \u001b[1msolving step 80\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:16.856\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m315\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:16.981\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m338\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 27000<0.001\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:16.981\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m355\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:16.982\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m364\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:17.097\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mThe number of updated different actions: 6\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:17.097\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m380\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:17.098\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m405\u001b[0m - \u001b[1msolving step 81\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:17.098\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m315\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:17.228\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m338\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 27000<0.001\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:17.228\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m355\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:17.228\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m364\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:17.341\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mThe number of updated different actions: 6\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:17.342\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m380\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:17.342\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m405\u001b[0m - \u001b[1msolving step 82\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:17.343\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m315\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:17.473\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m338\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 27000<0.001\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:17.473\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m355\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:17.473\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m364\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:17.586\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mThe number of updated different actions: 6\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:17.587\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m380\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:17.587\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m405\u001b[0m - \u001b[1msolving step 83\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:17.588\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m315\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:17.718\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m338\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 27000<0.001\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:17.719\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m355\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:17.719\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m364\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:17.835\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mThe number of updated different actions: 8\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:17.836\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m380\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:17.836\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m405\u001b[0m - \u001b[1msolving step 84\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:17.836\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m315\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:17.965\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m338\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 27000<0.001\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:17.966\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m355\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:17.966\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m364\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:18.083\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mThe number of updated different actions: 4\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:18.083\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m380\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:18.084\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m405\u001b[0m - \u001b[1msolving step 85\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:18.084\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m315\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:18.216\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m338\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 27000<0.001\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:18.216\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m355\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:18.217\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m364\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:18.335\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mThe number of updated different actions: 6\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:18.335\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m380\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:18.336\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m405\u001b[0m - \u001b[1msolving step 86\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:18.336\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m315\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:18.463\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m338\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 27000<0.001\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:18.463\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m355\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:18.464\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m364\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:18.573\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mThe number of updated different actions: 10\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:18.573\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m380\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:18.574\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m405\u001b[0m - \u001b[1msolving step 87\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:18.574\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m315\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:18.727\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m338\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 27000<0.001\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:18.727\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m355\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:18.728\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m364\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:18.907\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mThe number of updated different actions: 8\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:18.908\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m380\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:18.909\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m405\u001b[0m - \u001b[1msolving step 88\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:18.909\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m315\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:19.075\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m338\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 27000<0.001\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:19.076\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m355\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:19.076\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m364\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:19.250\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mThe number of updated different actions: 6\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:19.251\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m380\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:19.251\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m405\u001b[0m - \u001b[1msolving step 89\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:19.252\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m315\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:19.471\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m338\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 27000<0.001\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:19.471\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m355\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:19.471\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m364\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:19.588\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m380\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-03-06 19:17:19.771\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36msave\u001b[0m:\u001b[36m424\u001b[0m - \u001b[1mPolicy and value function saved.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "import airplane\n",
        "import numpy as np\n",
        "import gymnasium as gym\n",
        "from utils.utils import test_enviroment\n",
        "from PolicyIteration import PolicyIteration\n",
        "\n",
        "glider = gym.make('ReducedBankedGliderPullout-v0')\n",
        "\n",
        "bins_space = {\n",
        "    \"flight_path_angle\": np.linspace(np.deg2rad(-180), np.deg2rad(0),     30,      dtype=np.float32),    # Flight Path Angle  (γ)    (0)\n",
        "    \"airspeed_norm\":     np.linspace(0.9, 4.5,                            30,      dtype=np.float32),    # Air Speed          (V)    (1)\n",
        "    \"bank_angle\":        np.linspace( np.deg2rad(-20), np.deg2rad(200),   30,      dtype=np.float32),    # Bank Angle         (mu)   (2)\n",
        "}\n",
        "\n",
        "\n",
        "action_space= np.array(np.meshgrid(np.linspace(-0.5, 1.0, 6, dtype=np.float32), \n",
        "                                   np.linspace(np.deg2rad(-30), np.deg2rad(30), 12, dtype=np.float32))).T.reshape(-1, 2)\n",
        "\n",
        "pi = PolicyIteration(\n",
        "    env=glider, \n",
        "    bins_space=bins_space,\n",
        "    action_space= action_space,\n",
        "    gamma=0.99,\n",
        "    theta=1e-3,\n",
        ")\n",
        "\n",
        "\n",
        "pi.run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "442d7f05",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Action: [1.    0.524] | Reward: -0.011854943438053572 |                 State: (-80.16007232666016, 1.203194499015808, 150.3000030517578) | Terminated: False |                Episode Length: 0.01 | C_L: 1.0\n",
            "Action: [1.    0.524] | Reward: -0.02374708114579749 |                 State: (-80.3203353881836, 1.2063888311386108, 150.59999084472656) | Terminated: False |                Episode Length: 0.02 | C_L: 1.0\n",
            "Action: [1.    0.524] | Reward: -0.03567635565003305 |                 State: (-80.48078918457031, 1.2095831632614136, 150.89999389648438) | Terminated: False |                Episode Length: 0.03 | C_L: 1.0\n",
            "Action: [1.    0.524] | Reward: -0.047642708128035866 |                 State: (-80.64144134521484, 1.2127772569656372, 151.19998168945312) | Terminated: False |                Episode Length: 0.04 | C_L: 1.0\n",
            "Action: [1.    0.524] | Reward: -0.05964607839916092 |                 State: (-80.80228424072266, 1.2159712314605713, 151.5) | Terminated: False |                Episode Length: 0.05 | C_L: 1.0\n",
            "Action: [1.    0.524] | Reward: -0.0716864049166001 |                 State: (-80.96331787109375, 1.2191649675369263, 151.79998779296875) | Terminated: False |                Episode Length: 0.060000000000000005 | C_L: 1.0\n",
            "Action: [1.    0.524] | Reward: -0.0837636247592959 |                 State: (-81.12454223632812, 1.2223584651947021, 152.09999084472656) | Terminated: False |                Episode Length: 0.07 | C_L: 1.0\n",
            "Action: [1.    0.524] | Reward: -0.09587767362401492 |                 State: (-81.28596496582031, 1.2255516052246094, 152.39999389648438) | Terminated: False |                Episode Length: 0.08 | C_L: 1.0\n",
            "Action: [1.    0.524] | Reward: -0.10802848581758488 |                 State: (-81.44757843017578, 1.228744626045227, 152.6999969482422) | Terminated: False |                Episode Length: 0.09 | C_L: 1.0\n",
            "Action: [1.    0.524] | Reward: -0.12021599424929892 |                 State: (-81.60939025878906, 1.2319371700286865, 152.99998474121094) | Terminated: False |                Episode Length: 0.09999999999999999 | C_L: 1.0\n",
            "Action: [1.    0.524] | Reward: -0.1324401304234907 |                 State: (-81.77139282226562, 1.2351293563842773, 153.29998779296875) | Terminated: False |                Episode Length: 0.10999999999999999 | C_L: 1.0\n",
            "Action: [1.    0.524] | Reward: -0.14470082443228416 |                 State: (-81.93358612060547, 1.2383211851119995, 153.59999084472656) | Terminated: False |                Episode Length: 0.11999999999999998 | C_L: 1.0\n",
            "Action: [1.    0.524] | Reward: -0.15699800494852156 |                 State: (-82.09597778320312, 1.241512656211853, 153.8999786376953) | Terminated: False |                Episode Length: 0.12999999999999998 | C_L: 1.0\n",
            "Action: [1.    0.524] | Reward: -0.16933159921887353 |                 State: (-82.25856018066406, 1.2447036504745483, 154.1999969482422) | Terminated: False |                Episode Length: 0.13999999999999999 | C_L: 1.0\n",
            "Action: [1.    0.524] | Reward: -0.18170153305713466 |                 State: (-82.42134094238281, 1.247894048690796, 154.49998474121094) | Terminated: False |                Episode Length: 0.15 | C_L: 1.0\n",
            "Action: [1.    0.524] | Reward: -0.1941077308377086 |                 State: (-82.58431243896484, 1.2510839700698853, 154.79998779296875) | Terminated: False |                Episode Length: 0.16 | C_L: 1.0\n",
            "Action: [1.    0.524] | Reward: -0.20655011548928606 |                 State: (-82.74747467041016, 1.2542734146118164, 155.09999084472656) | Terminated: False |                Episode Length: 0.17 | C_L: 1.0\n",
            "Action: [1.    0.524] | Reward: -0.21902860848871952 |                 State: (-82.91084289550781, 1.2574621438980103, 155.39999389648438) | Terminated: False |                Episode Length: 0.18000000000000002 | C_L: 1.0\n",
            "Action: [1.    0.524] | Reward: -0.23154312985509834 |                 State: (-83.07439422607422, 1.260650396347046, 155.69998168945312) | Terminated: False |                Episode Length: 0.19000000000000003 | C_L: 1.0\n",
            "Action: [1.    0.524] | Reward: -0.2440935981440278 |                 State: (-83.2381362915039, 1.2638379335403442, 156.0) | Terminated: False |                Episode Length: 0.20000000000000004 | C_L: 1.0\n",
            "Action: [1.    0.524] | Reward: -0.2566799304421158 |                 State: (-83.4020767211914, 1.2670247554779053, 156.29998779296875) | Terminated: False |                Episode Length: 0.21000000000000005 | C_L: 1.0\n",
            "Action: [1.    0.524] | Reward: -0.2693020423616708 |                 State: (-83.56621551513672, 1.2702109813690186, 156.59999084472656) | Terminated: False |                Episode Length: 0.22000000000000006 | C_L: 1.0\n",
            "Action: [1.    0.524] | Reward: -0.28195984803561475 |                 State: (-83.73052978515625, 1.273396372795105, 156.89999389648438) | Terminated: False |                Episode Length: 0.23000000000000007 | C_L: 1.0\n",
            "Action: [1.    0.524] | Reward: -0.2946532601126142 |                 State: (-83.8950424194336, 1.276581048965454, 157.1999969482422) | Terminated: False |                Episode Length: 0.24000000000000007 | C_L: 1.0\n",
            "Action: [1.    0.524] | Reward: -0.3073821897524338 |                 State: (-84.05974578857422, 1.2797648906707764, 157.49998474121094) | Terminated: False |                Episode Length: 0.25000000000000006 | C_L: 1.0\n",
            "Action: [1.    0.524] | Reward: -0.3201465466215152 |                 State: (-84.22463989257812, 1.2829477787017822, 157.8000030517578) | Terminated: False |                Episode Length: 0.26000000000000006 | C_L: 1.0\n",
            "Action: [1.    0.524] | Reward: -0.3329462388887851 |                 State: (-84.38972473144531, 1.2861299514770508, 158.09999084472656) | Terminated: False |                Episode Length: 0.2700000000000001 | C_L: 1.0\n",
            "Action: [1.    0.524] | Reward: -0.34578117322169616 |                 State: (-84.55499267578125, 1.289311170578003, 158.39999389648438) | Terminated: False |                Episode Length: 0.2800000000000001 | C_L: 1.0\n",
            "Action: [1.    0.524] | Reward: -0.3586512547825038 |                 State: (-84.72044372558594, 1.2924914360046387, 158.6999969482422) | Terminated: False |                Episode Length: 0.2900000000000001 | C_L: 1.0\n",
            "Action: [1.    0.524] | Reward: -0.37155638722478307 |                 State: (-84.88609313964844, 1.295670747756958, 158.99998474121094) | Terminated: False |                Episode Length: 0.3000000000000001 | C_L: 1.0\n",
            "Action: [1.    0.524] | Reward: -0.384496472690188 |                 State: (-85.05192565917969, 1.2988489866256714, 159.29998779296875) | Terminated: False |                Episode Length: 0.3100000000000001 | C_L: 1.0\n",
            "Action: [1.    0.524] | Reward: -0.39747141180545814 |                 State: (-85.21793365478516, 1.3020262718200684, 159.59999084472656) | Terminated: False |                Episode Length: 0.3200000000000001 | C_L: 1.0\n",
            "Action: [1.    0.524] | Reward: -0.41048110367967466 |                 State: (-85.3841323852539, 1.3052024841308594, 159.89999389648438) | Terminated: False |                Episode Length: 0.3300000000000001 | C_L: 1.0\n",
            "Action: [1.    0.524] | Reward: -0.4235254459017697 |                 State: (-85.5505142211914, 1.3083775043487549, 160.19998168945312) | Terminated: False |                Episode Length: 0.34000000000000014 | C_L: 1.0\n",
            "Action: [1.    0.524] | Reward: -0.43660433453829267 |                 State: (-85.71707153320312, 1.3115514516830444, 160.5) | Terminated: False |                Episode Length: 0.35000000000000014 | C_L: 1.0\n",
            "Action: [1.    0.524] | Reward: -0.4497176641314361 |                 State: (-85.8838119506836, 1.3147242069244385, 160.79998779296875) | Terminated: False |                Episode Length: 0.36000000000000015 | C_L: 1.0\n",
            "Action: [1.    0.524] | Reward: -0.462865327697325 |                 State: (-86.05073547363281, 1.317895770072937, 161.09999084472656) | Terminated: False |                Episode Length: 0.37000000000000016 | C_L: 1.0\n",
            "Action: [1.    0.524] | Reward: -0.47604721672457256 |                 State: (-86.21782684326172, 1.32106614112854, 161.39999389648438) | Terminated: False |                Episode Length: 0.38000000000000017 | C_L: 1.0\n",
            "Action: [1.    0.524] | Reward: -0.48926322117310544 |                 State: (-86.38510131835938, 1.324235200881958, 161.6999969482422) | Terminated: False |                Episode Length: 0.3900000000000002 | C_L: 1.0\n",
            "Action: [1.    0.524] | Reward: -0.5025132294732619 |                 State: (-86.55255126953125, 1.327402949333191, 161.99998474121094) | Terminated: False |                Episode Length: 0.4000000000000002 | C_L: 1.0\n",
            "Action: [1.    0.524] | Reward: -0.5157971285251659 |                 State: (-86.72016906738281, 1.3305693864822388, 162.29998779296875) | Terminated: False |                Episode Length: 0.4100000000000002 | C_L: 1.0\n",
            "Action: [1.    0.524] | Reward: -0.5291148036983803 |                 State: (-86.8879623413086, 1.333734393119812, 162.59999084472656) | Terminated: False |                Episode Length: 0.4200000000000002 | C_L: 1.0\n",
            "Action: [1.    0.524] | Reward: -0.5424661388318416 |                 State: (-87.05592346191406, 1.3368979692459106, 162.89999389648438) | Terminated: False |                Episode Length: 0.4300000000000002 | C_L: 1.0\n",
            "Action: [1.    0.524] | Reward: -0.5558510162340805 |                 State: (-87.22406005859375, 1.3400602340698242, 163.19998168945312) | Terminated: False |                Episode Length: 0.4400000000000002 | C_L: 1.0\n",
            "Action: [1.    0.524] | Reward: -0.5692693166837299 |                 State: (-87.39236450195312, 1.3432209491729736, 163.5) | Terminated: False |                Episode Length: 0.45000000000000023 | C_L: 1.0\n",
            "Action: [1.    0.524] | Reward: -0.582720919430324 |                 State: (-87.56082153320312, 1.3463801145553589, 163.79998779296875) | Terminated: False |                Episode Length: 0.46000000000000024 | C_L: 1.0\n",
            "Action: [1.    0.524] | Reward: -0.5962057021953907 |                 State: (-87.72945404052734, 1.3495378494262695, 164.09999084472656) | Terminated: False |                Episode Length: 0.47000000000000025 | C_L: 1.0\n",
            "Action: [1.    0.524] | Reward: -0.6097235411738414 |                 State: (-87.89823913574219, 1.3526939153671265, 164.39999389648438) | Terminated: False |                Episode Length: 0.48000000000000026 | C_L: 1.0\n",
            "Action: [1.    0.524] | Reward: -0.6232743110356592 |                 State: (-88.06719207763672, 1.3558483123779297, 164.6999969482422) | Terminated: False |                Episode Length: 0.49000000000000027 | C_L: 1.0\n",
            "Action: [1.    0.524] | Reward: -0.6368578849278896 |                 State: (-88.23629760742188, 1.3590011596679688, 164.99998474121094) | Terminated: False |                Episode Length: 0.5000000000000002 | C_L: 1.0\n",
            "Action: [1.    0.524] | Reward: -0.6504741344769358 |                 State: (-88.40556335449219, 1.362152338027954, 165.29998779296875) | Terminated: False |                Episode Length: 0.5100000000000002 | C_L: 1.0\n",
            "Action: [1.    0.524] | Reward: -0.6641229297911606 |                 State: (-88.57498168945312, 1.3653017282485962, 165.59999084472656) | Terminated: False |                Episode Length: 0.5200000000000002 | C_L: 1.0\n",
            "Action: [1.    0.524] | Reward: -0.677804139463799 |                 State: (-88.74455261230469, 1.3684494495391846, 165.8999786376953) | Terminated: False |                Episode Length: 0.5300000000000002 | C_L: 1.0\n",
            "Action: [1.    0.524] | Reward: -0.6915176305761824 |                 State: (-88.91427612304688, 1.3715953826904297, 166.1999969482422) | Terminated: False |                Episode Length: 0.5400000000000003 | C_L: 1.0\n",
            "Action: [1.    0.524] | Reward: -0.7052632687012773 |                 State: (-89.08414459228516, 1.374739408493042, 166.49998474121094) | Terminated: False |                Episode Length: 0.5500000000000003 | C_L: 1.0\n",
            "Action: [1.    0.524] | Reward: -0.7190409179075412 |                 State: (-89.25415802001953, 1.377881646156311, 166.79998779296875) | Terminated: False |                Episode Length: 0.5600000000000003 | C_L: 1.0\n",
            "Action: [1.    0.524] | Reward: -0.7328504407630978 |                 State: (-89.42432403564453, 1.3810219764709473, 167.09999084472656) | Terminated: False |                Episode Length: 0.5700000000000003 | C_L: 1.0\n",
            "Action: [1.    0.524] | Reward: -0.7466916983402333 |                 State: (-89.59461975097656, 1.3841603994369507, 167.39999389648438) | Terminated: False |                Episode Length: 0.5800000000000003 | C_L: 1.0\n",
            "Action: [1.    0.524] | Reward: -0.7605645502202167 |                 State: (-89.76506042480469, 1.3872967958450317, 167.69998168945312) | Terminated: False |                Episode Length: 0.5900000000000003 | C_L: 1.0\n",
            "Action: [1.    0.524] | Reward: -0.7744688544984455 |                 State: (-89.93563842773438, 1.39043128490448, 168.0) | Terminated: False |                Episode Length: 0.6000000000000003 | C_L: 1.0\n",
            "Action: [1.    0.524] | Reward: -0.7884044677899188 |                 State: (-90.10635375976562, 1.3935637474060059, 168.29998779296875) | Terminated: False |                Episode Length: 0.6100000000000003 | C_L: 1.0\n",
            "Action: [1.    0.524] | Reward: -0.8023712452350408 |                 State: (-90.27719116210938, 1.3966940641403198, 168.59999084472656) | Terminated: False |                Episode Length: 0.6200000000000003 | C_L: 1.0\n",
            "Action: [1.    0.524] | Reward: -0.816369040505755 |                 State: (-90.44816589355469, 1.3998223543167114, 168.89999389648438) | Terminated: False |                Episode Length: 0.6300000000000003 | C_L: 1.0\n",
            "Action: [1.    0.524] | Reward: -0.8303977058120122 |                 State: (-90.6192626953125, 1.4029484987258911, 169.1999969482422) | Terminated: False |                Episode Length: 0.6400000000000003 | C_L: 1.0\n",
            "Action: [1.    0.524] | Reward: -0.8444570919085732 |                 State: (-90.79048919677734, 1.4060723781585693, 169.49998474121094) | Terminated: False |                Episode Length: 0.6500000000000004 | C_L: 1.0\n",
            "Action: [1.    0.524] | Reward: -0.8585470481021481 |                 State: (-90.96183776855469, 1.4091942310333252, 169.8000030517578) | Terminated: False |                Episode Length: 0.6600000000000004 | C_L: 1.0\n",
            "Action: [1.    0.524] | Reward: -0.8726674222588741 |                 State: (-91.13330078125, 1.41231369972229, 170.09999084472656) | Terminated: False |                Episode Length: 0.6700000000000004 | C_L: 1.0\n",
            "Action: [1.    0.524] | Reward: -0.8868180608121324 |                 State: (-91.30488586425781, 1.4154309034347534, 170.39999389648438) | Terminated: False |                Episode Length: 0.6800000000000004 | C_L: 1.0\n",
            "Action: [1.    0.524] | Reward: -0.9009988087707073 |                 State: (-91.4765853881836, 1.4185458421707153, 170.6999969482422) | Terminated: False |                Episode Length: 0.6900000000000004 | C_L: 1.0\n",
            "Action: [1.    0.524] | Reward: -0.9152095097272859 |                 State: (-91.64839172363281, 1.4216583967208862, 170.99998474121094) | Terminated: False |                Episode Length: 0.7000000000000004 | C_L: 1.0\n",
            "Action: [1.    0.524] | Reward: -0.9294500058673034 |                 State: (-91.82030487060547, 1.4247685670852661, 171.29998779296875) | Terminated: False |                Episode Length: 0.7100000000000004 | C_L: 1.0\n",
            "Action: [1.    0.524] | Reward: -0.9437201379781319 |                 State: (-91.99232482910156, 1.427876353263855, 171.59999084472656) | Terminated: False |                Episode Length: 0.7200000000000004 | C_L: 1.0\n",
            "Action: [1.    0.524] | Reward: -0.9580197454586156 |                 State: (-92.16444396972656, 1.4309816360473633, 171.89999389648438) | Terminated: False |                Episode Length: 0.7300000000000004 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -0.9723486663289523 |                 State: (-92.336669921875, 1.4340845346450806, 171.87271118164062) | Terminated: False |                Episode Length: 0.7400000000000004 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -0.9867067388035373 |                 State: (-92.50884246826172, 1.4371848106384277, 171.84544372558594) | Terminated: False |                Episode Length: 0.7500000000000004 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -1.0010938000212553 |                 State: (-92.68097686767578, 1.4402825832366943, 171.8181610107422) | Terminated: False |                Episode Length: 0.7600000000000005 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -1.01550968604518 |                 State: (-92.85306549072266, 1.4433777332305908, 171.7908935546875) | Terminated: False |                Episode Length: 0.7700000000000005 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -1.0299542318623343 |                 State: (-93.02511596679688, 1.4464702606201172, 171.7636260986328) | Terminated: False |                Episode Length: 0.7800000000000005 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -1.0444272713835097 |                 State: (-93.1971206665039, 1.4495600461959839, 171.73635864257812) | Terminated: False |                Episode Length: 0.7900000000000005 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -1.058928637443149 |                 State: (-93.36908721923828, 1.4526472091674805, 171.70907592773438) | Terminated: False |                Episode Length: 0.8000000000000005 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -1.0734581617992882 |                 State: (-93.54102325439453, 1.4557316303253174, 171.6818084716797) | Terminated: False |                Episode Length: 0.8100000000000005 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -1.088015675133562 |                 State: (-93.71292114257812, 1.4588133096694946, 171.654541015625) | Terminated: False |                Episode Length: 0.8200000000000005 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -1.10260100705127 |                 State: (-93.88478088378906, 1.4618921279907227, 171.62725830078125) | Terminated: False |                Episode Length: 0.8300000000000005 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -1.1172139860815071 |                 State: (-94.0566177368164, 1.464968204498291, 171.59999084472656) | Terminated: False |                Episode Length: 0.8400000000000005 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -1.1318544396773553 |                 State: (-94.2284164428711, 1.4680413007736206, 171.57272338867188) | Terminated: False |                Episode Length: 0.8500000000000005 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -1.1465221942161394 |                 State: (-94.40019226074219, 1.471111536026001, 171.5454559326172) | Terminated: False |                Episode Length: 0.8600000000000005 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -1.1612170749997466 |                 State: (-94.57192993164062, 1.4741789102554321, 171.51817321777344) | Terminated: False |                Episode Length: 0.8700000000000006 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -1.1759389062550092 |                 State: (-94.74364471435547, 1.477243185043335, 171.49090576171875) | Terminated: False |                Episode Length: 0.8800000000000006 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -1.1906875111341533 |                 State: (-94.91533660888672, 1.480304479598999, 171.463623046875) | Terminated: False |                Episode Length: 0.8900000000000006 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -1.2054627117153096 |                 State: (-95.08699798583984, 1.4833626747131348, 171.4363555908203) | Terminated: False |                Episode Length: 0.9000000000000006 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -1.2202643290030923 |                 State: (-95.2586441040039, 1.4864178895950317, 171.40907287597656) | Terminated: False |                Episode Length: 0.9100000000000006 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -1.2350921829292403 |                 State: (-95.43026733398438, 1.4894700050354004, 171.38182067871094) | Terminated: False |                Episode Length: 0.9200000000000006 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -1.2499460923533263 |                 State: (-95.60186004638672, 1.4925189018249512, 171.3545379638672) | Terminated: False |                Episode Length: 0.9300000000000006 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -1.264825875063531 |                 State: (-95.7734375, 1.495564579963684, 171.3272705078125) | Terminated: False |                Episode Length: 0.9400000000000006 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -1.2797313477774839 |                 State: (-95.94499969482422, 1.4986071586608887, 171.29998779296875) | Terminated: False |                Episode Length: 0.9500000000000006 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -1.2946623261431704 |                 State: (-96.11654663085938, 1.5016463994979858, 171.27272033691406) | Terminated: False |                Episode Length: 0.9600000000000006 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -1.3096186247399062 |                 State: (-96.28807067871094, 1.5046824216842651, 171.2454376220703) | Terminated: False |                Episode Length: 0.9700000000000006 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -1.3246000570793792 |                 State: (-96.45958709716797, 1.507715106010437, 171.21817016601562) | Terminated: False |                Episode Length: 0.9800000000000006 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -1.3396064356067585 |                 State: (-96.63109588623047, 1.510744333267212, 171.19090270996094) | Terminated: False |                Episode Length: 0.9900000000000007 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -1.3546375717018715 |                 State: (-96.80258178710938, 1.513770341873169, 171.16363525390625) | Terminated: False |                Episode Length: 1.0000000000000007 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -1.3696932756804499 |                 State: (-96.97406005859375, 1.5167927742004395, 171.1363525390625) | Terminated: False |                Episode Length: 1.0100000000000007 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -1.3847733567954428 |                 State: (-97.14552307128906, 1.5198118686676025, 171.1090850830078) | Terminated: False |                Episode Length: 1.0200000000000007 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -1.3998776232384 |                 State: (-97.31697845458984, 1.522827386856079, 171.08180236816406) | Terminated: False |                Episode Length: 1.0300000000000007 | C_L: 1.0\n",
            "Action: [1.    0.524] | Reward: -1.415005882140924 |                 State: (-97.48843383789062, 1.5258394479751587, 171.38182067871094) | Terminated: False |                Episode Length: 1.0400000000000007 | C_L: 1.0\n",
            "Action: [1.    0.524] | Reward: -1.430157933641584 |                 State: (-97.66004180908203, 1.5288479328155518, 171.6818084716797) | Terminated: False |                Episode Length: 1.0500000000000007 | C_L: 1.0\n",
            "Action: [1.    0.524] | Reward: -1.4453335765540751 |                 State: (-97.8318099975586, 1.5318528413772583, 171.9818115234375) | Terminated: False |                Episode Length: 1.0600000000000007 | C_L: 1.0\n",
            "Action: [1.    0.524] | Reward: -1.4605326083830976 |                 State: (-98.00372314453125, 1.5348541736602783, 172.2818145751953) | Terminated: False |                Episode Length: 1.0700000000000007 | C_L: 1.0\n",
            "Action: [1.    0.524] | Reward: -1.4757548253406192 |                 State: (-98.17578887939453, 1.5378518104553223, 172.58180236816406) | Terminated: False |                Episode Length: 1.0800000000000007 | C_L: 1.0\n",
            "Action: [1.    0.524] | Reward: -1.4910000223625202 |                 State: (-98.3479995727539, 1.5408457517623901, 172.88180541992188) | Terminated: False |                Episode Length: 1.0900000000000007 | C_L: 1.0\n",
            "Action: [1.    0.524] | Reward: -1.506267993125622 |                 State: (-98.52034759521484, 1.5438358783721924, 173.1818084716797) | Terminated: False |                Episode Length: 1.1000000000000008 | C_L: 1.0\n",
            "Action: [1.    0.524] | Reward: -1.5215585300650967 |                 State: (-98.69283294677734, 1.546822428703308, 173.4818115234375) | Terminated: False |                Episode Length: 1.1100000000000008 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -1.5368714243922568 |                 State: (-98.8654556274414, 1.5498050451278687, 173.45452880859375) | Terminated: False |                Episode Length: 1.1200000000000008 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -1.5522064713658146 |                 State: (-99.03807067871094, 1.5527838468551636, 173.42726135253906) | Terminated: False |                Episode Length: 1.1300000000000008 | C_L: 1.0\n",
            "Action: [1.    0.524] | Reward: -1.5675634651783588 |                 State: (-99.21070861816406, 1.5557587146759033, 173.72726440429688) | Terminated: False |                Episode Length: 1.1400000000000008 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -1.5829421934178767 |                 State: (-99.38346099853516, 1.5587297677993774, 173.6999969482422) | Terminated: False |                Episode Length: 1.1500000000000008 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -1.5983424478933381 |                 State: (-99.55622863769531, 1.5616968870162964, 173.67271423339844) | Terminated: False |                Episode Length: 1.1600000000000008 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -1.6137640193515221 |                 State: (-99.72900390625, 1.5646600723266602, 173.64544677734375) | Terminated: False |                Episode Length: 1.1700000000000008 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -1.6292066974794128 |                 State: (-99.90178680419922, 1.5676192045211792, 173.6181640625) | Terminated: False |                Episode Length: 1.1800000000000008 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -1.6446702709066718 |                 State: (-100.0745849609375, 1.5705742835998535, 173.5908966064453) | Terminated: False |                Episode Length: 1.1900000000000008 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -1.6601545272081852 |                 State: (-100.24739837646484, 1.573525309562683, 173.56361389160156) | Terminated: False |                Episode Length: 1.2000000000000008 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -1.675659252906687 |                 State: (-100.42021942138672, 1.576472282409668, 173.53636169433594) | Terminated: False |                Episode Length: 1.2100000000000009 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -1.6911842334754572 |                 State: (-100.59305572509766, 1.5794150829315186, 173.5090789794922) | Terminated: False |                Episode Length: 1.2200000000000009 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -1.7067292533410985 |                 State: (-100.76589965820312, 1.5823537111282349, 173.4818115234375) | Terminated: False |                Episode Length: 1.2300000000000009 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -1.7222940958863864 |                 State: (-100.93876647949219, 1.5852880477905273, 173.45452880859375) | Terminated: False |                Episode Length: 1.2400000000000009 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -1.7378785434531983 |                 State: (-101.11163330078125, 1.5882182121276855, 173.42726135253906) | Terminated: False |                Episode Length: 1.2500000000000009 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -1.753482377345518 |                 State: (-101.28453826904297, 1.5911442041397095, 173.3999786376953) | Terminated: False |                Episode Length: 1.260000000000001 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -1.7691053778325179 |                 State: (-101.45744323730469, 1.59406578540802, 173.37271118164062) | Terminated: False |                Episode Length: 1.270000000000001 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -1.784747324151718 |                 State: (-101.63037109375, 1.5969830751419067, 173.345458984375) | Terminated: False |                Episode Length: 1.280000000000001 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -1.8004079945122227 |                 State: (-101.80331420898438, 1.59989595413208, 173.31817626953125) | Terminated: False |                Episode Length: 1.290000000000001 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -1.8160871660980349 |                 State: (-101.97628021240234, 1.6028045415878296, 173.29090881347656) | Terminated: False |                Episode Length: 1.300000000000001 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -1.8317846150714476 |                 State: (-102.14926147460938, 1.6057085990905762, 173.2636260986328) | Terminated: False |                Episode Length: 1.310000000000001 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -1.847500116576514 |                 State: (-102.32227325439453, 1.6086082458496094, 173.23635864257812) | Terminated: False |                Episode Length: 1.320000000000001 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -1.8632334447425947 |                 State: (-102.49530029296875, 1.61150324344635, 173.20907592773438) | Terminated: False |                Episode Length: 1.330000000000001 | C_L: 1.0\n",
            "Action: [1.    0.524] | Reward: -1.8789843726879851 |                 State: (-102.66834259033203, 1.6143938302993774, 173.5090789794922) | Terminated: False |                Episode Length: 1.340000000000001 | C_L: 1.0\n",
            "Action: [1.    0.524] | Reward: -1.8947526641171475 |                 State: (-102.841552734375, 1.6172798871994019, 173.80908203125) | Terminated: False |                Episode Length: 1.350000000000001 | C_L: 1.0\n",
            "Action: [1.    0.524] | Reward: -1.9105380816697317 |                 State: (-103.01490783691406, 1.6201612949371338, 174.1090850830078) | Terminated: False |                Episode Length: 1.360000000000001 | C_L: 1.0\n",
            "Action: [1.    0.524] | Reward: -1.9263403869437747 |                 State: (-103.18840789794922, 1.6230380535125732, 174.40907287597656) | Terminated: False |                Episode Length: 1.370000000000001 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -1.942159340519283 |                 State: (-103.362060546875, 1.6259101629257202, 174.38180541992188) | Terminated: False |                Episode Length: 1.380000000000001 | C_L: 1.0\n",
            "Action: [1.    0.524] | Reward: -1.957994709347678 |                 State: (-103.53572845458984, 1.6287776231765747, 174.6818084716797) | Terminated: False |                Episode Length: 1.390000000000001 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -1.9738462518594333 |                 State: (-103.70954895019531, 1.6316403150558472, 174.70909118652344) | Terminated: False |                Episode Length: 1.400000000000001 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -1.989713731511336 |                 State: (-103.8833999633789, 1.6344982385635376, 174.73635864257812) | Terminated: False |                Episode Length: 1.410000000000001 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -2.005596910710276 |                 State: (-104.05731201171875, 1.6373512744903564, 174.7636260986328) | Terminated: False |                Episode Length: 1.420000000000001 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -2.021495550817133 |                 State: (-104.23126220703125, 1.6401995420455933, 174.7908935546875) | Terminated: False |                Episode Length: 1.430000000000001 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -2.0374094121507498 |                 State: (-104.40525817871094, 1.6430429220199585, 174.81817626953125) | Terminated: False |                Episode Length: 1.440000000000001 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -2.0533382539919853 |                 State: (-104.57931518554688, 1.6458814144134521, 174.84544372558594) | Terminated: False |                Episode Length: 1.450000000000001 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -2.069281834587856 |                 State: (-104.75341796875, 1.6487150192260742, 174.8727264404297) | Terminated: False |                Episode Length: 1.460000000000001 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -2.08523991115576 |                 State: (-104.92756652832031, 1.6515436172485352, 174.89999389648438) | Terminated: False |                Episode Length: 1.470000000000001 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -2.101212239887785 |                 State: (-105.10176849365234, 1.654367208480835, 174.92726135253906) | Terminated: False |                Episode Length: 1.480000000000001 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -2.1171985759551037 |                 State: (-105.2760238647461, 1.657185673713684, 174.95452880859375) | Terminated: False |                Episode Length: 1.490000000000001 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -2.133198673512451 |                 State: (-105.45032501220703, 1.6599992513656616, 174.9818115234375) | Terminated: False |                Episode Length: 1.500000000000001 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -2.1492122857026876 |                 State: (-105.62467956542969, 1.662807583808899, 175.0090789794922) | Terminated: False |                Episode Length: 1.5100000000000011 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -2.1652391646614513 |                 State: (-105.7990951538086, 1.665610909461975, 175.03636169433594) | Terminated: False |                Episode Length: 1.5200000000000011 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -2.1812790615218876 |                 State: (-105.97355651855469, 1.668408989906311, 175.06362915039062) | Terminated: False |                Episode Length: 1.5300000000000011 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -2.1973317264194723 |                 State: (-106.14806365966797, 1.6712018251419067, 175.0908966064453) | Terminated: False |                Episode Length: 1.5400000000000011 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -2.213396908496915 |                 State: (-106.32263946533203, 1.6739895343780518, 175.11817932128906) | Terminated: False |                Episode Length: 1.5500000000000012 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -2.229474355909151 |                 State: (-106.49726867675781, 1.6767719984054565, 175.1454315185547) | Terminated: False |                Episode Length: 1.5600000000000012 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -2.245563815828418 |                 State: (-106.67194366455078, 1.6795490980148315, 175.17271423339844) | Terminated: False |                Episode Length: 1.5700000000000012 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -2.2616650344494165 |                 State: (-106.8466796875, 1.6823208332061768, 175.19998168945312) | Terminated: False |                Episode Length: 1.5800000000000012 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -2.2777777569945603 |                 State: (-107.0214614868164, 1.6850873231887817, 175.22726440429688) | Terminated: False |                Episode Length: 1.5900000000000012 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -2.2939017277193106 |                 State: (-107.1963119506836, 1.6878483295440674, 175.25453186035156) | Terminated: False |                Episode Length: 1.6000000000000012 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -2.3100366899175944 |                 State: (-107.3712158203125, 1.6906039714813232, 175.2818145751953) | Terminated: False |                Episode Length: 1.6100000000000012 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -2.326182385927313 |                 State: (-107.54617309570312, 1.6933541297912598, 175.30908203125) | Terminated: False |                Episode Length: 1.6200000000000012 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -2.342338557135933 |                 State: (-107.72119140625, 1.696098804473877, 175.3363494873047) | Terminated: False |                Episode Length: 1.6300000000000012 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -2.358504943986166 |                 State: (-107.89627075195312, 1.6988379955291748, 175.36361694335938) | Terminated: False |                Episode Length: 1.6400000000000012 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -2.374681285981732 |                 State: (-108.07139587402344, 1.7015715837478638, 175.39089965820312) | Terminated: False |                Episode Length: 1.6500000000000012 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -2.390867321693211 |                 State: (-108.24658966064453, 1.7042995691299438, 175.4181671142578) | Terminated: False |                Episode Length: 1.6600000000000013 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -2.40706278876398 |                 State: (-108.42183685302734, 1.707021951675415, 175.44544982910156) | Terminated: False |                Episode Length: 1.6700000000000013 | C_L: 1.0\n",
            "Action: [1.    0.143] | Reward: -2.4232674239162377 |                 State: (-108.59713745117188, 1.7097387313842773, 175.52725219726562) | Terminated: False |                Episode Length: 1.6800000000000013 | C_L: 1.0\n",
            "Action: [1.    0.524] | Reward: -2.439480961416861 |                 State: (-108.77252197265625, 1.7124497890472412, 175.8272705078125) | Terminated: False |                Episode Length: 1.6900000000000013 | C_L: 1.0\n",
            "Action: [1.    0.524] | Reward: -2.455703128673297 |                 State: (-108.94804382324219, 1.7151552438735962, 176.12725830078125) | Terminated: False |                Episode Length: 1.7000000000000013 | C_L: 1.0\n",
            "Action: [1.    0.524] | Reward: -2.471933652504448 |                 State: (-109.12369537353516, 1.7178548574447632, 176.42726135253906) | Terminated: False |                Episode Length: 1.7100000000000013 | C_L: 1.0\n",
            "Action: [1.    0.524] | Reward: -2.488172259172252 |                 State: (-109.29946899414062, 1.7205486297607422, 176.72726440429688) | Terminated: False |                Episode Length: 1.7200000000000013 | C_L: 1.0\n",
            "Action: [1.    0.524] | Reward: -2.5044186744136048 |                 State: (-109.4753646850586, 1.7232366800308228, 177.0272674560547) | Terminated: False |                Episode Length: 1.7300000000000013 | C_L: 1.0\n",
            "Action: [1.    0.524] | Reward: -2.5206726234726107 |                 State: (-109.65137481689453, 1.7259188890457153, 177.32725524902344) | Terminated: False |                Episode Length: 1.7400000000000013 | C_L: 1.0\n",
            "Action: [1.    0.524] | Reward: -2.5369338311331626 |                 State: (-109.8274917602539, 1.7285951375961304, 177.6272735595703) | Terminated: False |                Episode Length: 1.7500000000000013 | C_L: 1.0\n",
            "Action: [1.    0.524] | Reward: -2.553202021751842 |                 State: (-110.00370788574219, 1.7312655448913574, 177.92726135253906) | Terminated: False |                Episode Length: 1.7600000000000013 | C_L: 1.0\n",
            "Action: [1.    0.524] | Reward: -2.569476919291133 |                 State: (-110.1800308227539, 1.733929991722107, 178.22726440429688) | Terminated: False |                Episode Length: 1.7700000000000014 | C_L: 1.0\n",
            "Action: [1.    0.524] | Reward: -2.5857582473529495 |                 State: (-110.35643768310547, 1.736588478088379, 178.52725219726562) | Terminated: False |                Episode Length: 1.7800000000000014 | C_L: 1.0\n",
            "Action: [1.    0.524] | Reward: -2.6020457292124655 |                 State: (-110.53292846679688, 1.7392408847808838, 178.8272705078125) | Terminated: False |                Episode Length: 1.7900000000000014 | C_L: 1.0\n",
            "Action: [1.    0.524] | Reward: -2.6183390878522435 |                 State: (-110.70950317382812, 1.7418873310089111, 179.12725830078125) | Terminated: False |                Episode Length: 1.8000000000000014 | C_L: 1.0\n",
            "Action: [1.    0.524] | Reward: -2.634638045996655 |                 State: (-110.88616180419922, 1.7445276975631714, 179.42726135253906) | Terminated: False |                Episode Length: 1.8100000000000014 | C_L: 1.0\n",
            "Action: [1.    0.524] | Reward: -2.6509423261465908 |                 State: (-111.06288146972656, 1.7471619844436646, 179.72726440429688) | Terminated: False |                Episode Length: 1.8200000000000014 | C_L: 1.0\n",
            "Action: [1.    0.524] | Reward: -2.6672516506144457 |                 State: (-111.23966217041016, 1.749790072441101, 180.0272674560547) | Terminated: False |                Episode Length: 1.8300000000000014 | C_L: 1.0\n",
            "Action: [1.    0.524] | Reward: -2.683565741559383 |                 State: (-111.41650390625, 1.752411961555481, 180.32725524902344) | Terminated: False |                Episode Length: 1.8400000000000014 | C_L: 1.0\n",
            "Action: [1.    0.524] | Reward: -2.6998843210228625 |                 State: (-111.59339141845703, 1.7550277709960938, 180.6272735595703) | Terminated: False |                Episode Length: 1.8500000000000014 | C_L: 1.0\n",
            "Action: [1.    0.524] | Reward: -2.716207110964431 |                 State: (-111.77033233642578, 1.7576372623443604, 180.92726135253906) | Terminated: False |                Episode Length: 1.8600000000000014 | C_L: 1.0\n",
            "Action: [1.    0.524] | Reward: -2.7325338332977673 |                 State: (-111.94730377197266, 1.7602405548095703, 181.22726440429688) | Terminated: False |                Episode Length: 1.8700000000000014 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -2.748864209926974 |                 State: (-112.12432098388672, 1.7628374099731445, 181.25453186035156) | Terminated: False |                Episode Length: 1.8800000000000014 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -2.7651979597966876 |                 State: (-112.30138397216797, 1.765428066253662, 181.28179931640625) | Terminated: False |                Episode Length: 1.8900000000000015 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -2.7815348011159116 |                 State: (-112.47850036621094, 1.7680124044418335, 181.30908203125) | Terminated: False |                Episode Length: 1.9000000000000015 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -2.79787445136622 |                 State: (-112.65567016601562, 1.7705903053283691, 181.3363494873047) | Terminated: False |                Episode Length: 1.9100000000000015 | C_L: 1.0\n",
            "Action: [1.    0.524] | Reward: -2.814216627310047 |                 State: (-112.83290100097656, 1.773161768913269, 181.6363525390625) | Terminated: False |                Episode Length: 1.9200000000000015 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -2.830561048355436 |                 State: (-113.0101547241211, 1.7757267951965332, 181.6636199951172) | Terminated: False |                Episode Length: 1.9300000000000015 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -2.846907429976822 |                 State: (-113.18745422363281, 1.7782853841781616, 181.69090270996094) | Terminated: False |                Episode Length: 1.9400000000000015 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -2.863255486956758 |                 State: (-113.36481475830078, 1.7808374166488647, 181.71817016601562) | Terminated: False |                Episode Length: 1.9500000000000015 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -2.8796049333945293 |                 State: (-113.54222869873047, 1.7833828926086426, 181.74545288085938) | Terminated: False |                Episode Length: 1.9600000000000015 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -2.895955482714844 |                 State: (-113.71969604492188, 1.7859219312667847, 181.77272033691406) | Terminated: False |                Episode Length: 1.9700000000000015 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -2.912306847676606 |                 State: (-113.897216796875, 1.788454294204712, 181.8000030517578) | Terminated: False |                Episode Length: 1.9800000000000015 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -2.928658740381763 |                 State: (-114.07479095458984, 1.7909799814224243, 181.82725524902344) | Terminated: False |                Episode Length: 1.9900000000000015 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -2.9450108722842367 |                 State: (-114.25241088867188, 1.7934989929199219, 181.8545379638672) | Terminated: False |                Episode Length: 2.0000000000000013 | C_L: 1.0\n",
            "Action: [ 1.    -0.524] | Reward: -2.961362954198928 |                 State: (-114.43009948730469, 1.7960114479064941, 181.55453491210938) | Terminated: False |                Episode Length: 2.010000000000001 | C_L: 1.0\n",
            "Action: [ 1.    -0.524] | Reward: -2.977714691269174 |                 State: (-114.60787963867188, 1.798517107963562, 181.25453186035156) | Terminated: False |                Episode Length: 2.020000000000001 | C_L: 1.0\n",
            "Action: [ 1.    -0.524] | Reward: -2.9940657886876125 |                 State: (-114.78573608398438, 1.8010159730911255, 180.9545440673828) | Terminated: False |                Episode Length: 2.0300000000000007 | C_L: 1.0\n",
            "Action: [ 1.    -0.524] | Reward: -3.010415951734592 |                 State: (-114.96367645263672, 1.8035080432891846, 180.65452575683594) | Terminated: False |                Episode Length: 2.0400000000000005 | C_L: 1.0\n",
            "Action: [ 1.    -0.524] | Reward: -3.0267648858168226 |                 State: (-115.14168548583984, 1.8059934377670288, 180.3545379638672) | Terminated: False |                Episode Length: 2.0500000000000003 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -3.0431122965062527 |                 State: (-115.31976318359375, 1.808471918106079, 180.38180541992188) | Terminated: False |                Episode Length: 2.06 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -3.0594578902503105 |                 State: (-115.4979019165039, 1.8109434843063354, 180.40908813476562) | Terminated: False |                Episode Length: 2.07 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -3.0758013729111005 |                 State: (-115.67610168457031, 1.8134081363677979, 180.4363555908203) | Terminated: False |                Episode Length: 2.0799999999999996 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -3.092142449775005 |                 State: (-115.8543472290039, 1.8158659934997559, 180.463623046875) | Terminated: False |                Episode Length: 2.0899999999999994 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -3.10848082556236 |                 State: (-116.03265380859375, 1.8183166980743408, 180.4908905029297) | Terminated: False |                Episode Length: 2.099999999999999 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -3.1248162044372028 |                 State: (-116.21102142333984, 1.8207606077194214, 180.51817321777344) | Terminated: False |                Episode Length: 2.109999999999999 | C_L: 1.0\n",
            "Action: [ 1.    -0.524] | Reward: -3.1411482900171013 |                 State: (-116.38945007324219, 1.823197364807129, 180.21817016601562) | Terminated: False |                Episode Length: 2.1199999999999988 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -3.157476784142873 |                 State: (-116.56792449951172, 1.825627088546753, 180.2454376220703) | Terminated: False |                Episode Length: 2.1299999999999986 | C_L: 1.0\n",
            "Action: [ 1.    -0.524] | Reward: -3.173801389259143 |                 State: (-116.74647521972656, 1.8280497789382935, 179.94544982910156) | Terminated: False |                Episode Length: 2.1399999999999983 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -3.190121806931055 |                 State: (-116.9250717163086, 1.830465316772461, 179.97271728515625) | Terminated: False |                Episode Length: 2.149999999999998 | C_L: 1.0\n",
            "Action: [ 1.    -0.524] | Reward: -3.206437738478889 |                 State: (-117.1037368774414, 1.8328737020492554, 179.67271423339844) | Terminated: False |                Episode Length: 2.159999999999998 | C_L: 1.0\n",
            "Action: [1.    0.333] | Reward: -3.2227488852726434 |                 State: (-117.28244018554688, 1.8352749347686768, 179.86361694335938) | Terminated: False |                Episode Length: 2.1699999999999977 | C_L: 1.0\n",
            "Action: [1.    0.333] | Reward: -3.2390549471873546 |                 State: (-117.46121215820312, 1.837669014930725, 180.05453491210938) | Terminated: False |                Episode Length: 2.1799999999999975 | C_L: 1.0\n",
            "Action: [1.    0.333] | Reward: -3.2553556239798835 |                 State: (-117.64004516601562, 1.8400558233261108, 180.2454376220703) | Terminated: False |                Episode Length: 2.1899999999999973 | C_L: 1.0\n",
            "Action: [1.    0.333] | Reward: -3.271650615311583 |                 State: (-117.81893920898438, 1.842435359954834, 180.4363555908203) | Terminated: False |                Episode Length: 2.199999999999997 | C_L: 1.0\n",
            "Action: [1.    0.333] | Reward: -3.2879396207710814 |                 State: (-117.99787902832031, 1.8448076248168945, 180.6272735595703) | Terminated: False |                Episode Length: 2.209999999999997 | C_L: 1.0\n",
            "Action: [1.    0.333] | Reward: -3.304222339897177 |                 State: (-118.1768569946289, 1.8471726179122925, 180.81817626953125) | Terminated: False |                Episode Length: 2.2199999999999966 | C_L: 1.0\n",
            "Action: [1.    0.333] | Reward: -3.320498472201847 |                 State: (-118.35588836669922, 1.8495302200317383, 181.00909423828125) | Terminated: False |                Episode Length: 2.2299999999999964 | C_L: 1.0\n",
            "Action: [ 1.    -0.524] | Reward: -3.336767717193361 |                 State: (-118.53497314453125, 1.8518805503845215, 180.70907592773438) | Terminated: False |                Episode Length: 2.239999999999996 | C_L: 1.0\n",
            "Action: [ 1.    -0.524] | Reward: -3.353029769245937 |                 State: (-118.7141342163086, 1.854223370552063, 180.40908813476562) | Terminated: False |                Episode Length: 2.249999999999996 | C_L: 1.0\n",
            "Action: [1.    0.333] | Reward: -3.3692843232496665 |                 State: (-118.89334106445312, 1.8565587997436523, 180.59999084472656) | Terminated: False |                Episode Length: 2.259999999999996 | C_L: 1.0\n",
            "Action: [ 1.    -0.524] | Reward: -3.385531076598317 |                 State: (-119.07262420654297, 1.85888671875, 180.29998779296875) | Terminated: False |                Episode Length: 2.2699999999999956 | C_L: 1.0\n",
            "Action: [1.    0.333] | Reward: -3.401769723709023 |                 State: (-119.251953125, 1.8612072467803955, 180.4908905029297) | Terminated: False |                Episode Length: 2.2799999999999954 | C_L: 1.0\n",
            "Action: [ 1.    -0.524] | Reward: -3.417999960972001 |                 State: (-119.43134307861328, 1.8635201454162598, 180.19090270996094) | Terminated: False |                Episode Length: 2.289999999999995 | C_L: 1.0\n",
            "Action: [ 1.    -0.524] | Reward: -3.4342214823882036 |                 State: (-119.61080169677734, 1.8658255338668823, 179.89089965820312) | Terminated: False |                Episode Length: 2.299999999999995 | C_L: 1.0\n",
            "Action: [1.    0.333] | Reward: -3.4504339826091193 |                 State: (-119.79029846191406, 1.8681234121322632, 180.08180236816406) | Terminated: False |                Episode Length: 2.3099999999999947 | C_L: 1.0\n",
            "Action: [ 1.    -0.524] | Reward: -3.466637156044582 |                 State: (-119.96986389160156, 1.8704136610031128, 179.7818145751953) | Terminated: False |                Episode Length: 2.3199999999999945 | C_L: 1.0\n",
            "Action: [1.    0.333] | Reward: -3.482830697034214 |                 State: (-120.14948272705078, 1.8726962804794312, 179.97271728515625) | Terminated: False |                Episode Length: 2.3299999999999943 | C_L: 1.0\n",
            "Action: [ 1.    -0.524] | Reward: -3.499014299075337 |                 State: (-120.32915496826172, 1.8749712705612183, 179.67271423339844) | Terminated: False |                Episode Length: 2.339999999999994 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -3.515187656254021 |                 State: (-120.50887298583984, 1.8772385120391846, 179.64544677734375) | Terminated: False |                Episode Length: 2.349999999999994 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -3.531350461836862 |                 State: (-120.68865966796875, 1.8794981241226196, 179.61817932128906) | Terminated: False |                Episode Length: 2.3599999999999937 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -3.54750240880656 |                 State: (-120.86849975585938, 1.8817499876022339, 179.5908966064453) | Terminated: False |                Episode Length: 2.3699999999999934 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -3.5636431898734986 |                 State: (-121.04837799072266, 1.8839939832687378, 179.56362915039062) | Terminated: False |                Episode Length: 2.3799999999999932 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -3.5797724974873826 |                 State: (-121.22832489013672, 1.8862303495407104, 179.53634643554688) | Terminated: False |                Episode Length: 2.389999999999993 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -3.5958900238489337 |                 State: (-121.40830993652344, 1.8884587287902832, 179.5090789794922) | Terminated: False |                Episode Length: 2.399999999999993 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -3.6119954609216465 |                 State: (-121.5883560180664, 1.8906793594360352, 179.48179626464844) | Terminated: False |                Episode Length: 2.4099999999999926 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -3.628088500443599 |                 State: (-121.7684555053711, 1.8928921222686768, 179.45452880859375) | Terminated: False |                Episode Length: 2.4199999999999924 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -3.644168833939322 |                 State: (-121.9486083984375, 1.8950968980789185, 179.42726135253906) | Terminated: False |                Episode Length: 2.429999999999992 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -3.660236152731724 |                 State: (-122.12881469726562, 1.8972938060760498, 179.39999389648438) | Terminated: False |                Episode Length: 2.439999999999992 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -3.67629014795407 |                 State: (-122.30906677246094, 1.8994827270507812, 179.37271118164062) | Terminated: False |                Episode Length: 2.4499999999999917 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -3.692330510562016 |                 State: (-122.48936462402344, 1.9016636610031128, 179.34544372558594) | Terminated: False |                Episode Length: 2.4599999999999915 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -3.708356931345696 |                 State: (-122.66972351074219, 1.9038366079330444, 179.31817626953125) | Terminated: False |                Episode Length: 2.4699999999999913 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -3.7243691009418636 |                 State: (-122.85013580322266, 1.9060015678405762, 179.2908935546875) | Terminated: False |                Episode Length: 2.479999999999991 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -3.740366709846083 |                 State: (-123.03060913085938, 1.9081584215164185, 179.2636260986328) | Terminated: False |                Episode Length: 2.489999999999991 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -3.7563494484249733 |                 State: (-123.21111297607422, 1.9103071689605713, 179.23635864257812) | Terminated: False |                Episode Length: 2.4999999999999907 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -3.7723170069285015 |                 State: (-123.39166259765625, 1.9124478101730347, 179.20909118652344) | Terminated: False |                Episode Length: 2.5099999999999905 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -3.7882690755023267 |                 State: (-123.57228088378906, 1.914580225944519, 179.1818084716797) | Terminated: False |                Episode Length: 2.5199999999999902 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -3.804205344200192 |                 State: (-123.75293731689453, 1.916704535484314, 179.154541015625) | Terminated: False |                Episode Length: 2.52999999999999 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -3.8201255029963637 |                 State: (-123.93363952636719, 1.9188207387924194, 179.12725830078125) | Terminated: False |                Episode Length: 2.53999999999999 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -3.836029241798119 |                 State: (-124.11441040039062, 1.9209285974502563, 179.09999084472656) | Terminated: False |                Episode Length: 2.5499999999999896 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -3.8519162504582796 |                 State: (-124.29520416259766, 1.9230282306671143, 179.0727081298828) | Terminated: False |                Episode Length: 2.5599999999999894 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -3.867786218787787 |                 State: (-124.47606658935547, 1.9251196384429932, 179.0454559326172) | Terminated: False |                Episode Length: 2.569999999999989 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -3.883638836568329 |                 State: (-124.6569595336914, 1.9272027015686035, 179.01817321777344) | Terminated: False |                Episode Length: 2.579999999999989 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -3.8994737935650035 |                 State: (-124.83789825439453, 1.9292774200439453, 178.99090576171875) | Terminated: False |                Episode Length: 2.5899999999999888 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -3.9152907795390273 |                 State: (-125.0188980102539, 1.9313437938690186, 178.963623046875) | Terminated: False |                Episode Length: 2.5999999999999885 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -3.931089484260488 |                 State: (-125.19994354248047, 1.9334018230438232, 178.9363555908203) | Terminated: False |                Episode Length: 2.6099999999999883 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -3.9468695975211348 |                 State: (-125.38102722167969, 1.9354513883590698, 178.90907287597656) | Terminated: False |                Episode Length: 2.619999999999988 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -3.9626308091472078 |                 State: (-125.56216430664062, 1.9374926090240479, 178.88180541992188) | Terminated: False |                Episode Length: 2.629999999999988 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -3.978372809012311 |                 State: (-125.74333953857422, 1.9395253658294678, 178.8545379638672) | Terminated: False |                Episode Length: 2.6399999999999877 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -3.9940952870503192 |                 State: (-125.924560546875, 1.9415496587753296, 178.8272705078125) | Terminated: False |                Episode Length: 2.6499999999999875 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -4.009797933268323 |                 State: (-126.10581970214844, 1.9435653686523438, 178.79998779296875) | Terminated: False |                Episode Length: 2.6599999999999873 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -4.02548043775961 |                 State: (-126.2871322631836, 1.9455726146697998, 178.77272033691406) | Terminated: False |                Episode Length: 2.669999999999987 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -4.041142490716683 |                 State: (-126.4684829711914, 1.9475712776184082, 178.7454376220703) | Terminated: False |                Episode Length: 2.679999999999987 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -4.05678378244431 |                 State: (-126.6498794555664, 1.949561357498169, 178.71817016601562) | Terminated: False |                Episode Length: 2.6899999999999866 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -4.072404003372606 |                 State: (-126.8313217163086, 1.951542854309082, 178.69088745117188) | Terminated: False |                Episode Length: 2.6999999999999864 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -4.088002844070155 |                 State: (-127.01280975341797, 1.9535157680511475, 178.66363525390625) | Terminated: False |                Episode Length: 2.709999999999986 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -4.103579995257151 |                 State: (-127.19432830810547, 1.9554799795150757, 178.6363525390625) | Terminated: False |                Episode Length: 2.719999999999986 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -4.119135147818583 |                 State: (-127.37589263916016, 1.9574354887008667, 178.6090850830078) | Terminated: False |                Episode Length: 2.7299999999999858 | C_L: 1.0\n",
            "Action: [1.    0.238] | Reward: -4.1346679928174375 |                 State: (-127.55750274658203, 1.9593822956085205, 178.7454376220703) | Terminated: False |                Episode Length: 2.7399999999999856 | C_L: 1.0\n",
            "Action: [1.    0.238] | Reward: -4.150178218079074 |                 State: (-127.7391586303711, 1.961320400238037, 178.88180541992188) | Terminated: False |                Episode Length: 2.7499999999999853 | C_L: 1.0\n",
            "Action: [1.    0.238] | Reward: -4.165665511855883 |                 State: (-127.92088317871094, 1.9632498025894165, 179.01817321777344) | Terminated: False |                Episode Length: 2.759999999999985 | C_L: 1.0\n",
            "Action: [1.    0.238] | Reward: -4.181129562847184 |                 State: (-128.10264587402344, 1.9651703834533691, 179.154541015625) | Terminated: False |                Episode Length: 2.769999999999985 | C_L: 1.0\n",
            "Action: [1.    0.238] | Reward: -4.19657006021917 |                 State: (-128.28448486328125, 1.9670822620391846, 179.2908935546875) | Terminated: False |                Episode Length: 2.7799999999999847 | C_L: 1.0\n",
            "Action: [1.    0.428] | Reward: -4.21198669362485 |                 State: (-128.4663543701172, 1.9689851999282837, 179.53634643554688) | Terminated: False |                Episode Length: 2.7899999999999845 | C_L: 1.0\n",
            "Action: [1.    0.428] | Reward: -4.227379152310669 |                 State: (-128.6482696533203, 1.970879316329956, 179.7818145751953) | Terminated: False |                Episode Length: 2.7999999999999843 | C_L: 1.0\n",
            "Action: [1.    0.238] | Reward: -4.242747126711566 |                 State: (-128.8302459716797, 1.9727646112442017, 179.9181671142578) | Terminated: False |                Episode Length: 2.809999999999984 | C_L: 1.0\n",
            "Action: [1.    0.238] | Reward: -4.25809030853487 |                 State: (-129.01226806640625, 1.9746410846710205, 180.05453491210938) | Terminated: False |                Episode Length: 2.819999999999984 | C_L: 1.0\n",
            "Action: [1.    0.238] | Reward: -4.273408390062784 |                 State: (-129.19432067871094, 1.9765084981918335, 180.19090270996094) | Terminated: False |                Episode Length: 2.8299999999999836 | C_L: 1.0\n",
            "Action: [1.    0.238] | Reward: -4.288701064172398 |                 State: (-129.3764190673828, 1.9783670902252197, 180.32725524902344) | Terminated: False |                Episode Length: 2.8399999999999834 | C_L: 1.0\n",
            "Action: [1.    0.238] | Reward: -4.3039680243557035 |                 State: (-129.55853271484375, 1.9802166223526, 180.463623046875) | Terminated: False |                Episode Length: 2.849999999999983 | C_L: 1.0\n",
            "Action: [1.    0.238] | Reward: -4.319208964739615 |                 State: (-129.74070739746094, 1.9820572137832642, 180.59999084472656) | Terminated: False |                Episode Length: 2.859999999999983 | C_L: 1.0\n",
            "Action: [1.    0.238] | Reward: -4.334423580105989 |                 State: (-129.9228973388672, 1.983888864517212, 180.73635864257812) | Terminated: False |                Episode Length: 2.869999999999983 | C_L: 1.0\n",
            "Action: [1.    0.238] | Reward: -4.349611565911646 |                 State: (-130.10511779785156, 1.9857113361358643, 180.87271118164062) | Terminated: False |                Episode Length: 2.8799999999999826 | C_L: 1.0\n",
            "Action: [1.    0.238] | Reward: -4.3647726183083835 |                 State: (-130.28738403320312, 1.9875248670578003, 181.00909423828125) | Terminated: False |                Episode Length: 2.8899999999999824 | C_L: 1.0\n",
            "Action: [1.    0.238] | Reward: -4.379906434162987 |                 State: (-130.46966552734375, 1.9893293380737305, 181.14544677734375) | Terminated: False |                Episode Length: 2.899999999999982 | C_L: 1.0\n",
            "Action: [ 1.    -0.524] | Reward: -4.39501271107723 |                 State: (-130.6519775390625, 1.9911246299743652, 180.84544372558594) | Terminated: False |                Episode Length: 2.909999999999982 | C_L: 1.0\n",
            "Action: [1.    0.238] | Reward: -4.410091139379743 |                 State: (-130.83433532714844, 1.9929108619689941, 180.9818115234375) | Terminated: False |                Episode Length: 2.9199999999999817 | C_L: 1.0\n",
            "Action: [1.    0.238] | Reward: -4.425141417086903 |                 State: (-131.01673889160156, 1.9946880340576172, 181.1181640625) | Terminated: False |                Episode Length: 2.9299999999999815 | C_L: 1.0\n",
            "Action: [1.    0.238] | Reward: -4.440163242994363 |                 State: (-131.1991424560547, 1.9964559078216553, 181.25453186035156) | Terminated: False |                Episode Length: 2.9399999999999813 | C_L: 1.0\n",
            "Action: [1.    0.238] | Reward: -4.455156316697055 |                 State: (-131.381591796875, 1.9982147216796875, 181.39089965820312) | Terminated: False |                Episode Length: 2.949999999999981 | C_L: 1.0\n",
            "Action: [1.    0.238] | Reward: -4.470120338609165 |                 State: (-131.56405639648438, 1.9999642372131348, 181.5272674560547) | Terminated: False |                Episode Length: 2.959999999999981 | C_L: 1.0\n",
            "Action: [1.    0.238] | Reward: -4.485055009984102 |                 State: (-131.74652099609375, 2.001704692840576, 181.6636199951172) | Terminated: False |                Episode Length: 2.9699999999999807 | C_L: 1.0\n",
            "Action: [1.    0.238] | Reward: -4.499960032934423 |                 State: (-131.92901611328125, 2.0034356117248535, 181.8000030517578) | Terminated: False |                Episode Length: 2.9799999999999804 | C_L: 1.0\n",
            "Action: [1.    0.238] | Reward: -4.514835110451747 |                 State: (-132.1115264892578, 2.005157470703125, 181.9363555908203) | Terminated: False |                Episode Length: 2.9899999999999802 | C_L: 1.0\n",
            "Action: [1.    0.238] | Reward: -4.529679946426629 |                 State: (-132.29405212402344, 2.0068700313568115, 182.0727081298828) | Terminated: False |                Episode Length: 2.99999999999998 | C_L: 1.0\n",
            "Action: [1.    0.238] | Reward: -4.544494245668409 |                 State: (-132.47657775878906, 2.008573293685913, 182.20907592773438) | Terminated: False |                Episode Length: 3.00999999999998 | C_L: 1.0\n",
            "Action: [1.    0.238] | Reward: -4.55927771392502 |                 State: (-132.65911865234375, 2.0102672576904297, 182.34544372558594) | Terminated: False |                Episode Length: 3.0199999999999796 | C_L: 1.0\n",
            "Action: [1.    0.238] | Reward: -4.574030057902761 |                 State: (-132.84165954589844, 2.0119516849517822, 182.4818115234375) | Terminated: False |                Episode Length: 3.0299999999999794 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -4.588750985286032 |                 State: (-133.02423095703125, 2.01362681388855, 182.45452880859375) | Terminated: False |                Episode Length: 3.039999999999979 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -4.6034401970720555 |                 State: (-133.20680236816406, 2.0152926445007324, 182.42726135253906) | Terminated: False |                Episode Length: 3.049999999999979 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -4.61809739483371 |                 State: (-133.38941955566406, 2.01694917678833, 182.39999389648438) | Terminated: False |                Episode Length: 3.0599999999999787 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -4.632722280733244 |                 State: (-133.5720672607422, 2.0185961723327637, 182.3727264404297) | Terminated: False |                Episode Length: 3.0699999999999785 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -4.647314557535973 |                 State: (-133.7547607421875, 2.020233631134033, 182.34544372558594) | Terminated: False |                Episode Length: 3.0799999999999783 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -4.661873928623979 |                 State: (-133.93748474121094, 2.0218617916107178, 182.31817626953125) | Terminated: False |                Episode Length: 3.089999999999978 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -4.676400098009809 |                 State: (-134.1202392578125, 2.0234804153442383, 182.2908935546875) | Terminated: False |                Episode Length: 3.099999999999978 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -4.690892770350157 |                 State: (-134.30300903320312, 2.0250895023345947, 182.2636260986328) | Terminated: False |                Episode Length: 3.1099999999999777 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -4.705351650959547 |                 State: (-134.48582458496094, 2.026689052581787, 182.23634338378906) | Terminated: False |                Episode Length: 3.1199999999999775 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -4.719776445824005 |                 State: (-134.6686553955078, 2.0282790660858154, 182.20907592773438) | Terminated: False |                Episode Length: 3.1299999999999772 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -4.734166861614718 |                 State: (-134.85153198242188, 2.0298595428466797, 182.1818084716797) | Terminated: False |                Episode Length: 3.139999999999977 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -4.74852260570169 |                 State: (-135.034423828125, 2.03143048286438, 182.154541015625) | Terminated: False |                Episode Length: 3.149999999999977 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -4.762843386167375 |                 State: (-135.21737670898438, 2.032991647720337, 182.12725830078125) | Terminated: False |                Episode Length: 3.1599999999999766 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -4.777128911820305 |                 State: (-135.40032958984375, 2.03454327583313, 182.09999084472656) | Terminated: False |                Episode Length: 3.1699999999999764 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -4.791378892208703 |                 State: (-135.5832977294922, 2.036085367202759, 182.0727081298828) | Terminated: False |                Episode Length: 3.179999999999976 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -4.805593037634076 |                 State: (-135.7663116455078, 2.0376176834106445, 182.04544067382812) | Terminated: False |                Episode Length: 3.189999999999976 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -4.819771059164793 |                 State: (-135.9493408203125, 2.039140462875366, 182.01817321777344) | Terminated: False |                Episode Length: 3.1999999999999758 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -4.833912668649649 |                 State: (-136.1324005126953, 2.0406534671783447, 181.99090576171875) | Terminated: False |                Episode Length: 3.2099999999999755 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -4.848017578731402 |                 State: (-136.3154754638672, 2.04215669631958, 181.963623046875) | Terminated: False |                Episode Length: 3.2199999999999753 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -4.862085502860297 |                 State: (-136.4985809326172, 2.0436501502990723, 181.9363555908203) | Terminated: False |                Episode Length: 3.229999999999975 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -4.8761161553075665 |                 State: (-136.68170166015625, 2.0451340675354004, 181.90907287597656) | Terminated: False |                Episode Length: 3.239999999999975 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -4.890109251178906 |                 State: (-136.8648681640625, 2.0466079711914062, 181.88180541992188) | Terminated: False |                Episode Length: 3.2499999999999747 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -4.904064506427926 |                 State: (-137.04803466796875, 2.048072338104248, 181.8545379638672) | Terminated: False |                Episode Length: 3.2599999999999745 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -4.917981637869583 |                 State: (-137.23123168945312, 2.0495266914367676, 181.82725524902344) | Terminated: False |                Episode Length: 3.2699999999999743 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -4.931860363193579 |                 State: (-137.41444396972656, 2.050971269607544, 181.8000030517578) | Terminated: False |                Episode Length: 3.279999999999974 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -4.945700400977736 |                 State: (-137.59767150878906, 2.052406072616577, 181.77272033691406) | Terminated: False |                Episode Length: 3.289999999999974 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -4.959501470701345 |                 State: (-137.78091430664062, 2.053831100463867, 181.74545288085938) | Terminated: False |                Episode Length: 3.2999999999999736 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -4.973263292758479 |                 State: (-137.9641876220703, 2.055246114730835, 181.77272033691406) | Terminated: False |                Episode Length: 3.3099999999999734 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -4.986985590469388 |                 State: (-138.1474609375, 2.0566511154174805, 181.8000030517578) | Terminated: False |                Episode Length: 3.319999999999973 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -5.0006680881195935 |                 State: (-138.33074951171875, 2.058046579360962, 181.82725524902344) | Terminated: False |                Episode Length: 3.329999999999973 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -5.014310510972952 |                 State: (-138.51405334472656, 2.059431791305542, 181.8545379638672) | Terminated: False |                Episode Length: 3.3399999999999728 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -5.027912585284676 |                 State: (-138.69735717773438, 2.060807228088379, 181.88180541992188) | Terminated: False |                Episode Length: 3.3499999999999726 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -5.041474038314325 |                 State: (-138.88067626953125, 2.0621726512908936, 181.90907287597656) | Terminated: False |                Episode Length: 3.3599999999999723 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -5.054994598338743 |                 State: (-139.06398010253906, 2.063528060913086, 181.9363555908203) | Terminated: False |                Episode Length: 3.369999999999972 | C_L: 1.0\n",
            "Action: [ 1.    -0.524] | Reward: -5.068473994664969 |                 State: (-139.24729919433594, 2.064873695373535, 181.6363525390625) | Terminated: False |                Episode Length: 3.379999999999972 | C_L: 1.0\n",
            "Action: [ 1.    -0.524] | Reward: -5.081911944917106 |                 State: (-139.43067932128906, 2.066209077835083, 181.3363494873047) | Terminated: False |                Episode Length: 3.3899999999999717 | C_L: 1.0\n",
            "Action: [ 1.    -0.524] | Reward: -5.095308169565211 |                 State: (-139.61410522460938, 2.0675346851348877, 181.03634643554688) | Terminated: False |                Episode Length: 3.3999999999999715 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -5.108662391969082 |                 State: (-139.7975616455078, 2.068850040435791, 181.06361389160156) | Terminated: False |                Episode Length: 3.4099999999999713 | C_L: 1.0\n",
            "Action: [ 1.    -0.524] | Reward: -5.121974344862185 |                 State: (-139.98101806640625, 2.070155382156372, 180.7636260986328) | Terminated: False |                Episode Length: 3.419999999999971 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -5.135243755405379 |                 State: (-140.1645050048828, 2.071450710296631, 180.79090881347656) | Terminated: False |                Episode Length: 3.429999999999971 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -5.148470358278541 |                 State: (-140.34800720214844, 2.0727360248565674, 180.81817626953125) | Terminated: False |                Episode Length: 3.4399999999999706 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -5.161653889274241 |                 State: (-140.53150939941406, 2.0740110874176025, 180.84544372558594) | Terminated: False |                Episode Length: 3.4499999999999704 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -5.174794085310372 |                 State: (-140.71499633789062, 2.0752761363983154, 180.87271118164062) | Terminated: False |                Episode Length: 3.45999999999997 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -5.187890684442723 |                 State: (-140.89849853515625, 2.076530933380127, 180.89999389648438) | Terminated: False |                Episode Length: 3.46999999999997 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -5.200943425877502 |                 State: (-141.08200073242188, 2.077775716781616, 180.92726135253906) | Terminated: False |                Episode Length: 3.47999999999997 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -5.213952049983806 |                 State: (-141.2655029296875, 2.079010486602783, 180.9545440673828) | Terminated: False |                Episode Length: 3.4899999999999696 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -5.226916298306043 |                 State: (-141.44900512695312, 2.0802347660064697, 180.9818115234375) | Terminated: False |                Episode Length: 3.4999999999999694 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -5.239835913576287 |                 State: (-141.63250732421875, 2.081449031829834, 181.00909423828125) | Terminated: False |                Episode Length: 3.509999999999969 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -5.252710639726586 |                 State: (-141.81600952148438, 2.082653045654297, 181.03634643554688) | Terminated: False |                Episode Length: 3.519999999999969 | C_L: 1.0\n",
            "Action: [ 1.    -0.524] | Reward: -5.265540221901212 |                 State: (-141.99949645996094, 2.0838470458984375, 180.73635864257812) | Terminated: False |                Episode Length: 3.5299999999999687 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -5.278324399729125 |                 State: (-142.1830291748047, 2.0850305557250977, 180.7636260986328) | Terminated: False |                Episode Length: 3.5399999999999685 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -5.291062920565764 |                 State: (-142.36654663085938, 2.0862040519714355, 180.79090881347656) | Terminated: False |                Episode Length: 3.5499999999999683 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -5.303755533013457 |                 State: (-142.550048828125, 2.087367057800293, 180.81817626953125) | Terminated: False |                Episode Length: 3.559999999999968 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -5.316401986933448 |                 State: (-142.73355102539062, 2.088520050048828, 180.84544372558594) | Terminated: False |                Episode Length: 3.569999999999968 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -5.32900203345787 |                 State: (-142.91705322265625, 2.089662551879883, 180.87271118164062) | Terminated: False |                Episode Length: 3.5799999999999677 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -5.341555425001649 |                 State: (-143.10055541992188, 2.0907950401306152, 180.89999389648438) | Terminated: False |                Episode Length: 3.5899999999999674 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -5.3540619152743405 |                 State: (-143.28404235839844, 2.091917037963867, 180.92726135253906) | Terminated: False |                Episode Length: 3.5999999999999672 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -5.3665212592919085 |                 State: (-143.467529296875, 2.0930285453796387, 180.9545440673828) | Terminated: False |                Episode Length: 3.609999999999967 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -5.378933213388429 |                 State: (-143.6510009765625, 2.094130039215088, 180.9818115234375) | Terminated: False |                Episode Length: 3.619999999999967 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -5.391297535227731 |                 State: (-143.83445739746094, 2.0952210426330566, 181.00909423828125) | Terminated: False |                Episode Length: 3.6299999999999666 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -5.403613983814968 |                 State: (-144.0178985595703, 2.096301794052124, 181.03634643554688) | Terminated: False |                Episode Length: 3.6399999999999664 | C_L: 1.0\n",
            "Action: [ 1.    -0.524] | Reward: -5.415882319508115 |                 State: (-144.20135498046875, 2.097372055053711, 180.73635864257812) | Terminated: False |                Episode Length: 3.649999999999966 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -5.428102297003799 |                 State: (-144.3848114013672, 2.0984320640563965, 180.7636260986328) | Terminated: False |                Episode Length: 3.659999999999966 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -5.440273679143574 |                 State: (-144.5682373046875, 2.0994815826416016, 180.79090881347656) | Terminated: False |                Episode Length: 3.6699999999999657 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -5.452396230154298 |                 State: (-144.75167846679688, 2.1005208492279053, 180.81817626953125) | Terminated: False |                Episode Length: 3.6799999999999655 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -5.464469715659372 |                 State: (-144.93508911132812, 2.1015496253967285, 180.84544372558594) | Terminated: False |                Episode Length: 3.6899999999999653 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -5.476493902689899 |                 State: (-145.11849975585938, 2.1025679111480713, 180.87271118164062) | Terminated: False |                Episode Length: 3.699999999999965 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -5.488468559695767 |                 State: (-145.3018798828125, 2.1035759449005127, 180.89999389648438) | Terminated: False |                Episode Length: 3.709999999999965 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -5.500393456556656 |                 State: (-145.48524475097656, 2.1045734882354736, 180.92726135253906) | Terminated: False |                Episode Length: 3.7199999999999647 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -5.512268364592966 |                 State: (-145.66860961914062, 2.105560541152954, 180.9545440673828) | Terminated: False |                Episode Length: 3.7299999999999645 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -5.524093056576668 |                 State: (-145.85194396972656, 2.106537103652954, 180.9818115234375) | Terminated: False |                Episode Length: 3.7399999999999642 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -5.535867306742075 |                 State: (-146.03526306152344, 2.1075031757354736, 181.00909423828125) | Terminated: False |                Episode Length: 3.749999999999964 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -5.547590890796526 |                 State: (-146.21856689453125, 2.108458995819092, 181.03634643554688) | Terminated: False |                Episode Length: 3.759999999999964 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -5.559263585930998 |                 State: (-146.40184020996094, 2.1094040870666504, 181.06361389160156) | Terminated: False |                Episode Length: 3.7699999999999636 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -5.5708851708306275 |                 State: (-146.58511352539062, 2.1103386878967285, 181.0908966064453) | Terminated: False |                Episode Length: 3.7799999999999634 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -5.5824554256851515 |                 State: (-146.76834106445312, 2.111262798309326, 181.1181640625) | Terminated: False |                Episode Length: 3.789999999999963 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -5.593974132199262 |                 State: (-146.95156860351562, 2.1121766567230225, 181.14544677734375) | Terminated: False |                Episode Length: 3.799999999999963 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -5.6054410736028775 |                 State: (-147.13475036621094, 2.113079786300659, 181.17271423339844) | Terminated: False |                Episode Length: 3.8099999999999627 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -5.616856034661321 |                 State: (-147.3179168701172, 2.1139721870422363, 181.1999969482422) | Terminated: False |                Episode Length: 3.8199999999999625 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -5.628218801685422 |                 State: (-147.50106811523438, 2.114854335784912, 181.22726440429688) | Terminated: False |                Episode Length: 3.8299999999999623 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -5.63952916254152 |                 State: (-147.6842041015625, 2.1157257556915283, 181.25453186035156) | Terminated: False |                Episode Length: 3.839999999999962 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -5.65078690666138 |                 State: (-147.86729431152344, 2.116586923599243, 181.28179931640625) | Terminated: False |                Episode Length: 3.849999999999962 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -5.661991825052023 |                 State: (-148.05035400390625, 2.1174371242523193, 181.30908203125) | Terminated: False |                Episode Length: 3.8599999999999617 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -5.673143710305459 |                 State: (-148.2333984375, 2.118277072906494, 181.3363494873047) | Terminated: False |                Episode Length: 3.8699999999999615 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -5.684242356608336 |                 State: (-148.41641235351562, 2.1191062927246094, 181.36363220214844) | Terminated: False |                Episode Length: 3.8799999999999613 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -5.695287559751484 |                 State: (-148.59939575195312, 2.119925022125244, 181.39089965820312) | Terminated: False |                Episode Length: 3.889999999999961 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -5.706279117139375 |                 State: (-148.7823486328125, 2.1207330226898193, 181.4181671142578) | Terminated: False |                Episode Length: 3.899999999999961 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -5.717216827799489 |                 State: (-148.9652557373047, 2.121530532836914, 181.4454345703125) | Terminated: False |                Episode Length: 3.9099999999999606 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -5.728100492391576 |                 State: (-149.14816284179688, 2.122317314147949, 181.47271728515625) | Terminated: False |                Episode Length: 3.9199999999999604 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -5.738929913216829 |                 State: (-149.33099365234375, 2.123093605041504, 181.49998474121094) | Terminated: False |                Episode Length: 3.92999999999996 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -5.749704894226958 |                 State: (-149.51382446289062, 2.123859167098999, 181.5272674560547) | Terminated: False |                Episode Length: 3.93999999999996 | C_L: 1.0\n",
            "Action: [ 1.    -0.524] | Reward: -5.760425241033164 |                 State: (-149.69662475585938, 2.1246142387390137, 181.22726440429688) | Terminated: False |                Episode Length: 3.9499999999999598 | C_L: 1.0\n",
            "Action: [ 1.    -0.524] | Reward: -5.771090749062885 |                 State: (-149.87940979003906, 2.1253585815429688, 180.92726135253906) | Terminated: False |                Episode Length: 3.9599999999999596 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -5.781701217664099 |                 State: (-150.0621795654297, 2.1260921955108643, 180.9545440673828) | Terminated: False |                Episode Length: 3.9699999999999593 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -5.79225645691224 |                 State: (-150.24493408203125, 2.1268153190612793, 180.9818115234375) | Terminated: False |                Episode Length: 3.979999999999959 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -5.802756278575147 |                 State: (-150.42764282226562, 2.1275277137756348, 181.00909423828125) | Terminated: False |                Episode Length: 3.989999999999959 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -5.813200496121603 |                 State: (-150.6103057861328, 2.1282293796539307, 181.03634643554688) | Terminated: False |                Episode Length: 3.9999999999999587 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -5.823588924729759 |                 State: (-150.79295349121094, 2.128920555114746, 181.06361389160156) | Terminated: False |                Episode Length: 4.009999999999959 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -5.833921381295476 |                 State: (-150.9755401611328, 2.129600763320923, 181.0908966064453) | Terminated: False |                Episode Length: 4.019999999999959 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -5.844197684440542 |                 State: (-151.15809631347656, 2.130270481109619, 181.1181640625) | Terminated: False |                Episode Length: 4.0299999999999585 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -5.8544176545207955 |                 State: (-151.3406219482422, 2.130929708480835, 181.14544677734375) | Terminated: False |                Episode Length: 4.039999999999958 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -5.864581113634146 |                 State: (-151.52308654785156, 2.131577968597412, 181.17271423339844) | Terminated: False |                Episode Length: 4.049999999999958 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -5.874687885628481 |                 State: (-151.7055206298828, 2.1322154998779297, 181.1999969482422) | Terminated: False |                Episode Length: 4.059999999999958 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -5.884737796109473 |                 State: (-151.88790893554688, 2.132842540740967, 181.22726440429688) | Terminated: False |                Episode Length: 4.069999999999958 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -5.894730672448273 |                 State: (-152.07025146484375, 2.1334588527679443, 181.25453186035156) | Terminated: False |                Episode Length: 4.079999999999957 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -5.904666343789106 |                 State: (-152.25254821777344, 2.1340644359588623, 181.28179931640625) | Terminated: False |                Episode Length: 4.089999999999957 | C_L: 1.0\n",
            "Action: [ 1.    -0.333] | Reward: -5.9145446410567475 |                 State: (-152.43479919433594, 2.1346592903137207, 181.0908966064453) | Terminated: False |                Episode Length: 4.099999999999957 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -5.924365389899896 |                 State: (-152.61703491210938, 2.1352434158325195, 181.1181640625) | Terminated: False |                Episode Length: 4.109999999999957 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -5.934128424636677 |                 State: (-152.79920959472656, 2.135816812515259, 181.14544677734375) | Terminated: False |                Episode Length: 4.119999999999957 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -5.943833581387006 |                 State: (-152.98133850097656, 2.1363794803619385, 181.17271423339844) | Terminated: False |                Episode Length: 4.129999999999956 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -5.953480698079652 |                 State: (-153.16342163085938, 2.1369314193725586, 181.1999969482422) | Terminated: False |                Episode Length: 4.139999999999956 | C_L: 1.0\n",
            "Action: [ 1.    -0.333] | Reward: -5.963069614459189 |                 State: (-153.345458984375, 2.137472629547119, 181.00909423828125) | Terminated: False |                Episode Length: 4.149999999999956 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -5.972600165439729 |                 State: (-153.52745056152344, 2.13800311088562, 181.03634643554688) | Terminated: False |                Episode Length: 4.159999999999956 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -5.982072194229442 |                 State: (-153.70941162109375, 2.1385228633880615, 181.06361389160156) | Terminated: False |                Episode Length: 4.1699999999999555 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -5.991485545871953 |                 State: (-153.8913116455078, 2.1390318870544434, 181.0908966064453) | Terminated: False |                Episode Length: 4.179999999999955 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -6.0008400672528595 |                 State: (-154.07315063476562, 2.1395301818847656, 181.1181640625) | Terminated: False |                Episode Length: 4.189999999999955 | C_L: 1.0\n",
            "Action: [ 1.    -0.333] | Reward: -6.01013560710614 |                 State: (-154.25494384765625, 2.1400177478790283, 180.92726135253906) | Terminated: False |                Episode Length: 4.199999999999955 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -6.019372009791492 |                 State: (-154.43670654296875, 2.1404945850372314, 180.9545440673828) | Terminated: False |                Episode Length: 4.209999999999955 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -6.028549127571287 |                 State: (-154.61839294433594, 2.140960693359375, 180.9818115234375) | Terminated: False |                Episode Length: 4.2199999999999545 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -6.037666814574293 |                 State: (-154.800048828125, 2.141416072845459, 181.00909423828125) | Terminated: False |                Episode Length: 4.229999999999954 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -6.046724926801644 |                 State: (-154.9816436767578, 2.1418607234954834, 181.03634643554688) | Terminated: False |                Episode Length: 4.239999999999954 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -6.055723322132683 |                 State: (-155.16317749023438, 2.142294406890869, 181.06361389160156) | Terminated: False |                Episode Length: 4.249999999999954 | C_L: 1.0\n",
            "Action: [ 1.    -0.333] | Reward: -6.064661860330699 |                 State: (-155.34463500976562, 2.1427175998687744, 180.87271118164062) | Terminated: False |                Episode Length: 4.259999999999954 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -6.073540397079951 |                 State: (-155.5260772705078, 2.143129825592041, 180.89999389648438) | Terminated: False |                Episode Length: 4.269999999999953 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -6.082358795741768 |                 State: (-155.7074432373047, 2.143531322479248, 180.92726135253906) | Terminated: False |                Episode Length: 4.279999999999953 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -6.091116921577444 |                 State: (-155.88876342773438, 2.1439220905303955, 180.9545440673828) | Terminated: False |                Episode Length: 4.289999999999953 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -6.099814641753517 |                 State: (-156.07000732421875, 2.1443023681640625, 180.9818115234375) | Terminated: False |                Episode Length: 4.299999999999953 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -6.108451825346931 |                 State: (-156.25119018554688, 2.1446714401245117, 181.00909423828125) | Terminated: False |                Episode Length: 4.3099999999999525 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -6.117028343350077 |                 State: (-156.43231201171875, 2.1450300216674805, 181.03634643554688) | Terminated: False |                Episode Length: 4.319999999999952 | C_L: 1.0\n",
            "Action: [ 1.    -0.333] | Reward: -6.125544068675716 |                 State: (-156.61337280273438, 2.1453778743743896, 180.84544372558594) | Terminated: False |                Episode Length: 4.329999999999952 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -6.133998870287579 |                 State: (-156.79437255859375, 2.1457149982452393, 180.87271118164062) | Terminated: False |                Episode Length: 4.339999999999952 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -6.142392624766832 |                 State: (-156.97532653808594, 2.14604115486145, 180.89999389648438) | Terminated: False |                Episode Length: 4.349999999999952 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -6.150725210628647 |                 State: (-157.1562042236328, 2.1463565826416016, 180.92726135253906) | Terminated: False |                Episode Length: 4.3599999999999515 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -6.158996508326665 |                 State: (-157.33702087402344, 2.1466615200042725, 180.9545440673828) | Terminated: False |                Episode Length: 4.369999999999951 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -6.167206400257331 |                 State: (-157.51776123046875, 2.1469554901123047, 180.9818115234375) | Terminated: False |                Episode Length: 4.379999999999951 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -6.1753547707641125 |                 State: (-157.69842529296875, 2.1472387313842773, 181.00909423828125) | Terminated: False |                Episode Length: 4.389999999999951 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -6.1834415061416035 |                 State: (-157.8790283203125, 2.1475112438201904, 181.03634643554688) | Terminated: False |                Episode Length: 4.399999999999951 | C_L: 1.0\n",
            "Action: [ 1.    -0.333] | Reward: -6.19146649463949 |                 State: (-158.0595703125, 2.147773027420044, 180.84544372558594) | Terminated: False |                Episode Length: 4.40999999999995 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -6.1994296205175115 |                 State: (-158.2400360107422, 2.148023843765259, 180.87271118164062) | Terminated: False |                Episode Length: 4.41999999999995 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -6.2073307757598855 |                 State: (-158.4204559326172, 2.148264169692993, 180.89999389648438) | Terminated: False |                Episode Length: 4.42999999999995 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -6.21516985431678 |                 State: (-158.6007843017578, 2.148493766784668, 180.92726135253906) | Terminated: False |                Episode Length: 4.43999999999995 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -6.222946752107822 |                 State: (-158.78103637695312, 2.148712396621704, 180.9545440673828) | Terminated: False |                Episode Length: 4.4499999999999496 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -6.230661367025471 |                 State: (-158.9612274169922, 2.1489205360412598, 180.9818115234375) | Terminated: False |                Episode Length: 4.459999999999949 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -6.238313598938286 |                 State: (-159.14134216308594, 2.1491177082061768, 181.00909423828125) | Terminated: False |                Episode Length: 4.469999999999949 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -6.245903349694053 |                 State: (-159.3213653564453, 2.1493043899536133, 181.03634643554688) | Terminated: False |                Episode Length: 4.479999999999949 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -6.253430523122794 |                 State: (-159.50131225585938, 2.149480104446411, 181.06361389160156) | Terminated: False |                Episode Length: 4.489999999999949 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -6.26089502503966 |                 State: (-159.68118286132812, 2.1496450901031494, 181.0908966064453) | Terminated: False |                Episode Length: 4.4999999999999485 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -6.268296763247685 |                 State: (-159.86097717285156, 2.1497995853424072, 181.1181640625) | Terminated: False |                Episode Length: 4.509999999999948 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -6.27563564754043 |                 State: (-160.0406951904297, 2.1499431133270264, 181.14544677734375) | Terminated: False |                Episode Length: 4.519999999999948 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -6.282911589704491 |                 State: (-160.22032165527344, 2.150075912475586, 181.17271423339844) | Terminated: False |                Episode Length: 4.529999999999948 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -6.290124503521893 |                 State: (-160.39988708496094, 2.150198221206665, 181.1999969482422) | Terminated: False |                Episode Length: 4.539999999999948 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -6.297274304772349 |                 State: (-160.579345703125, 2.1503095626831055, 181.22726440429688) | Terminated: False |                Episode Length: 4.549999999999947 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -6.3043609112354035 |                 State: (-160.75872802734375, 2.1504104137420654, 181.25453186035156) | Terminated: False |                Episode Length: 4.559999999999947 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -6.311384242692444 |                 State: (-160.9380340576172, 2.150500535964966, 181.28179931640625) | Terminated: False |                Episode Length: 4.569999999999947 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -6.318344220928596 |                 State: (-161.11724853515625, 2.1505796909332275, 181.30908203125) | Terminated: False |                Episode Length: 4.579999999999947 | C_L: 1.0\n",
            "Action: [ 1.    -0.524] | Reward: -6.325240769734483 |                 State: (-161.29635620117188, 2.150648355484009, 181.00909423828125) | Terminated: False |                Episode Length: 4.589999999999947 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -6.332073803686705 |                 State: (-161.47543334960938, 2.1507062911987305, 181.03634643554688) | Terminated: False |                Episode Length: 4.599999999999946 | C_L: 1.0\n",
            "Action: [ 1.    -0.524] | Reward: -6.338843250306368 |                 State: (-161.65440368652344, 2.1507537364959717, 180.73635864257812) | Terminated: False |                Episode Length: 4.609999999999946 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -6.34554903049409 |                 State: (-161.8333282470703, 2.150790214538574, 180.7636260986328) | Terminated: False |                Episode Length: 4.619999999999946 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -6.352191075512531 |                 State: (-162.0121612548828, 2.1508162021636963, 180.79090881347656) | Terminated: False |                Episode Length: 4.629999999999946 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -6.358769318636565 |                 State: (-162.19088745117188, 2.150831460952759, 180.81817626953125) | Terminated: False |                Episode Length: 4.6399999999999455 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -6.365283695154367 |                 State: (-162.36953735351562, 2.1508359909057617, 180.84544372558594) | Terminated: False |                Episode Length: 4.649999999999945 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -6.371734142368369 |                 State: (-162.54808044433594, 2.150829792022705, 180.87271118164062) | Terminated: False |                Episode Length: 4.659999999999945 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -6.378120599596094 |                 State: (-162.7265625, 2.150813102722168, 180.89999389648438) | Terminated: False |                Episode Length: 4.669999999999945 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -6.384443008170867 |                 State: (-162.90492248535156, 2.1507856845855713, 180.92726135253906) | Terminated: False |                Episode Length: 4.679999999999945 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -6.390701311442398 |                 State: (-163.08319091796875, 2.150747537612915, 180.9545440673828) | Terminated: False |                Episode Length: 4.689999999999944 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -6.396895454777247 |                 State: (-163.26136779785156, 2.1506989002227783, 180.9818115234375) | Terminated: False |                Episode Length: 4.699999999999944 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -6.403025385559156 |                 State: (-163.439453125, 2.150639533996582, 181.00909423828125) | Terminated: False |                Episode Length: 4.709999999999944 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -6.409091053189266 |                 State: (-163.617431640625, 2.150569438934326, 181.03634643554688) | Terminated: False |                Episode Length: 4.719999999999944 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -6.415092409086207 |                 State: (-163.79531860351562, 2.15048885345459, 181.06361389160156) | Terminated: False |                Episode Length: 4.729999999999944 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -6.421029406686061 |                 State: (-163.97311401367188, 2.150397777557373, 181.0908966064453) | Terminated: False |                Episode Length: 4.739999999999943 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -6.426902001442204 |                 State: (-164.15078735351562, 2.1502957344055176, 181.1181640625) | Terminated: False |                Episode Length: 4.749999999999943 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -6.432710150825031 |                 State: (-164.328369140625, 2.1501834392547607, 181.14544677734375) | Terminated: False |                Episode Length: 4.759999999999943 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -6.438453814321545 |                 State: (-164.505859375, 2.1500604152679443, 181.17271423339844) | Terminated: False |                Episode Length: 4.769999999999943 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -6.444132953434836 |                 State: (-164.68324279785156, 2.1499269008636475, 181.1999969482422) | Terminated: False |                Episode Length: 4.7799999999999425 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -6.4497475316834265 |                 State: (-164.8605194091797, 2.149782657623291, 181.22726440429688) | Terminated: False |                Episode Length: 4.789999999999942 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -6.455297514600507 |                 State: (-165.03768920898438, 2.149627923965454, 181.25453186035156) | Terminated: False |                Episode Length: 4.799999999999942 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -6.460782869733037 |                 State: (-165.21475219726562, 2.1494626998901367, 181.28179931640625) | Terminated: False |                Episode Length: 4.809999999999942 | C_L: 1.0\n",
            "Action: [ 1.    -0.333] | Reward: -6.46620356664073 |                 State: (-165.39170837402344, 2.1492867469787598, 181.0908966064453) | Terminated: False |                Episode Length: 4.819999999999942 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -6.471559569087422 |                 State: (-165.56858825683594, 2.1491003036499023, 181.1181640625) | Terminated: False |                Episode Length: 4.8299999999999415 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -6.47685085046711 |                 State: (-165.74534606933594, 2.1489033699035645, 181.14544677734375) | Terminated: False |                Episode Length: 4.839999999999941 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -6.482077386182963 |                 State: (-165.92201232910156, 2.148695945739746, 181.17271423339844) | Terminated: False |                Episode Length: 4.849999999999941 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -6.4872391536458425 |                 State: (-166.09857177734375, 2.1484780311584473, 181.1999969482422) | Terminated: False |                Episode Length: 4.859999999999941 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -6.492336132272703 |                 State: (-166.27499389648438, 2.148249387741089, 181.22726440429688) | Terminated: False |                Episode Length: 4.869999999999941 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -6.497368303484875 |                 State: (-166.45132446289062, 2.148010492324829, 181.25453186035156) | Terminated: False |                Episode Length: 4.87999999999994 | C_L: 1.0\n",
            "Action: [ 1.    -0.333] | Reward: -6.50233565070623 |                 State: (-166.62753295898438, 2.1477608680725098, 181.06361389160156) | Terminated: False |                Episode Length: 4.88999999999994 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -6.507238151701735 |                 State: (-166.80364990234375, 2.147500991821289, 181.0908966064453) | Terminated: False |                Episode Length: 4.89999999999994 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -6.512075793708099 |                 State: (-166.9796600341797, 2.147230625152588, 181.1181640625) | Terminated: False |                Episode Length: 4.90999999999994 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -6.516848565958584 |                 State: (-167.15554809570312, 2.1469497680664062, 181.14544677734375) | Terminated: False |                Episode Length: 4.9199999999999395 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -6.52155645968072 |                 State: (-167.33131408691406, 2.146658182144165, 181.17271423339844) | Terminated: False |                Episode Length: 4.929999999999939 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -6.526199468093888 |                 State: (-167.50697326660156, 2.1463565826416016, 181.1999969482422) | Terminated: False |                Episode Length: 4.939999999999939 | C_L: 1.0\n",
            "Action: [ 1.    -0.333] | Reward: -6.530777586406804 |                 State: (-167.68252563476562, 2.1460442543029785, 181.00909423828125) | Terminated: False |                Episode Length: 4.949999999999939 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -6.535290804493253 |                 State: (-167.85797119140625, 2.145721673965454, 181.03634643554688) | Terminated: False |                Episode Length: 4.959999999999939 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -6.539739121347791 |                 State: (-168.0332794189453, 2.145388603210449, 181.06361389160156) | Terminated: False |                Episode Length: 4.9699999999999385 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -6.544122537946304 |                 State: (-168.20849609375, 2.145045042037964, 181.0908966064453) | Terminated: False |                Episode Length: 4.979999999999938 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -6.5484410572430365 |                 State: (-168.38357543945312, 2.144691228866577, 181.1181640625) | Terminated: False |                Episode Length: 4.989999999999938 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -6.552694684167511 |                 State: (-168.5585479736328, 2.14432692527771, 181.14544677734375) | Terminated: False |                Episode Length: 4.999999999999938 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -6.556883425621326 |                 State: (-168.73338317871094, 2.1439523696899414, 181.17271423339844) | Terminated: False |                Episode Length: 5.009999999999938 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -6.5610072904748415 |                 State: (-168.9080810546875, 2.1435673236846924, 181.1999969482422) | Terminated: False |                Episode Length: 5.019999999999937 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -6.565066289563754 |                 State: (-169.08267211914062, 2.143172025680542, 181.22726440429688) | Terminated: False |                Episode Length: 5.029999999999937 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -6.5690604356855555 |                 State: (-169.25714111328125, 2.142766237258911, 181.25453186035156) | Terminated: False |                Episode Length: 5.039999999999937 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -6.57298974359588 |                 State: (-169.4314727783203, 2.142350196838379, 181.28179931640625) | Terminated: False |                Episode Length: 5.049999999999937 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -6.576854230004739 |                 State: (-169.60569763183594, 2.1419239044189453, 181.30908203125) | Terminated: False |                Episode Length: 5.0599999999999365 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -6.580653913572647 |                 State: (-169.77978515625, 2.1414873600006104, 181.3363494873047) | Terminated: False |                Episode Length: 5.069999999999936 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -6.584388814906632 |                 State: (-169.9537353515625, 2.141040563583374, 181.36363220214844) | Terminated: False |                Episode Length: 5.079999999999936 | C_L: 1.0\n",
            "Action: [ 1.    -0.333] | Reward: -6.588058956556141 |                 State: (-170.1275634765625, 2.1405832767486572, 181.17271423339844) | Terminated: False |                Episode Length: 5.089999999999936 | C_L: 1.0\n",
            "Action: [ 1.    -0.333] | Reward: -6.591664354590166 |                 State: (-170.30126953125, 2.140115976333618, 180.9818115234375) | Terminated: False |                Episode Length: 5.099999999999936 | C_L: 1.0\n",
            "Action: [ 1.    -0.333] | Reward: -6.59520502808266 |                 State: (-170.47486877441406, 2.1396381855010986, 180.79090881347656) | Terminated: False |                Episode Length: 5.1099999999999355 | C_L: 1.0\n",
            "Action: [ 1.    -0.333] | Reward: -6.598680999109631 |                 State: (-170.6483612060547, 2.139150381088257, 180.59999084472656) | Terminated: False |                Episode Length: 5.119999999999935 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -6.602092292745917 |                 State: (-170.8217315673828, 2.1386520862579346, 180.57272338867188) | Terminated: False |                Episode Length: 5.129999999999935 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -6.6054389394803295 |                 State: (-170.99496459960938, 2.13814377784729, 180.54544067382812) | Terminated: False |                Episode Length: 5.139999999999935 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -6.6087209717186255 |                 State: (-171.16807556152344, 2.137625217437744, 180.51817321777344) | Terminated: False |                Episode Length: 5.149999999999935 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -6.6119384237788505 |                 State: (-171.34104919433594, 2.137096405029297, 180.4908905029297) | Terminated: False |                Episode Length: 5.159999999999934 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -6.6150913318865765 |                 State: (-171.51388549804688, 2.1365575790405273, 180.463623046875) | Terminated: False |                Episode Length: 5.169999999999934 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -6.6181797341700355 |                 State: (-171.68658447265625, 2.1360085010528564, 180.4363555908203) | Terminated: False |                Episode Length: 5.179999999999934 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -6.621203670655149 |                 State: (-171.85916137695312, 2.135449171066284, 180.40908813476562) | Terminated: False |                Episode Length: 5.189999999999934 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -6.62416318326045 |                 State: (-172.0316162109375, 2.1348798274993896, 180.38180541992188) | Terminated: False |                Episode Length: 5.199999999999934 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -6.627058315791908 |                 State: (-172.2039031982422, 2.134300470352173, 180.3545379638672) | Terminated: False |                Episode Length: 5.209999999999933 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -6.629889113937646 |                 State: (-172.37606811523438, 2.1337108612060547, 180.32725524902344) | Terminated: False |                Episode Length: 5.219999999999933 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -6.632655625262556 |                 State: (-172.548095703125, 2.133111000061035, 180.29998779296875) | Terminated: False |                Episode Length: 5.229999999999933 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -6.635357899202814 |                 State: (-172.71998596191406, 2.1325013637542725, 180.272705078125) | Terminated: False |                Episode Length: 5.239999999999933 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -6.637995987060298 |                 State: (-172.8917236328125, 2.1318814754486084, 180.2454376220703) | Terminated: False |                Episode Length: 5.2499999999999325 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -6.6405699419968975 |                 State: (-173.06333923339844, 2.131251573562622, 180.21817016601562) | Terminated: False |                Episode Length: 5.259999999999932 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -6.643079819028735 |                 State: (-173.2347869873047, 2.1306116580963135, 180.19090270996094) | Terminated: False |                Episode Length: 5.269999999999932 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -6.645525675020278 |                 State: (-173.40611267089844, 2.1299617290496826, 180.16363525390625) | Terminated: False |                Episode Length: 5.279999999999932 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -6.647907568678362 |                 State: (-173.57730102539062, 2.1293017864227295, 180.1363525390625) | Terminated: False |                Episode Length: 5.289999999999932 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -6.650225560546113 |                 State: (-173.74832153320312, 2.128631830215454, 180.1090850830078) | Terminated: False |                Episode Length: 5.299999999999931 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -6.652479712996773 |                 State: (-173.91920471191406, 2.1279518604278564, 180.08180236816406) | Terminated: False |                Episode Length: 5.309999999999931 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -6.65467009022743 |                 State: (-174.08993530273438, 2.1272621154785156, 180.05453491210938) | Terminated: False |                Episode Length: 5.319999999999931 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -6.656796758252656 |                 State: (-174.26052856445312, 2.1265621185302734, 180.0272674560547) | Terminated: False |                Episode Length: 5.329999999999931 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -6.65885978489805 |                 State: (-174.43096923828125, 2.125852584838867, 180.0) | Terminated: False |                Episode Length: 5.339999999999931 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -6.660859239793686 |                 State: (-174.60125732421875, 2.1251327991485596, 179.97271728515625) | Terminated: False |                Episode Length: 5.34999999999993 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -6.662795194367471 |                 State: (-174.7714080810547, 2.124403238296509, 179.94544982910156) | Terminated: False |                Episode Length: 5.35999999999993 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -6.664667721838412 |                 State: (-174.94140625, 2.123663902282715, 179.9181671142578) | Terminated: False |                Episode Length: 5.36999999999993 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -6.6664768972097885 |                 State: (-175.1112518310547, 2.1229145526885986, 179.89089965820312) | Terminated: False |                Episode Length: 5.37999999999993 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -6.668222797262241 |                 State: (-175.2809295654297, 2.1221554279327393, 179.86361694335938) | Terminated: False |                Episode Length: 5.3899999999999295 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -6.669905500546765 |                 State: (-175.45045471191406, 2.1213862895965576, 179.83636474609375) | Terminated: False |                Episode Length: 5.399999999999929 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -6.671525087377619 |                 State: (-175.61984252929688, 2.120607614517212, 179.80908203125) | Terminated: False |                Episode Length: 5.409999999999929 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -6.6730816398251465 |                 State: (-175.7890625, 2.119818925857544, 179.7818145751953) | Terminated: False |                Episode Length: 5.419999999999929 | C_L: 1.0\n",
            "Action: [ 1.    -0.048] | Reward: -6.67457524170851 |                 State: (-175.95811462402344, 2.119020700454712, 179.75453186035156) | Terminated: False |                Episode Length: 5.429999999999929 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -6.67600597858834 |                 State: (-176.12701416015625, 2.1182124614715576, 179.7818145751953) | Terminated: False |                Episode Length: 5.4399999999999284 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -6.677373937359804 |                 State: (-176.2957763671875, 2.1173946857452393, 179.80908203125) | Terminated: False |                Episode Length: 5.449999999999928 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -6.678679206645139 |                 State: (-176.46435546875, 2.1165671348571777, 179.83636474609375) | Terminated: False |                Episode Length: 5.459999999999928 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -6.679921876786087 |                 State: (-176.63279724121094, 2.115729808807373, 179.86361694335938) | Terminated: False |                Episode Length: 5.469999999999928 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -6.681102039836258 |                 State: (-176.80105590820312, 2.114882707595825, 179.89089965820312) | Terminated: False |                Episode Length: 5.479999999999928 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -6.6822197895534075 |                 State: (-176.96917724609375, 2.1140260696411133, 179.9181671142578) | Terminated: False |                Episode Length: 5.489999999999927 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -6.683275221391629 |                 State: (-177.13711547851562, 2.113159656524658, 179.94544982910156) | Terminated: False |                Episode Length: 5.499999999999927 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -6.6842684324934725 |                 State: (-177.30491638183594, 2.112283706665039, 179.97271728515625) | Terminated: False |                Episode Length: 5.509999999999927 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -6.685199521681984 |                 State: (-177.47251892089844, 2.1113979816436768, 180.0) | Terminated: False |                Episode Length: 5.519999999999927 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -6.6860685894526615 |                 State: (-177.63998413085938, 2.1105027198791504, 180.0272674560547) | Terminated: False |                Episode Length: 5.5299999999999265 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -6.686875737965342 |                 State: (-177.80726623535156, 2.10959792137146, 180.05453491210938) | Terminated: False |                Episode Length: 5.539999999999926 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -6.687621071036003 |                 State: (-177.97439575195312, 2.1086835861206055, 180.08180236816406) | Terminated: False |                Episode Length: 5.549999999999926 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -6.688304694128498 |                 State: (-178.141357421875, 2.107759714126587, 180.1090850830078) | Terminated: False |                Episode Length: 5.559999999999926 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -6.688926714346211 |                 State: (-178.3081512451172, 2.1068263053894043, 180.1363525390625) | Terminated: False |                Episode Length: 5.569999999999926 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -6.689487240423641 |                 State: (-178.47476196289062, 2.1058833599090576, 180.16363525390625) | Terminated: False |                Episode Length: 5.5799999999999255 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -6.68998638271791 |                 State: (-178.64120483398438, 2.104930877685547, 180.19090270996094) | Terminated: False |                Episode Length: 5.589999999999925 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -6.6904242532002085 |                 State: (-178.80747985839844, 2.103968858718872, 180.21817016601562) | Terminated: False |                Episode Length: 5.599999999999925 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -6.690800965447158 |                 State: (-178.97360229492188, 2.1029975414276123, 180.2454376220703) | Terminated: False |                Episode Length: 5.609999999999925 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -6.691116634632113 |                 State: (-179.1395263671875, 2.1020166873931885, 180.272705078125) | Terminated: False |                Episode Length: 5.619999999999925 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -6.691371377516391 |                 State: (-179.30528259277344, 2.1010262966156006, 180.29998779296875) | Terminated: False |                Episode Length: 5.629999999999924 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -6.691565312440434 |                 State: (-179.47085571289062, 2.1000266075134277, 180.32725524902344) | Terminated: False |                Episode Length: 5.639999999999924 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -6.691698559314906 |                 State: (-179.6362762451172, 2.09901762008667, 180.3545379638672) | Terminated: False |                Episode Length: 5.649999999999924 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -6.691771239611721 |                 State: (-179.80149841308594, 2.097999334335327, 180.38180541992188) | Terminated: False |                Episode Length: 5.659999999999924 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -6.691783476355007 |                 State: (-179.966552734375, 2.0969715118408203, 180.40908813476562) | Terminated: False |                Episode Length: 5.6699999999999235 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -6.691735394112011 |                 State: (-180.13143920898438, 2.0959343910217285, 180.4363555908203) | Terminated: False |                Episode Length: 5.679999999999923 | C_L: 1.0\n",
            "Action: [1.    0.048] | Reward: -6.691687311869015 |                 State: (-180.13143920898438, 2.0959343910217285, 180.4363555908203) | Terminated: True |                Episode Length: 5.689999999999923 | C_L: 1.0\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA5YAAAHWCAYAAAAMzBY7AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAADbJ0lEQVR4nOzdd3hTZfvA8W+S7j3TvVv23puWKVNUHKDIUoYgAu7xA8TX1xcXIMhwAQqK4lYQ2bsylCEU6B6U7tK9m/z+CI3UMtpSSMf9ua5ecNZz7pOTpufOsxRarVaLEEIIIYQQQghRS0pDByCEEEIIIYQQomGTxFIIIYQQQgghxG2RxFIIIYQQQgghxG2RxFIIIYQQQgghxG2RxFIIIYQQQgghxG2RxFIIIYQQQgghxG2RxFIIIYQQQgghxG2RxFIIIYQQQgghxG2RxFIIIYQQQgghxG2RxFIIIcRNKRQKFi1a1GDKbSiCg4MJDg42dBi1sm/fPhQKBfv27TN0KEIIIeoJSSyFEKIJW7VqFQqFgu7duxs6lHonLCyMRYsWERsba+hQamXVqlWsX7/e0GEIIYRoIowMHYAQQgjD2bRpE76+vhw7dozIyEgCAwOr7FNYWIiRUdP7cxEWFsbrr79OcHAwvr6+dV7+jh076rzMa61atQonJycmTZpU52X369ePwsJCTExM6rxsIYQQDZPUWAohRBMVExPDkSNHeP/993F2dmbTpk3X3c/MzOyWiWV+fv6dCLHB0Gq1FBYW1ugYExOTBpeYFRUVodFoUCqVmJmZoVTKY4QQQggd+YsghBBN1KZNm7C3t2fEiBGMHTv2honlv/tCLlq0CIVCQVhYGOPHj8fe3p4+ffoAMGnSJKysrIiOjmbo0KFYWlri7u7O4sWL0Wq1N40nLi6Op556iubNm2Nubo6joyMPPvhglaao69evR6FQcPjwYebPn4+zszOWlpbcd999pKWlVSn3t99+o2/fvlhaWmJtbc2IESM4d+7cTWNZv349Dz74IAAhISEoFIpKfQp9fX0ZOXIkv//+O126dMHc3Jy1a9cCsG7dOgYMGIBarcbU1JRWrVqxevXqKue4Xh/L4uJiFi5cSGBgIKampnh5efHCCy9QXFxc5fiNGzfSrVs3LCwssLe3p1+/fvpaUF9fX86dO8f+/fv1sV97rujoaB588EEcHBywsLCgR48ebN26tVL5Ff0oN2/ezGuvvYaHhwcWFhbk5OTcsI/l0aNHueeee7C1tcXCwoL+/ftz+PDhSvvk5uYyd+5cfH19MTU1Ra1WM3jwYP7666+b3hMhhBD1W9Nr2ySEEALQJZb3338/JiYmjBs3jtWrV3P8+HG6du1areMffPBBgoKC+O9//1spaSwvL+eee+6hR48evP3222zfvp2FCxdSVlbG4sWLb1je8ePHOXLkCI888gienp7ExsayevVqgoODCQsLw8LCotL+Tz/9NPb29ixcuJDY2FiWLVvG7Nmz+frrr/X7fPHFF0ycOJGhQ4eyZMkSCgoKWL16NX369OHkyZM3bOLar18/5syZwwcffMArr7xCy5YtAfT/Aly8eJFx48Yxffp0nnzySZo3bw7A6tWrad26NaNHj8bIyIhffvmFp556Co1Gw6xZs254/RqNhtGjR3Po0CGmTZtGy5Yt+fvvv1m6dCnh4eH8+OOP+n1ff/11Fi1aRK9evVi8eDEmJiYcPXqUPXv2MGTIEJYtW8bTTz+NlZUVr776KgAuLi4ApKSk0KtXLwoKCpgzZw6Ojo5s2LCB0aNH8+2333LfffdViuuNN97AxMSE5557juLi4hvWsu7Zs4dhw4bRuXNnFi5ciFKp1CfZBw8epFu3bgDMmDGDb7/9ltmzZ9OqVSsyMjI4dOgQ58+fp1OnTjd8fYQQQtRzWiGEEE3OiRMntIB2586dWq1Wq9VoNFpPT0/tM888U2VfQLtw4UL98sKFC7WAdty4cVX2nThxohbQPv300/p1Go1GO2LECK2JiYk2LS3thuUWFBRUKS80NFQLaD///HP9unXr1mkB7aBBg7QajUa/ft68eVqVSqXNysrSarVabW5urtbOzk775JNPViozOTlZa2trW2X9v23ZskULaPfu3Vtlm4+PjxbQbt++vcq2613H0KFDtf7+/pXW9e/fX9u/f3/98hdffKFVKpXagwcPVtpvzZo1WkB7+PBhrVar1UZERGiVSqX2vvvu05aXl1fa99rXo3Xr1pXKrzB37lwtUOk8ubm5Wj8/P62vr6++zL1792oBrb+/f5VrqthW8dpoNBptUFCQdujQoZViKCgo0Pr5+WkHDx6sX2dra6udNWtWlbiEEEI0bNIUVgghmqBNmzbh4uJCSEgIoGvu+vDDD7N582bKy8urVcaMGTNuuG327Nn6/ysUCmbPnk1JSQm7du264THm5ub6/5eWlpKRkUFgYCB2dnbXbSY5bdo0FAqFfrlv376Ul5cTFxcHwM6dO8nKymLcuHGkp6frf1QqFd27d2fv3r3Vus4b8fPzY+jQoTe9juzsbNLT0+nfvz/R0dFkZ2ffsLwtW7bQsmVLWrRoUSneAQMGAOjj/fHHH9FoNCxYsKBKH8drX48b2bZtG926ddM3XwawsrJi2rRpxMbGEhYWVmn/iRMnVrqm6zl16hQRERGMHz+ejIwMfez5+fkMHDiQAwcOoNFoALCzs+Po0aNcvnz5lrEKIYRoOKQprBBCNDHl5eVs3ryZkJAQYmJi9Ou7d+/Oe++9x+7duxkyZMgty/Hz87vueqVSib+/f6V1zZo1A7jp1B2FhYW89dZbrFu3jsTExErNa6+XkHl7e1datre3B+DKlSsAREREAOgTs3+zsbG5YSzVcaPrP3z4MAsXLiQ0NJSCgoJK27Kzs7G1tb3ucREREZw/fx5nZ+frbk9NTQUgKioKpVJJq1atahV3XFzcdaeXqWjmGxcXR5s2bfTrb3Sd16p4rSdOnHjDfbKzs7G3t+ftt99m4sSJeHl50blzZ4YPH87jjz9e5T0jhBCiYZHEUgghmpg9e/aQlJTE5s2b2bx5c5XtmzZtqlZieatarJp6+umnWbduHXPnzqVnz57Y2tqiUCh45JFH9LVd11KpVNctpyIhrTjmiy++wNXVtcp+tzuFyvWuPyoqioEDB9KiRQvef/99vLy8MDExYdu2bSxduvS611FBo9HQtm1b3n///etu9/Lyuq14a6s697niut555x06dOhw3X2srKwAeOihh+jbty8//PADO3bs4J133mHJkiV8//33DBs2rM7iFkIIcXdJYimEEE3Mpk2bUKvVfPjhh1W2ff/99/zwww+sWbOm1omjRqMhOjpaX0sJEB4eDnDT+SC//fZbJk6cyHvvvadfV1RURFZWVq3iCAgIAECtVjNo0KAaH1+dZqX/9ssvv1BcXMzPP/9cqUa1Os1uAwICOH36NAMHDrzpuQMCAtBoNISFhd0wiYMbx+/j48PFixerrL9w4YJ+e01VvNY2NjbVeq3d3Nx46qmneOqpp0hNTaVTp068+eabklgKIUQDJn0shRCiCSksLOT7779n5MiRjB07tsrP7Nmzyc3N5eeff76t86xcuVL/f61Wy8qVKzE2NmbgwIE3PEalUlWZkmTFihXV7vP5b0OHDsXGxob//ve/lJaWVtl+valJrmVpaQlQo8S2ohb13814161bd8tjH3roIRITE/n444+rbCssLNTPFTpmzBiUSiWLFy+uUgN67XktLS2vG/vw4cM5duwYoaGh+nX5+fl89NFH+Pr61qqJbefOnQkICODdd98lLy+vyvaK17q8vLxKs2a1Wo27u/t1p1QRQgjRcEiNpRBCNCE///wzubm5jB49+rrbe/TogbOzM5s2beLhhx+u1TnMzMzYvn07EydOpHv37vz2229s3bqVV1555Yb9BwFGjhzJF198ga2tLa1atSI0NJRdu3bh6OhYqzhsbGxYvXo1EyZMoFOnTjzyyCM4OzsTHx/P1q1b6d27d6UE+N86dOiASqViyZIlZGdnY2pqqp+f8kaGDBmCiYkJo0aNYvr06eTl5fHxxx+jVqtJSkq6abwTJkzgm2++YcaMGezdu5fevXtTXl7OhQsX+Oabb/RzZgYGBvLqq6/yxhtv0LdvX+6//35MTU05fvw47u7uvPXWW4Au2Vu9ejX/+c9/CAwMRK1WM2DAAF566SW++uorhg0bxpw5c3BwcGDDhg3ExMTw3XffVRkQqDqUSiWffPIJw4YNo3Xr1kyePBkPDw8SExPZu3cvNjY2/PLLL+Tm5uLp6cnYsWNp3749VlZW7Nq1i+PHj1eqqRZCCNHwSGIphBBNyKZNmzAzM2Pw4MHX3a5UKhkxYgSbNm0iIyOjVkmdSqVi+/btzJw5k+effx5ra2sWLlzIggULbnrc8uXLUalUbNq0iaKiInr37s2uXbuuO/JqdY0fPx53d3f+97//8c4771BcXIyHhwd9+/Zl8uTJNz3W1dWVNWvW8NZbbzF16lTKy8vZu3fvTRPL5s2b8+233/Laa6/x3HPP4erqysyZM3F2dmbKlCk3PZ9SqeTHH39k6dKlfP755/zwww9YWFjg7+/PM888U6lp8eLFi/Hz82PFihW8+uqrWFhY0K5dOyZMmKDfZ8GCBcTFxfH222+Tm5tL//79GTBgAC4uLhw5coQXX3yRFStWUFRURLt27fjll18YMWJENV/ZqoKDgwkNDeWNN95g5cqV5OXl4erqSvfu3Zk+fToAFhYWPPXUU+zYsYPvv/8ejUZDYGAgq1atYubMmbU+txBCCMNTaP/d7kgIIYSopUmTJvHtt99etzmkqKxv376YmpredAoWIYQQoqGQPpZCCCGEASQlJeHk5GToMIQQQog6IYmlEEIIcRcdOXKE5557Tj81iRBCCNEYSB9LIYQQ4i76+OOP+e2335g7d+4t+3kKIYQQDYX0sRRCCCGEEEIIcVukKawQQgghhBBCiNsiiaUQQgghhBBCiNsifSxrqKysjJMnT+Li4lKrSaSFEEIIIYQQjYNGoyElJYWOHTtiZNS0U6umffW1cPLkSbp162boMIQQQgghhBD1xLFjx+jatauhwzAoSSxryMXFBdC9edzc3AwWR1lZGbt372bgwIFN/tuRpkDud9Mi97vpkXvetMj9blrkfjduSUlJdOvWTZ8jNGXy7q6hiuavbm5ueHp6GiyO0tJSnJyc8PDwwNjY2GBxiLtD7nfTIve76ZF73rTI/W5a5H43DdJFTgbvEUIIIYQQQghxmySxFEIIIYQQQghxWySxFEIIIYQQQghxW6SPpRBCCCEaLK1WS1lZGeXl5YYOpdpKS0sxMjKiqKioQcUtakfud8NnbGyMSqUydBj1niSWQgghhGiQSkpKSEpKoqCgwNCh1IhWq8XV1ZWEhAQUCoWhwxF3mNzvhk+hUODp6YmVlZWhQ6nXJLG8y+677z727dvHwIED+fbbb6tsP3bsGJMnT6a4uJjHH3+cBQsWABAVFcXDDz9MVlYWgwYN4oMPPrjboQshhBD1hkajISYmBpVKhbu7OyYmJg3moV2j0ZCXl4eVlZWMJNkEyP1u2LRaLWlpaVy6dImgoCCpubwJSSzvsmeeeYYpU6awYcOG626fNWsWX331Fa1bt6Z3797cd999tG3blhdffJFFixYxcuRIxo4dy7Zt2xrMH1AhhBCirpWUlKDRaPDy8sLCwsLQ4dSIRqOhpKQEMzMzSTSaALnfDZ+zszOxsbGUlpZKYnkT8u6+y4KDg7G2tr7utsuXL1NWVka7du1QqVQ88sgj/Prrr2i1Wo4cOcKIESMAeOyxx9i6devdDFsIIYSol+RBXQhxp0llTvXIp3E9cvnyZTw8PPTLHh4eJCYmkpGRgYODg/5N7eHhweXLlw0VphBCCCGEEEJUIollA5SXl0dRUdF1t126dIns7Oy7HJEQQgghhBCiKWtUiWV4eDj33nsvTk5O2NjY0KdPH/bu3Vtpn/j4eEaMGIGFhQVqtZrnn3+esrIyA0Vcmbu7O4mJifrlxMRE3N3dcXR0JDMzE61WS3Z2NjNmzOCvv/6qcnxCQgL9+/fnnnvukeRSCCGEEMKAJk2axJgxYwwdxk3t27cPhUJBVlaWoUMRjUCjSixHjhxJWVkZe/bs4c8//6R9+/aMHDmS5ORkAMrLyxkxYgQlJSUcOXKEDRs2sH79ev3Iq4bm7u6OSqXizJkzlJeXs3nzZkaNGoVCoaBHjx5s3bqV3NxcEhMT9UOrVySiCQkJBAcHEx0dTWpqKrm5uYa8FCGEEEJcx6hRoxg2bNh1tx08eBCFQsGZM2fuclR3V1FREZMmTaJt27YYGRlVK/mKjY1l6tSp+Pn5YW5uTkBAAAsXLqSkpKRG5160aBEKhUL/Y2trS9++fdm/f38tr0bcypw5c+jcuTOmpqZ06NChyvbY2NhK96Ti548//qi035YtW2jRogVmZma0bduWbdu23fLc+/bto1OnTpiamhIYGMj69esrbc/Pz+eRRx7Bzc2NcePGNbipi+qbRpNYpqenExERwUsvvUS7du0ICgrif//7HwUFBZw9exaAHTt2EBYWxsaNG+nQoQPDhg3jjTfe4MMPP6zxB1NtDRo0iAcffJBt27bh6elJaGgow4cP1/eZXLlyJePGjaNZs2bcc889tG3bFoAlS5awcOFC+vfvz+jRo/H39wdg2MjRHDlyRJ9U+vv7s2/fPjw9Pe/K9QghhBCi+qZOncquXbsqtVCqsG7dOrp06UK7du0MEBmUlpbelfOUl5djbm7OnDlzGDRoULWOuXDhAhqNhrVr13Lu3DmWLl3KmjVreOWVV2p8/tatW5OUlERSUhKhoaEEBQUxcuRIae11B02ZMoWHH374pvvs2rVLf1+SkpLo3LmzftuRI0cYN24cU6dO5eTJk4wZM4YxY8bon/GvJyYmhhEjRhASEsKpU6eYO3cuTzzxBL///rt+n2XLlmFlZcWOHTswNzdn2bJlt32tTVmjmW7E0dGR5s2b8/nnn+u/mVi7di1qtVr/xgwNDaVt27a4uLjojxs6dCgzZ87k3LlzdOzYsUq5xcXFFBcX65cragLLyspq9QH822+/VVn3008/AboP9M6dO3Pq1Cn9topz+Pr6VvrmJj4+nu1Hz1Iw+DXuXbCOwpwiWrZsybZt23B1db1rfxzE3VFxP+W+Ng1yv5uea+/5zrBUTl/KxsfRgiC1JS1crTEzluHt/620tBStVotGo0Gj0QC6+eYKS8sNEo+5sapaI0cOHz4cZ2dnvvrqK15//XV97Hl5eWzZsoUlS5bo191IxXzYO3bs4OWXXyYsLIwOHTrw6aef0rx5c/1+q1ev5v333ychIQE/Pz9eeeUVJkyYoN+uUqlYuXIl27dvZ8+ePTz33HOA7rlk9uzZLF68mMzMTCZMmMAHH3zA+++/z9KlS9FoNMyZM6dWSR2Aubk5H374IQCHDh0iKyvrltc8ZMgQhgwZol/29fXl2WefZc2aNbz99tvVPrdWq8XIyAi1Wg2AWq1m0aJFrFu3jgsXLtC1a1cAli5dyvr164mOjsbBwYGRI0eyZMkSrKysAFi/fj3z58/nq6++Yv78+SQkJNC7d28+++wz3Nzc9Oeq+AHdXOWjRo3i2Wef5YUXXrhpnFFRUTz77LMcPXqU/Px8WrZsyZtvvlkpEff39+fJJ58kMjKSb7/9Fnt7e1555RWmTZum3+fIkSPMnj2bCxcu0KZNG1555RUeeOAB/vzzTzp06KB/3a/9PTp06BCvvvoqJ06cwMnJiTFjxvDf//4XS0vLar/O16pI1lJTUzlz5kyVe12xbG9vr78v/962bNkyhg4dyrPPPgvA66+/zs6dO1mxYgWrV6++7nlXr16Nn58f77zzDgDNmzfn4MGDvP/++wwePBiAzMxMgoKCaN26Nc2bNyc9Pf2670WNRoNWq73udCP1pUtdfdBoEkuFQsGuXbsYM2YM1tbWKJVK1Go127dvx97eHoDk5ORKSSWgX65oLvtvb731Fq+//nqV9bt378bJyamOr6JmjqcpUZhaYtllDDZd76Wtk5bfQ0/janHaoHGJO2fnzp2GDkHcRXK/m54Pv93FviRdcnLo6rr7fTU4men+n1MCSgVYGRsmvvrEyMgIV1dX8vLy9K2OCkvK6fn+H7c48s4Ind8Dc5PqfQHw0EMP8eWXX/Lss8/qk9FNmzbpu+zk5OTc9PiK5nqvvPIKr7/+Oo6OjsyfP59Jkybpa2N+/fVX5s2bx3//+1+Cg4P5/fffmTp1Kg4ODvTt21df1uuvv87ChQt54403UKlUbNq0iaioKH799Ve++eYbYmJimDRpEhEREQQEBPDLL79w7NgxZs+eTY8ePejSpQsAY8eOrdJ08VpeXl6EhoZWWV9aWkpZWdktr/l6UlNTsbW1rdGxxcXFlJeX648pLi5m7dq12Nra4ubmpl9fUlLCf//7X3x8fIiNjeW5555j3rx5vPfee4CuOW9BQQFvv/02q1atQqlUMn36dObOncvHH39c6dpyc3M5cOAAEyZM4PXXX2fSpEm3jDk5OZmQkBBeeuklTE1N2bx5M/feey/Hjh3Dy8sL0CU77733Hq+88gpPP/00P/30E7NmzaJz584EBQWRk5PD6NGjGTx4MGvWrCEhIYEXX3wR0DUBzcnJ0b+XcnNzUSqVxMTEMHz4cF599VWWLVtGeno6L7zwAjNmzNB/GTBv3jy2bNly0/gvXbp0y9e+Ql5eHgCjR4+muLiYgIAA5syZw/Dhw/X7HDlyhFmzZlU6tn///mzduvWGr+WhQ4fo27dvpe39+vXj5Zdf1q+bOHEi9957L6+99hr+/v788MMP1y2vpKSEwsJCDhw4UCWRTE9Pv+lr0ZTU+8TypZdeYsmSJTfd5/z58zRv3pxZs2ahVqs5ePAg5ubmfPLJJ4waNYrjx4/rvz2qqZdffpn58+frlxMTE2nVqhUDBw6sNDXI3RYfH49Ge5bfNnyAqs09mLi34GiagqNpSkKaO/FEH1+6+tjLvDuNRGlpKTt37mTw4MEYG8sTZWMn97vpKS0t5YufdnKh3AW1Gnr6O2KsUhCfWchjQ5uhVOo+y9cdiSM0OgNHS1OC1JYEqa0IVFvhamPa5D7vi4qKSEhIwMrKCjMzXeZtVGK4mgNrG2ssTKr3WDV9+nRWrFjBX3/9RUhICABff/01999/vz5puBkLCwsA/vvf/zJw4EBAl2SOGjUKExMTzMzMWL16NRMnTtQ/w3Tq1IlTp06xevVq/bzYAOPHj2fmzJn6ZVNTUzQaDRs2bMDa2ppu3bqxfv16wsPD2b59O0qlks6dO7NixQqOHz/OgAEDAF0z3sLCwhvGbGxsjI2NzXXXGxkZXXfbzURGRvLxxx/z9ttv1+hYU1NTwsLC9F2GCgoKsLa25quvvqrUjagiAQNo06YNRUVFPPXUU/qk0czMjNLSUj766CMCAgIAePrpp3njjTf08VRc2+7du5k0aRIfffTRLZuDVujduze9e/fWL3fs2JHffvuNffv2MWvWLEA3h+vw4cP197h9+/asWbOG48eP07lzZ7788kuUSiXr1q3DzMyMbt26ceXKFaZPn46lpSU2Njb695K1tTU2NjasXLmS8ePHV7r+FStWEBISwscff4yZmRlvvfUWL7/88k3jv949MTU1RaVSVdnm6urKu+++S69evVAqlXz//fc89thjfP/994wePRrQfYng7e1d6Vhvb2/S0tJueP/T09Px8vKqtN3Hx4fc3FyMjY0xNzenTZs2REREkJqaiouLyw0/R4uKijA3N6dfv376z5sK12vW3lTV+8Ty2WefZdKkSTfdx9/fnz179vDrr79y5coV/Rto1apV7Ny5kw0bNvDSSy/h6urKsWPHKh2bkpIC6N7U12Nqaoqpqal+ueJbDCMjI4M98CUkJDBq1CjeeustHIsS+WRGTx6bu4A8zx5YBHVn78V09l5Mp72XHdP7+TO0tSsqZdN64GisjI2NJdFoQuR+Nx0ZecXsSFRi4whdfB15sl/AdR9wyrSgUqq4UlDKsdgsjsVmAWBtZkSQizUz+gc0mc/78vJyFAoFSqUSpVI3ZISlqTFhi4caJJ7qNoUFaNmypT5hGzhwIJGRkRw8eJC9e/fqr+VmKvbp0KGD/v8VX3anp6fj7e3N+fPnmTZtWqXy+vTpw/Llyyut69q1a6VlhUKBr68vtra2+nWurq4YGRlhZPTPY6OLiwtpaWn6Y6uTEF9PxUAt1bnuComJiQwfPpwHH3yQ6dOn1/h8zZs35+effwZ0NXVff/01Dz/8MHv37tXXwO7atYu33nqLCxcukJOTQ1lZGUVFRRQVFWFhYYFSqcTCwoKgoCB92e7u7qSmpuqvRaFQcOzYMbZu3cqGDRt4+OGHq32deXl5LFq0iK1bt5KUlERZWRmFhYUkJCRUKqN9+/aVll1dXUlPT0epVBIREUG7du30ySNAjx49APS/NxXHVvz/zJkznDlzhi+//FJ/TEWT87i4OFq2bImrq+sNn5tvpuL349+vgVqt1jdxBejevTtJSUm89957lQZ2ujbem5X373Neu/3f11vxf3d395vGrlQqUSgU1/27fO3vRVNX718JZ2dnnJ2db7lfRVX+v99cSqVS31a6Z8+evPnmm6SmpurbcO/cuRMbGxtatWpVx5HfGZcuXSI4OJikpCQAtm3bhq+vL/u/W0dwcDDx+9bhOXAixs36cDohi6c2/YWPowVP9PFjbGevajfTEUIIcfck5xRTpgEvewum9vG7YYLyVHAgRaXlRKXlEZGSx8WUXGLS8sktKiM5u6hSUrnlRAJmxiqauVjj52SJiVGjGa/vhhQKRbVrDQ1twoQJvPjii6xatYp169YREBBA//79a1TGtQ+4Fe+ZW/VV/Lfr9Zv794NzxQP1v9dde65hw4Zx8ODBG57Hx8eHc+fO1Si267l8+TIhISH06tWLjz76qFZlmJiYEBgYqF/u2LEjP/74I8uWLWPjxo3ExsYycuRIZs6cyZtvvomDgwOHDh1i6tSplJSU6BO1670mFf0pKwQEBODo6MjGjRsZO3ZspcqKm3nuuefYuXMn7777LoGBgZibmzN27Ngqg03e6r7UVF5eHtOnT2fOnDlVtnl7ewMwY8YMNm7ceMtybkf37t0rdQdxdXXVVwZVSElJuWmCe6NjbGxsMDc3v634xPU1jE/faujZsyf29vZMnDiRBQsWYG5uzscff6wfEQp0Hb9btWrFhAkTePvtt0lOTua1115j1qxZ1f5FNzRra2vUarU+3opvKL28vNi3bx/BwcGoL+1l0/J5/HA2ky/+iCMuo4D/++kcS3dFMKGHD4/39MHRqmFcrxBCNAWt3W0Y7aNhZLD/LQfqMTNW0drdltbuuhql0nINcRn5FJX+8zBZVq5h9/lUSst161RKBX5OlgS5WNPMRdd8tqEkYI3VmDFjePnll/nyyy/5/PPPmTlzZp02Z27ZsiWHDx9m4sSJ+nWHDx++Y1+kf/LJJ7dsCnu7EhMTCQkJoXPnzqxbt65GtZy3olKp9PH/+eef+v6LFef45ptvalWuk5MT3377LcHBwTz88MNs2bKlWq/F4cOHmTRpEvfddx+gS9RiY2NrdO7mzZuzceNGiouL9c+Nx48fv+kxnTp1IiwsrFLi/W+LFy/WD/R0p5w6dapSN7aePXuye/du5s6dq1+3c+dOevbsecMyevbsWWVKklsdI25Po/mr4uTkxPbt23n11VcZMGAApaWltG7dmp9++on27dsDug+NX3/9lZkzZ9KzZ08sLS2ZOHEiixcvNnD01Wdra8v27dvJysqqNHos6JLL/fv3Y21tja2tLc+6OzMzOIBvjifwyaEYLl0pZPnuCNYeiOLBzl480dcPH8fajfAlhBDi9hWUlOkTPCczcLA0qXEZxiolgWrrSuvKtVrGdvYkIjWPiJRcsgtLiUzNIzI1j9/+hraetswd1Ey/f05RKTZmt37YLSvXEJuRT3iKrsb0SkEJT/T1w9Pe4pbHisqsrKx46KGH9AOJ3KrbT009//zzPPTQQ3Ts2JFBgwbxyy+/8P3337Nr1646PU+Fmo47ERYWRklJCZmZmeTm5uqfaSrmOTx27BiPP/44u3fvxsPDg8TERIKDg/Hx8eHdd98lLS1NX1ZNm2WWlZXpB22saAobFham71cYGBhIaWkpK1asYNSoURw+fJg1a9bU6BzXUqvV/PTTT4wZM4Zx48axefPmWzafDAoK4vvvv9fPZ/5///d/Na6JHD9+PK+++irTpk3jpZdeIj4+nnfffRfghl9ivPjii/To0YPZs2fzxBNPYGlpSVhYGDt37mTlypX66/n36K03ExkZSV5eHsnJyRQWFurvdatWrTAxMWHDhg2YmJjoZ2f4/vvv+eyzz/jkk0/0ZTzzzDP079+f9957jxEjRrB582ZOnDhRqdb65ZdfJjExkc8//xzQ1ayuXLmSF154gSlTprBnzx6++eYbtm7dWv0XUdRIo0ksAbp06VJpbprr8fHxqdaEqvWZra0tFhYWVRJLoMr8lRYmRkzq7cdjPXz47WwyHx2I5u/EbL74I45NR+O4p40r0/oF0MHL7u4EL4S4oYvJuZyMv8KFpGzOhCvx6ZBDBx9HQ4cl7pCDEWl8/1ciswcE4m1Xt61ITI1UDGrlwqBWLmi1WtJyiwm/2nQ2MjWXZi7/JKKZ+SU8v+U0ahszmrlY0czFmiAXK5ytTCku02CsUuqb2H59IoE951MrnWvrmSSm9w+o0/ibiilTpvDZZ58xfPjwW/bxqqkxY8awfPly3n33XZ555hn8/PxYt07XbaY+GD58OHFxcfrliqSioilpQUEBFy9e1E/Fs3PnTiIjI4mMjKzyrHNt81OFQsG6detumqifO3dOXxtmYWFBQEAAq1ev5vHHHwd0/Rbff/99lixZwssvv0y/fv1466239Ntrw8XFhV27djFgwAAeffRRvvzyyyrTVlzr/fffZ8qUKfTq1QsnJydefPHFGo+ca2Njwy+//MLMmTPp0KEDbdu2ZcGCBYwfP77KADQV2rVrx/79+3n11Vfp27cvWq2WgICAag86dD1PPPEE+/fv1y9X3OuYmBh8fX0BeOONN4iLi8PIyIgWLVrw9ddfM3bsWP0xvXr14ssvv+S1117jlVdeISgoiB9//JE2bdro90lKSiI+Pl6/7Ofnx9atW5k3bx7Lly/H09OTTz75hKFDDdMPuylQaP/dGFzc1KVLl/Dy8iIhIaHKB9vdVFpayrZt2xg+fHiNmpdotVpCozP46EA0+y7+821fNz8HpvfzJ6S5Wj/6oKg/anu/Rf2k1WrJyC8hPCWXTt72+qaPW04ksP1sMhqthtTUVPq0CeDlEQ2j/7eomYvJuby34yLlGi33dvRgWCvnu/o7rtVq9TUWpxOyWLEngn8/DVibGZFXXM6L9zQn6GoiejQ6gy+PxdPMxRoXGzN++zsJI5WC9x/qgKXp3f2uuqioiJiYGPz8/G74kFxfaTQacnJysLGxqdPmnE1dTEwMzZo1IywsrNKgOoZWn+73pk2bmDx5MtnZ2dLPsAZu9nlTX3KD+qBR1ViKW1MoFPQKcKJXgBMXk3P56EA0P59O5FhMJsdiMglUWzGtrz/3dnTH1EgG+hGiLl3JL+G7vy5xITmXK/m6ARhsBhvTxkPXV66dpx1FZRo8bEx4/5dUwlNzSc0pQm3TsB6axc2l5hTx4d5IyjVauvo5MKqd212fYPvaZnDtvez4YFxHIlLy9E1nY9J1AwIBxGUU6BPLLr4OdPNz0A9S8velLC5dKeRYTCYhLarfNE6IO2Hbtm1MmzatXiWVhvb555/j7++Ph4cHp0+f5sUXX+Shhx6SpFLcEZJYNmHNXa1576H2PDe0GesOx/Ll0XgiU/N44bszvLvjIpN7+zG+uze25lJDJkRd+OlUIqFRGQAolQp8HS0q1RI1d7Wmuas1paWlfGMJxcChyHTu79S0vwFtTApKyvhgTwT5xWX4OlkypfeNR4C9myxMjGjvZUf7q90iSso0JFwpwN7CpFK/z2tHnVUoFPQOdOJkQhaOVjXvG9pY5RSVEpGSi4WJES3dajY3Y4Wbjbr52GOP3VZ/v8asYn7HhqB169aVmgJfa+3atTz66KN1cp7k5GQWLFhAcnIybm5uPPjgg7z55pt1UrYQ/yaJpcDN1pxXhrdk9oBAvjoaz7rDsSTnFLFk+wU+3BvJ+O7eTO3jh4vUmghRa0Wl5RyPvQLA5N5+dPG1v+non81sNfxdBkeiMhjTwUOaqDcC5Rota/ZHk5RVhJ2FCU8PCKy3U4CYGCkJcLa65X6DW7kwpHXN57NrLLRaLWl5xThYmGCk0t3LX05fZs/5VBQKWDiqNV4ONR/Y6Gajbt5oMnjRsGzbtk3ff/TfXFxc6uw8L7zwAi+88EKdlSfEzUhiKfRszIyZ3j+Ayb39+OX0ZT46EM3FFF1z2fWHY7m/kwfT+vnjX42HDSFEZX9EZ1BUWo6ztSm9Ax1vWUvlawVWDo70DHCmHlRoiTqwMyyZc4nZGKuUzBkYiJ1Fw6/lqw+1rXeTVqvl0pVCIlPzCE/J5WJKLtkFpbxwTwuau+qaCzd3seZIVAZFJeUcjkznkW7eNT5PTUfdbGyu7QPcWPn4+FRazioo4efTl7mntSvW1vJFvmiYJLEUVZgYKXmgsyf3d/Jg38U0Vu+L4lhsJpuPJ/D1iQTuae3KjP4B+iZTQojKNBotEal5GKkU+lqfilE4ewc6VeuBSaWEyb18ZLCmRiS4uZqotHx6+Ds0uqmecopKORadSXBzZ33N3d1yN8YgjEnP55fTl4lIzaOguHJ/WKVSQWpukT6x7OLrgImRkuW7IgiNzmBsZ88avyZFpeVEpuYRkZpLfEYhvQId6errUGfXU59otVpSc4sJT8klPCWPyNRc0nKLmd4/4I5ec7lGS0JmAeEpuUSm5eFoacJDXbyqfD6XlWuIyywgPrOA1u42qG8z6SsuKyc6LZ/wlFxszIz1fZMtTIw4FJFOXEYBr41o2egT64ZGxjqtHkksxQ0pFApCWqgJaaHmz7hMVu+LZtf5FH47m8xvZ5PpFeDIzOAA+lTzQVmIpmLT0Tj2XUyjg5cdTw/UDSLhZmtGv2bOMsBJE5BTVEpRSXmVQZfMjFU8FRzQ6D4vtVoti38J40p+CY5WJnT0tr8r56340qWgoKDOBiIpKtU99Eek5hKotqK1u25gLa1Wy+mELABMjXXNhINcrAlSW+HvbFllsLvW7rbYWhiTXVDK6UtZdPa5eYKUU1SKkVKhn9M0NCqDjX/80//uYkoOAc5WmBgpsbrLo+/eST+fvsy+C6lkF1ZtErr1TFKdJ5ZRaXmcT8ohPCWPqNQ8ikrL9dvMTVT0b6bG0crk6kBWuYSn5BKdlk9JmW7+SLWNGYvvbY2xSklhyT/Jf3hKHiYqBTOCA/T3sEJ+cRnhyTmcjkvjUs5l4jMLKNfokhQvBwv934TC0nLKNVpi0/M5EJFO/2bOdXrt4vaUlOgG3LvZFDFCEktRTZ19HPhkogPhKbms3R/NT6cSORKVwZGoDFq72zAzOIBhbdwqDewgRFNUUFLG4UjdAD1WZv98xCoUCib28q1xeak5RRyISMfdzoxeAU51Faa4g/6Ku8I3JxJYfG8byjVaTsZfYWhrVxQKRaNLKkH33u7m58DvZ5PZcCQWgA5ednf8WlUqFXZ2diQmpaDVarG0tKzxOfOKy4hKyycyNZ/ItHzdQ//VioneAQ4EOOjmF1VbKLmvvSsBzpZ42ZtVqoHUlpVSVFY1MerqbcvvYansO59Ma5fK/SzTcov4Oy6dy/mpRKUVkJRTzPiuHvQL0v2Oe9sZY2euItDZisvZhSRcKeLV709TWq7l/bFtMDFSkpFXwpa/EunqY4+7nZn+GiLT8jAzVjFvYEClJFSr1ZKYVURKTjFt3K0xvUEfb41GS5lGe8v+v2XlGrSA8S1qY0vLNcRlFBCZlk9Eaj6Te3nr4yoqKiYzvxijq4OZBTpb4u1gzvnkXHr6O1BYWFjr91FBSTlxGQW0dPtnztYf/ozn7OVc/bKFsRJ/Z0u0Wnisuxd2ppCRnc/b289XKsvSRIVGqyUpq4AT0Wl09LJl29/J/PJ3SqX9vjsex4i2rliY/PPaLvgpjIy8EsrKyzBSGYFCgZ25MUFqS4LUlvprNFXA/R1c2fLXZb45FkdrF/NG9SVCQ6bRaEhLS8PCwgIjI7knNyOvjqiRZi66kWTnD2nGJwej2XwsgXOXc5j95Ul8HS/yZD9/HujkedNBSYRozI7HXqG0XIObnRmTapFI/tvpS9n89ncSPo6Wdyyx1Gq1bD6egEqh4MEuno0y+bmbkrOLMFEp2XEuhbOXs0nJLqK0XMuo9u6GDu2O6RPoxO9nk8ktKmPlnkge6+lDSPMb184XlJQRkZJHXnEZvQNr9r6uGHU1IiWPi8m5RCRdwd3yCpM62d/yvVtarsVYpdunoFTD2wdS+XcDN1tTJd52Jthp84iJidGvDzADcvNIyKVaPI3KKCgo4HhUAX+7aSjXwK6oXOKySsguKqe8XINKpQR08YTFJOJlpCtcq9XyRDtzoJwkKwUfXS6goEC359GzEXjamrAvOo8jMXkcCU+ucu6eXhZcio+juEzL3ylFxGWVEJ9VQmGZ7mpbOpvySLt/apYv55QSmVlMfFYJCdmlaLQwuZMD7jb/NMUv12iJzyohLquUuKwSEnJKMVLAtK6OOFj88zhZXKYhIbv06jlLuZRTwtUKPwACLYtp4ayrzfcwKuPhFmZ42BhfvS9FUF5EL2cgN5XYXEjLL8PBXHXLL65zi8uJyyolPlt3rcm5ZWiB+b2dsTXTPZOoVYX4WWnwtjPGx84EFysjlFffM1kpl8i6WpbapAxrUyU+dib42JngbKkiPKMYE6UCu7JMYmIysSgtwVRbjI+tMbZmKvbH5vPLyXh2/Z3Ai/3U+veig6qYAkUpbjYQ6GyMr70JdmYqFAoNkEts7D9vKB9jLVaKElKzyli35xwjW8hATfWFUqnE29tb/j7egiSWolY87MxZOKo1cwYEsSE0lvVHYonNKODVH86ydGcEU/v48WgPb2zMpH+YaFoOR6YD1FkT8R7+Dmw5kUBcRj4JmQW1GmHyVo5EZbArTPfNexdfexmgqxY0Gi0l5RrMjFX4OVmyMyyF3ed1r6m9pQn9ghp3szZ3O3N6Bjjqp9PZfzGtUmKZVVBCROrVRDAll8SsQrRasDQ1oleAbjCrotJy8orLcLIy1R+n1WrRatGPinwkMp1PD8VUOrepqSnppVqwccHPybLSsam5xUSk6mrKItPyUFub8swAf/0+fuG6msZAZ0sC1ZYEOVvV2dQpfsB4hQ3NXKzwc7SgsFTD2pNn0SrNsLTQosjPILh9M5q72RDgbHnD2ik/wN2jgLziMvydLPW1YR5eGqLzL5KWV4KxSlfjF+RsiZ+TJc1ddM1mo9PzOXQyElChMDHH3kKpq0HMh3xTR9q46xKXQ0cTCE0qBIxQmhihBA4mK5jg44qHna6ZcWm5huVbzlKq0QJGGF+Nd0eCljkhXlheXT4clcF34ZeuRm+EiZkRjqZGV19fSzp42eqnsPG7xWv44b5o/r5cwKz+frT1uH6SdTTmClvPJpOaW3LNWhPMLUxwtjLBxtlN/77wu9UJr1p8nR39/Ssv+/pqCen0z2e85lAsf8ZnowAsndz1I+k/461BqynnwIED9OvW8Zb95qdZqXl/dxRhV+BeWxe878Bnvqg5ExMTlMr6OYp3fSKJpbgt9pYmzB3UjGn9/Pn6eAIfH4jmcrZuqpJVeyN5tIcPU3r7ygTvokm4nFVIVGoeCoWCnv51U7tobWZMey87/oq7UusRJm+moKSMLScS9MuHItMlsayFLX8mcDYxhzkDg+jobY+5iYrCknJMjZU8MzAIW4vG/yXbE339eaSbN/O/PkVCZoH+i5C1+6M4FpNZZX+1jRnNXKwoLtNw7nIOnx2KIUBtxcNdvQhP0SWg4Sl5jG7vTr+r/c0qvljxsDcnyMWaZmorTsRd4a+4K5y5nE8rT0f2h6dxNjGbiJRccosqD7RTVF6MiYmpPlFdPKbdHZ3yZUznf0b+NDeHx3vppu7ytjNh987fGd7Dt1oDdLXwqPo31AxYMLoN6XkleNqbX7dJajM3E7r5O+LvZEVzV2u87M357q9L7DiXgrWFOWZmunI7+TpRqlXQTG2Nh705K/ZEkHCliM+PJvL6vW305+vs54gCXeslJytTVuyJ4FJWMUdic/Q18m28HFGfT6eZi7X+x8XGtFZftHk6WhGWnM/RuGxc7a2ITM3jYkouQ1u76pNFczNTMvLLMFIp8bAzp5mr7pxBaqu7OvLyjJBmxGUU4G5nVqWfZWlpKWVlZZiZmd3yfrfzMaNnQDbHYjLZcjKZV4bLQD6i4ZDEUtQJCxMjJvf247EePvx86jJr9kcRkZrHmv1RfHYohgc6ezK9nz++To1rJEQhrlVRW9nO07ZOE4k+gU78FXel1iNM3kxJmYYAZyvCr452eSwmk0e6etfb+RXrowPhaew4p6udjMvIp4uvA0Nau7L9bBJP9vW/I7XM9ZWVqRGDWrpgYarS/w44WZmiUICnvYXugd/FimZq60q/I1725hSVlnMuMZsFidmVygxPydUnlp725iwf17FS7Z67nTl9g5z0A+38GZvJucs5ABipFPg7WxGktqKZizUBzlaV5oS92+/zioFabjR/YU1ZmxljfZOWQUYqJU8FB1Zad28HD3KLyvQD0gB09rGns88/TWMf6uLFxj/iKNdqKS3X6JPWGf0DKpU1pqMH3/91ifxrRsp1sTHj7bHtb+u6KvQOdGLHuRROxmdxMj5Lv97L3kKfWLZyt2HOwCAC1Vb6WlNDMFYpCVTXzZdyD3XxIjYj/6bNyYWojySxFHXKWKWbquS+jh7suZDK6v1R/Bl3ha+OxfP18XiGtXVjZv8A2njYGjpUIeqcpakRNubGNe4zdittPK4dYTK70gPg7bKzMOHpgUHkFZex+JdzZOSV8Ff8FZysTHC1lcEjbuVCcg5fXB29896OHnS5Oorl6PbujGrn1iRrGh7q6lVpeXBrF4a1da1Si3MttY0ZbTxsOXt1ns8AteXVWidr/J3/+UJSoVBUeU96OVhUSt77BDnT3NWG5q5W+Dha3nJwmabGzFjFE339b7pPcHM1/YKcKyXh1zO8rRv3tHa95X615WlvQXNXay4m51Yajbed5z/PEFamRo1u+jN7SxPeHNNW/7oWl5VjolI2yc8T0bDIE4O4I5RKBYNauTColQvHYzNZvS+KPRdS2Xomia1nkugb5MSM/gH6vjVCNAbD27oxtLVrnZerUiro6e/I9rPJHIpIv25imZlfQkRKLhYmRrT1rPkXN1amRvQOdOJYTCZ/RGfw96VsWrrZMHdQECXlmpsmBU1Vak4Rq/ZGodFo6ebnwKh2bpW2y2ebTnX72s8MDiA9rxhXG7PbqpXv5tc453u826qbLN6ppLLCnIFBpOcV42Zr3qRGnr/2dd30RzxnL2cTpLammYuu9t3DzvyOv/ZC1JQ8KYg7rquvA10nOXAhOYe1+6P5+fRlDkakczAinfaetjwVEsjgli7yASkahTv14NMnyImDEem42Jii1WpJyamYUFz3k5H3z8AVC0a1wsfx5s3OQ6MyCEvKYWxnT2zNdQ/+I9q6Mbq9O7vOp/L3pWzOJ+Xwn63nSckpYuGo1rjaSl/pCgUlZSzfHUF+cRm+TpZM7u0nieRtMjNW4WnfdJoNi+qR9wVEp+eRXVDKidhMTsTq+iubm6gIVFvR3MWae9q4NonPn6LScqLS8ohM1Y0oPaKt213tRytuTRJLcde0cLVh6cMdmD9YN1XJ1ycSOH0pm+lf/EmQ2oqnQgIY1c69TvuPCXE35BWXEZueTys3mzv2BYmbrTnvP9QeI5USrVbLuzsuciX/n2RSoQBzEyMKiss4lZB108SysKScLScSyC4sxd3WjGFtdTVtFb97g1u5cCwmg+g03Ui0JkZK7JrA4DM18dWxBJKzi7C3NOHpAYHSJ1UIcccsGNmamPR8/aBWkWl5FJaU8/elbNLzivWf4QAHI9JwsDQhwNmq0Uz9djYxmx9PJhKbUYBW+88EQf2CnCWxrGcksRR3nZeDBa/f24anBwax7nAMnx+JIyI1j3lfn+b9neHM6B8gc2GKBuVIZDpfH0+gnacdzwwKumPnqUj8FAoFrd1tSM0tppmLFUFqawLVVqTnFVNarsXX8ebf7v90KpHswlLUNmYMauVy3X2GtHZlzb4oAO7r6CG/j//yQCcPMvKKeaSrtzzYCCHuKBMjJc1drWnuag1cnVM0s4CIlNxKX2qVlWvY9Ec8peUaFAoFPo4WBKl1/VKDXKzq/RRwmfkl+uS5q58DLVx1U8woFBCTng/o+p82d7HGydoEG/P6fT03c+DAAd555x3+/PNPkpKS+OGHHxgzZox+e15eHi+99BI//vgjGRkZ+Pn5MWfOHGbMmKHfp6ioiGeffZbNmzdTXFzM0KFDWbVqFS4u1/+7fjdIYikMxsnKlOeHtmB6/wC+CI3js0MxJGQW8uoPZ1m+K4In+/ozvru3QUd5E+JWtFqtfjTYtp53bzLryb2rzrN2bXOxhMwCYtLz9aNpVrh0pYBd51MBeLS79w0HNungZUegixWmKiUDWsjIhP9mZ2HC80ObN4nmZ0KI+kWlVODnZFlp3laAwtJyuvja67tHxKbnE5uez86r8xT3b+7M4z19DRBxVVqtluScIsJT8q5OLVS5S4epkUqfWAY4WzG1r59+mpvGID8/n/bt2zNlyhTuv//+Ktvnz5/Pnj172LhxI76+vuzYsYOnnnoKd3d3Ro8eDcC8efPYunUrW7ZswdbWltmzZ3P//fdz+PDhu305evLELgzOxsyYWSGBTOntx+bj8Xx0IJqk7CLe3HaeD/dFMrmXHxN7+UitgKiX4jIKuHSlECOVgm5+joYOB9ANKrPo53MoFArae9np+1BqtVo2HY1Hq9XSycf+pqMzG6uUvDysJaBr6nvofCpXCkowNVJib2GinzahKTmflENOYSnd/XX3WZJKIUR9Ym1mrB/x99rav4spuSRlFVVKyq7kl/Dfbef/mQLIxRo3W7M79rlWrtFSWFquH9U5LbeY1344W2mfa2tZrx3p18xYRa+Auh1t3dCGDRvGsGHDbrj9yJEjTJw4keDgYACmTZvG2rVrOXbsGKNHjyY7O5tPP/2UL7/8kgEDBgCwbt06WrZsyR9//EGPHj3uxmVUIYmlqDfMTVRM7u3Ho919+PFkIqv3RxGTns/SXeF8dCCKx3r4MLWPH2obGUBE1B+HrtZWdvS2rzdTc6htzPB3tiQ6LZ83t4bxUBcvuvg6cCwmk/DkXIxVSh7+15QQN5NTWMqWEwmV1nk7WhCVmkdwc3WT6F+YnF3Eh3sjKSwpx0iloLOPjDwqhKi/HCxN6OHvSI+rX4TlFpVWShrDU3LJzC/hj+gM/ojOAMDKzEjfdLaTtz3O1rWvHSwp0xCTnk9Eai7hKXlEpebR2sNGP6+qs7UpTlamOFiZ6Ee6bej9QnNzc8nJydEvm5qaYmpau9ewV69e/Pzzz0yZMgV3d3f27dtHeHg4S5cuBeDPP/+ktLSUQYMG6Y9p0aIF3t7ehIaGSmIpRAUTIyUPdfXigc6ebPs7iQ/3RnIhOZe1B6JZdySWh7p4Mr1fQJOadFzUTyVlGo7G6Ebo61PHc1fert6BTkSn5ZORV8LqfVEsGm3Gb2eTARjRzq1GzYnc7cz1iWqFTw/FkFVQQkFJOWM6etR5/PVJfrFuBNjCknIC1Fa09bAzdEhCCFEj1v/qX9ney475Q5oRkZJHeEou0Wn55BWVcTI+i5PxWdiZG+sTy/S8YtLzivF3srrlF4k/nUokLCmHmLR8yjXaStsuXSnU/1+hUPC/B9o2qpYfrVq1qrS8cOFCFi1aVKuyVqxYwbRp0/D09MTIyAilUsnHH39Mv379AEhOTsbExAQ7O7tKx7m4uJCcnFyrc9YFSSxFvaVSKhjV3p2R7dzYezGVlXsi+Ss+i41/xPPVsQTube/OUyEBBKqtDR2qaKJOX8qioLgMe0sTWrndvf6V1dHD35G/L2VzKiEL0NWsvnBPc3aGpdRqrs1+zZz1ieWYjh6YGin5+ngCO8KSGd3evdFOF1RWrmH1vihSc4pwsDRhVoiMACuEaPjMjFW0dreltbuuS0RZuYbYjIKr/R3zaObyz7PV0ehMvv/rEiqlAl8nS13zWbUVpeUa0nIrj0p7NjFb/7fCxtxYv28zF2s87c0rxdCYkkqAsLAwPDz++aK1trWVoEss//jjD37++Wd8fHw4cOAAs2bNwt3dvVItZX0jiaWo9xQKBQNauBDSXM3RmEw+3BvJwYh0vj+ZyA+nEhnaypWnQgJo52ln6FBFE3M+SdfkpVeAY71LrMyMVTw9MIi/L2WzbFc4oVEZPNjZk3s71K52sU+gE2bGKpqprbG1MKakTMPPpy9TWFLOmcRsOlzTH6YxORiZzvmkHEyNlcwZGKTvryqEEI2JkUpJoNqKQLUVw9pW3qZUgK2FMdkFpUSl6pq1/nZ1m0IBIS3U+iasQ1q7UlRaTjMXa9TWpo0uebwZa2trbGxu/0vmwsJCXnnlFX744QdGjBgBQLt27Th16hTvvvsugwYNwtXVlZKSErKysirVWqakpODqWvMvj+uKJJaiwVAoFPr+AmcuZfHh3kh+P5fC9nPJbD+XTN8gJ2aFBNLdz6FJfZAJw5nQw4c+gU7Y1+OBpVq729DF14H2XjceqKc6FAoFXX3/6VdoYqSku78j+y6ksmJ3BGobU4LU1vQMcKRlPau9ra1yjZbfrzYfvr+jpzS/F0I0ScPaunFPG1fS8or1TWcjU/MwvpqMFpdp9InltX8nRO2UlpZSWlqKUlm5dYxKpUKj0QDQuXNnjI2N2b17Nw888AAAFy9eJD4+np49e971mCtIYikapHaedqyd0IWIlFxW74vip9OXORiRzsGIdLr42DMrJJDg5s6SYIo7SqFQ4O9sZegwbkqpVDAzOOCOlD20tQux6fnEZeSTmlNMak4x3g4W+sQyM7+Ev+Ku0NzVGg8783pXq3sr55NySMstxsrMiL7N6lcfWiGEuJsUCgVqazPU1mb0rmdjCjREeXl5REZG6pdjYmI4deoUDg4OeHt7079/f55//nnMzc3x8fFh//79fP7557z//vsA2NraMnXqVObPn4+DgwM2NjY8/fTT9OzZ02AD94AklqKBC3Kx5v2HOzBvcDPW7I9iy4lLnIi7wuT1x2npZsOskACGtXFD1cAeaEX9ptVqK31D21Sprc34v5GtKCgpIzI1j/AU3ah/Fc5dzuarY/GAbtTnwKv9bJq5WOHraInRDebQrC/aeNjy8vAWXCkoxdSoad9rIYQQdefEiROEhITol+fPnw/AxIkTWb9+PZs3b+bll1/m0UcfJTMzEx8fH958801mzJihP2bp0qUolUoeeOABiouLGTp0KKtWrbrr13ItSSxFo+DlYMGb97XlmYFBfHIoho1/xHE+KYfZX57EzymcmcEB3NfR44aTwQtRExGpeSzfFUHfICce6eZt6HAMzsLEiHaedlX6OVubGdPa3YbItDwKS8r5+1I2f1/KBnTzZD47pBlBLvV78C0ZHEwIIURdCw4ORqvV3nC7q6sr69atu2kZZmZmfPjhh3z44Yd1HV6tSWIpGhW1jRmvDG/JU8EBrD8Sy7rDscSk5/PCt2dYviuCGcEBPNjZs8nXNInbcyginaLScgpLyw0dSr3WwcuODl52lGu0xGfqRhuMSNX1z8krKsPN7p8RAn8+fZnTCVk0c9HNoRaktqoyPP7dUlqu4dKVQvycLA1yfiGEEKIhksRSNEp2FibMHdSMJ/r68+XROD46EENiViH/9+NZVuyOYFo/f8Z398bCRH4FRM0UlZZzIq5+zl1ZX6mUCvycLPFzsmRIa11T4rTcYqxM//n9O5+UQ2x6PrHp+ew4lwKAm53Z1aHqrenqa39Xms5qtVo+D43jj+gMJvXylb5EQgghRDVJu0DRqFmZGjGtXwCHXgzh9dGtcbM1IzW3mP9sPU+fJXv5cG8kuUWlhg5TNCAnYq9QXKpBbWNGoLp+D9xTXykUCtQ2ZpXWPdnXnyf7+RPc3Bn3qzWZSVlF7L+YxqajcZX6SZ9PyuFyVuFNmxHV1u/nkjkSmY5Wi0wtIoQQQtSAVNeIJsHMWMXEXr6M6+bN939dYtW+KOIzC3jn94us3R/FpN5+TOnti109njZC1A+HItMBXW2ljDpcdxwsTfTTCQHkFZfpms6m5AGVJ9JedziGjLwSrMyMCFLrms42c7HG28HitgbqOhl/hW//vATAuG5etPG4vSlahBBCiKZEEkvRpJgYKXmkmzdjO3vyy5nLrNwTSVRaPh/sjuDTg9E81tOHJ/r442xtauhQRT2UmlNEREouCgX0CnA0dDiNmpWpER297enobV9pfVFpOU5WpuQUlpFXVMbJ+CxOxmcBYGqspGeAExN6+NT4fAmZBXx8MBqtFoJbqBnQQl0XlyGEEEI0GZJYiibJSKXkvo6ejG7vwe/nklmxJ5LzSTms3R/N+sOxjOvmzfT+/rjZmt+6MNFkVNRWtna3xd5SarcNwcxYxQv3tKCsXENshm5AoPCUPCJScyksKefaCsuSMg1Ld4UT4Gx1tWbT6rr9qrMLS/lgdwTFpRpautkwrquX1EYLIYQQNSSJpWjSVEoFw9u6MayNK3supPLBnkhOJ2Sx/kgsXx6NZ2wXT2b2D8DLwcLQoYp6oG+QM0qFggBn6VtpaEYqJYFqKwLVVgxrqxt059KVQkyM/hk6IDYjn/DkXMKTc/kNUCjA096CIBfdfJrNXa2xMTPmYEQamfkluNiaMTM4oN7PrymEEELUR5JYCoGu/9bAli4MaKHmcGQGH+yJ4FhMJl8ejefr4wmM6eDBUyEBklA0cc7Wpozp6GHoMMR1KBSKKl8AudqaMaWPH+FXazVTc4pIyCwgIbOAPedTebCLF/e0cWVEWzeMlAo6eNljaSp/FoUQQojakL+gQlxDoVDQJ8iJPkFOHI3OYOXeSA5GpPPdX5f4/uQlRrR1Y1ZIIC3dbAwdqhDiFmzMjOkd6KSfMiS7oJTwVN2AQOEpuTR3tQZ0v/f3tHEzZKhCCCFEgyeJpRA30N3fke7+jpxKyGLlnkh2nU/h1zNJ/HomicGtXJgdEkh7LztDhynugrziMjYciaWHvyOdvO2k/10DZWthTFdfB7r6Ohg6FCGEEKLRkY4kQtxCBy87PpnYhW1z+jKinRsKBewMS+HeDw/z+GfHOB6baegQxR12NDqDv+Ku8Mvpy5JUCiGEEEJch9RYClFNrdxt+HB8JyJT81i1L5KfTl3mQHgaB8LT6O7nwNMDgugd6CiJRyNUMRpsRZNKIYQQQghRmdRYClFDgWor3n+oA3ufDWZcN2+MVQqOxmTy2KdHuW/VEXafT0Gr1Ro6TFFHEjILiM8oQKVU0MNfmlAKIYQQQlyPJJZC1JK3owVv3d+W/c+HMKmXL6ZGSk4lZDF1wwlGfHCI3/5OQqORBLOhq6itbO9lh7WZsYGjEUIIIYSonySxFOI2uduZs2h0aw69OIDp/f2xMFERlpTDzE1/MWTZAX48mUhZucbQYYpaKCvX8Ed0BgB9pBmsEEIIIcQNSWIpRB1xtjbl5WEtOfziAOYMCMTazIjI1Dzmfn2Kge/v5+vj8ZSUSYLZkJy+lEVeURm2Fsa08bA1dDhCCCGEEPWWJJZC1DF7SxPmD2nO4ZcG8PzQ5jhYmhCXUcCL3/1N8Dt7+Tw0lqLSckOHKarBWKXE18mSXgFOqJQyKJMQQgghxI3IqLBC3CE2ZsbMCglkcm9fvjwaz9oD0VzOLmLBT+dYsSeSaX39Gd/dG0tT+TWsr9p52tHO045y6SsrhBBCCHFTUmMpxB1mYWLEE339OfhCCG/c2xoPO3PScot5c9t5+izZw8o9EeQUlRo6THETUlsphBBCCHFzklgKcZeYGauY0NOXvc8F8/YD7fBxtOBKQSnv7gin9//28N6Oi2Tmlxg6TAFotVpCozIoKCkzdChCCCGEEA2CJJZC3GUmRkoe6urF7vn9Wf5IB4LUVuQWlbFiTyR9luzhv9vOk5pbZOgwm7To9Hw+ORjNS9/9LSP6CiGEEEJUgySWQhiIkUrJvR08+H1uP9Y81onW7jYUlJTz0YFo+i7Zy8KfznI5q9DQYTZJhyJ0c1e287TFSCUfk0IIIYQQtyKjhghhYEqlgnvauDG0tSv7LqbxwZ4ITsZnsSE0ji+PxTO2sxdP9vE2dJhNRnFZOcdiMgHoEyRzVwohhBBCVIcklkLUEwqFgpAWaoKbO3MkKoMPdkdwNCaTr47F882JBDo7KmmRlk9zdztDh9qo/Rl3haLScpytTWnuYm3ocIQQQgghGgRp4yVEPaNQKOgd6MTX03vyzfSe9A1yolyj5ViakntWHObpr05yMTnX0GE2Wocjdc1gewU6oVDIaLBCCCGEENUhiaUQ9Vg3Pwe+mNqdb6d3p429Bq0Wfjl9maHLDjD9ixOcTcw2dIiNSlpuMReSclEooHeAo6HDEUIIIYRoMCSxFKIBaO9py5MtNPz0VA+Gt3VFoYDfz6UwcsUhJq87xl/xVwwdYqMQkapLKlu62eBoZWrocIQQQgghGgzpYylEA9LKzYZVj3YmIiWXD/dG8vPpy+y9mMbei2n0DnTk6QFB9PCXmrba6hXgRCs3G/JLyg0dihBCCCFEgyI1lkI0QEEu1ix7pCO7nw3moS6eGCkVHI7M4JGP/uChNaEcCE9Dq9UaOswGyc7CBA87c0OHIYQQQgjRoEhiKUQD5udkydtj27P3uWAe7e6NiUrJsdhMHv/sGGNWHWFXWIokmNVUUFJm6BCEEEIIIRosSSyFaAS8HCx48762HHghhMm9fTE1UnI6IYsnPj/B8A8Ose3vJDQaSTBvpKCkjGe/Oc17Oy5KgimEEEIIUQuSWArRiLjamrFwVGsOvTiA6f39sTRRcT4ph6c2/cXQZQf46VQiZeUaQ4dZ7xyNyaSkTENWQSnmxipDhyOEEEII0eA0mMTyzTffpFevXlhYWGBnZ3fdfeLj4xkxYgQWFhao1Wqef/55ysoq1z7s27ePTp06YWpqSmBgIOvXr7/zwQtxlzlbm/LysJYcenEAcwYEYm1mRERqHs9sPsWg9/fzzYkESiXB1DscoZu7srfMXSmEEEIIUSsNJrEsKSnhwQcfZObMmdfdXl5ezogRIygpKeHIkSNs2LCB9evXs2DBAv0+MTExjBgxgpCQEE6dOsXcuXN54okn+P333+/WZQhxV9lbmjB/SHMOvzSA54Y0w97CmNiMAl749gzB7+xj4x9xFJc17RFQE7MKiUnPR6lU0FPmrhRCCCGEqJUGk1i+/vrrzJs3j7Zt2153+44dOwgLC2Pjxo106NCBYcOG8cYbb/Dhhx9SUlICwJo1a/Dz8+O9996jZcuWzJ49m7Fjx7J06dK7eSlC3HU2ZsbMHhDEoRcH8MrwFjhZmZKYVchrP56l39t7+exQDIVNdIqNitrKdh622JobGzgaIYQQQoiGqdHMYxkaGkrbtm1xcXHRrxs6dCgzZ87k3LlzdOzYkdDQUAYNGlTpuKFDhzJ37twblltcXExxcbF+OTc3F4CysjJKS0vr9iJqoOLchoxB3D11db9NlDC5pzfjunjwzZ+JfHQwhpScYhb/GsaHeyOZ0tuH8d28sDJtNB8NN1VWruFQRBoarYYefnb15vdJfr+bHrnnTYvc76ZF7nfj9u9ud01Zo3l6TE5OrpRUAvrl5OTkm+6Tk5NDYWEh5uZV56576623eP3116us3717N05OTnUVfq3t3LnT0CGIu6gu77cT8EJLOJamYGeikoz8Et7ZEcGHe8IJdtPQ11WLRaP5hLi+2FyISlRipoKEM8lc/tvQEVUmv99Nj9zzpkXud9Mi97txSk9PN3QI9YZBHxtfeukllixZctN9zp8/T4sWLe5SRFW9/PLLzJ8/X7+cmJhIq1atGDhwIB4eHgaLq7S0lJ07dzJ48GCMjaX5XmN3J+/3aGBhuYafTyex5kAMsRkFbEtQcSDViMd7eDOplzf2FiZ1es76ori0nA7xWZSWa+jfzNnQ4ejJ73fTI/e8aZH73bTI/W7cEhMTDR1CvWHQxPLZZ59l0qRJN93H39+/WmW5urpy7NixSutSUlL02yr+rVh37T42NjbXra0EMDU1xdTUVL+ck5MDgJGRUb34cDA2Nq4XcYi7407db2NjeKS7Lw929eHXM5f5cG8k4Sl5rNofzfrQOCb08OGJvv44W5veurAGxNjYmP4tXA0dxg3J73fTI/e8aZH73bTI/W6cjIwaefOuGjDoK+Hs7Iyzc93UEvTs2ZM333yT1NRU1Go1oGtyYGNjQ6tWrfT7bNu2rdJxO3fupGfPnnUSgxANnUqp4N4OHoxq586OsGRW7Ink3OUc1h6IZv2RWMZ182ZG/wBcbc0MHaoQQgghhKhHGsyosPHx8Zw6dYr4+HjKy8s5deoUp06dIi8vD4AhQ4bQqlUrJkyYwOnTp/n999957bXXmDVrlr7GccaMGURHR/PCCy9w4cIFVq1axTfffMO8efMMeWlC1DtKpYJ72rjx69N9+GxSFzp42VFcpmH9kVj6vb2XV374m4TMAkOHWWtarZbV+6LYcS6ZotKmORquEEIIIURdajCJ5YIFC+jYsSMLFy4kLy+Pjh070rFjR06cOAGASqXi119/RaVS0bNnTx577DEef/xxFi9erC/Dz8+PrVu3snPnTtq3b897773HJ598wtChQw11WULUawqFggEtXPjhqV5snNqd0u1vE/Xegyx/aQYh7+7j+S2niUnP1+9/7NgxWrduTWBgYKXfvaioKLp06UJgYCAzZsxAq9Ua4nIAyCkq5YeTiZyIzeT7vxLRGDAWIYQQQojGosE0Cl6/fj3r16+/6T4+Pj5Vmrr+W3BwMCdPnqzDyIRo/BQKBX2CnNi07HVORCSyYu2nlGm0bPnzEt/9dYlR7d2ZFRLIrFmz+Oqrr2jdujW9e/fmvvvuo23btrz44ossWrSIkSNHMnbsWLZu3crIkSPvSuwFJWWcSsgiIiWP8JRckrOL9NvuaeOKhUmD+RgUQgghhKi3GkyNpRDC8IKDg+kS5EFXXwe+f6oXA1uo0Wjhp1OXGbD4B2LSclA6+qBSqXjkkUf49ddf0Wq1HDlyhBEjRgDw2GOP8csvv9yR+LRaLYlZhZWa6eYVlfHpwRgOhKfpk0oPe3NmBAcwpqPhRnYWQgghhGhMJLEUQtRKJ297Pp3UlV+f7sM9rV0pz8ukwMiWkSsO8cSG45Sa2pGYmEhGRgYODg4oFAoAPDw86mxo7rJyDdFpeWw/m8yK3RE8s/kUC348y8+nL+v3cbY2pa2nLUNbuzJ7QCDLx3Vk8b1t6OrrUCcxCCGEEELUxIEDBxg1ahTu7u4oFAp+/PHHStsVCsV1f9555x39Pr6+vlW2/+9//7vLV1KZtAETQtyWNh62rJnQmcHqPJ77+zsUCth1PpWfLlzEMTeF+xKyKu2fl5dHUVHRdcu6dOkS1tbW2Nra3vScWq2W5bsjCE/JpbhUU2mbsUqJ8moSC7oP57mDmtXu4oQQQggh6lh+fj7t27dnypQp3H///VW2JyUlVVr+7bffmDp1Kg888ECl9YsXL+bJJ5/UL1tbW9+ZgKtJEkshRJ3o2TYIO20e383vz8q9kXx+IoOUMgumbL5A2qUUjkZn0MLRiBkzZpCUlERCQgJeXl764xMSEggODkatVrN9+3ZsbW3JLy4jMlXXNzK3qIwpffwAXbJYUFJOcakGC1MjgtRWNHOxIsjFGh8HC4xU0hhDCCGEEPXTsGHDGDZs2A23u7pWnmP7p59+IiQkBH9//0rrra2tq+xrSJJYCiHqhLu7OyqVirykaN55oC173z5Fx3EvciBDCS5BjHrhA3r3D+FSejYFubkEBwezb98+vLy89Ell7OVUtE7+fBEaQ1qxEYlZhVQM2qpQwLhu3pibqAB4qIsXpkZKPO3N9c1shRBCCCEMITc3l5ycHP2yqampfsrD25GSksLWrVvZsGFDlW3/+9//eOONN/D29mb8+PHMmzcPIyPDpXeSWAohqm3QoEGcPn2a/Px8PD092bJlC2+88QaffPIJ7u7urFy5knHjxlFUVMSECRNY9OwDJGQW8KaHhvX/mcuvuz/CzKcD3vfew+W9G+h3z2g2frSSxx9/nOjoaHzveYIe907gZHIpUAqAi60ZQWormrtYc23+GKi2MsyLIIQQQgjxL61ataq0vHDhQhYtWnTb5W7YsAFra+sqTWbnzJlDp06dcHBw4MiRI7z88sskJSXx/vvv3/Y5a0sSSyFEte3atavKumun+OnRowfnzp2rtN3LwYI1s0by2vgBvLfjIr+cTqJMo8Xl4f9QVpjHkOkLKIiOxt/fnyWvzeNshpbmrtY0c7EiUG2NrbnxHb8uIYQQQojbERYWhofHP6PN10VtJcBnn33Go48+ipmZWaX18+fP1/+/Xbt2mJiYMH36dN566606O3dNSWIphLjjsgtKWbozgpzCMrr7OxKfkc+lK4WozK1wHjmf4s4jmXtvRx7o1ZKx0qxVCCGEEA2MtbU1NjY2dVrmwYMHuXjxIl9//fUt9+3evTtlZWXExsbSvHnzOo2jumSECyHEHXcwMo2sghJMjZV09rHnia7OsHc52cd/QFNShKlbM947ls+Q9/aw/WwyGo3W0CELIYQQQhjUp59+SufOnWnfvv0t9z116hRKpRK1Wn0XIrs+qbEUQtxxUan5ADzW3Qcv00KCg4cRe7X568rXJvHU8m8p9+9DRDrM2PgnLVyteXpAEMPauKJUSg2mEEIIIRqPvLw8IiMj9csxMTGcOnUKBwcHvL29AcjJyWHLli289957VY4PDQ3l6NGjhISEYG1tTWhoKPPmzeOxxx7D3t7+rl3Hv0liKYS44+YMDCQ6PR/yMwkODiH6alJZMSrsgUAf+g8ZTqZzB+y63suFZJj15V8Eqa2YPSCQke3cUUmCKYQQQohG4MSJE4SEhOiXK/pLTpw4kfXr1wOwefNmtFot48aNq3K8qakpmzdvZtGiRRQXF+Pn58e8efMq9bs0BEkshRB3RHFZOT+fukzPAEc87S0IcLYi26Rc30SjIqkE8PLyYv+ObQQHB+OkvcR9Ly5n04kkIlLzeGbzKZbvimD2gEBGt3eXOSqFEEII0aAFBwej1d6828+0adOYNm3adbd16tSJP/74406EdlsksRRC3BF/xl1h+9lkjsdmsuSBdigUCmxtbdm+fTu5ubl4enpW2t/Ly4v9+/djbW2Nra0tTw1qyedHYvnkUAzR6fnM/+Y0y3dHMCskkPs6emAsCaYQQgghRL0hT2ZCiDvicGQ6AL0DnVBcM9Krra1tlaSygqenJ7a2tgDYmBkze0AQh14cwIv3tMDB0oS4jAJe+PYMIe/u46tj8ZSUae78hQghhBBCiFuSxFIIUefS84q5kJSLQqFLLG+HlakRM4MDOPRiCK8Ob4mTlSmXrhTy8vd/E/zOXr4IjaWotLyOIhdCCCGEELUhiaUQos5V1Fa2cLXByapuJum1MDHiyX7+HHwhhAUjW6G2NuVydhH/99M5+r+zl3WHYyTBFEIIIYQwEEkshRB1SqvV6hPLPkG3V1t5PeYmKqb08ePACyEsvrc1brZmpOQU8/ovYfRZspdPDkZTUFJW5+cVQgghhBA3JomlEE2ERqNl299JbD2TRGRqLqXld6Z/4oXkXDLySjA3UdHJ+87NpWRmrOLxnr7sez6Y/97XFg87c9LzivnP1vP0XbKXNfujyC+WBFMIIYQQ4m6QUWGFaCKOx2by3Z+X9MtGKgX+zlZM7uWL2saszs6TXViKlZkRXXzsMTG6899dmRqpGN/dmwe7ePLDX4ms3BtJfGYB//vtAmv3R/FEX38e7+mDtZnxHY9FCCGEEKKpqlZi+cEHNS948mSwtq75cUKIO+PQ1eap7nbm5BaVkltURkRKLjbm/yRcu8+nkJpbTDMXK4JcrLGpRTLWw9+RLj72FN3lEVuNVUoe6urF/Z08+OnUZVbujSQmPZ93fr/I2v1RTO3jz6TevtiaS4IphBBCCFHXqpVYzp0Lnp6gUlWv0IQEGDlSEksh6ouMvGLOJ+UAMGdgEE5WJqTkFJOYVYCZ8T+/2H9EZxCdls+usBQAXGzNaO5iTZCLFc1crHG0NKk0dciNGKmUWBlonkkjlZIHOnsypqMHv565zAe7I4hKy2fprnA+ORjN5D5+TO3th62FJJhCCCGEEHWl2k1hT5wAtbp6+0pCKYThXbpSwLnLOfQMcMTYSMmIdm5k5JXgbK0bpdXV1gxX28pNYIe0duVCci4RKbkkXikkJbuIlOwiDoSnYW1mxNKHO+j3vZJfgp2FcaVEMzotDz8ny2oln3eaSqng3g4ejGznzm9nk1ixO5KLKbl8sDuCdYdimNzblyl9/LCzMDF0qEIIIYQQDV61EsuFC8HKqvqFvvIKODjUNiQhRF3YdzGNvRdSiU3PZ3r/AO7r6HnLY7r6OtDVV/fLm1esayobkZJHRGouTlam+oRRq9Wy+NcwyjVagtS6ZrNOVias3heF2saUxfe2wdhANZb/plIqGNnOneFt3Pj9XDLLd0dwITmXD/ZE8tnhWCb39mWqJJhCCCGEELel2ollTbz8cm1CEULUlZIyDUdjMgHoHVi7KT+sTI3o6G1Px6sju2q1Wv22rIJSCkvKKS3XcCohi1MJWfpt7rbm9SapvJZSqWBYWzeGtnZlR1gyy3bpEswVeyJZdziWib18eKKPP/aWkmAKIYQQQtSUjAorRCN0+lIWBcVl2Fua0MrNpk7KvLZ5q72lCSvHdyQus4CIlFzCU/KISM2jsKSMwa1d6uR8d4pSqeCeNm4MaeXKjrAUlu+O4HxSDh/ujWL94Vgm9vLlib7+OEiCKYQQQghRbdVOLNPT4dVXITsbXnsN2rS5k2EJIW7HoQjdCLC9AhxRKu9Mf0cjlZIAZysCnK24p42uRrO0XHtXphipC7oE05UhrVzYeT6F5bsiCEvKYdW+KDYcieXxXr48KQmmEEIIIUS1VPsJcNIkcHGB++6D4cPhmlZxQoh6JDO/hHOXswHoU8tmsLWhUCgaTFJ5LaVSwdDWrmyd04ePJnSmtbsN+SXlrN4XRZ8le/jfbxfIyCs2dJhCCCGEEPVatZ8C//oLHn4YHnoIkpMhLe1OhiWEqK0jUelotRDkYo3axuzWBwhAlxgPae3Kr0/34ePHu9DGw4aCknLW7I+i79t7eeu385JgCiGEEELcQLWbwo4ZoxuUx9cX2rWr/tQjQoi7q6C4HJVSQd+gu1db2ZgoFAoGt3JhUEs1ey6ksmxXBH8nZrN2fzSfH4nj8Z4+PNnPHycrU0OHKoQQQghRb1Q7sVy5EjZvhitX4I037mRIQojb8VBXL4a3c8OkHo7M2pAoFAoGtnRhQAs1ey/qEswzl7JZeyCaz0PjmNDTh2mSYAohhBBCADVILJVKGD/+ToYihKgrVqYy4HNdUSgUDGjhQkhzNfsuprFsVzinL2Xz0YFoPg+NZUIPH6b1C8DZWhJMIYQQQjRdUqUhRCNRVFpOcnaRocNotBQKBSEt1Pw4qzfrJnelg5cdRaUaPj4YQ9+39/DGr2Gk5srrL4QQQoimqVqJZadOuiaw1dWnDyQm1jYkIURt/Bl3hVd/+JtPDkYbOpRGTaFQENJczQ9P9WL9NQnmp4di6LtkL4t/CSM1RxJMIYQQQjQt1Wovd+oUnD4NDg7VK/TUKSiWwROFuKsORermrnSzNTdwJE2DQqEguLma/s2cORCRzvJd4fwVn8Vnh2PYdDSO8d29mdk/QEbmFUIIIUSTUO2OWAMHVn/uSsWdmY9dCHEDqTlFhCfnolBArwBHQ4fTpCgUCvo3c6ZfkBOHItNZtiuCP+OusO5wLF8ejWdcN29mBgfgIgmmEEIIIRqxaiWWMTE1L9jTs+bHCCFqp6K2srW7LfaWJgaOpmlSKBT0DXKmT6AThyMzWLYrnBNxV1h/JJYvj8Uzvps3M/oH4GorCaYQQgghDCgmBg4ehLg4KCgAZ2fo2BF69gSz2j+nVCux9PGpdflCiDtMo9FyJCoDgD4yd6XBKRQK+gQ50TvQkSNRugTzeOw/Cea4rl7MDA6UBFMIIYQQd9emTbB8OZw4AS4u4O4O5uaQmQlRUbqk8tFH4cUXa5UAypwEQtRAWbkGlVKBoh619w5LyuFKfgmWpkZ08LIzdDjiKoVCQe9AJ3oFOBIalcGyXREci81kQ2gcXx1L4JFuXjwlCaYQQggh7oaOHcHEBCZNgu++Ay+vytuLiyE0FDZvhi5dYNUqePDBGp1CEkshbiI1pwilUoGTlW6OwkOR6fx4MpEgF2uC1FY0c7HGy8ECldJwiebRmEwAuvs7YKySGYTqG4VCQa9AJ3oGOBIafTXBjMnk89A4Nh9PYLz0wRRCCCHEnfa//8HQoTfebmoKwcG6nzffhNjYGp9CEkshbuLn05cJjcrgwS5e3NPGlcjUPHKLyvgr7gp/xenm4DE1VhLobEWQizUhLdRYmd7dX6sJPXxo52mLp72MBlufKRQKegU40SvAidCoDJbuCudYTGalPphPBcsoskIIIYS4A26WVP6bo6Pup4YksRTiBgpLyjkRq0seg1ysAJjYy5fg5s6Ep+QRnpJLZGoehSXlnLucQ1hSDgNbqvXHn03MRquFALUlFiZ37lfNxEhJV99qzgUk6oWeAY708O+hTzAr+mB+dSyeR7v78ERvb0OHKIQQQojG5MyZmh/TqhUYVf8Z9raedouLdbWmQjRGx2MzKS3X4GZnhr+TJQDGKiWBamsC1dYMb+uGRqPl0pVCwlNyycwvqZRA/nLmMpEpeSgU4GlvQTMXa5q56Go2bc2N6yRGrVZbr/p7iuq7tons4Uhdgvln3BU+OxzDl8fi6OGkpFteMW72dfNeEUIIIUQT1qGDbk7I6s4fqVRCeDj4+1f7FDVKLH/7Tdef8+BBSEgAjQYsLXV9QYcMgcmTdYMLCdEYVEzh0SfQ6YbJm1KpwNvRAm9HiyrbPO3MySksJTWnmITMAhIyC9h9PgWAALUVrwxveVvxJWQWsGpfJP2bOXNPG7fbKksYzrWjyB6KTGfpznD+is9iX5KSkPcPMqGHD9P7B+j7+QohhBBC1MrRo7qpRW5Fq4U2bWpcfLUSyx9+0I06m5sLw4fr/n/t6LRnz8KuXfDGG7qBht54o3oxC1FfJWUXEpWah0KhoKd/7abwmNDTF4CsghIiUnVNZ8OTc0nMKsT6mn6YWq2W/247j6OVqa5GU22Np735LWsiD0emk5pTTFRafq3iE/XLtfNg7j2fzOvf/0lcnoaPD8aw8Y94Hu/pw7R+/jhKgimEEEKImurfHwIDwc6uevv366dL9mqgWonl22/D0qUwbJiuVvTfHnpI929iIqxYARs3wrx5NYpDiHrlcKRuXsh2nrbYWtxeU0Q7CxO6+jro+0EWlJSRX1yu356RX0J0Wj7RafkcvzrCq4WpEYHOVjRzsaKNhy2u1pVjKCvXEBp9de7KQJm7sjHRJZhOzGtTjlVQV1bsjeb0pWzWHojmiz/ieLynL9P6+eNgaWLoUIUQQgjRUOzdW7P9t22r8SmqlViGhlavMA8P3Ui2QjRkWq2Wv+J1g/b0vgNJm4WJUaW+mLbmxjx/T3PCU/KISMklKi2PguIyzlzK4sylLLIKSxnbUdfUtaRMQ0RaDtmFpeQVlWFrYUwbD9s6j1EYnkIB/Zs5M7CVG/suprF0VzhnLmWzZn8Un4fGMrGXL9P6+mMvCaYQQggh6oEaD97z448wahSoVHcgGiHqAYVCwYKRrfgr/grtPe980masUtLC1YYWrjaArjYy4eqAQOHJubR2t9HvG5Oez9LdUfrlXgFOBp1DU9x5CoWCkBZqgps7s+dCKkt3hXM2MYfV+6L4/Egsk3r78mRff+wsJMEUQgghxC1s3gxZWfD442BRdYyQ21HjxHLCBLCygokTYepUCAqq03iEqBfMjFX0CjBME1MjlRI/J0v8nCwZ2toVgNLSUgAKSsqxtzThSn4JxiolfYOkGWxToVAoGNjShQEt1Ow6n8qyXeGcu5zDh3uj2HAkjsm9fXmij/9tN90WQgghRCM1Zw5ERelGeh0yBA4dqtPia5xYJiXBpk3w6afwzjvQqxc88QQ8+GCdJ71C3HXlGi1KBfV2Co+O3nZ0C3AmPa8YpUIh/eyaIIVCweBWLgxqqWZnWArLdkUQlpTDij2RrD8cy+Q+fkzt41dnU9oIIYQQopH47jvYvl034qupKaSmglp96+OqqcaJpZUVTJ+u+zlzBj7+GObP1yXAjzwCrVv/s++cOXUWpxB3xe7zKRyMSGdkOze6+zsaOpwbkqknhEKhYEhrVwa1dGFHWArLdoVzITmXD3ZHsO5wDFN6+zFFEkwhhBBCVGjfHr79Fi5eBAcHcKrblm81Tiyv1a6drnmuRgNr18Lnn4OrruUeCoUklqJh0Wq1HI5M53JWIfklZYYOR4hqUSoV3NPGlSGtXPj9XDLLdkVwMSWX5VcTzKl9/JncxxcbM0kwhRBCiCZt3Tr4v/+D8+dh69brT/dxG2qVWJ45o+v3+c03cPkyDB0KGzbA6NFgbV2n8Qlx18RnFnDpSiEqpYJufvW3tlKI61EqFQxr68bQ1q5sP5fMsl3hhKfksXRXOJ8eiubJvv5M6u2LtSSYQgghRNPk4gIffXTHiq9xmvrMM9C1qy7RXbwYUlLghx/g0UclqRQN26HIdAA6+dhjZXpblflCGIxSqWB4Wze2P9OPleM7EqS2IqeojPd2htNnyV5W7okgr1hq5IUQQghRt2qcWK5dq+vz+cMPMH68JJOicSgp0/BHdCYAfe7A3JVC3G1KpYKR7dzZPrcfH4zrSICzJdmFpby7I5w+S/bw4d5ISTCFEEKIpmL+fMjPr/7+L78MmZk1OkWNE8uLFyE4uKZHCVG/nb6URUFxGfaWJrRys7n1AUI0ECqlgtHt3dkxrz/LH+mAv7MlWQWlvPP7Rfou2cPqfVHkS4IphBBCNG7Ll0NBQfX3//BD3XyXNVCtxPKPP/75v4+PbmCeGykogHPnahSDEAZ3KELXDLZXgCNKZf2cakSI26FSKri3gwc75/Vn2cMd8Hey5EpBKUu2X6Dv23tZsz+KAhm0SgghhLjjDhw4wKhRo3B3d0ehUPDjjz9W2q5QKK7788477+j3yczM5NFHH8XGxgY7OzumTp1KXl7ejU+q1UKzZrrRYKvzU5Pazauq1ZFswgTdPJpPPAHDh4OlZdV9wsJg40bdYENLllSedkSI+m5wKxfMjFXSDFY0eiqlgjEdPRjZzo2fT1/mg90RxGYU8L/fLvDxgWim9/fnsR4+WJhIP2MhhBDiTsjPz6d9+/ZMmTKF+++/v8r2pKSkSsu//fYbU6dO5YEHHtCve/TRR0lKSmLnzp2UlpYyefJkpk2bxpdffnn9k65bV/NAXVxqtHu1nhzCwmD1anjtNV2/ymbNwN0dzMzgyhW4cAHy8uC++2DHDmjbtuZxC2FIbTxsaeNha+gwhLhrjFRK7u/kyej27vx46jIr9kQQl1HAf7dd4KMD0czoH8Cj3X0wN1EZOlQhhBCiURk2bBjDhg274XbXivkbr/rpp58ICQnB398fgPPnz7N9+3aOHz9Oly5dAFixYgXDhw/n3Xffxd3dvWqhEyfW3QXcQLWawhob6+akvHgRQkPhySehTRvw8ND1t1y7VjftyFdfSVIphBANiZFKydjOnuye3593xrbD28GC9LwS/rP1PH3f3sunh2IoKi03dJhCCCFEvZabm0tOTo7+p7i4uE7KTUlJYevWrUydOlW/LjQ0FDs7O31SCTBo0CCUSiVHjx6tk/PWRo0H7+nSBebOhaVLYc0a+M9/4IEHdE1x76Q333yTXr16YWFhgZ2dXZXtp0+fZty4cXh5eWFubk7Lli1Zvnx5lf327dtHp06dMDU1JTAwkPXr19/ZwEW9FpWWx5YTCSRlFxo6FCEMykil5MEuXux+tj9vP9AOLwdz0vOKeePXMPq9vZcNR2IpLpMEUwghhLieVq1aYWtrq/9566236qTcDRs2YG1tXanJbHJyMmq1utJ+RkZGODg4kJycXCfnrY0G04mmpKSEBx98kJ49e/Lpp59W2f7nn3+iVqvZuHEjXl5eHDlyhGnTpqFSqZg9ezYAMTExjBgxghkzZrBp0yZ2797NE088gZubG0OHDr3blyTqgf0X0zgcmU5ecRmTe/sZOhwhDM5YpeShrl7c18mD7/68xIo9kSRmFbLw53Os2R/F7AGBPNjZCxOjGn8vKYQQQjRaYWFheHh46JdNTU3rpNzPPvuMRx99FDMzszop705qMInl66+/DnDDGsYpU6ZUWvb39yc0NJTvv/9en1iuWbMGPz8/3nvvPQBatmzJoUOHWLp0qSSWTVBRaTkn4mTuSiGux1il5JFu3tzfyZNvTiSwck8kSdlFvPrDWVbtjWLOwEDu7+SJsUoSTCGEEMLa2hobm7qdsu7gwYNcvHiRr7/+utJ6V1dXUlNTK60rKysjMzOzSv/Mu6nBJJa1kZ2djcM1bXRDQ0MZNGhQpX2GDh3K3Llzb1hGcXFxpTbSubm5gO7mlZaW1m3ANVBxbkPG0NAdjcqgsKQMtbUZPvam9fq1lPvdtNSn+60AHu7szph2Lnz9ZyJr9keTmFXIi9/9zYd7I5kdHMCodq4YSYJ5W+rTPRd3ntzvpkXud+NWVnbnpur69NNP6dy5M+3bt6+0vmfPnmRlZfHnn3/SuXNnAPbs2YNGo6F79+53LJ5babSJ5ZEjR/j666/ZunWrfl1ycjIu/xo218XFhZycHAoLCzE3N69SzltvvaWvLb3W7t27cXIyfC3Xzp07DR1Cg/VznJLUQvDRavntt1hDh1Mtcr+blvp2v52AF1rB4RQFuy4ric8s5IXvz/Lutr8Z6qmhk5MWmQb29tS3ey7uLLnfTYvc78YpPT29xsfk5eURGRmpX46JieHUqVM4ODjg7e0NQE5ODlu2bNG3tLxWy5Ytueeee3jyySdZs2YNpaWlzJ49m0ceeeT6I8JeKysLfvgBDh6EuDgoKABnZ+jYEYYOhV69anw9FW4rsSwq0k05UlsvvfQSS5Ysuek+58+fp0WLFjUq9+zZs9x7770sXLiQIUOG1D5A4OWXX2b+/Pn65cTERFq1asXAgQMrtaO+20pLS9m5cyeDBw/G2NjYYHE0VKm5xfyYeQ4XawVP3d8aewsTQ4d0U3K/m5b6fr/HAAUlZWw8msAnh2JJLSjli0gVodmWzBkQwNBWLiglw6yR+n7PRd2S+920yP1u3BITE2t8zIkTJwgJCdEvV+QaEydO1Hf727x5M1qtlnHjxl23jE2bNjF79mwGDhyIUqnkgQce4IMPPrjxSS9fhgULYNMm3byR3bpBhw5gbg6ZmbB3L7z7Lvj4wMKF8PDDNb6uGieWGg28+aZuRNiUFAgPB39/+L//A19fuGYk3Ft69tlnmTRp0k33qZivpbrCwsIYOHAg06ZN47XXXqu0zdXVlZSUlErrUlJSsLGxuW5tJeg63l7b+TYnJwfQjbxUHz4cjI2N60UcDc3R2BSUCiVtPGxR21oaOpxqk/vdtNTn+21rbMysAc2Y2NufDUdi+ehANJFp+cz5+gwtXK2ZO6gZQ1u7oFBIglkT9fmei7on97tpkfvdOBkZ1byeLjg4GK1We9N9pk2bxrRp02643cHBgS+//LL6J+3YUTeX5Z9/QqtW19+nsBB+/BGWLYOEBHjuueqXTy0Sy//8BzZsgLff1s1nWaFNG10MNUksnZ2dcXZ2rmkIN3Tu3DkGDBjAxIkTefPNN6ts79mzJ9u2bau0bufOnfTs2bPOYhANg7FKiaWpEX2CDN+cWYiGzMrUiFkhgUzo6cNnh2L49GAMF5JzmbHxT1q72zB/cDMGtFBLgimEEEIYUlgYODrefB9zcxg3TveTkVHjU9R4tIXPP4ePPoJHHwWV6p/17dvDhQs1Pn+1xcfHc+rUKeLj4ykvL+fUqVOcOnWKvLw8QNf8NSQkhCFDhjB//nySk5NJTk4mLS1NX8aMGTOIjo7mhRde4MKFC6xatYpvvvmGefPm3bnARb00qr077z3Uno5edoYORYhGwcbMmLmDmnHoxQE8PSAQSxMV5y7nMHXDCcasOsL+8LRbfjsrhBBCiDvkVkklwJUrur6X1d3/X2pcY5mYCIGBVddrNHAnB7tasGABGzZs0C937NgRgL179xIcHMy3335LWloaGzduZOPGjfr9fHx8iI2NBcDPz4+tW7cyb948li9fjqenJ5988olMNdJEyTQJQtQ9Wwtjnh3SnMm9/fjoQDQbjsRyOiGLiZ8do7OPPfMHN6NXgKPUYAohhBCG8vnn119/8SJ8+KFugJ9aqHFi2aqVLpH18am8/ttvdU1375T169ffcA5LgEWLFrFo0aJblhMcHMzJkyfrLjDRoOQXl3HpSiHNXKzkwVaIO8jB0oSXhrXgib5+rNkXxRd/xPFn3BUe/eQo3fwceHZwM7r71/zbUCGEEELcpmeeqbxcXg55eaBQwKxZtS62xonlggW6fp+Jibpayu+/1yW3n38Ov/5a6ziEuCv+iM7gy6PxdPCy4+mBQYYOR4hGz8nKlNdGtmJaP39W7Yviy6PxHIvJ5OGP/qB3oCPzBzejs4/DrQsSQgghRN24cqXqurQ0eOopqMVgRBVq3Bbw3nvhl19g1y6wtNQlmufP69YNHlzrOIS4Kw5F6uYaauFmY+BIhGha1DZmLBrdmv0vBPNYD2+MVQoOR2bwwOpQJn52jFMJWYYOUQghhGi6nJ1h8WL4+ONaF1GrlLRvX5A5XkVDk5BZQHxGASqlgh7+UkMihCG42ZrznzFtmdE/gA/3RrLlxCX2h6exPzyNgS3UzBvcjDYetoYOUwghhGh6cnLAqfYzJtS+rlOIBubw1drK9l52WJvJPFJCGJKnvQVv3d+Omf0D+WBPBN//dYndF1LZfSGVIa1cmDe4GS2lZYEQQghR937+ueq6lBRYuhTuu6/y9tGjq11stRJLe3tdX87qyMys9rmFuGvKyjWERuvm4+kTKHNXClFfeDta8O6D7XkqOIAPdkfw0+nL7AhLYUdYCiPauvHMoCCauVgbOkwhhBCi8Rgz5sbbLlyAZct0/1codAP7VFO1EsuKsoVoqE5fyiKvqAxbC2NpZidEPeTvbMWyRzoye0Agy3ZF8OuZJLb+ncS2s0mMaufOM4OCCHC2MnSYQgghRMOn0dyRYquVWE6ceEfOLcRdc+ZSNgC9ApxQKWWaESHqq0C1NSvHd2L2gByW7Yxg+7lkfj59mV/PXGZMRw/mDAjC18nS0GEKIYQQ4l9q3McyJ+f66xUKMDUFE5PbDUmIujeply+9ApxwtJI3qBANQQtXG9ZM6MzZxGyW7Ypg1/kUvv8rkZ9OXWZsJ09mDwjEy8HC0GEKIYQQDcP//qebv9Lc/Nb7Hj0K6ekwYkSNTlHj6Ubs7HR9Lv/9Y2eni9PHBxYuvGM1rELUikKhoLmrNU5WpoYORQhRA208bPlkYhd+mtWb4ObOlGu0fH0igZB39/HKD39zOavQ0CEKIYQQ9V9YGHh76+aq/O033byVFcrK4MwZWLUKevWChx8G65qPb1DjGsv16+HVV2HSJOjWTbfu2DHYsAFee00X47vv6movX3mlxvEIUae0Wi1lGi3Gqhp/hyKEqEfae9mxfnI3/oy7wrJd4RyMSOfLo/F8e+IS47p58VRIIC42ZoYOUwghhKifPv8cTp+GlSth/HhdM1SVSpe0FRTo9unYEZ54QpfomdX8b2qNE8sNG+C99+Chh/5ZN2oUtG0La9fC7t26ZPjNNyWxFIYXnZ7P8l0R9GvmzNjOnoYORwhxmzr72PPF1O4cjc7g/Z3hHI3JZENoHJuPJ/Bodx9mBgfgbC0tE4QQQogq2reHjz/WJW1nzkBcHBQW6uau7NDhtuawhFoklkeOwJo1Vdd37Aihobr/9+kD8fG3FZcQdeJwZDr5xWVkFZQYOhQhRB3q7u/I19N7ciQqnfd3hHMi7gqfHY7hy2NxTOzpy7R+/jhK03chhBCiKqVSl0h26FC3xdb0AC8v+PTTqus//VS3DSAjQ9fvUghDKi4r52i0bmLVPkEyd6UQjVGvACe2zOjJ51O60cHLjqJSDWsPRNP37b28+/tFsgtKDR2iEEII0STUuMby3XfhwQd1fT67dtWtO3FCN5fmt9/qlo8f1/X5FMKQ/oy7QlFpOU5WpjSXCdaFaLQUCgX9mjnTN8iJfRfTeG/nRc4m5rBybyQbQmN5sq8/k3v7Ym1mbOhQhRBCiEarxonl6NG6JHLtWggP160bNgx+/BF8fXXLM2fWXYBC1NbhyHQAegc5oVDI3JVCNHYKhYKQFmqCmzuzIyyF93eEczEll/d3hvPZ4Rhm9A/g8Z4+WJjU+E+fEEIIIW6hVn9d/fx0U6EIUV+l5RZzISkXhQJ6BzgaOhwhxF2kUCgY2tqVwS1d+PXvJJbtCic6LZ///XaBTw5G81RwIOO7e2NmrDJ0qEIIIUSjUavEMitLN8VIamrV+Soff7wOohLiNh2J0tVWtnSzkQE8hGiilEoFo9u7M7yNKz+euszy3eEkZBay+NcwPjoQzewBgTzUxQsTI5mOSAghRBMUGQlRUdCvH5ibg1YLt9HKr8aJ5S+/wKOPQl4e2NhUPrdCIYmlqB+6+zlSUqYhUG1l6FCEEAZmpFIytrMn93Zwp9fA4Zw8epg073a8lvMKa/ZHMWdgEPd39MBIpeTYsWNMnjyZ4uJiHn/8cRYsWABAVFQUDz/8MFlZWQwaNIjVq1dLE3shhBANU0aGbkCcPXt0CVxEBPj7w9SpuhFY33uvVsXW+GvaZ5+FKVN0iWVWFly58s9PZmatYhCizrnamvFgFy86esvwxEIIHWOVkncWvcTXX35BK3cbnK1NuXSlkBe+PcPgpQf46VQis2bN4quvvuLixYts27aNv//+G4AXX3yRRYsWERkZSXp6Olu3bjXw1QghhBC1NG8eGBnp5oe0sPhn/cMPw/bttS62xollYiLMmVM5BiGEEKIhCA4OxtHeDh9HSw48H8Irw1vgYGlCTHo+sz7ezYXLWSQqnFEolDzyyCP8+uuvaLVajhw5wogRIwB47LHH+OWXXwx8JUIIIUQt7dgBS5aAp2fl9UFBEBdX62JrnFgOHaqbXkSI+qigpIyPDkTx96VstFqtocMRQtRj5iYqpvUL4MALITw3pBlmpdmUm9szc9NfjFp5iEytJZcuXSIjIwMHBwd901cPDw8SExMNHL0QQghRS/n5168lzMwE09qPTVLjPpYjRsDzz0NYGLRtC8b/mhZs9OhaxyLEbTsWk8nR6EwSMgtp49Ha0OEIIRoAK1MjZg8Ioo1JBk+d/g6FiYpzl3M4diEa6yvJ3HN1MDCA7OxsUlJSrlvOpUuXsLa2xtbW9m6FLoQQQtRc377w+efwxhu6ZYVCNyLr229DSEiti61xYvnkk7p/Fy+uuk2hgPLyWscixG07FHF17spAmbtSCFEzzfy9MS3JZveLA1h7IIqlf/3MFayY/X0kqZdS2H0mjtemP0JMTAwDBgyodGxCQgLBwcGo1Wq2b98uyaUQQoj66+23YeBAXTPUkhJ44QU4d05XY3n4cK2LrXFTWI3mxj+SVApDupxVSEx6PgqFgp4yd6UQoobc3d1RqVRcirrAC0Oa4XXlJOPGjsHUSIXCJYhxiz8jqflYUrPz2bNnDwkJCcA/SWV0dDSpqank5uYa+EqEEEKIm2jTBsLDoU8fuPdeXdPY+++HkychIKDWxdZqHsvrycqCjRth9uy6KlGImqmorWzvaYutufEt9hZCNEWDBg3i9OnT5Ofn4+npyZYtW3jjjTf45JNPcHd3Z+XKlYwbN46ioiImTJjAoqfvIym7kMXu5Xz2n7lcKcrHsnlvygO60X/MY2xc8RYTJkwgOjoaf39/9u3bh+e/B0MQQggh6htbW3j11Tot8rYTy9274dNP4YcfdH1AJbEUhlBWriE0OgOAPkFOBo5GCFFf7dq1q8q6bdu26f/fo0cPzp07V2m7m605q2eN5JVxA/hgdwTf/XUJjRY0Qd25951fyc4p0yeVXl5ed/wahBBCiBo7c6b6+7ZrV6tT1CqxTEiAdet0P/Hx8MgjusRy4MBaxSDEbfs7MZucwlKszYxo6yF9m4QQdc/LwYJ3HmzPzOAAXvv/9u47vuaz/+P462QLGSJLJEjECBW7NrGpalXvDi2ldFNqdN3tT9H2VtVqtbQ6lLa3trqXGZLYW4OiIRGNECEhE5nn98eptLmtTN+M9/PxOI+e7zjf7/u4FJ9c1/e6vtrK5viL1GzaFccmneno60COg9bNFRGRCqp1a8uEONdbNaEUk+YUubDMyYEff4SPP4aNG2HgQJgzB4YPt/SiNm9eovuLlBkf1xrcVM8ZG+tiPzosIlJkthfPsf3tx0hIy8Ol233UbNqVLSey6Td3PcPa+jKhT2P83LTYs4iIVCCxseV+iyIXlvXqQbNmMGIEfPUV1P7rB7PDh5dXNJGia1O/Nq39XMnN19qVIlJ+/jlRT0BAAJ8/fSsjnnyeDP8QHANv5pvd8fwYeYK72/sxvncgdV1qGB1ZREQEGjQo91sUubDMzbX0jJpMYG1dnpFESsZkMmFrrSVGRKR8xMfHFyoqLz1Tuf7H/xISEkL81mXU7fcwOd7NWLo9jm92x3N/x/o8ERKIh1PJF5wWEREpUz//fOX9JhM4OEBgIPj7F/uyRS4sT56E776zTNQzcSIMGmTpvdRSgWIks9nMnrhztPBxwcFWP/EQkfLj5OSEp6cnQKGJevz8/IiIiLCsYxn1La9MWcYHm0+w49hZFm8+xlc7jvNAlwY81qMRtWvaGfkVREREYOjQKz9veWmfyWRZiuTHH/8eploERX4YzcEB7r8fwsJg/34ICoIJEyw9ma++CqGhWsdSbrxjyed5LzyG577bR25evtFxRKQKc3FxYdWqVaxfv/6y2V/9/PxYv349q1atok/L+ix7tBOfj72ZVn6uXMjJ44P1R+n+ejhz10SReiHHoG8gIiKCpXDr0MHy39RUyys0FDp2hF9/hQ0bIDkZpk4t1mVLNMtJo0bwyivw55+wfDlkZcGtt4KXV0muJlJym6Ita1cG1dWkPSJS/lxcXK66TqWvry8uLpZZqU0mE90be/DjE11YNKo9zes6k5GVyzth0XSfHcb8sCNkZOXeyOgiIiIWEyfC3LmWJT2cnCyvPn0sM7M+/TR07Qpvv20pNouhVOtYWllZhsQOGgRnzsDnn5fmaiLFk52bz3atXSkiFZjJZKJPkBe9mnqy+sAp5oYe5sjpDN5Yc5hPNh/j8Z6NGNGpATZ6rERERG6UmBhwdr58v7MzHD1qed+4MSQlFeuyZdbF4+EBkyeX1dVEru+3uHNcyM7DraYdQd5X+J9DRKSCsLIyMahlXVY91YN597amYR1HzmZm8+qKQ/SYE85n2+LI1Wh+ERG5Edq1s/RMnjnz974zZ+CZZyxDZAGOHIH/eezjekrVYylipM1/DYPtGuiOlZV+3C8iFZ+1lYnbW9djcMu6fP/bCeatPcKJlAu8vPwPXO2sueAdzz03N8BWQ/tFRKS8LFoEt98Ovr5/F4/Hj0NAAPz0k2U7IwNefLFYl1VhKZVSckYWBxPSAOgSWMfgNCIixWNjbcXd7f0Y2roeX+86zrthR0hMy+LFnw7y4cZjTOzTmKFt6mGtH5qJiEhZa9oUDh6ENWvg8OG/9/XrZ3nWESwzxxaTCkuplKJOpWM2Q1NvJzydHIyOIyJSInY2Vozo1IChwV7832dr2HCmBnFnzzPlm70siIhmUt8mDG5ZV6MyRESkbFlZwcCBllcZUWEplVKXQHcaezlxIVtr3IhI5Wdva01IXTPTR3bjy10nWbg+hqNnMnnyy99YEB7NpH5N6N/cC5MWjxYRkbKwbp3ldfo05P/PQ/6ffFKiSxb7IY68PMuw3Pvug759oXfvwi+RG8XDyZ76dRyNjiEiUmYc7Wx4rGcjNj7Ti0l9m+Bkb8Mfp9J59PPd3L5gMxFRpzH/74LWIiJSqWzYsIEhQ4bg4+ODyWTixx9/vOycQ4cOcdttt+Hi4kLNmjXp0KEDcXFxBcdDQkIwmUyFXo899ljRAsyYAf37WwrLpCQ4d67wq4SK3WM5cSIsWQKDB8NNN4F+eCo32sWcPBxsrY2OISJSbpwcbJnYtzGjujTgo41HWbz5GPviUxm9eCcdGtZmav+mdAzQ8+UiIpVRZmYmrVq1YsyYMQwbNuyy4zExMXTr1o2xY8cyY8YMnJ2dOXDgAA4OhR//evjhh5k5c2bBtqNjETtcFi60FHQjR5bma1ym2IXlV1/B11/DLbeUaQ6RIrmYk8fUb/bSxMuJh7r742in0dwiUnW5Otrx9IBmPNjVn4URMXy27U92HjvHPR9uo3tjd6b0b0prP1ejY4qISDEMGjSIQYMGXfX4Cy+8wC233MLrr79esK9Ro0aXnefo6Ii3t3fxA2RnQ5cuxf/cdRR7KKydHQQGlnkOkSLZeewsF7LzOJV2kRrqtRSRasK9lj0v3tqcDU/3YkSn+thYmdh4JImhCzbz0Ke7OHgyzeiIIiLVWnp6OmlpaQWvrKysEl0nPz+f5cuX06RJEwYMGICnpycdO3a84nDZpUuX4u7uzk033cTzzz/P+fPni3aThx6CL74oUb5rKXZ3z5QpMG8ezJ+vYbBy4206Ylm7sluguyaxEJFqx9vFgVeGtuTRHo2Yt+4I3++JZ+2hRNYeSuTW4Lo81bcJgZ61jI4pIlLtNG/evND2Sy+9xPTp04t9ndOnT5ORkcFrr73GK6+8wuzZs1m1ahXDhg0jPDycnj17AnDffffRoEEDfHx82LdvH88++yxRUVF8//3317/JxYvw4Yewdi0EB4OtbeHjc+cWOzcUsbD836G/YWGwciW0aHF5jqJ8F5GSOJV6kejTGZhM0KWRni0SkerLz82RN+5qxeMhjXgr9DC/7kvg130JrNifwLC2vkzs0xg/N01uJiJyoxw8eJB69eoVbNvb25foOvl/zdB6++23M2nSJABat27Nli1bWLhwYUFh+cgjjxR8pmXLltStW5c+ffoQExNzxWGzhezbB61bW97//nuJcl5JkQpLF5fC23fcUWb3FymyzdGW3sqb6rng6mhncBoREeM18qjF/PvaMq5XGm+uOczaQ4l8uzueH387wT0d/Hiyd2O8XbTWr4hIeXNycsLZ2bnU13F3d8fGxuayHtCgoCA2bdp01c917NgRgOjo6OsXluHhpc55JUUqLBcvLpd7ixRZfr6ZzTGWwrJ7Y3eD04iIVCxBdZ35eFR7Io+n8OaaKDYeSWLp9ji+2R3PyE4NeDykEe61SvbTcxERuXHs7Ozo0KEDUVFRhfYfPnyYBg0aXPVzkZGRANStW7dkNzabYdUqy7qS335boksUe/Ke3r0hJeXy/WlpWsdSys+Bk2mkns+hpr0NrXxdjY4jIlIhtfZz5fOxHVn2SCc6NKxNdm4+izbF0uP1cOas/oPU8zlGRxQRqfYyMjKIjIwsKAZjY2OJjIwsWKfy6aefZtmyZXz00UdER0czf/58fvnlF5544gnAshzJyy+/zO7duzl27Bg///wzDzzwAD169CA4OLh4YWJj4f/+D+rXtwxLvXixxN+r2JP3RERYZqj9XxcvwsaNJc4hck0BHjUZ0akBuflmbKyL/fMQEZFqpWNAHb5+tDMbjiTx5poo9sWnsiA8hs+2/skj3QN4sJs/tey1XJOIiBF27dpFr169CrYnT54MwKhRo1iyZAl33HEHCxcuZNasWUyYMIGmTZvy3Xff0a1bN8DSq7l27VrefvttMjMz8fPz48477+TFF18sWoCsLEuv5KJFsGkT5OXBG2/A2LFQiuG8Rf5bZd++v98fPAinTv29nZdn6Tn9x/OqImWqpr0NvZp5Gh1DRKTSMJlM9GziQY/G7oQeTGRu6GH+OJXOm6GH+WRzLI+HNOKBzg1x0NJNIiI3VEhICGaz+ZrnjBkzhjFjxlzxmJ+fH+vXry/+jXfvthSTX35pWT9y5EjLe19fGDCgVEUlFKOwbN3asryIyXTlIa81asC775Yqi4iIiJQxk8lE/xbe9A3y4tf9CbwdepijSZn8Z8UffLwxlvG9A7mngx/2NiowRUSqtI4d4cknYds2aNq0zC9f5MIyNtbyTGdAAOzYAR4efx+zswNPT7DW30lSDhZtiiXAoyadA+roJ+siIiVkZWXitlY+3HKTN9//doJ5a49wIuUC0346wAfrjzKxT2OGta2nxw1ERKqqPn0sPZanT1t6KwcMsPQalpEiF5aXJiH6a2kVkRsiLvk8W6KT2H40mQ4N3YyOIyJS6dlYW3F3ez+Gtq7Hsp1xvBsWzYmUCzzz3T7eXx/DU30bMyTYByursvvHhoiIVACrV8Px45YlPx5/HC5cgHvusRwrgwKzxD+WPHjQ8lzlzz8XfomUpU1/rV3Zpn5tTTQhIlKG7GysGNm5IRue6cULtwThVtOO2KRMJn4VyaB5G1l94NR1nwESEZFKxs8Ppk2zDEf9/HM4cwZsbOD22+Hf/4Y9e0p86WL/S/3oUctMtPv3WwrbS3/nXCpy8/JKnEWkkJy8fLYdTQagW6DWrhQRKQ8OttY83COA4R3rs2RzLB9sOEpUYjqPfr6bYF8XJvdrQs8mHpjKcLiUiIhUAP36WV7nzsF//wuffAKzZ5e4oCt2j+XEieDvbxma6+gIBw7Ahg3Qvr1lKRKRsrL3eAqZWbm4OtrRwqd0s1SJiMi11bK3YXzvxmx6pjfjewXiaGfNvvhURi/eyd0fbGX7Xz/oExGRKqZ2bcukPr/9Bjt3lvgyxS4st26FmTPB3R2srCyvbt1g1iyYMKHEOUQuc2kYbJdGdfSsj4jIDeLiaMvUAU3Z8EwvHurmj52NFTuPneOeD7cxctF2Io+nGB1RRETKS9u2Jf5osQvLvDxwcrK8d3eHkyct7xs0gKioEucQKSTlfDa/n0gFoFtjDYMVEbnR3GvZ8+KtzdnwdC9GdKqPjZWJjUeSGLpgMw99uouDJ9OMjigiIhVIsQvLm26CvXst7zt2hNdfh82bLb2YAQFlHU+qqws5ebSs50pTbye8nB2MjiMiUm15uzjwytCWhE8N4V/tfLEywdpDidzyzkbGf7GH6NMZRkcUEZEKoNiF5Ysv/r3kyMyZlgmFuneHFSvgnXfKOt7fXn31Vbp06YKjoyOurq7XPDc5ORlfX19MJhMpKSmFjkVERNC2bVvs7e0JDAxkyZIl5ZZZSq6uSw0m9m3MlP5lv3iriIgUn5+bI2/c1YrQyT25NbguAL/uS6D/W+uZ+s1ejp89b3BCERExUrELy5AQy1qaAIGB8McfkJRkmcynd+8yTvcP2dnZ3HXXXTz++OPXPXfs2LEEBwdftj82NpbBgwfTq1cvIiMjeeqpp3jooYdYvXp1eUSWMmCtZytFRCqURh61mH9fW1ZO7E7fIC/yzfDt7nh6vRHBCz/s51TqRaMjiojItXz55dWPPf10iS9b5MLyzBkYNAhq1QJnZ+jUCaKjLcfc3MpkTc1rmjFjBpMmTaJly5bXPO/9998nJSWFqVOnXnZs4cKF+Pv78+abbxIUFMT48eP517/+xVtvvVVesaUEIo+nkJSRZXQMERG5hqC6znw8qj0/jutK98bu5OabWbo9jh5zwnn514P6c1xEpKJ6/HFYufLy/ZMmWZYdKaEir2P57LMQGWkZ/urgAB98AA8/DOHhJb53mTt48CAzZ85k+/btHD169LLjW7dupW/fvoX2DRgwgKeeeuqq18zKyiIr6++/HNPT0wHIzc0lJyenbIKXwKV7G5mhPGTl5LEwIprs3HxeHNwUv9qORkeqEKpqe8uVqb2rn8rc5i28a/LJA23Zcewsb62NZtefKSzaFMuXO+IY1ak+Y7s1xKWGrdExK5TK3N5SfGrvqi03N9foCMW3dCkMHw6//mpZ3gMsy418/32pirsiF5ahobBkyd/DYG+9FYKCICsL7O1LfP8yk5WVxfDhw5kzZw7169e/YmF56tQpvLy8Cu3z8vIiLS2NCxcuUKNGjcs+M2vWLGbMmHHZ/nXr1uHubvxspaGhoUZHKFOHU00cTzDhbAv7tiSwXyNhC6lq7S3Xpvaufip7m4+oC+0dTSyPs+J4Zh7vb4hlyeaj9PLJp2ddMw7WRiesWCp7e0vxqL2rpqSkJKMjFN/gwfDee3DbbZYib9Ei+OknS1HZpEmJL1vkwvLkSWjV6u/txo0tBWVCAjRsWLKbP/fcc8yePfua5xw6dIhmzZpd91rPP/88QUFBjBgxomRhrnHdyZMnF2yfOHGC5s2b06dPH+rVq1em9yqOnJwcQkND6devH7a2VecnwQfXHMEzL52hrXy4paW30XEqjKra3nJlau/qpyq1+WBgstnMuj/O8Pa6aKISM1hx3JqtybY80t2fER39cLCt3hVmVWpvuT61d9V24sQJoyOUzH33QUoKdO0KHh6wfr1lAp1SKHJhCWBtffm22Vzym0+ZMoXRo0df85yAIq5hEhYWxv79+/n2228BMP8VzN3dnRdeeIEZM2bg7e1NYmJioc8lJibi7Ox8xd5KAHt7e+z/0SWblmZZt8vGxqZC/OFga2tbIXKUhdPpF4k+k4m1lRXdm3pVme9VlqpSe8v1qb2rn6rU5oOC6zHgJh9+3Z/A26GHOZqUyezVh1m85U/G9w7kng5+2NtU7wKzKrW3XJ/au2qysSlWOWWcf3SUFeLhAW3bWnowL5k7t0S3KPKvhNls6Rn95yQ9GRnQpg1Y/WMKoLNni35zDw8PPDw8iv6Ba/juu++4cOFCwfbOnTsZM2YMGzdupFGjRgB07tyZFStWFPpcaGgonTt3LpMMUjpbopMBaF7XGbeadganERGR0rKyMnFbKx9uucmb7387wby1RziRcoFpPx3gg/VHmdinMcPa1sPGutiT1IuISHH89tuV9wcGQlra38dLMSNrkQvLxYtLfI8yERcXx9mzZ4mLiyMvL4/IyEgAAgMDqVWrVkHxeMml8c5BQUEF614+9thjzJ8/n2eeeYYxY8YQFhbG119/zfLly2/kV5EryM83syna0mbdGpfNDxtERKRisLG24u72fgxtXY9lO+N4NyyaEykXeOa7fby/Poan+jZmSLAPVlpiSkSkfNyAGVeLXFiOGlWeMa5v2rRpfPrppwXbbdq0ASA8PJyQkJAiXcPf35/ly5czadIk5s2bh6+vLx9//DEDLs1IJIY5lXaR89m51LCzprWfq9FxRESkHNjZWDGyc0Puau/H51v/5P31McQmZTLxq0jeC49hcv8m9G/uham81zATEZEyV0kGBcOSJUtYsmRJkc8PCQkpeM7yf/f/drWuYDGMj2sN5t7dmhMpF7Cz0ZAoEZGqzMHWmod7BDC8Y32WbI7lgw1HiUpM59HPdxPs68Lkfk3o2cRDBaaISHnIzITXXoN16+D0acjPL3z8CqtrFEWlKSyl6nOwtaaRRy2jY4iIyA1Sy96G8b0bM7JTQz7aeJRPNseyLz6V0Yt30qFhbab2b0rHgDpGxxQRqVoeesgyC+zIkVC3bqmeq/wnFZZiuMysXBztrPWTaRGRasrF0ZapA5ryYNeGvB8Rw2fb/mTnsXPc8+E2ujd2Z0r/pnpMQkSkrKxcCcuXW5YaKUMacyiGmxt6mOk/H+DP5Eyjo4iIiIHq1LLnxVubs+HpXozoVB9baxMbjyQxdMFmHvp0FwdPphkdUUSk8qtdG9zcyvyyxS4sZ86E8+cv33/hguWYSHHEnzvPsaRMTqZepLaWGBEREcDbxYFXhrYkbEoId7XzxcoEaw8lcss7Gxn/xR6iT2cYHVFEpPJ6+WWYNu3KRV0pFLuwnDHDsn7l/zp/3nJMpDg2/7XESGs/V5wdtGiwiIj8zc/NkTl3tSJ0ck+GtPIB4Nd9CfR/az1Tv9nL8bNl+48iEZFq4c03YfVq8PKCli2hbdvCrxIq9jOWZvOVn+/cu7dcelSlCsvNy2drTDIAXQPdDU4jIiIVVSOPWrw7vA1PhDRibuhhQg8m8u3ueH787QT3dPDjyd6N8XZxMDqmiEjlMHRouVy2yIVl7dqWgtJkgiZNCheXeXmWXszHHiuPiFJV7TuRSvrFXJxr2NKynovRcUREpIILquvMRw+0J/J4Cm+uiWLjkSSWbo/jm93xjOzUgMdDGuFey97omCIiFdtLL5XLZYtcWL79tqW3cswYy5BXl3/UAXZ20LAhdO5c9gGl6tp8xDIMtnOjOlhbaUZYEREpmtZ+rnw+tiPbjybz5prD7Dh2lkWbYvlyRxyjuzTkkR4BuDrquX0RkRupyIXlqFGW//r7Q5cuYKvH4aQUUi/ksDc+FYBuGgYrIiIl0DGgDsse7cTGI0m8uSaKvfGpvBcRw+db/+Sh7gGM6dYQJz2/LyJSWF4evPUWfP01xMVBdnbh42fPluiyxX7GsmdPyM+Hw4fh9GnL+3/q0aNEOaSaqWVvw4Q+gRxJzMDHtYbRcUREpJIymUz0aOJB98burD10mjfXRPHHqXTeWnuYxVtieaxnIx7o3ABHOy3dLSICWIaffvwxTJkCL74IL7wAx47Bjz9aZostoWL/KbttG9x3H/z5p2Vo7D+ZTJYCWOR6rK1MBPu6EuzranQUERGpAkwmE/2ae9GnmScrfk9gbuhhjp7J5LWVf/DxxljG92rE8I71sbexNjqqiIixli6Fjz6CwYNh+nQYPhwaNYLgYEuxN2FCiS5b7OVGHnsM2reH33+39JKeO/f3q4S9piIiIiJlwsrKxK3BPqx5qgdv3NUKP7caJGVkMf2Xg/SaE8GXO+LIycu//oVERKqqU6csy4wA1KoFqZbH07j1Vli+vMSXLXZheeQI/Oc/EBQErq6WSXz++RK5nh9/O8G3u+NJzsgyOoqIiFRRNtZW/KudL+smh/DqHTdR18WBk6kXef77/fR5cz3f74knL998/QuJiFQ1vr6QkGB536gRrFljeb9zJ9iXfGbtYheWHTtCdHSJ7yfVXHZuPmsPJbJyfwKn01VYiohI+bKzseL+jg0InxrCtFub417Ljriz55n89V4GvL2B5fsSyFeBKSLVyR13wLp1lvdPPgn/93/QuDE88IBlCZASKtIzlvv2/f3+ySctz3le6kH939lhg4NLnEWqgT1x57iQnUedWnY083YyOo6IiFQTDrbWjOnmz703+/Hplj9ZuD6G6NMZjPtiD83rOjOlfxN6N/PEZNLyVyJSxb322t/v77kH6teHrVstxeWQISW+bJEKy9atLRPz/HOynn8Ws5eOafIeuZ7N0Za1K7sGuusvbxERueEc7Wx4PKQR93eqzyebYvl4YywHE9IY++kuWvu5MrV/U7oG1tHfUSJSfXTubHmVUpEKy9jYUt9HhKSMLA4lpAGWwlJERMQozg62PNW3CaM6N+TDjUdZsvkYkcdTGLFoOx393Zg6oCkdGroZHVNEpOwlJ0OdOpb3x49bZoi9cAFuuw26dy/xZYtUWDZoUOLrixTYEpOM2QzN6jrhXqvkDwaLiIiUldo17Xh2YDPGdPXnvYholm6LY3vsWe5auJUeTTyY0q8JrfxcjY4pIlJ6+/dbhroeP24Z9vrVVzBwIGRmgpUVvPUWfPstDB1aossXex3Ln3++8n6TCRwcIDAQ/P1LlEWqMLPZzKYjZwD1VoqISMXj4WTPS0Na8HD3AOaHR/P1zuNsOHyGDYfP0K+5F5P7NSGorrPRMUVESu6ZZyyT5CxdCp9/blleZPBgS48lWCbTee21G1dYDh16+fOWUPg5y27d4McfoXbtEmWSKigrN59gX1f2xafQroF+Y4iISMXk41qD/9zRksd6NGLeuiP88Fs8oQcTCT2YyK3BdXmqbxMCPWsZHVNEpPh27oSwMMtsq61awYcfwhNPWHorwVJYdupU4ssXe7mR0FDo0MHy39RUyys01LIMya+/woYNlmG7U6eWOJNUQQ621ozo1IDZdwZjb2NtdBwREZFrql/HkTfvbsWaST25NbguAL/uS6D/W+uZ8vVejp89b3BCEZFiOnsWvL0t72vVgpo1C/cE1q4N6eklvnyxeywnTrQUt126/L2vTx/LMNhHHoEDB+Dtt0u1BIpUYZplT0REKpNAz1rMv68t43qlMTf0MKEHE/luTzw/RZ7gng5+jO8dSF2XGkbHFBEpmv/9t3gZ/tu82IVlTAw4X+ERA2dnOHrU8r5xY0hKKm00qSqiTqVjMkFjz1oqLEVEpFIKquvMRw+0J/J4CnNDD7Ph8BmWbo/jm93xjOjYgMdDGuHhpInpRKSCGz0a7P/6s+riRXjsMUvPJUBWVqkuXeyhsO3awdNPw5kzf+87c8byLGiHDpbtI0fAz69UuaQK+W5PPLNX/kFE1JnrnywiIlKBtfZz5bMxN/P1o5252d+N7Nx8PtkcS4/Xw5m96g9SzmcbHVFE5MpGjQJPT3BxsbxGjAAfn7+3PT3hgQdKfPli91guWgS33w6+vn8Xj8ePQ0AA/PSTZTsjA158scSZpAo5mXKBmNMZmEwm2tbXpD0iIlI13OzvxrJHOrEpOok31hxm7/EU3o+I4b9b/+Sh7gGM6dYQJwdbo2OKSAW0YcMG5syZw+7du0lISOCHH35g6P/MxHro0CGeffZZ1q9fT25uLs2bN+e7776jfv36AFy8eJEpU6bw1VdfkZWVxYABA3jvvffw8vK6+o0XLy7Hb1WCwrJpUzh4ENasgcOH/97Xr9/fEwqVcIZaqYI2R1vGRAf7uuDiqL9gRUSk6jCZTHRv7EG3QHfWHTrNm6GHOZSQxltrD7N4SyyP9WzEA50b4GhX7H9uiUgVlpmZSatWrRgzZgzDhg277HhMTAzdunVj7NixzJgxA2dnZw4cOICDg0PBOZMmTWL58uV88803uLi4MH78eIYNG8bmzZtv5FcppER/0llZWdbSHDiwrONIVZKXb2ZrTDKgtStFRKTqMplM9G3uRe9mnqz8/RRzQ6OIOZPJayv/4OONsYzr1YjhN9fHwVazoosIDBo0iEGDBl31+AsvvMAtt9zC66+/XrCvUaNGBe9TU1NZtGgRX3zxBb179wZg8eLFBAUFsW3bNjqVYsmQ0ihSYfnOO5YZXx0cLO+vZcKEsoglVcHvJ1JJvZBDLQcbWvm6GB1HRESkXFlZmRgcXJeBN3nz428neHvdYY6fvcCMXw7y4YajPNm7MXe19zU6poiUg/T0dNLS0gq27e3tsbcv/oRe+fn5LF++nGeeeYYBAwbw22+/4e/vz/PPP18wXHb37t3k5OTQt2/fgs81a9aM+vXrs3Xr1opdWL71Ftx/v6WwfOutq59nMqmwlL9t+msYbOeAOthYF3ueKBERkUrJ2srEne18ua21D9/siufdsCMkpF7k3z/sZ+H6GJ7sFYCN2eiUIlKWmjdvXmj7pZdeYvr06cW+zunTp8nIyOC1117jlVdeYfbs2axatYphw4YRHh5Oz549OXXqFHZ2dri6uhb6rJeXF6dOnSrFtyidIhWWsbFXfi9yNbl5+ZxIuQBoGKyIiFRPttZW3NexPsPa1uPLHXEsCI8h7ux5nv7ud7xqWGNV/xRDWvtiZaWluEQqu4MHD1KvXr2C7ZL0VoKlxxLg9ttvZ9KkSQC0bt2aLVu2sHDhQnr27Fn6sOVE3UhSLmysrXh16E38e3AQfm6ORscRERExjIOtNQ929WfDMyE8N6gZrjVsSbxgYuLX+xj87ibWHkzEbFYXpkhl5uTkhLOzc8GrpIWlu7s7NjY2l/WABgUFERcXB4C3tzfZ2dmkpKQUOicxMRFvb+8S3bcsFKnHcvLkol9w7tySRpGqxmQy0cijltExREREKgRHOxse69mIu9v68MKnoWw8Y8+hhDQe+mwXrfxcmdq/Cd0C3TGZ1IMpUl3Z2dnRoUMHoqKiCu0/fPgwDRo0AKBdu3bY2tqybt067rzzTgCioqKIi4ujc+fONzzzJUUqLH/7rWgX05+DApCZlYu9jZWeqxQREbkCJwcbBvqZmTmyO4u3xrF48zH2Hk9h5KId3OzvxtT+TbnZ383omCJSTjIyMoiOji7Yjo2NJTIyEjc3N+rXr8/TTz/NPffcQ48ePejVqxerVq3il19+ISIiAgAXFxfGjh3L5MmTcXNzw9nZmSeffJLOnTsbNnEPFLGwDA8v7xhSlfwYeYIdsWe5p4MfXRrp+UoREZErcXW05ZmBzXiwqz/vR8Tw3+1/siP2LHd/sJXujd2Z0r8prf1cjY4pImVs165d9OrVq2B78l/DQ0eNGsWSJUu44447WLhwIbNmzWLChAk0bdqU7777jm7duhV85q233sLKyoo777yTrKwsBgwYwHvvvXfDv8s/FXkdy6NHwd9fvZJybdm5+Ww7epbzWbk4O9gaHUdERKTC83CyZ9qQ5jzcw5/5YdEs23mcjUeS2Hgkib5BXkzp34Sgus5GxxSRMhISEnLd56rHjBnDmDFjrnrcwcGBBQsWsGDBgrKOV2JFHqvYuDGcOfP39j33QGJieUSSymxvfArns3KpXdOO5vpLUEREpMjqutTg1TtaEj41hH+188XKBGsPJTJo3kbGf7GH6NMZRkcUEbmqIheW/1tUr1gBmZllHUcqu01HLGtXdmlUR9Oni4iIlICfmyNv3NWK0Mk9GdLKB4Bf9yXQ/631TPl6L3HJ5w1OKCJyOc2uImXmbGY2B06mAtBNa1eKiIiUSiOPWrw7vA0rJ3anf3Mv8s3w3Z54er8Zwb9/2E9C6gWjI4qIFChyYWkyXf58pZ63lH/aEpOE2QxNvJ3wdHYwOo6IiEiVEFTXmQ8faE9A5PskvDuchO9e5YvtcfScE8GMXw5wJj0LgB07dtCiRQsCAwOZOXNmwedjYmJo3749gYGBPPbYY1ozU0TKRbGGwo4eDcOGWV4XL8Jjj/29fekl1ZPZbGZztGUYrHorRUREyt6056by7VdL6RRQh47+bmTn5rN48zF6vB7O7FV/8NjjT/Dll18SFRXFihUr2L9/PwDPPvss06dPJzo6mqSkJJYvX27wNxGRqqjIheWoUeDpCS4ulteIEeDj8/f2pZdUTyaTifG9GzPwJm/aNahtdBwREZEqJyQkBCcnJ2rXtOOrRzrx37Edae3nyoWcPN79ZQeHTqYQdtqBzJx87r33Xn799VfMZjNbtmxh8ODBAIwYMYJffvnF4G8iIlVRkZcbWby4PGNIVVDPtQZ3tfczOoaIiEiVZzKZ6NbYna6BdQj74zT/9/HPnK3pxttrj7B48zHa51tjc/o4ycnJuLm5Yfrr+aV69epx4sQJg9OLSFVU5MJSRERERCoWk8lEnyAvnO5pzfhdLjh71iL6dAY//3ESEk7QdEtswcz+qampJF5lrbj4+HicnJxw0fAzESkhzQorpbY1JpkP1scQfTrd6CgiIiLVkq9vPXLSklj9VA/evqc1Lvlp5Dq4Mm9zIkeOJ7Ag9CADBg3moYcewtm58DrTx48fp2fPngwcOJDU1FSDvoGIVHYqLKXU1h8+w47Ys/xxSoWliIiIEXx8fLC2tubA7/sZEuxNncTdvPD4CPzcHLGp25QZHyzjVPvHSbpoIiw8guPHjwOWojIkJISjR49y+vRp0tP1d7mIlIwKSymVxLSLHElMx2SCLo00G6yIiEh56du3L3fddRcrVqzA19eXrVu3csstt3Dy5EkA5s+fz/Dhw2nSpAmDBg1k6r39CJsSwiuvzOL81i858flUajRshfXtL9PjwefZsGlzQVEZEBBAREQEvr6+Bn9LEams9IyllMqlJUZa+LjgVtPO4DQiIiJV19q1ay/bt2LFioL3nTp14sCBA4WO29lYMfmunoy74xDLdh5nXmgUyedzMbcfzvDPD5FaoyH+jayICA/Dz08T8IlIyanHUkosP9/M5uhkALo1Vm+liIhIRWVvY80DnRuy+fm+jGxRg7zMc9jWrov7rZPxGv0Oe5KtyMs3Gx1TRCoxFZZSYgcT0kg5n01Nexta+7kaHUdERESu48ypk3wx/WFOfPAQ58IXk3c+lYSMfCZ+FcmgeRtYsT+BfBWYIlICKiylxDb9NQy2U0AdbK31W0lERKQi++dEPf5+9Vj51mRsV7/CuQ2fQfZ5Didm8MTSPQx+dxNrDpzCbFaBKSJFp2pASizQoxZ1XR3oFqhhsCIiIhVZfHz8ZRP1dOnShfVrV+OeuIu49x7EdGAlNe2sOJSQxiOf7+b2BZsJjzqtAlNEikSFpZRY3+ZevHz7TdSv42h0FBEREbkGJycnPD09C4rKSxP1+Pn5ERERgX89L7yTdrPyiQ6M69UIRztr9sWn8uDindz5/hY2HUlSgSki16RZYaVUTCaT0RFERETkOlxcXFi1ahXp6emXLSni5+fH+vXrcXJywsXFhae93RnT1Z8PNxzl063H2BOXwohF27nZ343J/ZrQKaCOQd9CRCoy9VhKsZ1KvciWmCSycvOMjiIiIiJF5OLictV1Kn19fXFxcSnYrlPLnudvCWLDM714sGtD7Gys2BF7lns/3Mb9H29j95/nblRsEakkVFhKsUVEnWbRxlg+3XLM6CgiIiJSjjydHHhpSAvWPx3CyE4NsLU2sTk6mTvf38KoT3aw93iK0RFFpIJQYSnFkpuXz9ajlrUrO/prKIyIiEh1UNelBi8PvYnwqSEMv9kPGysT6w+f4fYFm3no050cOJlqdEQRMZgKSymWvfEpZFzMxcXRlpvquVz/AyIiIlJl+NZ2ZNawYMKmhHBnW1+sTLD20GkGv7OJx/+7m6hT6UZHFBGDqLCUYtl0xNJb2aWRO9ZWmrhHRESkOqpfx5E3727F2sk9ub21DyYTrPz9FAPnbeDJL38j+nSG0RFF5AZTYSlFlnI+m/0nUgC0dqWIiIgQ4FGLefe2YfVTPRjcsi5mM/yy9yT931rP5GWRHEvKNDqiiNwglaawfPXVV+nSpQuOjo64urpe9bwlS5YQHByMg4MDnp6ejBs3rtDxffv20b17dxwcHPDz8+P1118v5+RVx9aYZMxmCPSshbeLg9FxREREpIJo4uXEgvvbsmJCd/o19yLfDN//doI+c9fz7Lf7OH72vNERRaScVZp1LLOzs7nrrrvo3LkzixYtuuI5c+fO5c0332TOnDl07NiRzMxMjh07VnA8LS2N/v3707dvXxYuXMj+/fsZM2YMrq6uPPLIIzfom1Rep9IuAtBVvZUiIiJyBc19nPnogfbsj09lbmgU4VFnWLbrON//Fs/d7f0Y1ysQH9caRscUkXJQaQrLGTNmAJYeySs5d+4cL774Ir/88gt9+vQp2B8cHFzwfunSpWRnZ/PJJ59gZ2dHixYtiIyMZO7cuSosi+DBrv4MblkX5xq2RkcRERGRCqylrwuLH7yZPXHneCv0MBuPJLF0exzf7Irnvo71eSKkEZ7OGv0kUpVUmsLyekJDQ8nPz+fEiRMEBQWRnp5Oly5dePPNN/Hz8wNg69at9OjRAzs7u4LPDRgwgNmzZ3Pu3Dlq16592XWzsrLIysoq2E5Pt8x2lpubS05OTjl/q6u7dO8bnaF2DWsgn5yc/Bt63+rOqPYWY6i9qx+1efVSndq7Zd1afPJAW3YeO8fb66LZcewcS7Yc48sdcdx/sx8Pd2+Iey17o2OWq+rU3tVRbm6u0REqjCpTWB49epT8/Hz+85//MG/ePFxcXHjxxRfp168f+/btw87OjlOnTuHv71/oc15eXgCcOnXqioXlrFmzCnpL/2ndunW4uxs/JDQ0NLTc75GbDzn5UKPK/G6pvG5Ee0vFofauftTm1Ut1a+/7vKGDo4kVx62ITc/nky1/8t9tx+jmZaZ3vXycqviAqOrW3tVFUlKS0REqDENLheeee47Zs2df85xDhw7RrFmz614rPz+fnJwc3nnnHfr37w/Al19+ibe3N+Hh4QwYMKBEGZ9//nkmT55csH3ixAmaN29Onz59qFevXomuWRZycnIIDQ2lX79+2NqW75/E246e5dOtf9KjiTvDO/iV673kym5ke4vx1N7Vj9q8eqnu7T3RbGZjdDLzwqLZF59GWIKJrUk2jOhYn4e6NcStpt31L1KJVPf2rupOnDhhdIQKw9DCcsqUKYwePfqa5wQEBBTpWnXr1gWgefPmBfs8PDxwd3cnLi4OAG9vbxITEwt97tK2t7f3Fa9rb2+Pvf3fQzTS0tIAsLGxqRB/ONja2pZ/YXnsHGZMuNZ0qBDfuTq7Ee0tFYfau/pRm1cv1bm9+zSvS+8gbyKizvDW2sPsi0/lo03HWLrjOKO6NOTh7gFVrsCszu1dldnYaEjfJYb+Snh4eODh4VEm1+ratSsAUVFR+Pr6AnD27FmSkpJo0KABAJ07d+aFF14gJyen4H/s0NBQmjZtesVhsAJn0rP4IyEdkwm6NKpjdBwRERGpIkwmE72aeRLS1IOwP07z9toj7D+RyvsRMXy25VhBgVm7ihWYIlVVpVnHMi4ujsjISOLi4sjLyyMyMpLIyEgyMjIAaNKkCbfffjsTJ05ky5Yt/P7774waNYpmzZrRq1cvAO677z7s7OwYO3YsBw4cYNmyZcybN6/QUFcpbEuMZdx4UF3nKv9wvYiIiNx4JpOJPkFe/Dy+Kx8/0J4WPs5kZufxXkQM3V8P543VUaSczzY6pohcR6Xpu502bRqffvppwXabNm0ACA8PJyQkBIDPPvuMSZMmMXjwYKysrOjZsyerVq0q6J10cXFhzZo1jBs3jnbt2uHu7s60adO01MhVmM1mNkdbCstuWrtSREREypHJZKJvcy/6BHkSejCRt9ce4WBCGvPDo/l0yzEe7NqQsd0CcHHUcFKRiqjSFJZLliy56hqWlzg7O7No0SIWLVp01XOCg4PZuHFjGaermg4lpJOckU0NO2va1NdQYRERESl/JpOJ/i286RvkxZqDiby99jB/nErnnbBoFm85xpiu/ozp5o+L1tUWqVAqzVBYufEuDYPt6O+GnY1+q4iIiMiNY2VlYuBN3qyY0J33729LUy8n0i/mMm/dEbrNDmPe2iOkXdTakCIVRaXpsZQb796b6+PvXpMmXk5GRxEREZFqysrKxKCWdRnQwptVB07x9trDHE7M4K21h1m06SgPdQ/gwa4NcXJQD6aIkdQNJVdVy96GPkFe+Lk5Gh1FREREqjkrKxO3tKzLqok9mH9fGxp71iLtYi5zQw/TbXY488OOkJGVa3RMkWpLhaWIiIiIVBpWViZuDfZh1VM9eGd4Gxp51CT1Qg5vrDlMt9lhLAiPVoEpYgAVlnKZkykXeHX5QTYdSTI6ioiIiMgVWVuZuK2VD2sm9WTeva0J8KhJyvkc5qyOovvsMN6PiCFTBabIDaPCUi6z6UgSR89k8lvcOaOjiIiIiFyTtZWJ21vXI3RST96+pzUB7jU5dz6H2av+oPvr4SxcH8P5bBWYIuVNhaUUkpuXz9ajyQB0a6y1K0VERKRysLYyMbRNPdZM6sHcu1vRsI4jZzOzeW3lH3SfHc6HG2K4kJ1ndEyRKkuFpRSy/0QqaRdycHKwoWU9F6PjiIiIiBSLjbUVw9r6snZyT964qxUN6jiSnJnNf1b8QffXw/h441EVmCLlQIWlFLI52vJcZZdG7thY67eHiIiIVE421lb8q52lwHz9X8H4udUgKSObV5Yfovvr4SzaFMvFHBWYcuNt2LCBIUOG4OPjg8lk4scffyx0fPTo0ZhMpkKvgQMHFjqnYcOGl53z2muv3cBvcTmtYykF0i7msDc+FYCuGgYrIiIiVYCttRV3t/fjjjb1+H5PPO+GRRN/7gIv/3qQhetjeLxnI+7rWB8HW2ujo0o1kZmZSatWrRgzZgzDhg274jkDBw5k8eLFBdv29vaXnTNz5kwefvjhgm0nJ2PXnldhKQW2xiSTn2+moXtN6rnWMDqOiIiISJmxtbbing71uaONb0GBeSLlAjP/KjAfU4EpN8igQYMYNGjQNc+xt7fH29v7muc4OTld95wbSWMdpYBv7RrcVM+F7uqtFBERkSrKzsaKe2+uT/jUEP5zR0vqudbgdHoWM389SPfXw/UMppRIeno6aWlpBa+srKxSXS8iIgJPT0+aNm3K448/TnJy8mXnvPbaa9SpU4c2bdowZ84ccnONnf1YPZZSoIWPCy18NGGPiIiIVH12Nlbc17E+/2rny7e741kQbunBfGX5IRauP8qjPQK4v1N9HO30z2W5vubNmxfafumll5g+fXqJrjVw4ECGDRuGv78/MTEx/Pvf/2bQoEFs3boVa2tLj/qECRNo27Ytbm5ubNmyheeff56EhATmzp1b2q9SYvo/RURERESqrX8WmN/viWd+uOUZzFdXHGLh+hge6RHAiE4NqGmvfzbL1R08eJB69eoVbF/pmciiuvfeewvet2zZkuDgYBo1akRERAR9+vQBYPLkyQXnBAcHY2dnx6OPPsqsWbNKde/S0FBYITs3n+X7EjibmW10FBERERFD/HOI7Ot3BlPfzbJMyayVf9D99XDei4gmI8vYoYZScTk5OeHs7FzwKsviLiAgAHd3d6Kjo696TseOHcnNzeXYsWNldt/iUmEp/BZ3ju/3xPPaykOYzWaj44iIiIgYxtbairs7+LFuimUdzIZ1HDmbmc3rq6LoPjuMBeHRpF/MMTqmVCPx8fEkJydTt27dq54TGRmJlZUVnp6eNzBZYerTFzb9Y+1Kk8lkcBoRERER49n+tQ7m0NY+/Lz3JPPDojmalMmc1VF8tPEoY7v6M6prQ5wdbI2OKpVMRkZGod7H2NhYIiMjcXNzw83NjRkzZnDnnXfi7e1NTEwMzzzzDIGBgQwYMACArVu3sn37dnr16oWTkxNbt25l0qRJjBgxgtq1axv1tVRYVnfJGVkcSkgDoEtgHYPTiIiIiFQsNtZWDGvry+2t6/HL3pO8E3aEo2cyeTP0sKXA7BbA6K4NcamhAlOKZteuXfTq1atg+9LzkqNGjeL9999n3759fPrpp6SkpODj40P//v15+eWXC4bX2tvb89VXXzF9+nSysrLw9/dn0qRJhZ67NIIKy2puS0wyZjM09XbC08nB6DgiIiIiFZK1lYmhbeoxpJUPv+47ybth0USfzuCttYf5eNNRxnT1Z0w3fxWYcl0hISHXfPxs9erV1/x827Zt2bZtW1nHKjU9Y1mNmc1mNv81DLab1q4UERERuS5rKxO3t67H6qd68O7wNjTxqkX6xVzmrTtCt9fCmLsmipTzmhBRqh8VltXY4cQMzqRn4WBrTbsGxo3HFhEREalsrK1MDGnlw6qJPVhwX1uaejmRnpXLO2HRdJsdzhurozinGfelGtFQ2GrsdPpF7Gys6NCwNvY21kbHEREREal0rKxMDA6uy6CbvFlz8BTz1kVzKCGN+eHRLN4cy4iO9amvSWSlGlBhWY11b+xBh4ZuZOXkGx1FREREpFKzsjIx8Ka69G/uTeihROatPcLBhDQ+2BiLnZU1xxwO81hIIHVqGbN4vUh501DYas7B1hoXRz1kLiIiIlIWrKxMDGjhzfIJ3fjogfa08HEiO9/ER5uO0W12OP9ZcYikjCyjY4qUORWW1dSp1ItGRxARERGpskwmE/2ae/HDY514uFkeLes5cyEnjw83HKXb7DBe+fUgp9P17zGpOlRYVkOnUi/ywg/7mfnLQXLzNAxWREREpLyYTCZuqm3mu0c7snh0B1r5uXIxJ5+PN8XSfXY4M345QGKaCkyp/FRYVkOb/lpixKWGLTbW+i0gIiIiUt5MJhO9mnny4xNd+HTMzbSt70pWbj6LNx+j++xwXvxxP/HnzhsdU6TENHlPNZOXb2ZLzKW1K+sYnEZERESkejGZTPRs4kGPxu5sik7i3XXR7Dh2lv9ui+OrHce5s60vT/RqRIM6NY2OKlIsKiyrmQMnU0k9n0NNexta+boaHUdERESkWjKZTHRv7EH3xh5sO5rMu2FH2BydzLJdx/l2Tzy3t/LhiV6BBHrWMjqqSJGosKxmLg2D7dyojobBioiIiFQAnQLq0CmgDrv/PMf8sCOER53h+99O8EPkCW5pWZcnewfSzNvZ6Jgi16TKohpJv5hDZFwKAN0C3Y0NIyIiIiKFtGtQm8UP3swv47vRv7kXZjMs35fAwLc38shnu9gfn2p0RJGrUmFZjew6do68fDN+bo74uTkaHUdERERErqClrwsfPtCelRO7Mzi4LiYTrDmYyJD5mxi9eAe7/zxndESRy2gobDXSo4kHbjXtsDKZjI4iIiIiItcRVNeZBfe1Jfp0Bu+FR/PT3pNERJ0hIuoMXQPrML5XYzoFuGHSv+2kAlCPZTVibWWilZ8rLX1djI4iIiIiIkUU6FmLufe0JmxKT+5p74eNlYnN0ckM/2gbd3+wlQ2Hz2A2m42OKdWcCksRERERkUqgQZ2azP5XMOuf6cXITg2ws7Zi57FzPPDJDoa+t4V1hxJVYIphVFhWAzl5+Uz/+QDf74nnYk6e0XFEREREpBTqudbg5aE3sfHZXozp6o+DrRV7j6cw9tNdDH5nEyv3J5CfrwJTbiwVltXA3uMpHD97ns3RydhpiRERERGRKsHL2YFpQ5qz6dnePNazETXtrDmYkMbjS/cwcN4Gfoo8QZ4KTLlBVGVUAxuPWNau7NKoDlZWerhbREREpCpxr2XPc4OasenZ3kzoHYiTgw2HEzOY+FUkfeeu55tdx8nJyzc6plRxKiyruHOZ2Rw4aVnzqKvWrhQRERGpsmrXtGNy/6ZserY3U/o1wdXRltikTJ7+dh+93ojgi+1xZOXqsSgpHyosq7itR5Mxmy2ziXm7OBgdR0RERETKmUsNW57s05jNz/bm+UHNcK9lR/y5C/z7h/2EzIlg8eZYLmSrwJSypcKyCjObzWyKtgyD7dZYvZUiIiIi1UlNexse7dmIjc/0ZtqtzfFytich9SIzfjlIt9lhLAiPJu1ijtExpYpQYVmFxZzJIDH1InY2VnRo6GZ0HBERERExQA07a8Z082fDM714ZehN+LnVIDkzmzmro+j6WhhvrI7ibGa20TGlkrMxOoCUHycHW0KaemBjbYWDrbXRcURERETEQPY21ozo1IB7O/jxy76TvBcew5HTGcwPj2bRpliG31yfh3v4U9elhtFRpRJSYVmFeTk7MLJzQ6NjiIiIiEgFYmNtxR1tfLm9VT3WHExkQXg0+0+k8snmWD7fdox/tfPl0R6NaOhe0+ioUomosBQRERERqYasrEwMvMmbAS282HgkiQXh0WyPPcuXO46zbOdxhrTy4YmQQJp6OxkdVSoBPWNZRa3cn0D06XTMZi2KKyIiIiJXZzKZ6NHEg2WPdubbxzrTq6kH+Wb4KfIkA97ewMOf7SLyeIrRMaWCU2FZBZ1Ov8i3u+N5beUfpJzXTF8iIiIiUjTtG7qx+MGb+fXJbgxuWReTCUIPJjJ0wWbu/3gbW2KS1HEhV6ShsFXQluhkAJr7uFC7pp3BaURERESksrmpngsL7m9LzJkM3o+I4cffTrA5OpnN0cm0qe/K+F6B9G7miclkMjqqVBDqsaxi8vP/sXZloNauFBEREZGSa+RRizfuakXE0yE80LkBdjZW/BaXwthPdzFo3kZ+3nuSvHz1YIoKyyrn0Kk0zmVmU8POmtZ+rkbHEREREZEqwLe2IzNvv4lNz/bi0Z4B1LSz5o9T6Uz48jf6vBnBsp1xZOfmGx1TDKTCsorZdMTSW9kpoA52NmpeERERESk7nk4OPD8oiC3P9WFS3ya4OtpyLPk8z363n55zwlm8OZYL2XlGxxQDqPKoQjKzctkTdw7QMFgRERERKT8ujrZM7NuYzc/25sXBQXg62ZOQepEZvxyk2+wwFoRHk3ZRk0hWJyosq5DT6Vm41LDFt3YNGtRxNDqOiIiIiFRxNe1teKh7ABue6cWrd9yEn1sNkjOzmbM6iq6vhTFn9R8kZWQZHVNuAM0KW4X4u9dk9p3BpJzP0QxdIiIiInLDONhac3/HBtzT3o9f9p3kvfAYjpzOYEF4DB9vjOWeDn483D0APzd1flRV6rGsYkwmk5YYERERERFD2FhbcUcbX1Y/1YOFI9rRys+VrNx83nj6YRrW86Rxx778cSrtss/t2LGDFi1aEBgYyMyZMwv2x8TE0L59ewIDA3nssce0hmYFpsKyiog/d57cPM3EJSIiIiLGs7IyMfAmb358ogtfPNyRrrePpM7gyZxMucDAtzcyZslOdh47W3D+uHHj+PLLL4mKimLFihXs378fgGeffZbp06cTHR1NUlISy5cvN+oryXWosKwCcvPyeWN1FFO/2cvJlAtGxxERERERASyj6bo0cid0zhPMvudmvF1qYDJB2B+nuWvhVv71/haWrd9Lbm4uwcHBWFtbc++99/Lrr79iNpvZsmULgwcPBmDEiBH88ssvBn8juRoVllXAvhOppF/MxWQy4eXsYHQcEREREZHL+HvUok19V8KmhDD85vrYWVux689zPPVJOPHZNfjxtxPk5uVTr149Tpw4QXJyMm5ubgVzh1zaLxWTCssqYPNfa1d2blQHaytN2iMiIiIiFZe/e01mDWvJpmd78WjPABztrMnMyuWpZZGEvBHB+sOnyc0r/CxlamoqiYmJV7xefHw8qampNyK6XEOlKSxfffVVunTpgqOjI66urlc8Z+fOnfTp0wdXV1dq167NgAED2Lt3b6Fz9u3bR/fu3XFwcMDPz4/XX3/9BqQvP6kXctgbb/kfSWtXioiIiEhl4enswPODglj+3G3UMWVQp6Yd8ecu8EXYXn45coEv954lOfksKSkpDBw4kIceeghnZ+dC1zh+/Dg9e/Zk4MCBKi4NVmkKy+zsbO666y4ef/zxKx7PyMhg4MCB1K9fn+3bt7Np0yacnJwYMGAAOTmWxVnT0tLo378/DRo0YPfu3cyZM4fp06fz4Ycf3sivUqa2x57FbDYT4FETH9caRscRERERESmWZo0a4OXiyMJb3JlxazNyjmzC3KAdb4YeIdPFn4f/8wmJaRdJTEwkLCyM48ePA5aiMiQkhKNHj3L69GnS09MN/ibVW6VZx3LGjBkALFmy5IrH//jjD86ePcvMmTPx8/MD4KWXXiI4OJg///yTwMBAli5dSnZ2Np988gl2dna0aNGCyMhI5s6dyyOPPHKjvkqZMZthc0wyAF3VWykiIiIiFVTfvn3Zu3cvmZmZ+Pr68s033/Dyyy/z8ccf4+Pjw/z58xn9wAguXrzIpNEjaDdsKO9HxLC/xyh+/ux18rMyqeXfmqRziYSEhPD5558zcuRIjh49SkBAABEREfj6+hr9Nau1SlNYXk/Tpk2pU6cOixYt4t///jd5eXksWrSIoKAgGjZsCMDWrVvp0aMHdnZ/r/M4YMAAZs+ezblz56hdu/Zl183KyiIrK6tg+9JPQnJzcwt6Qo2Qk5PD2Sw4mXEBO1tr2vg6GZpHyteltlUbVw9q7+pHbV69qL2rF7W3xcqVKy/b99NPPwGWX5t27doRGRlZ6Pig5h6sPxLIB21asOvPFMtOcz5ZZ+O5+5NIUrNtCQoKYsWKFXh7exvya5ybm3vD71lRmcyVbJXRJUuW8NRTT5GSknLZsd9//52hQ4cSGxsLQOPGjVm9ejUNGjQAoH///vj7+/PBBx8UfObgwYO0aNGCgwcPEhQUdNk1p0+fXtBb+k8ff/wx7u7G9xImX4SzWSYau1SqZhQRERERKbKYNFh30ooD5/5+km/STbk0dDIwFJCUlMRDDz3E8ePHi9xjumHDBubMmcPu3btJSEjghx9+YOjQoQXHR48ezaefflroMwMGDGDVqlUF22fPnuXJJ5/kl19+wcrKijvvvJN58+ZRq1atMvleJWFoj+Vzzz3H7Nmzr3nOoUOHaNas2XWvdeHCBcaOHUvXrl358ssvycvL44033mDw4MHs3LmTGjVK9vzh888/z+TJkwu2T5w4QfPmzenTpw/16tUr0TXLQk5ODqGhodw7pB+2traG5ZAb41J79+un9q4O1N7Vj9q8elF7Vy9q77Iz7MQJBt71AAlpltGE/14YQwMfT1asWGHYv8tLsvxJZmYmrVq1YsyYMQwbNuyK5wwcOJDFixcXbNvb2xc6fv/995OQkEBoaCg5OTk8+OCDPPLII3zxxRfFzlNWDC0sp0yZwujRo695TkBAQJGu9cUXX3Ds2DG2bt2KlZVVwb7atWvz008/ce+99+Lt7X3ZNMWXtr29va94XXt7+0INmZaWBoCNjU2F+MPB1ta2QuSQG0PtXb2ovasftXn1ovauXtTepXP8+HH69OlT8EzlpWcsDx06RJ8+fYiIiCiYZ+VGsrGxlFPp6ekFdQJcXkP806BBgxg0aNA1r2tvb3/V+uTQoUOsWrWKnTt30r59ewDeffddbrnlFt544w18fHxK8lVKzdBZYT08PGjWrNk1X/98HvJazp8/j5WVVcECqkDBdn5+PgCdO3dmw4YNhcZfh4aG0rRp0ys+XykiIiIiIsaKj48vmP310kQ9Xbp0ISIigoCAAI4ePUpISAjx8fGGZWzevDkuLi4Fr1mzZpXqehEREXh6etK0aVMef/xxkpOTC45t3boVV1fXgqISLJMjWVlZsX379lLdtzQqzXIjcXFxREZGEhcXR15eHpGRkURGRpKRkQFAv379OHfuHOPGjePQoUMcOHCABx98EBsbG3r16gXAfffdh52dHWPHjuXAgQMsW7aMefPmFRrqKiIiIiIiFYeTkxOenp4FReWlnkk/P7+C4tLT0xMnJ+MeuDx48CCpqakFr+eff77E1xo4cCCfffYZ69atY/bs2axfv55BgwaRl5cHwKlTp/D09Cz0GRsbG9zc3Dh16lSpvkdpVJpZYadNm1boIdY2bdoAEB4eTkhICM2aNeOXX35hxowZdO7cGSsrK9q0acOqVauoW7cuAC4uLqxZs4Zx48bRrl073N3dmTZtWqVcakREREREpDpwcXFh1apVpKenXzZBjp+fH+vXr8fJyQkXFxeDElqKX2dn5zK51r333lvwvmXLlgQHB9OoUSMiIiLo06dPmdyjPFSawnLJkiVXXcPykn79+tGvX79rnhMcHMzGjRvLMJmIiIiIiJSnS0NMr6Sqr18ZEBCAu7s70dHR9OnTB29vb06fPl3onNzcXM6ePXvV5zJvhEozFFZERERERKS6iY+PJzk5uWAUZufOnUlJSWH37t0F54SFhZGfn0/Hjh2Nill5eixFREREREQqu4yMDKKjowu2Y2NjiYyMxM3NDTc3N2bMmMGdd96Jt7c3MTExPPPMMwQGBjJgwAAAgoKCGDhwIA8//DALFy4kJyeH8ePHc++99xo2Iyyox1JEREREROSG2bVrF23atCmYM2by5Mm0adOGadOmYW1tzb59+7jtttto0qQJY8eOpV27dmzcuLHQ8iVLly6lWbNm9OnTh1tuuYVu3brx4YcfGvWVAPVYioiIiIiI3DAhISGYzearHl+9evV1r+Hm5sYXX3xRlrFKTT2WIiIiIiIiUioqLEVERERERKRUVFiKiIiIiIhIqaiwFBERERERkVJRYSkiIiIiIiKlosJSRERERERESkXLjRRTfn4+AAkJCYbmyM3NJSkpiRMnTmBjo2as6tTe1Yvau/pRm1cvau/qRe1dtV2qCS7VCNWZfncXU2JiIgA333yzwUlERERERKQiSExMpH79+kbHMJTJfK3VOeUyubm5/Pbbb3h5eWFlZdxI4vT0dJo3b87BgwdxcnIyLIfcGGrv6kXtXf2ozasXtXf1ovau2vLz80lMTKRNmzbVvkdahWUllZaWhouLC6mpqTg7OxsdR8qZ2rt6UXtXP2rz6kXtXb2ovaW60OQ9IiIiIiIiUioqLEVERERERKRUVFhWUvb29rz00kvY29sbHUVuALV39aL2rn7U5tWL2rt6UXtLdaFnLEVERERERKRU1GMpIiIiIiIipaLCUkREREREREpFhaWIiIiIiIiUigpLERERERERKRUVlpXUggULaNiwIQ4ODnTs2JEdO3YYHUnKyYYNGxgyZAg+Pj6YTCZ+/PFHoyNJOZk1axYdOnTAyckJT09Phg4dSlRUlNGxpJy8//77BAcH4+zsjLOzM507d2blypVGx5Ib5LXXXsNkMvHUU08ZHUXKwfTp0zGZTIVezZo1MzqWSLlSYVkJLVu2jMmTJ/PSSy+xZ88eWrVqxYABAzh9+rTR0aQcZGZm0qpVKxYsWGB0FCln69evZ9y4cWzbto3Q0FBycnLo378/mZmZRkeTcuDr68trr73G7t272bVrF7179+b222/nwIEDRkeTcrZz504++OADgoODjY4i5ahFixYkJCQUvDZt2mR0JJFypeVGKqGOHTvSoUMH5s+fD0B+fj5+fn48+eSTPPfccwank/JkMpn44YcfGDp0qNFR5AY4c+YMnp6erF+/nh49ehgdR24ANzc35syZw9ixY42OIuUkIyODtm3b8t577/HKK6/QunVr3n77baNjSRmbPn06P/74I5GRkUZHEblh1GNZyWRnZ7N792769u1bsM/Kyoq+ffuydetWA5OJSFlLTU0FLMWGVG15eXl89dVXZGZm0rlzZ6PjSDkaN24cgwcPLvT3uFRNR44cwcfHh4CAAO6//37i4uKMjiRSrmyMDiDFk5SURF5eHl5eXoX2e3l58ccffxiUSkTKWn5+Pk899RRdu3blpptuMjqOlJP9+/fTuXNnLl68SK1atfjhhx9o3ry50bGknHz11Vfs2bOHnTt3Gh1FylnHjh1ZsmQJTZs2JSEhgRkzZtC9e3d+//13nJycjI4nUi5UWIqIVEDjxo3j999/1zM5VVzTpk2JjIwkNTWVb7/9llGjRrF+/XoVl1XQ8ePHmThxIqGhoTg4OBgdR8rZoEGDCt4HBwfTsWNHGjRowNdff62h7lJlqbCsZNzd3bG2tiYxMbHQ/sTERLy9vQ1KJSJlafz48fz6669s2LABX19fo+NIObKzsyMwMBCAdu3asXPnTubNm8cHH3xgcDIpa7t37+b06dO0bdu2YF9eXh4bNmxg/vz5ZGVlYW1tbWBCKU+urq40adKE6Ohoo6OIlBs9Y1nJ2NnZ0a5dO9atW1ewLz8/n3Xr1um5HJFKzmw2M378eH744QfCwsLw9/c3OpLcYPn5+WRlZRkdQ8pBnz592L9/P5GRkQWv9u3bc//99xMZGamisorLyMggJiaGunXrGh1FpNyox7ISmjx5MqNGjaJ9+/bcfPPNvP3222RmZvLggw8aHU3KQUZGRqGfcMbGxhIZGYmbmxv169c3MJmUtXHjxvHFF1/w008/4eTkxKlTpwBwcXGhRo0aBqeTsvb8888zaNAg6tevT3p6Ol988QURERGsXr3a6GhSDpycnC57XrpmzZrUqVNHz1FXQVOnTmXIkCE0aNCAkydP8tJLL2Ftbc3w4cONjiZSblRYVkL33HMPZ86cYdq0aZw6dYrWrVuzatWqyyb0kaph165d9OrVq2B78uTJAIwaNYolS5YYlErKw/vvvw9ASEhIof2LFy9m9OjRNz6QlKvTp0/zwAMPkJCQgIuLC8HBwaxevZp+/foZHU1ESik+Pp7hw4eTnJyMh4cH3bp1Y9u2bXh4eBgdTaTcaB1LERERERERKRU9YykiIiIiIiKlosJSRERERERESkWFpYiIiIiIiJSKCksREREREREpFRWWIiIiIiIiUioqLEVERERERKRUVFiKiIiIiIhIqaiwFBERERERkVJRYSkiIhXG6NGjGTp0qGH3HzlyJP/5z38Mu39ZWLJkCa6urkU6d9WqVbRu3Zr8/PzyDSUiIlWeCksREbkhTCbTNV/Tp09n3rx5LFmyxJB8e/fuZcWKFUyYMMGQ+xth4MCB2NrasnTpUqOjiIhIJWdjdAAREakeEhISCt4vW7aMadOmERUVVbCvVq1a1KpVy4hoALz77rvcddddhmYwwujRo3nnnXcYOXKk0VFERKQSU4+liIjcEN7e3gUvFxcXTCZToX21atW6bChsSEgITz75JE899RS1a9fGy8uLjz76iMzMTB588EGcnJwIDAxk5cqVhe71+++/M2jQIGrVqoWXlxcjR44kKSnpqtny8vL49ttvGTJkSKH97733Ho0bN8bBwQEvLy/+9a9/FRzLz89n1qxZ+Pv7U6NGDVq1asW3335b6PMHDhzg1ltvxdnZGScnJ7p3705MTEzB52fOnImvry/29va0bt2aVatWFXz22LFjmEwmvv/+e3r16oWjoyOtWrVi69athe6xZMkS6tevj6OjI3fccQfJycmFju/du5devXrh5OSEs7Mz7dq1Y9euXQXHhwwZwq5duwpyiYiIlIQKSxERqdA+/fRT3N3d2bFjB08++SSPP/44d911F126dGHPnj3079+fkSNHcv78eQBSUlLo3bs3bdq0YdeuXaxatYrExETuvvvuq95j3759pKam0r59+4J9u3btYsKECcycOZOoqChWrVpFjx49Co7PmjWLzz77jIULF3LgwAEmTZrEiBEjWL9+PQAnTpygR48e2NvbExYWxu7duxkzZgy5ubkAzJs3jzfffJM33niDffv2MWDAAG677TaOHDlSKNsLL7zA1KlTiYyMpEmTJgwfPrzgGtu3b2fs2LGMHz+eyMhIevXqxSuvvFLo8/fffz++vr7s3LmT3bt389xzz2Fra1twvH79+nh5ebFx48aSNI+IiIiFWURE5AZbvHix2cXF5bL9o0aNMt9+++0F2z179jR369atYDs3N9dcs2ZN88iRIwv2JSQkmAHz1q1bzWaz2fzyyy+b+/fvX+i6x48fNwPmqKioK+b54YcfzNbW1ub8/PyCfd99953Z2dnZnJaWdtn5Fy9eNDs6Opq3bNlSaP/YsWPNw4cPN5vNZvPzzz9v9vf3N2dnZ1/xnj4+PuZXX3210L4OHTqYn3jiCbPZbDbHxsaaAfPHH39ccPzAgQNmwHzo0CGz2Ww2Dx8+3HzLLbcUusY999xT6NfWycnJvGTJkitmuKRNmzbm6dOnX/McERGRa1GPpYiIVGjBwcEF762tralTpw4tW7Ys2Ofl5QXA6dOnAcvQz/Dw8IJnNmvVqkWzZs0Arjrc88KFC9jb22MymQr29evXjwYNGhAQEMDIkSNZunRpQa9odHQ058+fp1+/foXu89lnnxXcIzIyku7duxfqHbwkLS2NkydP0rVr10L7u3btyqFDh676/evWrVvoux46dIiOHTsWOr9z586FtidPnsxDDz1E3759ee211674a1CjRo2C7yYiIlISmrxHREQqtP8tzEwmU6F9l4rBS0tmZGRkMGTIEGbPnn3ZtS4VZv/L3d2d8+fPk52djZ2dHQBOTk7s2bOHiIgI1qxZw7Rp05g+fTo7d+4kIyMDgOXLl1OvXr1C17K3twcsxVpZuNZ3LYrp06dz3333sXz5clauXMlLL73EV199xR133FFwztmzZ/Hw8CiTvCIiUj2px1JERKqUtm3bcuDAARo2bEhgYGChV82aNa/4mdatWwNw8ODBQvttbGzo27cvr7/+Ovv27ePYsWOEhYXRvHlz7O3tiYuLu+wefn5+gKWncePGjeTk5Fx2P2dnZ3x8fNi8eXOh/Zs3b6Z58+ZF/q5BQUFs37690L5t27Zddl6TJk2YNGkSa9asYdiwYSxevLjg2MWLF4mJiaFNmzZFvq+IiMj/UmEpIiJVyrhx4zh79izDhw9n586dxMTEsHr1ah588EHy8vKu+BkPDw/atm3Lpk2bCvb9+uuvvPPOO0RGRvLnn3/y2WefkZ+fT9OmTXFycmLq1KlMmjSJTz/9lJiYGPbs2cO7777Lp59+CsD48eNJS0vj3nvvZdeuXRw5coTPP/+8YImVp59+mtmzZ7Ns2TKioqJ47rnniIyMZOLEiUX+rhMmTGDVqlW88cYbHDlyhPnz5xeaWfbChQuMHz+eiIgI/vzzTzZv3szOnTsJCgoqOGfbtm3Y29tfNoRWRESkOFRYiohIlXKpJzAvL4/+/fvTsmVLnnrqKVxdXbGyuvpfew899BBLly4t2HZ1deX777+nd+/eBAUFsXDhQr788ktatGgBwMsvv8z//d//MWvWLIKCghg4cCDLly/H398fgDp16hAWFkZGRgY9e/akXbt2fPTRRwVDWydMmMDkyZOZMmUKLVu2ZNWqVfz88880bty4yN+1U6dOfPTRR8ybN49WrVqxZs0aXnzxxYLj1tbWJCcn88ADD9CkSRPuvvtuBg0axIwZMwrO+fLLL7n//vtxdHQs8n1FRET+l8lsNpuNDiEiImK0Cxcu0LRpU5YtW1Zteu+SkpJo2rQpu3btKiiIRURESkI9liIiIlgm2/nss89ISkoyOsoNc+zYMd577z0VlSIiUmrqsRQREREREZFSUY+liIiIiIiIlIoKSxERERERESkVFZYiIiIiIiJSKiosRUREREREpFRUWIqIiIiIiEipqLAUERERERGRUlFhKSIiIiIiIqWiwlJERERERERKRYWliIiIiIiIlMr/A/DKXhycm1zOAAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 1000x500 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from utils.utils import get_optimal_action\n",
        "\n",
        "\n",
        "\n",
        "# generate a list of random initial states allowing for a wide range of values\n",
        "np.random.seed(0)\n",
        "initial_states = np.random.rand(5, 3)\n",
        "initial_states[:, 0] = initial_states[:, 0] * np.deg2rad(90) - np.deg2rad(90)  # Flight path angle\n",
        "initial_states[:, 1] = initial_states[:, 1] * 3.3 + 0.7  # Airspeed\n",
        "initial_states[:, 2] = initial_states[:, 2] * np.deg2rad(230) - np.deg2rad(30)  # Bank angle\n",
        "\n",
        "initial_states = [np.array([np.deg2rad(-80.),  1.2, np.deg2rad(150)])]  # Example state\n",
        "\n",
        "#initial_states  = [np.array([np.deg2rad(-80.),  1.2, np.deg2rad(150)])]  # Example state\n",
        "fig, ax1 = plt.subplots(figsize=(10, 5))  # Main figure\n",
        "\n",
        "ax2 = ax1.twinx()  # Create secondary y-axis\n",
        "\n",
        "# Loop through each initial state\n",
        "for initial_state in initial_states:\n",
        "    state = np.array(initial_state)  # Convert list to numpy array\n",
        "    glider.airplane.flight_path_angle = state[0]\n",
        "    glider.airplane.airspeed_norm = state[1]\n",
        "    glider.airplane.bank_angle = state[2]\n",
        "\n",
        "    # Storage for plotting\n",
        "    flight_path_angles = []\n",
        "    time_steps = []\n",
        "    cl_values = []\n",
        "    height_lost_values = []\n",
        "\n",
        "    total_height_lost = 0\n",
        "    episode_length = 0\n",
        "    terminated = False\n",
        "\n",
        "    # Run simulation\n",
        "    while episode_length < 150:\n",
        "\n",
        "        if not terminated:\n",
        "            try:\n",
        "                action = get_optimal_action(state, pi)\n",
        "                #action[0] = 1.0\n",
        "                state, reward, terminated, _, _ = glider.step(action)\n",
        "                state = state[0]\n",
        "            except:\n",
        "                terminated = True\n",
        "            \n",
        "\n",
        "        total_height_lost += reward # Update height lost\n",
        "        episode_length += 0.01\n",
        "\n",
        "        # Convert to readable format\n",
        "        flight_path_angle = float(np.rad2deg(state[0]))\n",
        "        V_norm = float(state[1])\n",
        "        bank_angle = float(np.rad2deg(state[2]))\n",
        "        C_L = float(action[0])  # Extract lift coefficient\n",
        "\n",
        "        # Store values\n",
        "        flight_path_angles.append(flight_path_angle)\n",
        "        time_steps.append(episode_length)\n",
        "        cl_values.append(C_L)\n",
        "        height_lost_values.append(float(np.rad2deg(state[2])))\n",
        "\n",
        "        print(f\"Action: {np.round(action,3)} | Reward: {total_height_lost} | \\\n",
        "                State: {flight_path_angle, V_norm, bank_angle} | Terminated: {terminated} |\\\n",
        "                Episode Length: {episode_length} | C_L: {C_L}\")\n",
        "\n",
        "        if terminated:\n",
        "            break\n",
        "\n",
        "    # Plot the flight path angle on primary axis\n",
        "    ax1.plot(time_steps, flight_path_angles,label=f\"V_norm={round(initial_state[1],2)}, Bank_angle={round(np.rad2deg(initial_state[2]),1)}°\") \n",
        "    # Plot height lost on secondary axis\n",
        "    ax2.plot(time_steps, height_lost_values, linestyle=\"dashed\", alpha=0.7)\n",
        "\n",
        "    # Select 5 evenly spaced indices for C_L annotations\n",
        "    num_points = 5\n",
        "    if len(time_steps) > num_points:\n",
        "        indices = np.linspace(0, len(time_steps) - 1, num_points, dtype=int)\n",
        "    else:\n",
        "        indices = range(len(time_steps))  # If fewer than 5 points exist\n",
        "\n",
        "    # Plot markers and add annotations for C_L\n",
        "    for i in indices:\n",
        "        ax1.scatter(time_steps[i], flight_path_angles[i], color=\"black\", marker=\"x\")  # Mark point\n",
        "        ax1.text(time_steps[i], flight_path_angles[i], f\"{cl_values[i]:.2f}\", fontsize=7, \n",
        "                 verticalalignment='bottom', \n",
        "                 horizontalalignment='right')\n",
        "\n",
        "# Graph settings\n",
        "ax1.set_xlabel(\"Time (seconds)\")\n",
        "ax1.set_ylabel(\"Flight Path Angle (γ) [°]\", color=\"blue\")\n",
        "ax2.set_ylabel(\"Bank Angle (μ) [°])\", color=\"red\")\n",
        "ax1.set_title(\"Airplane trajectories\")\n",
        "ax1.legend()\n",
        "ax1.grid()\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "id": "bc4b24f4",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.colors as mcolors\n",
        "from utils.utils import get_optimal_action\n",
        "\n",
        "vel_norm = 1.2\n",
        "# Example discretization\n",
        "flight_path_bins = np.linspace(np.deg2rad(-100), np.deg2rad(0), 20, dtype=np.float32)\n",
        "bank_bins = np.linspace(np.deg2rad(0), np.deg2rad(180), 20, dtype=np.float32)\n",
        "\n",
        "# Prepare a 2D array to store the policy (CL values)\n",
        "policy_values = np.zeros((len(bank_bins), len(flight_path_bins)))  # Transpose shape\n",
        "\n",
        "# Fill in the 2D array by evaluating your policy at each (γ, μ)\n",
        "for i, mu_rad in enumerate(bank_bins):  # μ is now columns\n",
        "    for j, gamma_rad in enumerate(flight_path_bins):  # γ is now rows\n",
        "        state = np.array([gamma_rad, vel_norm, mu_rad])\n",
        "        action = get_optimal_action(state, pi)  # Replace with your actual policy call\n",
        "        cl = float(action[0])  # Assuming first element of `action` is the lift coefficient\n",
        "        policy_values[i, j] = cl\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "id": "d76a9ff0",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Create the plot\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.imshow(policy_values.T, cmap=\"gray\", origin=\"lower\",\n",
        "           extent=[np.rad2deg(bank_bins[0]), np.rad2deg(bank_bins[-1]), \n",
        "                   np.rad2deg(flight_path_bins[0]), np.rad2deg(flight_path_bins[-1])],  interpolation=\"bicubic\")\n",
        "\n",
        "# ValueError: 'nearet' is not a valid value for interpolation; supported values are 'lanczos', \n",
        "# 'bilinear', 'bessel', 'spline36', 'catrom', 'none', 'spline16', 'gaussian', 'hamming', 'antialiased', \n",
        "# 'hermite', 'mitchell', 'blackman', 'quadric', 'hanning', 'sinc', 'kaiser', 'bicubic', 'nearest'\n",
        "\n",
        "\n",
        "# Add labels and colorbar\n",
        "plt.xlabel(\"Bank Angle μ (degrees)\")  # Now X-axis\n",
        "plt.ylabel(\"Flight Path Angle γ (degrees)\")  # Now Y-axis\n",
        "plt.colorbar(label=\"Lift Coefficient (C_L)\")\n",
        "plt.title(f\"Policy Visualization V/Vs={vel_norm}\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81f11551",
      "metadata": {},
      "outputs": [],
      "source": [
        "state = np.array([np.deg2rad(-80.),  1.2, np.deg2rad(150)])  # Example state\n",
        "get_optimal_action(state, pi)[0]  # Replace with your actual policy call"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3dd56bb",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Normalize the policy values (0 to 1) for grayscale plotting\n",
        "vmin, vmax = policy_values.min(), policy_values.max()\n",
        "norm_values = (policy_values - vmin) / (vmax - vmin + 1e-8)\n",
        "\n",
        "# Create a mesh for plotting\n",
        "X, Y = np.meshgrid(bank_angles, flight_path_angles)\n",
        "\n",
        "# Plot using pcolormesh (grayscale)\n",
        "fig, ax = plt.subplots(figsize=(6, 4))\n",
        "c = ax.pcolormesh(X, Y, norm_values, cmap='gray', shading='auto', norm=mcolors.Normalize(vmin=0, vmax=1))\n",
        "\n",
        "# Labels and title\n",
        "ax.set_xlabel(\"Bank Angle (deg)\")\n",
        "ax.set_ylabel(\"Flight Path Angle (deg)\")\n",
        "ax.set_title(\"Optimal Policy (CL)\")\n",
        "\n",
        "# Optional: colorbar\n",
        "plt.colorbar(c, ax=ax, label=\"Normalized CL\")\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8323f6d",
      "metadata": {},
      "outputs": [],
      "source": [
        "-192769.51 + -125086.89"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e954bd11",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from utils.utils import get_optimal_action\n",
        "\n",
        "# initial state\n",
        "state = np.array([np.deg2rad(-60), 1.2, np.deg2rad(30)])\n",
        "glider.airplane.flight_path_angle = state[0]\n",
        "glider.airplane.airspeed_norm     = state[1]\n",
        "glider.airplane.bank_angle        = state[2]\n",
        "\n",
        "total_height_lost = 0\n",
        "episode_length    = 0\n",
        "terminated        = False\n",
        "\n",
        "time_history = []\n",
        "height_lost_history = []\n",
        "\n",
        "while episode_length < 20:\n",
        "    action = get_optimal_action(state, pi)\n",
        "    prev_state = state.copy()\n",
        "    state, reward, terminated, _, _ = glider.step(action)\n",
        "    state = state[0] \n",
        "    total_height_lost += reward\n",
        "    episode_length += 0.01\n",
        "\n",
        "    time_history.append(episode_length)  # for plotting!\n",
        "    height_lost_history.append(total_height_lost)\n",
        "\n",
        "    #print(f\"Action: {np.round(action,3)} | Lost Height: {total_height_lost:.3f} | State: {state} | Terminated: {terminated} | Time: {episode_length:.2f}\")\n",
        "    if terminated:\n",
        "        break\n",
        "\n",
        "# Plotting the results\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(time_history, height_lost_history, label=\"Height Lost\")\n",
        "plt.xlabel(\"Time (s)\")\n",
        "plt.ylabel(\"Height Lost (m)\")\n",
        "plt.title(\"Height Lost Over Time\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5cd13daf",
      "metadata": {},
      "outputs": [],
      "source": [
        "STALL_AIRSPEED = 27.331231856346\n",
        "from utils.utils import get_optimal_action\n",
        "from tqdm import tqdm\n",
        "with open(glider.__class__.__name__ + \".pkl\", \"rb\") as f:\n",
        "    pi: PolicyIteration = pickle.load(f)\n",
        "\n",
        "prom_episode_lenght = 0\n",
        "dict_result = {}\n",
        "dict_episode_length = {}\n",
        "state_spaces = [v for v in pi.states_space if v[0] > -np.pi/2]\n",
        "for state in tqdm(state_spaces):\n",
        "    initial_state = state.copy()\n",
        "    prev_state = state.copy()\n",
        "    glider.reset()\n",
        "    glider.airplane.flight_path_angle = state[0]\n",
        "    glider.airplane.airspeed_norm = state[1]\n",
        "    glider.airplane.bank_angle = state[2]\n",
        "    done = False\n",
        "    episode_length = 0\n",
        "    total_reward = 0\n",
        "    while not done:\n",
        "        action = get_optimal_action(state, pi)\n",
        "        prev_state  = state.copy()\n",
        "        state, reward, done, _, _ = glider.step(action)\n",
        "        done  = bool(done)\n",
        "        if done:\n",
        "            break\n",
        "        state = state[0]\n",
        "        # check if our state is in the state space\n",
        "        index = pi.triangulation.find_simplex(state)\n",
        "        if not done:\n",
        "            total_reward -= reward#*STALL_AIRSPEED\n",
        "        if (index ==-1) or episode_length > 70: \n",
        "            done = True\n",
        "        episode_length += 1\n",
        "        \n",
        "    dict_result[tuple(initial_state)] = total_reward\n",
        "    dict_episode_length[tuple(initial_state)] = episode_length\n",
        "    prom_episode_lenght += episode_length / len(pi.states_space)\n",
        "    #print(f\"Initial state: {initial_state} - Total reward: {total_reward}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab055601",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "epsilon = 1*1e-1\n",
        "#dict_result = dict_episode_length\n",
        "# Your dictionary with keys as coordinates (x, y) and values as the color intensity (z)\n",
        "# Extracting the x, y and z values\n",
        "x = [np.degrees(coord[0]) for coord in dict_result.keys() if 0.05 >= coord[0] >= -np.pi/2 - epsilon and coord[1] > 0.7]\n",
        "#convert x to grad\n",
        "y = [coord[1] for coord in dict_result.keys() if 0.05 >= coord[0] >= -np.pi/2 - epsilon and coord[1] > 0.7]\n",
        "#convert y to Vs\n",
        "keys_list = list(dict_result.keys())\n",
        "values_list = list(dict_result.values())\n",
        "z = [v for e,v in zip(keys_list, values_list) if 0.05 >= e[0] >= -np.pi/2 - epsilon and e[1] > 0.7]\n",
        "\n",
        "# Creating a 2D scatter plot\n",
        "cmap = plt.get_cmap('viridis', 2048)\n",
        "plt.tricontourf(y, x, z, cmap=cmap, levels=18)   # Change 'viridis' to any other colormap you like\n",
        "plt.colorbar(label='', shrink=0.8,  )  # Add color bar for the z values\n",
        "\n",
        "# Add labels and a title\n",
        "plt.ylabel('Flight Path Angle (γ) [deg]')\n",
        "plt.xlabel('V/Vs')\n",
        "\n",
        "x_min, x_max = min(x), max(x)\n",
        "y_min, y_max = min(y), max(y)\n",
        "\n",
        "# Set the minor ticks for the grid, keeping the dense grid with smaller squares\n",
        "ax = plt.gca()  # Get current axes\n",
        "ax.set_yticks(np.linspace(x_min, x_max, 60), minor=True)  # 20 minor ticks for grid\n",
        "ax.set_xticks(np.linspace(y_min, y_max, 60), minor=True)  # 20 minor ticks for grid\n",
        "# put line x = 1\n",
        "plt.axvline(x=1, color='r', linestyle='--', linewidth=0.5)\n",
        "# put line y = 0\n",
        "#plt.axhline(y=0, color='k', linestyle='--')\n",
        "\n",
        "# Show the plot\n",
        "vals = np.round(np.linspace(-90, 0,6))\n",
        "plt.yticks(vals)  # Only 5 labels on x-axis\n",
        "plt.xticks(np.linspace(round(y_min), round(y_max), 6))  # Only 5 labels on y-axis\n",
        "# Enable the minor grid lines\n",
        "ax.grid(which='minor', color='gray', linestyle='-', linewidth=0.5)\n",
        "\n",
        "# Habilitar la cuadrícula en las marcas menores\n",
        "ax.grid(which='minor', color='gray', linestyle='-', linewidth=0.5)\n",
        "\n",
        "# Guardar la imagen sin borde blanco\n",
        "plt.savefig('output.png', bbox_inches='tight')\n",
        "\n",
        "# set size of the plot\n",
        "plt.gcf().set_size_inches(9, 5)\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8416867",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.interpolate import griddata\n",
        "\n",
        "# Your dictionary with keys as coordinates (x, y) and values as the color intensity (z)\n",
        "# Extracting the x, y and z values\n",
        "x = [np.degrees(coord[0]) for coord in dict_result.keys() if 5 >= coord[0] >= -np.pi/2 and coord[1] > 0.7]\n",
        "y = [coord[1] for coord in dict_result.keys() if 5 >= coord[0] >= -np.pi/2 and coord[1] > 0.7]\n",
        "keys_list = list(dict_result.keys())\n",
        "values_list = list(dict_result.values())\n",
        "z = [v for e,v in zip(keys_list, values_list) if 5 >= e[0] >= -np.pi/2 and e[1] > 0.7]\n",
        "\n",
        "# Create a grid for interpolation\n",
        "x_grid = np.linspace(min(x), max(x), 100)\n",
        "y_grid = np.linspace(min(y), max(y), 100)\n",
        "X, Y = np.meshgrid(x_grid, y_grid)\n",
        "\n",
        "# Interpolate the scattered data into the grid\n",
        "Z = griddata((y, x), z, (Y, X), method='linear')\n",
        "\n",
        "# Create the scatter plot\n",
        "cmap = plt.get_cmap('viridis', 2048)\n",
        "plt.scatter(y, x, c=z, cmap=cmap)\n",
        "\n",
        "# Add color bar\n",
        "plt.colorbar(label='', shrink=0.8)\n",
        "contour_levels = np.linspace(np.min(z), np.max(z), 10)  # 10 levels\n",
        "contour_levels = contour_levels[contour_levels != 0]    # Remove zero from levels\n",
        "\n",
        "# Add contour lines on top of the scatter plot\n",
        "contour = plt.contour(Y, X, Z, levels=contour_levels, colors='black', linewidths=0.75)\n",
        "plt.clabel(contour, inline=True, fontsize=8)  # Optional: add labels to the contours\n",
        "\n",
        "# Add labels and a title\n",
        "plt.ylabel('Flight Path Angle (γ) [deg]')\n",
        "plt.xlabel('V/Vs')\n",
        "\n",
        "# Plot vertical line at x=1\n",
        "plt.axvline(x=1, color='k', linestyle='--')\n",
        "\n",
        "# Configure the minor ticks and grid\n",
        "x_min, x_max = min(x), max(x)\n",
        "y_min, y_max = min(y), max(y)\n",
        "ax = plt.gca()  # Get current axes\n",
        "ax.set_yticks(np.linspace(x_min, x_max, 60), minor=True)\n",
        "ax.set_xticks(np.linspace(y_min, y_max, 60), minor=True)\n",
        "plt.yticks(np.linspace(x_min, x_max, 6))  # Major ticks on y-axis\n",
        "plt.xticks(np.linspace(y_min, y_max, 4))  # Major ticks on x-axis\n",
        "\n",
        "# Set size of the plot\n",
        "plt.gcf().set_size_inches(9, 5)\n",
        "\n",
        "# Enable the minor grid lines\n",
        "ax.grid(which='minor', color='white', linestyle='-', linewidth=0.25)\n",
        "\n",
        "# Habilitar la cuadrícula en las marcas menores\n",
        "ax.grid(which='minor', color='white', linestyle='-', linewidth=0.25)\n",
        "\n",
        "# Save the image\n",
        "plt.savefig('output_with_contours.png', bbox_inches='tight')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "204e0318",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "3c8fe4a4",
      "metadata": {},
      "source": [
        "# CartPoleEnv \n",
        "\n",
        "### Observation Space\n",
        "\n",
        "The observation is a `ndarray` with shape `(4,)` with the values corresponding to the following positions and velocities:\n",
        "\n",
        "| Num | Observation           | Min                 | Max               |\n",
        "|-----|-----------------------|---------------------|-------------------|\n",
        "| 0   | Cart Position         | -4.8                | 4.8               |\n",
        "| 1   | Cart Velocity         | -Inf                | Inf               |\n",
        "| 2   | Pole Angle            | ~ -0.418 rad (-24°) | ~ 0.418 rad (24°) |\n",
        "| 3   | Pole Angular Velocity | -Inf                | Inf               |\n",
        "\n",
        "### Action Space\n",
        "\n",
        "The action is a `ndarray` with shape `(1,)` which can take values `{0, 1}` indicating the direction\n",
        "of the fixed force the cart is pushed with.\n",
        "\n",
        "- 0: Push cart to the left\n",
        "- 1: Push cart to the right"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1c04b7b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train cartpole environment:\n",
        "from classic_control.cartpole import CartPoleEnv\n",
        "# CartPole environment:\n",
        "env = CartPoleEnv(sutton_barto_reward=True)\n",
        "# position thresholds:\n",
        "x_lim         = 2.4\n",
        "theta_lim     = 0.418 \n",
        "# velocity thresholds:\n",
        "x_dot_lim     = 3.1\n",
        "theta_dot_lim = 3.1\n",
        "\n",
        "bins_space = {\n",
        "    \"x_space\"         : np.linspace(-x_lim, x_lim, 10,  dtype=np.float32),                     # position space          (0)\n",
        "    \"x_dot_space\"     : np.linspace(-x_dot_lim, x_dot_lim, 10,  dtype=np.float32),             # velocity space          (1)\n",
        "    \"theta_space\"     : np.linspace(-theta_lim, theta_lim, 10, dtype=np.float32),              # angle space             (2)\n",
        "    \"theta_dot_space\" : np.linspace(-theta_dot_lim, theta_dot_lim, 10, dtype=np.float32),      # angular velocity space  (3)\n",
        "}\n",
        "\n",
        "pi = PolicyIteration(\n",
        "    env=env, \n",
        "    bins_space=bins_space,\n",
        "    action_space=np.array([0, 1], dtype=np.int32),\n",
        "    gamma=0.99,\n",
        "    theta=1e-3\n",
        ")\n",
        "\n",
        "pi.run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0462a904",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test cartpole environment:\n",
        "\n",
        "with open(env.__class__.__name__ + \".pkl\", \"rb\") as f:\n",
        "    pi = pickle.load(f)\n",
        "\n",
        "test_enviroment(CartPoleEnv(sutton_barto_reward=True, render_mode=\"human\"), pi)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "063b6002",
      "metadata": {},
      "source": [
        "## Observation Space\n",
        "\n",
        "The observation is a `ndarray` with shape `(2,)` where the elements correspond to the following:\n",
        "\n",
        "| Num | Observation                          | Min   | Max  | Unit         |\n",
        "|-----|--------------------------------------|-------|------|--------------|\n",
        "| 0   | position of the car along the x-axis | -1.2  | 0.6  | position (m) |\n",
        "| 1   | velocity of the car                  | -0.07 | 0.07 | velocity (v) |\n",
        "\n",
        "## Action Space\n",
        "\n",
        "There are 3 discrete deterministic actions:\n",
        "\n",
        "- 0: Accelerate to the left\n",
        "- 1: Don't accelerate\n",
        "- 2: Accelerate to the right\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d617686",
      "metadata": {},
      "outputs": [],
      "source": [
        "from classic_control.continuous_mountain_car import Continuous_MountainCarEnv\n",
        "\n",
        "env=Continuous_MountainCarEnv()\n",
        "\n",
        "bins_space = {\n",
        "    \"x_space\":     np.linspace(env.min_position, env.max_position, 100,      dtype=np.float32),    # position space    (0)\n",
        "    \"x_dot_space\": np.linspace(-abs(env.max_speed), abs(env.max_speed), 100, dtype=np.float32),    # velocity space    (1)\n",
        "}\n",
        "\n",
        "pi = PolicyIteration(\n",
        "    env=env, \n",
        "    bins_space=bins_space,\n",
        "    action_space=np.linspace(-1.0, +1.0, 9, dtype=np.float32),\n",
        "    gamma=0.99,\n",
        "    theta=1e-3,\n",
        ")\n",
        "pi.run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f556b5a",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test mountain car environment:\n",
        "with open(env.__class__.__name__ + \".pkl\", \"rb\") as f:\n",
        "    pi: PolicyIteration = pickle.load(f)\n",
        "\n",
        "test_enviroment(Continuous_MountainCarEnv(render_mode=\"human\"), pi)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "DynamicProgramming",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
