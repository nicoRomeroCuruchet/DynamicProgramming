{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "b149d005",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nicoRomeroCuruchet/DynamicProgramming/blob/main/testing_bary.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "9c6a7123",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m2025-02-25 15:25:26.162\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m18\u001b[0m - \u001b[33m\u001b[1mCUDA is not available. Falling back to NumPy.\u001b[0m\n",
            "\u001b[32m2025-02-25 15:25:26.165\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m129\u001b[0m - \u001b[1mLower bounds: [-1.5707964  0.7       -0.5235988]\u001b[0m\n",
            "\u001b[32m2025-02-25 15:25:26.166\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m130\u001b[0m - \u001b[1mUpper bounds: [0.08726646 4.         3.4906585 ]\u001b[0m\n",
            "\u001b[32m2025-02-25 15:25:26.167\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m149\u001b[0m - \u001b[1mNumber of states: 64000\u001b[0m\n",
            "\u001b[32m2025-02-25 15:25:26.168\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m150\u001b[0m - \u001b[1mTotal states:4096000\u001b[0m\n",
            "\u001b[32m2025-02-25 15:25:26.175\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mPolicy Iteration was correctly initialized.\u001b[0m\n",
            "\u001b[32m2025-02-25 15:25:26.175\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m164\u001b[0m - \u001b[1mThe enviroment name is: TimeLimit\u001b[0m\n",
            "\u001b[32m2025-02-25 15:25:26.176\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m387\u001b[0m - \u001b[1mCreating Delaunay triangulation over the state space...\u001b[0m\n",
            "\u001b[32m2025-02-25 15:25:32.942\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m389\u001b[0m - \u001b[1mDelaunay triangulation created.\u001b[0m\n",
            "\u001b[32m2025-02-25 15:25:32.942\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m399\u001b[0m - \u001b[1mGenerating transition and reward function table...\u001b[0m\n",
            "/home/nromero/anaconda3/envs/DynamicProgramming/lib/python3.11/site-packages/gymnasium/utils/passive_env_checker.py:159: UserWarning: \u001b[33mWARN: The obs returned by the `reset()` method is not within the observation space.\u001b[0m\n",
            "  logger.warn(f\"{pre} is not within the observation space.\")\n",
            "/home/nromero/anaconda3/envs/DynamicProgramming/lib/python3.11/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.airplane to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.airplane` for environment variables or `env.get_wrapper_attr('airplane')` that will search the reminding wrappers.\u001b[0m\n",
            "  logger.warn(\n",
            "/home/nromero/anaconda3/envs/DynamicProgramming/lib/python3.11/site-packages/gymnasium/utils/passive_env_checker.py:228: UserWarning: \u001b[33mWARN: Expects `terminated` signal to be a boolean, actual type: <class 'numpy.ndarray'>\u001b[0m\n",
            "  logger.warn(\n",
            "/home/nromero/anaconda3/envs/DynamicProgramming/lib/python3.11/site-packages/gymnasium/utils/passive_env_checker.py:159: UserWarning: \u001b[33mWARN: The obs returned by the `step()` method is not within the observation space.\u001b[0m\n",
            "  logger.warn(f\"{pre} is not within the observation space.\")\n",
            "/home/nromero/anaconda3/envs/DynamicProgramming/lib/python3.11/site-packages/gymnasium/utils/passive_env_checker.py:246: UserWarning: \u001b[33mWARN: The reward returned by `step()` must be a float, int, np.integer or np.floating, actual type: <class 'numpy.ndarray'>\u001b[0m\n",
            "  logger.warn(\n",
            "\u001b[32m2025-02-25 15:25:32.950\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m255\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-02-25 15:29:25.898\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m255\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-02-25 15:33:05.319\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m255\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-02-25 15:36:31.596\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m255\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-02-25 15:39:57.990\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m255\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-02-25 15:42:59.197\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m255\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-02-25 15:46:06.820\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m255\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-02-25 15:49:17.804\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m255\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-02-25 15:52:29.794\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m255\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-02-25 15:55:55.456\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m255\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-02-25 15:59:21.930\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m255\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-02-25 16:02:48.727\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m255\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-02-25 16:06:14.258\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m255\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-02-25 16:09:15.672\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m255\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-02-25 16:12:22.061\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m255\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-02-25 16:15:33.557\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m255\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-02-25 16:18:45.803\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m255\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-02-25 16:22:11.658\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m255\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-02-25 16:25:37.236\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m255\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-02-25 16:29:05.559\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m255\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-02-25 16:32:31.717\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m255\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-02-25 16:35:32.463\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m255\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-02-25 16:38:38.590\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m255\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-02-25 16:41:49.991\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m255\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-02-25 16:45:03.953\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m255\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-02-25 16:48:41.608\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m255\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-02-25 16:52:41.746\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m255\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-02-25 16:56:31.246\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m255\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-02-25 17:00:48.783\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m255\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-02-25 17:04:15.531\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m255\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-02-25 17:07:38.490\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m255\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-02-25 17:11:13.055\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m255\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-02-25 17:14:54.671\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m255\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-02-25 17:18:33.861\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m255\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-02-25 17:22:02.506\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m255\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-02-25 17:25:38.367\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m255\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-02-25 17:28:57.521\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m255\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-02-25 17:31:56.801\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m255\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-02-25 17:35:01.075\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m255\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-02-25 17:38:13.410\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m255\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-02-25 17:41:26.291\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m255\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-02-25 17:44:47.901\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m255\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-02-25 17:48:13.639\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m255\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-02-25 17:51:38.889\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m255\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-02-25 17:55:16.805\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m255\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-02-25 17:58:21.922\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m255\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-02-25 18:01:59.550\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m255\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-02-25 18:05:20.911\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m255\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-02-25 18:08:37.690\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m255\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-02-25 18:12:05.652\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m255\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-02-25 18:15:33.303\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m255\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-02-25 18:19:02.015\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m255\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-02-25 18:22:28.433\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m255\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-02-25 18:25:31.888\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m255\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-02-25 18:28:38.556\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m255\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-02-25 18:31:48.961\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m255\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-02-25 18:35:00.523\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m255\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-02-25 18:38:30.151\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m255\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-02-25 18:41:59.684\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m255\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-02-25 18:45:29.647\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m255\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-02-25 18:49:14.526\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m255\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-02-25 18:52:33.962\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m255\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-02-25 18:55:37.049\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m255\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-02-25 18:58:44.925\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mcalculate_transition_reward_table\u001b[0m:\u001b[36m255\u001b[0m - \u001b[33m\u001b[1mSome states are outside the bounds of the environment.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:01:53.070\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m401\u001b[0m - \u001b[1mTransition and reward function table generated.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:01:53.071\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m403\u001b[0m - \u001b[1msolving step 0\u001b[0m\n",
            "\u001b[32m2025-02-25 19:01:53.071\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m313\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-02-25 19:01:53.358\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.03999999910593033 | Avg Error: 0.014000000432133675 | 5646<0.001\u001b[0m\n",
            "\u001b[32m2025-02-25 19:02:35.896\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.008999999612569809 | Avg Error: 0.004000000189989805 | 6049<0.001\u001b[0m\n",
            "\u001b[32m2025-02-25 19:03:18.996\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.0020000000949949026 | Avg Error: 0.0010000000474974513 | 31751<0.001\u001b[0m\n",
            "\u001b[32m2025-02-25 19:04:02.055\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 64000<0.001\u001b[0m\n",
            "\u001b[32m2025-02-25 19:04:02.055\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m353\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:04:02.056\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-02-25 19:04:02.322\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m375\u001b[0m - \u001b[1mThe number of updated different actions: 4096000\u001b[0m\n",
            "\u001b[32m2025-02-25 19:04:02.322\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m378\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:04:02.323\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m403\u001b[0m - \u001b[1msolving step 1\u001b[0m\n",
            "\u001b[32m2025-02-25 19:04:02.323\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m313\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-02-25 19:04:02.612\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.09099999815225601 | Avg Error: 0.004999999888241291 | 20168<0.001\u001b[0m\n",
            "\u001b[32m2025-02-25 19:04:45.872\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.004999999888241291 | Avg Error: 0.0010000000474974513 | 39585<0.001\u001b[0m\n",
            "\u001b[32m2025-02-25 19:05:29.239\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.0010000000474974513 | Avg Error: 0.0 | 64000<0.001\u001b[0m\n",
            "\u001b[32m2025-02-25 19:06:12.159\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 64000<0.001\u001b[0m\n",
            "\u001b[32m2025-02-25 19:06:12.160\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m353\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:06:12.161\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-02-25 19:06:12.423\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m375\u001b[0m - \u001b[1mThe number of updated different actions: 74964\u001b[0m\n",
            "\u001b[32m2025-02-25 19:06:12.423\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m378\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:06:12.424\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m403\u001b[0m - \u001b[1msolving step 2\u001b[0m\n",
            "\u001b[32m2025-02-25 19:06:12.424\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m313\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-02-25 19:06:12.712\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.057999998331069946 | Avg Error: 0.0010000000474974513 | 55101<0.001\u001b[0m\n",
            "\u001b[32m2025-02-25 19:06:55.799\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.0010000000474974513 | Avg Error: 0.0 | 63983<0.001\u001b[0m\n",
            "\u001b[32m2025-02-25 19:07:38.672\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 64000<0.001\u001b[0m\n",
            "\u001b[32m2025-02-25 19:07:38.672\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m353\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:07:38.672\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-02-25 19:07:38.934\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m375\u001b[0m - \u001b[1mThe number of updated different actions: 33834\u001b[0m\n",
            "\u001b[32m2025-02-25 19:07:38.934\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m378\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:07:38.934\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m403\u001b[0m - \u001b[1msolving step 3\u001b[0m\n",
            "\u001b[32m2025-02-25 19:07:38.935\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m313\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-02-25 19:07:39.220\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.04899999871850014 | Avg Error: 0.0 | 62296<0.001\u001b[0m\n",
            "\u001b[32m2025-02-25 19:08:22.347\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 64000<0.001\u001b[0m\n",
            "\u001b[32m2025-02-25 19:08:22.347\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m353\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:08:22.348\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-02-25 19:08:22.611\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m375\u001b[0m - \u001b[1mThe number of updated different actions: 12002\u001b[0m\n",
            "\u001b[32m2025-02-25 19:08:22.611\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m378\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:08:22.612\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m403\u001b[0m - \u001b[1msolving step 4\u001b[0m\n",
            "\u001b[32m2025-02-25 19:08:22.612\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m313\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-02-25 19:08:22.896\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.01899999938905239 | Avg Error: 0.0 | 63021<0.001\u001b[0m\n",
            "\u001b[32m2025-02-25 19:09:05.690\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 64000<0.001\u001b[0m\n",
            "\u001b[32m2025-02-25 19:09:05.690\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m353\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:09:05.691\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-02-25 19:09:05.951\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m375\u001b[0m - \u001b[1mThe number of updated different actions: 3122\u001b[0m\n",
            "\u001b[32m2025-02-25 19:09:05.951\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m378\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:09:05.952\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m403\u001b[0m - \u001b[1msolving step 5\u001b[0m\n",
            "\u001b[32m2025-02-25 19:09:05.952\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m313\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-02-25 19:09:06.239\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.00800000037997961 | Avg Error: 0.0 | 63551<0.001\u001b[0m\n",
            "\u001b[32m2025-02-25 19:09:49.111\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 64000<0.001\u001b[0m\n",
            "\u001b[32m2025-02-25 19:09:49.111\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m353\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:09:49.112\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-02-25 19:09:49.379\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m375\u001b[0m - \u001b[1mThe number of updated different actions: 324\u001b[0m\n",
            "\u001b[32m2025-02-25 19:09:49.380\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m378\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:09:49.380\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m403\u001b[0m - \u001b[1msolving step 6\u001b[0m\n",
            "\u001b[32m2025-02-25 19:09:49.380\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m313\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-02-25 19:09:49.674\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.0010000000474974513 | Avg Error: 0.0 | 64000<0.001\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:33.180\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 64000<0.001\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:33.180\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m353\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:33.181\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:33.449\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m375\u001b[0m - \u001b[1mThe number of updated different actions: 64\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:33.449\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m378\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:33.450\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m403\u001b[0m - \u001b[1msolving step 7\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:33.450\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m313\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:33.744\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 64000<0.001\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:33.744\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m353\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:33.745\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:34.012\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m375\u001b[0m - \u001b[1mThe number of updated different actions: 10\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:34.013\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m378\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:34.013\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m403\u001b[0m - \u001b[1msolving step 8\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:34.013\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m313\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:34.310\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 64000<0.001\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:34.311\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m353\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:34.311\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:34.580\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m375\u001b[0m - \u001b[1mThe number of updated different actions: 12\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:34.581\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m378\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:34.581\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m403\u001b[0m - \u001b[1msolving step 9\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:34.581\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m313\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:34.876\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 64000<0.001\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:34.877\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m353\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:34.877\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:35.147\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m375\u001b[0m - \u001b[1mThe number of updated different actions: 14\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:35.147\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m378\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:35.148\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m403\u001b[0m - \u001b[1msolving step 10\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:35.148\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m313\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:35.444\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 64000<0.001\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:35.444\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m353\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:35.445\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:35.713\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m375\u001b[0m - \u001b[1mThe number of updated different actions: 8\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:35.714\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m378\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:35.714\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m403\u001b[0m - \u001b[1msolving step 11\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:35.715\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m313\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:36.012\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 64000<0.001\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:36.012\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m353\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:36.012\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:36.283\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m375\u001b[0m - \u001b[1mThe number of updated different actions: 18\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:36.284\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m378\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:36.284\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m403\u001b[0m - \u001b[1msolving step 12\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:36.284\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m313\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:36.578\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 64000<0.001\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:36.579\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m353\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:36.579\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:36.849\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m375\u001b[0m - \u001b[1mThe number of updated different actions: 10\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:36.849\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m378\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:36.850\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m403\u001b[0m - \u001b[1msolving step 13\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:36.850\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m313\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:37.144\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 64000<0.001\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:37.145\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m353\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:37.145\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:37.412\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m375\u001b[0m - \u001b[1mThe number of updated different actions: 6\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:37.413\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m378\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:37.413\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m403\u001b[0m - \u001b[1msolving step 14\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:37.414\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m313\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:37.707\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 64000<0.001\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:37.708\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m353\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:37.708\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:37.977\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m375\u001b[0m - \u001b[1mThe number of updated different actions: 14\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:37.977\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m378\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:37.977\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m403\u001b[0m - \u001b[1msolving step 15\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:37.978\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m313\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:38.273\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 64000<0.001\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:38.274\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m353\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:38.274\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:38.543\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m375\u001b[0m - \u001b[1mThe number of updated different actions: 16\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:38.543\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m378\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:38.543\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m403\u001b[0m - \u001b[1msolving step 16\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:38.544\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m313\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:38.838\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 64000<0.001\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:38.839\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m353\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:38.839\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:39.112\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m375\u001b[0m - \u001b[1mThe number of updated different actions: 8\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:39.112\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m378\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:39.112\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m403\u001b[0m - \u001b[1msolving step 17\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:39.113\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m313\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:39.407\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 64000<0.001\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:39.408\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m353\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:39.408\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:39.677\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m375\u001b[0m - \u001b[1mThe number of updated different actions: 4\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:39.677\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m378\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:39.678\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m403\u001b[0m - \u001b[1msolving step 18\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:39.678\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m313\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:39.975\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 64000<0.001\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:39.975\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m353\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:39.976\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:40.247\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m375\u001b[0m - \u001b[1mThe number of updated different actions: 8\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:40.247\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m378\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:40.248\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m403\u001b[0m - \u001b[1msolving step 19\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:40.248\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m313\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:40.545\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 64000<0.001\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:40.546\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m353\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:40.546\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:40.813\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m375\u001b[0m - \u001b[1mThe number of updated different actions: 8\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:40.814\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m378\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:40.814\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m403\u001b[0m - \u001b[1msolving step 20\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:40.815\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m313\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:41.113\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 64000<0.001\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:41.114\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m353\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:41.114\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:41.385\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m375\u001b[0m - \u001b[1mThe number of updated different actions: 12\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:41.386\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m378\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:41.386\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m403\u001b[0m - \u001b[1msolving step 21\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:41.386\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m313\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:41.682\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 64000<0.001\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:41.682\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m353\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:41.683\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:41.953\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m375\u001b[0m - \u001b[1mThe number of updated different actions: 12\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:41.954\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m378\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:41.954\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m403\u001b[0m - \u001b[1msolving step 22\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:41.955\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m313\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:42.248\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 64000<0.001\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:42.248\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m353\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:42.249\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:42.517\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m375\u001b[0m - \u001b[1mThe number of updated different actions: 14\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:42.517\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m378\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:42.518\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m403\u001b[0m - \u001b[1msolving step 23\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:42.518\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m313\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:42.814\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 64000<0.001\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:42.814\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m353\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:42.815\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:43.087\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m375\u001b[0m - \u001b[1mThe number of updated different actions: 14\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:43.088\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m378\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:43.088\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m403\u001b[0m - \u001b[1msolving step 24\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:43.089\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m313\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:43.382\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 64000<0.001\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:43.382\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m353\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:43.383\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:43.654\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m375\u001b[0m - \u001b[1mThe number of updated different actions: 14\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:43.654\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m378\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:43.654\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m403\u001b[0m - \u001b[1msolving step 25\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:43.655\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m313\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:43.946\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 64000<0.001\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:43.947\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m353\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:43.947\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:44.214\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m375\u001b[0m - \u001b[1mThe number of updated different actions: 10\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:44.214\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m378\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:44.214\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m403\u001b[0m - \u001b[1msolving step 26\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:44.215\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m313\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:44.564\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 64000<0.001\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:44.564\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m353\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:44.565\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:44.829\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m375\u001b[0m - \u001b[1mThe number of updated different actions: 4\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:44.830\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m378\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:44.830\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m403\u001b[0m - \u001b[1msolving step 27\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:44.830\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m313\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:45.124\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 64000<0.001\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:45.124\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m353\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:45.125\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:45.390\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m375\u001b[0m - \u001b[1mThe number of updated different actions: 10\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:45.390\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m378\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:45.391\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m403\u001b[0m - \u001b[1msolving step 28\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:45.391\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m313\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:45.681\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 64000<0.001\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:45.681\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m353\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:45.682\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:45.947\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m375\u001b[0m - \u001b[1mThe number of updated different actions: 10\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:45.947\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m378\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:45.948\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m403\u001b[0m - \u001b[1msolving step 29\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:45.948\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m313\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:46.237\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 64000<0.001\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:46.238\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m353\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:46.238\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:46.503\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m375\u001b[0m - \u001b[1mThe number of updated different actions: 4\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:46.503\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m378\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:46.504\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m403\u001b[0m - \u001b[1msolving step 30\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:46.504\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m313\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:46.793\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 64000<0.001\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:46.794\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m353\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:46.794\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:47.059\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m375\u001b[0m - \u001b[1mThe number of updated different actions: 8\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:47.059\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m378\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:47.060\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m403\u001b[0m - \u001b[1msolving step 31\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:47.060\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m313\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:47.353\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 64000<0.001\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:47.353\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m353\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:47.354\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:47.621\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m375\u001b[0m - \u001b[1mThe number of updated different actions: 16\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:47.621\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m378\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:47.622\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m403\u001b[0m - \u001b[1msolving step 32\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:47.622\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m313\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:47.918\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 64000<0.001\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:47.919\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m353\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:47.919\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:48.188\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m375\u001b[0m - \u001b[1mThe number of updated different actions: 8\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:48.188\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m378\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:48.189\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m403\u001b[0m - \u001b[1msolving step 33\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:48.189\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m313\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:48.483\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 64000<0.001\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:48.483\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m353\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:48.484\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:48.752\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m375\u001b[0m - \u001b[1mThe number of updated different actions: 6\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:48.753\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m378\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:48.753\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m403\u001b[0m - \u001b[1msolving step 34\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:48.753\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m313\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:49.049\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 64000<0.001\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:49.049\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m353\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:49.050\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:49.317\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m375\u001b[0m - \u001b[1mThe number of updated different actions: 8\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:49.317\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m378\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:49.318\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m403\u001b[0m - \u001b[1msolving step 35\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:49.318\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m313\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:49.611\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 64000<0.001\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:49.612\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m353\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:49.612\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:49.881\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m375\u001b[0m - \u001b[1mThe number of updated different actions: 10\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:49.882\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m378\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:49.882\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m403\u001b[0m - \u001b[1msolving step 36\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:49.883\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m313\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:50.178\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 64000<0.001\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:50.179\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m353\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:50.179\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:50.449\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m375\u001b[0m - \u001b[1mThe number of updated different actions: 6\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:50.450\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m378\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:50.450\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m403\u001b[0m - \u001b[1msolving step 37\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:50.451\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m313\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:50.749\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 64000<0.001\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:50.749\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m353\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:50.750\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:51.018\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m375\u001b[0m - \u001b[1mThe number of updated different actions: 4\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:51.018\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m378\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:51.019\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m403\u001b[0m - \u001b[1msolving step 38\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:51.019\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m313\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:51.311\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 64000<0.001\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:51.312\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m353\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:51.312\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:51.581\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m375\u001b[0m - \u001b[1mThe number of updated different actions: 6\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:51.581\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m378\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:51.582\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m403\u001b[0m - \u001b[1msolving step 39\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:51.583\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m313\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:51.877\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 64000<0.001\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:51.878\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m353\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:51.878\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:52.153\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m375\u001b[0m - \u001b[1mThe number of updated different actions: 10\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:52.153\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m378\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:52.153\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m403\u001b[0m - \u001b[1msolving step 40\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:52.154\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m313\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:52.443\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 64000<0.001\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:52.443\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m353\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:52.443\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:52.708\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m375\u001b[0m - \u001b[1mThe number of updated different actions: 8\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:52.708\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m378\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:52.709\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m403\u001b[0m - \u001b[1msolving step 41\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:52.709\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m313\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:53.003\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 64000<0.001\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:53.004\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m353\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:53.004\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:53.271\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m375\u001b[0m - \u001b[1mThe number of updated different actions: 10\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:53.272\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m378\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:53.272\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m403\u001b[0m - \u001b[1msolving step 42\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:53.273\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m313\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:53.566\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 64000<0.001\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:53.566\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m353\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:53.567\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:53.832\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m375\u001b[0m - \u001b[1mThe number of updated different actions: 8\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:53.833\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m378\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:53.833\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m403\u001b[0m - \u001b[1msolving step 43\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:53.833\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m313\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:54.127\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 64000<0.001\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:54.127\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m353\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:54.127\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:54.396\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m375\u001b[0m - \u001b[1mThe number of updated different actions: 2\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:54.396\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m378\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:54.397\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m403\u001b[0m - \u001b[1msolving step 44\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:54.397\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m313\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:54.688\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 64000<0.001\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:54.689\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m353\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:54.689\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:54.959\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m375\u001b[0m - \u001b[1mThe number of updated different actions: 2\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:54.960\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m378\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:54.960\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m403\u001b[0m - \u001b[1msolving step 45\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:54.961\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m313\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:55.253\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 64000<0.001\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:55.254\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m353\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:55.254\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:55.519\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m375\u001b[0m - \u001b[1mThe number of updated different actions: 10\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:55.520\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m378\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:55.520\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m403\u001b[0m - \u001b[1msolving step 46\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:55.522\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m313\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:55.814\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 64000<0.001\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:55.814\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m353\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:55.815\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:56.080\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m375\u001b[0m - \u001b[1mThe number of updated different actions: 8\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:56.081\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m378\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:56.081\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m403\u001b[0m - \u001b[1msolving step 47\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:56.081\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m313\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:56.415\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 64000<0.001\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:56.415\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m353\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:56.416\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:56.681\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m375\u001b[0m - \u001b[1mThe number of updated different actions: 10\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:56.682\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m378\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:56.683\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m403\u001b[0m - \u001b[1msolving step 48\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:56.683\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m313\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:56.981\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 64000<0.001\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:56.982\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m353\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:56.982\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:57.254\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m375\u001b[0m - \u001b[1mThe number of updated different actions: 10\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:57.254\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m378\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:57.254\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m403\u001b[0m - \u001b[1msolving step 49\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:57.255\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m313\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:57.547\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 64000<0.001\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:57.547\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m353\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:57.548\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:57.815\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m375\u001b[0m - \u001b[1mThe number of updated different actions: 6\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:57.816\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m378\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:57.816\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m403\u001b[0m - \u001b[1msolving step 50\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:57.816\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m313\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:58.117\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 64000<0.001\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:58.117\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m353\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:58.117\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:58.386\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m375\u001b[0m - \u001b[1mThe number of updated different actions: 16\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:58.387\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m378\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:58.387\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m403\u001b[0m - \u001b[1msolving step 51\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:58.387\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m313\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:58.681\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 64000<0.001\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:58.682\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m353\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:58.682\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:58.947\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m375\u001b[0m - \u001b[1mThe number of updated different actions: 6\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:58.947\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m378\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:58.947\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m403\u001b[0m - \u001b[1msolving step 52\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:58.948\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m313\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:59.242\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 64000<0.001\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:59.242\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m353\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:59.243\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:59.512\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m375\u001b[0m - \u001b[1mThe number of updated different actions: 4\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:59.512\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m378\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:59.513\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m403\u001b[0m - \u001b[1msolving step 53\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:59.513\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m313\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:59.808\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 64000<0.001\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:59.808\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m353\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:10:59.809\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-02-25 19:11:00.079\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m375\u001b[0m - \u001b[1mThe number of updated different actions: 4\u001b[0m\n",
            "\u001b[32m2025-02-25 19:11:00.079\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m378\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:11:00.080\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m403\u001b[0m - \u001b[1msolving step 54\u001b[0m\n",
            "\u001b[32m2025-02-25 19:11:00.080\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m313\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-02-25 19:11:00.375\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 64000<0.001\u001b[0m\n",
            "\u001b[32m2025-02-25 19:11:00.376\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m353\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:11:00.376\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-02-25 19:11:00.644\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m375\u001b[0m - \u001b[1mThe number of updated different actions: 8\u001b[0m\n",
            "\u001b[32m2025-02-25 19:11:00.645\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m378\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:11:00.645\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m403\u001b[0m - \u001b[1msolving step 55\u001b[0m\n",
            "\u001b[32m2025-02-25 19:11:00.645\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m313\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-02-25 19:11:00.938\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 64000<0.001\u001b[0m\n",
            "\u001b[32m2025-02-25 19:11:00.939\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m353\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:11:00.939\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-02-25 19:11:01.204\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m375\u001b[0m - \u001b[1mThe number of updated different actions: 8\u001b[0m\n",
            "\u001b[32m2025-02-25 19:11:01.205\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m378\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:11:01.205\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m403\u001b[0m - \u001b[1msolving step 56\u001b[0m\n",
            "\u001b[32m2025-02-25 19:11:01.205\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m313\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-02-25 19:11:01.497\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 64000<0.001\u001b[0m\n",
            "\u001b[32m2025-02-25 19:11:01.497\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m353\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:11:01.498\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-02-25 19:11:01.763\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m375\u001b[0m - \u001b[1mThe number of updated different actions: 8\u001b[0m\n",
            "\u001b[32m2025-02-25 19:11:01.764\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m378\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:11:01.764\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m403\u001b[0m - \u001b[1msolving step 57\u001b[0m\n",
            "\u001b[32m2025-02-25 19:11:01.764\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m313\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-02-25 19:11:02.056\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 64000<0.001\u001b[0m\n",
            "\u001b[32m2025-02-25 19:11:02.056\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m353\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:11:02.057\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-02-25 19:11:02.321\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m375\u001b[0m - \u001b[1mThe number of updated different actions: 8\u001b[0m\n",
            "\u001b[32m2025-02-25 19:11:02.322\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m378\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:11:02.322\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m403\u001b[0m - \u001b[1msolving step 58\u001b[0m\n",
            "\u001b[32m2025-02-25 19:11:02.323\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m313\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-02-25 19:11:02.615\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 64000<0.001\u001b[0m\n",
            "\u001b[32m2025-02-25 19:11:02.615\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m353\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:11:02.616\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-02-25 19:11:02.884\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m375\u001b[0m - \u001b[1mThe number of updated different actions: 4\u001b[0m\n",
            "\u001b[32m2025-02-25 19:11:02.885\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m378\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:11:02.885\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m403\u001b[0m - \u001b[1msolving step 59\u001b[0m\n",
            "\u001b[32m2025-02-25 19:11:02.886\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m313\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-02-25 19:11:03.179\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 64000<0.001\u001b[0m\n",
            "\u001b[32m2025-02-25 19:11:03.179\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m353\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:11:03.180\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-02-25 19:11:03.448\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m375\u001b[0m - \u001b[1mThe number of updated different actions: 4\u001b[0m\n",
            "\u001b[32m2025-02-25 19:11:03.449\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m378\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:11:03.449\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m403\u001b[0m - \u001b[1msolving step 60\u001b[0m\n",
            "\u001b[32m2025-02-25 19:11:03.450\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m313\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-02-25 19:11:03.740\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 64000<0.001\u001b[0m\n",
            "\u001b[32m2025-02-25 19:11:03.741\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m353\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:11:03.742\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-02-25 19:11:04.013\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m375\u001b[0m - \u001b[1mThe number of updated different actions: 4\u001b[0m\n",
            "\u001b[32m2025-02-25 19:11:04.013\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m378\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:11:04.014\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m403\u001b[0m - \u001b[1msolving step 61\u001b[0m\n",
            "\u001b[32m2025-02-25 19:11:04.014\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m313\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-02-25 19:11:04.311\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 64000<0.001\u001b[0m\n",
            "\u001b[32m2025-02-25 19:11:04.311\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m353\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:11:04.312\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-02-25 19:11:04.579\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m375\u001b[0m - \u001b[1mThe number of updated different actions: 4\u001b[0m\n",
            "\u001b[32m2025-02-25 19:11:04.579\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m378\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:11:04.580\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m403\u001b[0m - \u001b[1msolving step 62\u001b[0m\n",
            "\u001b[32m2025-02-25 19:11:04.580\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m313\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-02-25 19:11:04.872\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 64000<0.001\u001b[0m\n",
            "\u001b[32m2025-02-25 19:11:04.872\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m353\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:11:04.873\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-02-25 19:11:05.140\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m375\u001b[0m - \u001b[1mThe number of updated different actions: 6\u001b[0m\n",
            "\u001b[32m2025-02-25 19:11:05.141\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m378\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:11:05.141\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m403\u001b[0m - \u001b[1msolving step 63\u001b[0m\n",
            "\u001b[32m2025-02-25 19:11:05.142\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m313\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-02-25 19:11:05.476\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 64000<0.001\u001b[0m\n",
            "\u001b[32m2025-02-25 19:11:05.476\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m353\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:11:05.477\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-02-25 19:11:05.744\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m375\u001b[0m - \u001b[1mThe number of updated different actions: 8\u001b[0m\n",
            "\u001b[32m2025-02-25 19:11:05.744\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m378\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:11:05.745\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m403\u001b[0m - \u001b[1msolving step 64\u001b[0m\n",
            "\u001b[32m2025-02-25 19:11:05.745\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m313\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-02-25 19:11:06.039\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 64000<0.001\u001b[0m\n",
            "\u001b[32m2025-02-25 19:11:06.040\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m353\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:11:06.040\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-02-25 19:11:06.306\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m375\u001b[0m - \u001b[1mThe number of updated different actions: 8\u001b[0m\n",
            "\u001b[32m2025-02-25 19:11:06.307\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m378\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:11:06.307\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m403\u001b[0m - \u001b[1msolving step 65\u001b[0m\n",
            "\u001b[32m2025-02-25 19:11:06.307\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m313\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-02-25 19:11:06.598\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 64000<0.001\u001b[0m\n",
            "\u001b[32m2025-02-25 19:11:06.599\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m353\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:11:06.599\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-02-25 19:11:06.863\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m375\u001b[0m - \u001b[1mThe number of updated different actions: 2\u001b[0m\n",
            "\u001b[32m2025-02-25 19:11:06.864\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m378\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:11:06.864\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m403\u001b[0m - \u001b[1msolving step 66\u001b[0m\n",
            "\u001b[32m2025-02-25 19:11:06.864\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m313\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-02-25 19:11:07.153\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 64000<0.001\u001b[0m\n",
            "\u001b[32m2025-02-25 19:11:07.154\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m353\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:11:07.154\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-02-25 19:11:07.420\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m375\u001b[0m - \u001b[1mThe number of updated different actions: 6\u001b[0m\n",
            "\u001b[32m2025-02-25 19:11:07.421\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m378\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:11:07.421\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m403\u001b[0m - \u001b[1msolving step 67\u001b[0m\n",
            "\u001b[32m2025-02-25 19:11:07.421\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m313\u001b[0m - \u001b[1mStarting policy evaluation\u001b[0m\n",
            "\u001b[32m2025-02-25 19:11:07.718\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mMax Error: 0.0 | Avg Error: 0.0 | 64000<0.001\u001b[0m\n",
            "\u001b[32m2025-02-25 19:11:07.718\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_evaluation\u001b[0m:\u001b[36m353\u001b[0m - \u001b[1mPolicy evaluation finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:11:07.719\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mStarting policy improvement\u001b[0m\n",
            "\u001b[32m2025-02-25 19:11:07.983\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36mpolicy_improvement\u001b[0m:\u001b[36m378\u001b[0m - \u001b[1mPolicy improvement finished.\u001b[0m\n",
            "\u001b[32m2025-02-25 19:11:08.367\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mPolicyIteration\u001b[0m:\u001b[36msave\u001b[0m:\u001b[36m422\u001b[0m - \u001b[1mPolicy and value function saved.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "import airplane\n",
        "import numpy as np\n",
        "import gymnasium as gym\n",
        "from utils.utils import test_enviroment\n",
        "from PolicyIteration import PolicyIteration\n",
        "\n",
        "glider = gym.make('ReducedBankedGliderPullout-v0')\n",
        "\n",
        "bins_space = {\n",
        "    \"flight_path_angle\": np.linspace(np.deg2rad(-90), np.deg2rad(5),    40,      dtype=np.float32),    # Flight Path Angle  (γ)    (0)\n",
        "    \"airspeed_norm\":     np.linspace(0.7, 4.0,                          40,      dtype=np.float32),    # Air Speed          (V)    (1)\n",
        "    \"bank_angle\":        np.linspace( np.deg2rad(-30), np.deg2rad(200), 40,      dtype=np.float32),    # Bank Angle         (mu)   (2)\n",
        "}\n",
        "\n",
        "action_space= np.array(np.meshgrid(np.linspace(-0.5, 1.0, 8, dtype=np.float32), \n",
        "                                   np.linspace(np.deg2rad(-30), np.deg2rad(30), 8, dtype=np.float32))).T.reshape(-1, 2)\n",
        "\n",
        "pi = PolicyIteration(\n",
        "    env=glider, \n",
        "    bins_space=bins_space,\n",
        "    action_space= action_space,\n",
        "    gamma=0.99,\n",
        "    theta=1e-3,\n",
        ")\n",
        "\n",
        "\n",
        "pi.run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "442d7f05",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Action: [-0.5    0.224] | Reward: -0.011899000705081882 |                 State: (-79.964599609375, 1.2032743692398071, 150.12855529785156) | Terminated: False |                Episode Length: 0.01 | C_L: -0.5\n",
            "Action: [-0.5    0.224] | Reward: -0.023828915756348074 |                 State: (-79.92896270751953, 1.2065467834472656, 150.2571258544922) | Terminated: False |                Episode Length: 0.02 | C_L: -0.5\n",
            "Action: [-0.5    0.224] | Reward: -0.03578970671527806 |                 State: (-79.89308166503906, 1.2098175287246704, 150.3856964111328) | Terminated: False |                Episode Length: 0.03 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -0.047736574786324336 |                 State: (-79.85697174072266, 1.2130863666534424, 150.42857360839844) | Terminated: False |                Episode Length: 0.04 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -0.05971424325823324 |                 State: (-79.82067108154297, 1.216353416442871, 150.47142028808594) | Terminated: False |                Episode Length: 0.05 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -0.07172267510003692 |                 State: (-79.78419494628906, 1.2196186780929565, 150.5142822265625) | Terminated: False |                Episode Length: 0.060000000000000005 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -0.08376183307306448 |                 State: (-79.7475357055664, 1.2228820323944092, 150.55714416503906) | Terminated: False |                Episode Length: 0.07 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -0.09583167973013908 |                 State: (-79.71070098876953, 1.226143479347229, 150.59999084472656) | Terminated: False |                Episode Length: 0.08 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -0.1079321774147755 |                 State: (-79.6736831665039, 1.2294031381607056, 150.64285278320312) | Terminated: False |                Episode Length: 0.09 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -0.12006328826037801 |                 State: (-79.63648223876953, 1.2326608896255493, 150.6857147216797) | Terminated: False |                Episode Length: 0.09999999999999999 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -0.13222497418943885 |                 State: (-79.59910583496094, 1.2359168529510498, 150.7285614013672) | Terminated: False |                Episode Length: 0.10999999999999999 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -0.14441719691273694 |                 State: (-79.5615463256836, 1.2391709089279175, 150.77142333984375) | Terminated: False |                Episode Length: 0.11999999999999998 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -0.15663991792853746 |                 State: (-79.52381896972656, 1.2424230575561523, 150.8142852783203) | Terminated: False |                Episode Length: 0.12999999999999998 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -0.16889309852179174 |                 State: (-79.48590850830078, 1.2456732988357544, 150.8571319580078) | Terminated: False |                Episode Length: 0.13999999999999999 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -0.18117669976333786 |                 State: (-79.44782257080078, 1.2489217519760132, 150.89999389648438) | Terminated: False |                Episode Length: 0.15 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -0.19349068250910184 |                 State: (-79.40955352783203, 1.2521681785583496, 150.94284057617188) | Terminated: False |                Episode Length: 0.16 | C_L: -0.5\n",
            "Action: [-0.5    0.224] | Reward: -0.20587976751211395 |                 State: (-79.37110900878906, 1.2554126977920532, 151.0714111328125) | Terminated: False |                Episode Length: 0.17 | C_L: -0.5\n",
            "Action: [-0.5    0.224] | Reward: -0.21829915276391743 |                 State: (-79.33242797851562, 1.2586554288864136, 151.19998168945312) | Terminated: False |                Episode Length: 0.18000000000000002 | C_L: -0.5\n",
            "Action: [-0.5    0.224] | Reward: -0.23074879610917523 |                 State: (-79.29352569580078, 1.2618961334228516, 151.32855224609375) | Terminated: False |                Episode Length: 0.19000000000000003 | C_L: -0.5\n",
            "Action: [-0.5    0.224] | Reward: -0.243228655131753 |                 State: (-79.25437927246094, 1.2651349306106567, 151.45712280273438) | Terminated: False |                Episode Length: 0.20000000000000004 | C_L: -0.5\n",
            "Action: [-0.5    0.224] | Reward: -0.2557386871536206 |                 State: (-79.21500396728516, 1.268371820449829, 151.585693359375) | Terminated: False |                Episode Length: 0.21000000000000005 | C_L: -0.5\n",
            "Action: [-0.5    0.224] | Reward: -0.26827884923375733 |                 State: (-79.17540740966797, 1.271606683731079, 151.71426391601562) | Terminated: False |                Episode Length: 0.22000000000000006 | C_L: -0.5\n",
            "Action: [-0.5    0.224] | Reward: -0.28084909816706227 |                 State: (-79.13557434082031, 1.2748396396636963, 151.8428497314453) | Terminated: False |                Episode Length: 0.23000000000000007 | C_L: -0.5\n",
            "Action: [-0.5    0.224] | Reward: -0.29344939048326796 |                 State: (-79.09550476074219, 1.2780706882476807, 151.97142028808594) | Terminated: False |                Episode Length: 0.24000000000000007 | C_L: -0.5\n",
            "Action: [-0.5    0.224] | Reward: -0.3060796824458595 |                 State: (-79.05520629882812, 1.2812997102737427, 152.09999084472656) | Terminated: False |                Episode Length: 0.25000000000000006 | C_L: -0.5\n",
            "Action: [-0.5    0.224] | Reward: -0.31873993005099766 |                 State: (-79.01468658447266, 1.2845268249511719, 152.2285614013672) | Terminated: False |                Episode Length: 0.26000000000000006 | C_L: -0.5\n",
            "Action: [-0.5    0.224] | Reward: -0.3314300890264473 |                 State: (-78.97393798828125, 1.2877519130706787, 152.3571319580078) | Terminated: False |                Episode Length: 0.2700000000000001 | C_L: -0.5\n",
            "Action: [-0.5    0.224] | Reward: -0.3441501148305103 |                 State: (-78.93295288085938, 1.2909749746322632, 152.48570251464844) | Terminated: False |                Episode Length: 0.2800000000000001 | C_L: -0.5\n",
            "Action: [-0.5    0.224] | Reward: -0.3568999626509635 |                 State: (-78.89173889160156, 1.2941961288452148, 152.61427307128906) | Terminated: False |                Episode Length: 0.2900000000000001 | C_L: -0.5\n",
            "Action: [-0.5    0.224] | Reward: -0.3696795874040024 |                 State: (-78.85031127929688, 1.2974152565002441, 152.7428436279297) | Terminated: False |                Episode Length: 0.3000000000000001 | C_L: -0.5\n",
            "Action: [-0.5    0.224] | Reward: -0.3824889437331893 |                 State: (-78.80864715576172, 1.300632357597351, 152.8714141845703) | Terminated: False |                Episode Length: 0.3100000000000001 | C_L: -0.5\n",
            "Action: [-0.5    0.224] | Reward: -0.3953279860084075 |                 State: (-78.76676177978516, 1.3038474321365356, 152.99998474121094) | Terminated: False |                Episode Length: 0.3200000000000001 | C_L: -0.5\n",
            "Action: [-0.5    0.224] | Reward: -0.4081966683248209 |                 State: (-78.72464752197266, 1.3070604801177979, 153.12855529785156) | Terminated: False |                Episode Length: 0.3300000000000001 | C_L: -0.5\n",
            "Action: [-0.5    0.224] | Reward: -0.42109494450183893 |                 State: (-78.68230438232422, 1.3102715015411377, 153.2571258544922) | Terminated: False |                Episode Length: 0.34000000000000014 | C_L: -0.5\n",
            "Action: [-0.5    0.224] | Reward: -0.43402276808208806 |                 State: (-78.6397476196289, 1.3134804964065552, 153.3856964111328) | Terminated: False |                Episode Length: 0.35000000000000014 | C_L: -0.5\n",
            "Action: [-0.5    0.224] | Reward: -0.4469800923303885 |                 State: (-78.59695434570312, 1.3166873455047607, 153.51426696777344) | Terminated: False |                Episode Length: 0.36000000000000015 | C_L: -0.5\n",
            "Action: [-0.5    0.224] | Reward: -0.4599668702327374 |                 State: (-78.55394744873047, 1.3198922872543335, 153.64283752441406) | Terminated: False |                Episode Length: 0.37000000000000016 | C_L: -0.5\n",
            "Action: [-0.5    0.224] | Reward: -0.4729830544952982 |                 State: (-78.5107192993164, 1.3230950832366943, 153.7714080810547) | Terminated: False |                Episode Length: 0.38000000000000017 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -0.4859838374305819 |                 State: (-78.4672622680664, 1.3262958526611328, 153.8142852783203) | Terminated: False |                Episode Length: 0.3900000000000002 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -0.49901393384722176 |                 State: (-78.42363739013672, 1.3294944763183594, 153.8571319580078) | Terminated: False |                Episode Length: 0.4000000000000002 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -0.5120732982019348 |                 State: (-78.37985229492188, 1.3326910734176636, 153.8999786376953) | Terminated: False |                Episode Length: 0.4100000000000002 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -0.525161884711572 |                 State: (-78.33589935302734, 1.3358856439590454, 153.94285583496094) | Terminated: False |                Episode Length: 0.4200000000000002 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -0.5382796473523557 |                 State: (-78.29177856445312, 1.3390779495239258, 153.98570251464844) | Terminated: False |                Episode Length: 0.4300000000000002 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -0.5514265398591198 |                 State: (-78.24748992919922, 1.3422683477401733, 154.028564453125) | Terminated: False |                Episode Length: 0.4400000000000002 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -0.5646025157245519 |                 State: (-78.20304107666016, 1.3454564809799194, 154.07142639160156) | Terminated: False |                Episode Length: 0.45000000000000023 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -0.5778075281984365 |                 State: (-78.1584243774414, 1.3486425876617432, 154.11427307128906) | Terminated: False |                Episode Length: 0.46000000000000024 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -0.591041530286902 |                 State: (-78.11363983154297, 1.351826548576355, 154.15713500976562) | Terminated: False |                Episode Length: 0.47000000000000025 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -0.6043044747516684 |                 State: (-78.06868743896484, 1.3550082445144653, 154.1999969482422) | Terminated: False |                Episode Length: 0.48000000000000026 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -0.6175963141092983 |                 State: (-78.0235824584961, 1.3581879138946533, 154.2428436279297) | Terminated: False |                Episode Length: 0.49000000000000027 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -0.6309170006304496 |                 State: (-77.97830200195312, 1.3613654375076294, 154.28570556640625) | Terminated: False |                Episode Length: 0.5000000000000002 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -0.6442664863391309 |                 State: (-77.932861328125, 1.3645408153533936, 154.3285675048828) | Terminated: False |                Episode Length: 0.5100000000000002 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -0.6576447230119586 |                 State: (-77.88726806640625, 1.3677140474319458, 154.3714141845703) | Terminated: False |                Episode Length: 0.5200000000000002 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -0.6710516621774176 |                 State: (-77.84149932861328, 1.3708851337432861, 154.41427612304688) | Terminated: False |                Episode Length: 0.5300000000000002 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -0.6844872551151232 |                 State: (-77.79557037353516, 1.374053955078125, 154.45713806152344) | Terminated: False |                Episode Length: 0.5400000000000003 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -0.6979514528550862 |                 State: (-77.74948120117188, 1.3772207498550415, 154.49998474121094) | Terminated: False |                Episode Length: 0.5500000000000003 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -0.7114442061769803 |                 State: (-77.7032241821289, 1.380385160446167, 154.5428466796875) | Terminated: False |                Episode Length: 0.5600000000000003 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -0.7249654656094128 |                 State: (-77.65681457519531, 1.3835475444793701, 154.58570861816406) | Terminated: False |                Episode Length: 0.5700000000000003 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -0.7385151814291963 |                 State: (-77.6102294921875, 1.3867076635360718, 154.62855529785156) | Terminated: False |                Episode Length: 0.5800000000000003 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -0.752093303660625 |                 State: (-77.56349182128906, 1.389865517616272, 154.67141723632812) | Terminated: False |                Episode Length: 0.5900000000000003 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -0.7656997820747525 |                 State: (-77.5166015625, 1.3930212259292603, 154.7142791748047) | Terminated: False |                Episode Length: 0.6000000000000003 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -0.7793345661886729 |                 State: (-77.46953582763672, 1.396174669265747, 154.75714111328125) | Terminated: False |                Episode Length: 0.6100000000000003 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -0.7929976052648042 |                 State: (-77.42231750488281, 1.3993258476257324, 154.79998779296875) | Terminated: False |                Episode Length: 0.6200000000000003 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -0.8066888483101753 |                 State: (-77.37493133544922, 1.4024748802185059, 154.8428497314453) | Terminated: False |                Episode Length: 0.6300000000000003 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -0.820408244075715 |                 State: (-77.327392578125, 1.4056216478347778, 154.88571166992188) | Terminated: False |                Episode Length: 0.6400000000000003 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -0.8341557410555452 |                 State: (-77.27969360351562, 1.4087661504745483, 154.92855834960938) | Terminated: False |                Episode Length: 0.6500000000000004 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -0.8479312874862758 |                 State: (-77.23182678222656, 1.4119083881378174, 154.97142028808594) | Terminated: False |                Episode Length: 0.6600000000000004 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -0.8617348313463031 |                 State: (-77.18380737304688, 1.415048360824585, 155.0142822265625) | Terminated: False |                Episode Length: 0.6700000000000004 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -0.8755663203551122 |                 State: (-77.13562774658203, 1.418186068534851, 155.05712890625) | Terminated: False |                Episode Length: 0.6800000000000004 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -0.8894257019725806 |                 State: (-77.08728790283203, 1.4213215112686157, 155.09999084472656) | Terminated: False |                Episode Length: 0.6900000000000004 | C_L: -0.5\n",
            "Action: [-0.5    0.224] | Reward: -0.9033576835111018 |                 State: (-77.0387954711914, 1.424454689025879, 155.2285614013672) | Terminated: False |                Episode Length: 0.7000000000000004 | C_L: -0.5\n",
            "Action: [-0.5    0.224] | Reward: -0.9173174486512886 |                 State: (-76.99008178710938, 1.427585482597351, 155.3571319580078) | Terminated: False |                Episode Length: 0.7100000000000004 | C_L: -0.5\n",
            "Action: [-0.5    0.224] | Reward: -0.9313049408759787 |                 State: (-76.94115447998047, 1.4307141304016113, 155.48570251464844) | Terminated: False |                Episode Length: 0.7200000000000004 | C_L: -0.5\n",
            "Action: [-0.5    0.224] | Reward: -0.9453201033565961 |                 State: (-76.89202117919922, 1.433840274810791, 155.61428833007812) | Terminated: False |                Episode Length: 0.7300000000000004 | C_L: -0.5\n",
            "Action: [-0.5    0.224] | Reward: -0.9593628789523377 |                 State: (-76.84266662597656, 1.4369642734527588, 155.74285888671875) | Terminated: False |                Episode Length: 0.7400000000000004 | C_L: -0.5\n",
            "Action: [-0.5    0.224] | Reward: -0.9734332102093702 |                 State: (-76.79310607910156, 1.4400858879089355, 155.87142944335938) | Terminated: False |                Episode Length: 0.7500000000000004 | C_L: -0.5\n",
            "Action: [-0.5    0.224] | Reward: -0.9875310393600369 |                 State: (-76.74332427978516, 1.4432051181793213, 156.0) | Terminated: False |                Episode Length: 0.7600000000000005 | C_L: -0.5\n",
            "Action: [-0.5    0.224] | Reward: -1.0016563083220758 |                 State: (-76.6933364868164, 1.4463220834732056, 156.12857055664062) | Terminated: False |                Episode Length: 0.7700000000000005 | C_L: -0.5\n",
            "Action: [-0.5    0.224] | Reward: -1.0158089586978472 |                 State: (-76.64314270019531, 1.4494366645812988, 156.25714111328125) | Terminated: False |                Episode Length: 0.7800000000000005 | C_L: -0.5\n",
            "Action: [-0.5    0.224] | Reward: -1.0299889317735735 |                 State: (-76.59273529052734, 1.452548861503601, 156.38571166992188) | Terminated: False |                Episode Length: 0.7900000000000005 | C_L: -0.5\n",
            "Action: [-0.5    0.224] | Reward: -1.0441961685185892 |                 State: (-76.5421142578125, 1.4556586742401123, 156.5142822265625) | Terminated: False |                Episode Length: 0.8000000000000005 | C_L: -0.5\n",
            "Action: [-0.5    0.224] | Reward: -1.0584306095846017 |                 State: (-76.49128723144531, 1.458766222000122, 156.64285278320312) | Terminated: False |                Episode Length: 0.8100000000000005 | C_L: -0.5\n",
            "Action: [-0.5    0.224] | Reward: -1.072692195304964 |                 State: (-76.44024658203125, 1.4618712663650513, 156.77142333984375) | Terminated: False |                Episode Length: 0.8200000000000005 | C_L: -0.5\n",
            "Action: [-0.5    0.224] | Reward: -1.0869808656939584 |                 State: (-76.38900756835938, 1.464974045753479, 156.89999389648438) | Terminated: False |                Episode Length: 0.8300000000000005 | C_L: -0.5\n",
            "Action: [-0.5    0.224] | Reward: -1.1012965604460918 |                 State: (-76.33755493164062, 1.4680743217468262, 157.028564453125) | Terminated: False |                Episode Length: 0.8400000000000005 | C_L: -0.5\n",
            "Action: [-0.5    0.224] | Reward: -1.115639218935403 |                 State: (-76.28590393066406, 1.4711722135543823, 157.15713500976562) | Terminated: False |                Episode Length: 0.8500000000000005 | C_L: -0.5\n",
            "Action: [-0.5    0.224] | Reward: -1.1300087802147811 |                 State: (-76.2340316772461, 1.4742677211761475, 157.28570556640625) | Terminated: False |                Episode Length: 0.8600000000000005 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -1.1443604229024822 |                 State: (-76.18196105957031, 1.4773608446121216, 157.3285675048828) | Terminated: False |                Episode Length: 0.8700000000000006 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -1.158738848822406 |                 State: (-76.1297378540039, 1.4804514646530151, 157.3714141845703) | Terminated: False |                Episode Length: 0.8800000000000006 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -1.1731439994099218 |                 State: (-76.07736206054688, 1.4835397005081177, 157.41427612304688) | Terminated: False |                Episode Length: 0.8900000000000006 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -1.187575815824079 |                 State: (-76.02483367919922, 1.4866255521774292, 157.45713806152344) | Terminated: False |                Episode Length: 0.9000000000000006 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -1.2020342389470078 |                 State: (-75.97215270996094, 1.4897087812423706, 157.49998474121094) | Terminated: False |                Episode Length: 0.9100000000000006 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -1.216519209383324 |                 State: (-75.91932678222656, 1.4927897453308105, 157.5428466796875) | Terminated: False |                Episode Length: 0.9200000000000006 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -1.2310306674595386 |                 State: (-75.86634063720703, 1.4958680868148804, 157.58570861816406) | Terminated: False |                Episode Length: 0.9300000000000006 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -1.2455685532234724 |                 State: (-75.8132095336914, 1.4989440441131592, 157.62855529785156) | Terminated: False |                Episode Length: 0.9400000000000006 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -1.2601328064436743 |                 State: (-75.75992584228516, 1.5020174980163574, 157.6714324951172) | Terminated: False |                Episode Length: 0.9500000000000006 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -1.274723366608845 |                 State: (-75.70649719238281, 1.505088448524475, 157.7142791748047) | Terminated: False |                Episode Length: 0.9600000000000006 | C_L: -0.5\n",
            "Action: [-0.5    0.224] | Reward: -1.2893849330400795 |                 State: (-75.65291595458984, 1.5081568956375122, 157.8428497314453) | Terminated: False |                Episode Length: 0.9700000000000006 | C_L: -0.5\n",
            "Action: [-0.5    0.224] | Reward: -1.3040726810457082 |                 State: (-75.59912872314453, 1.5112228393554688, 157.97142028808594) | Terminated: False |                Episode Length: 0.9800000000000006 | C_L: -0.5\n",
            "Action: [-0.5    0.224] | Reward: -1.318786545716995 |                 State: (-75.54513549804688, 1.5142862796783447, 158.09999084472656) | Terminated: False |                Episode Length: 0.9900000000000007 | C_L: -0.5\n",
            "Action: [-0.5    0.224] | Reward: -1.3335264618147762 |                 State: (-75.4909439086914, 1.5173472166061401, 158.2285614013672) | Terminated: False |                Episode Length: 1.0000000000000007 | C_L: -0.5\n",
            "Action: [-0.5    0.224] | Reward: -1.3482923637689288 |                 State: (-75.43655395507812, 1.520405650138855, 158.3571319580078) | Terminated: False |                Episode Length: 1.0100000000000007 | C_L: -0.5\n",
            "Action: [-0.5    0.224] | Reward: -1.363084185677852 |                 State: (-75.38195037841797, 1.5234614610671997, 158.48570251464844) | Terminated: False |                Episode Length: 1.0200000000000007 | C_L: -0.5\n",
            "Action: [-0.5    0.224] | Reward: -1.3779018613079623 |                 State: (-75.32716369628906, 1.5265147686004639, 158.61427307128906) | Terminated: False |                Episode Length: 1.0300000000000007 | C_L: -0.5\n",
            "Action: [-0.5    0.224] | Reward: -1.3927453240932037 |                 State: (-75.27216339111328, 1.5295655727386475, 158.7428436279297) | Terminated: False |                Episode Length: 1.0400000000000007 | C_L: -0.5\n",
            "Action: [-0.5    0.224] | Reward: -1.4076145071345711 |                 State: (-75.21697235107422, 1.532613754272461, 158.8714141845703) | Terminated: False |                Episode Length: 1.0500000000000007 | C_L: -0.5\n",
            "Action: [-0.5    0.224] | Reward: -1.4225093431996478 |                 State: (-75.16157531738281, 1.5356594324111938, 158.99998474121094) | Terminated: False |                Episode Length: 1.0600000000000007 | C_L: -0.5\n",
            "Action: [-0.5    0.224] | Reward: -1.4374297647221586 |                 State: (-75.10598754882812, 1.5387024879455566, 159.12857055664062) | Terminated: False |                Episode Length: 1.0700000000000007 | C_L: -0.5\n",
            "Action: [-0.5    0.224] | Reward: -1.452375703801536 |                 State: (-75.05018615722656, 1.5417430400848389, 159.25714111328125) | Terminated: False |                Episode Length: 1.0800000000000007 | C_L: -0.5\n",
            "Action: [-0.5    0.224] | Reward: -1.4673470922025025 |                 State: (-74.99420166015625, 1.5447808504104614, 159.38571166992188) | Terminated: False |                Episode Length: 1.0900000000000007 | C_L: -0.5\n",
            "Action: [-0.5    0.224] | Reward: -1.482343861354667 |                 State: (-74.93801879882812, 1.5478161573410034, 159.5142822265625) | Terminated: False |                Episode Length: 1.1000000000000008 | C_L: -0.5\n",
            "Action: [-0.5    0.224] | Reward: -1.4973659423521357 |                 State: (-74.88163757324219, 1.5508488416671753, 159.64285278320312) | Terminated: False |                Episode Length: 1.1100000000000008 | C_L: -0.5\n",
            "Action: [-0.5    0.224] | Reward: -1.51241326595314 |                 State: (-74.82505798339844, 1.553878903388977, 159.77142333984375) | Terminated: False |                Episode Length: 1.1200000000000008 | C_L: -0.5\n",
            "Action: [-0.5    0.224] | Reward: -1.5274857625796765 |                 State: (-74.7682876586914, 1.5569063425064087, 159.89999389648438) | Terminated: False |                Episode Length: 1.1300000000000008 | C_L: -0.5\n",
            "Action: [-0.5    0.224] | Reward: -1.542583362317166 |                 State: (-74.7113265991211, 1.5599311590194702, 160.028564453125) | Terminated: False |                Episode Length: 1.1400000000000008 | C_L: -0.5\n",
            "Action: [-0.5    0.224] | Reward: -1.5577059949141256 |                 State: (-74.65415954589844, 1.562953233718872, 160.15713500976562) | Terminated: False |                Episode Length: 1.1500000000000008 | C_L: -0.5\n",
            "Action: [-0.5    0.224] | Reward: -1.572853589781857 |                 State: (-74.59680938720703, 1.5659726858139038, 160.28570556640625) | Terminated: False |                Episode Length: 1.1600000000000008 | C_L: -0.5\n",
            "Action: [-0.5    0.224] | Reward: -1.5880260759941507 |                 State: (-74.53926086425781, 1.5689895153045654, 160.41427612304688) | Terminated: False |                Episode Length: 1.1700000000000008 | C_L: -0.5\n",
            "Action: [-0.5    0.224] | Reward: -1.603223382287007 |                 State: (-74.48152160644531, 1.572003722190857, 160.5428466796875) | Terminated: False |                Episode Length: 1.1800000000000008 | C_L: -0.5\n",
            "Action: [-0.5    0.224] | Reward: -1.6184454370583712 |                 State: (-74.42359161376953, 1.5750151872634888, 160.67141723632812) | Terminated: False |                Episode Length: 1.1900000000000008 | C_L: -0.5\n",
            "Action: [-0.5    0.224] | Reward: -1.6336921683678869 |                 State: (-74.36546325683594, 1.5780240297317505, 160.79998779296875) | Terminated: False |                Episode Length: 1.2000000000000008 | C_L: -0.5\n",
            "Action: [-0.5    0.224] | Reward: -1.6489635039366641 |                 State: (-74.30714416503906, 1.5810301303863525, 160.92855834960938) | Terminated: False |                Episode Length: 1.2100000000000009 | C_L: -0.5\n",
            "Action: [-0.5    0.224] | Reward: -1.6642593711470648 |                 State: (-74.24864959716797, 1.584033489227295, 161.05712890625) | Terminated: False |                Episode Length: 1.2200000000000009 | C_L: -0.5\n",
            "Action: [-0.5    0.224] | Reward: -1.6795796970425048 |                 State: (-74.18995666503906, 1.5870342254638672, 161.1857147216797) | Terminated: False |                Episode Length: 1.2300000000000009 | C_L: -0.5\n",
            "Action: [-0.5    0.224] | Reward: -1.694924408327272 |                 State: (-74.13107299804688, 1.5900321006774902, 161.3142852783203) | Terminated: False |                Episode Length: 1.2400000000000009 | C_L: -0.5\n",
            "Action: [-0.5    0.224] | Reward: -1.7102934313663627 |                 State: (-74.0719985961914, 1.5930273532867432, 161.44285583496094) | Terminated: False |                Episode Length: 1.2500000000000009 | C_L: -0.5\n",
            "Action: [-0.5    0.224] | Reward: -1.7256866921853324 |                 State: (-74.01274108886719, 1.5960198640823364, 161.57142639160156) | Terminated: False |                Episode Length: 1.260000000000001 | C_L: -0.5\n",
            "Action: [-0.5    0.224] | Reward: -1.7411041164701664 |                 State: (-73.95328521728516, 1.59900963306427, 161.6999969482422) | Terminated: False |                Episode Length: 1.270000000000001 | C_L: -0.5\n",
            "Action: [-0.5    0.224] | Reward: -1.7565456295671664 |                 State: (-73.8936538696289, 1.601996660232544, 161.8285675048828) | Terminated: False |                Episode Length: 1.280000000000001 | C_L: -0.5\n",
            "Action: [-0.5    0.224] | Reward: -1.7720111564828542 |                 State: (-73.83383178710938, 1.6049808263778687, 161.95713806152344) | Terminated: False |                Episode Length: 1.290000000000001 | C_L: -0.5\n",
            "Action: [-0.5    0.224] | Reward: -1.7875006218838934 |                 State: (-73.77383422851562, 1.6079622507095337, 162.08570861816406) | Terminated: False |                Episode Length: 1.300000000000001 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -1.8029691899842142 |                 State: (-73.71363830566406, 1.610940933227539, 162.12855529785156) | Terminated: False |                Episode Length: 1.310000000000001 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -1.8184615485510527 |                 State: (-73.65331268310547, 1.6139168739318848, 162.17141723632812) | Terminated: False |                Episode Length: 1.320000000000001 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -1.8339776249379982 |                 State: (-73.59284210205078, 1.6168899536132812, 162.2142791748047) | Terminated: False |                Episode Length: 1.330000000000001 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -1.8495173461974963 |                 State: (-73.53224182128906, 1.619860291481018, 162.2571258544922) | Terminated: False |                Episode Length: 1.340000000000001 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -1.8650806390805443 |                 State: (-73.47150421142578, 1.6228276491165161, 162.29998779296875) | Terminated: False |                Episode Length: 1.350000000000001 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -1.8806674300363933 |                 State: (-73.41061401367188, 1.625792384147644, 162.3428497314453) | Terminated: False |                Episode Length: 1.360000000000001 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -1.8962776452122576 |                 State: (-73.34960174560547, 1.6287541389465332, 162.3856964111328) | Terminated: False |                Episode Length: 1.370000000000001 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -1.9119112104530318 |                 State: (-73.28844451904297, 1.6317131519317627, 162.42855834960938) | Terminated: False |                Episode Length: 1.380000000000001 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -1.927568051301014 |                 State: (-73.22715759277344, 1.634669303894043, 162.47142028808594) | Terminated: False |                Episode Length: 1.390000000000001 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -1.9432480929956375 |                 State: (-73.16572570800781, 1.637622594833374, 162.5142822265625) | Terminated: False |                Episode Length: 1.400000000000001 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -1.9589512604732084 |                 State: (-73.10416412353516, 1.6405730247497559, 162.55712890625) | Terminated: False |                Episode Length: 1.410000000000001 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -1.9746774783666519 |                 State: (-73.04247283935547, 1.6435205936431885, 162.59999084472656) | Terminated: False |                Episode Length: 1.420000000000001 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -1.990426671005265 |                 State: (-72.98063659667969, 1.6464651823043823, 162.64285278320312) | Terminated: False |                Episode Length: 1.430000000000001 | C_L: -0.5\n",
            "Action: [-0.5    0.224] | Reward: -2.006243522527291 |                 State: (-72.91865539550781, 1.6494070291519165, 162.77142333984375) | Terminated: False |                Episode Length: 1.440000000000001 | C_L: -0.5\n",
            "Action: [-0.5    0.224] | Reward: -2.022083192636644 |                 State: (-72.85651397705078, 1.652345895767212, 162.89999389648438) | Terminated: False |                Episode Length: 1.450000000000001 | C_L: -0.5\n",
            "Action: [-0.5    0.224] | Reward: -2.0379456008074732 |                 State: (-72.79418182373047, 1.655281901359558, 163.028564453125) | Terminated: False |                Episode Length: 1.460000000000001 | C_L: -0.5\n",
            "Action: [-0.5    0.224] | Reward: -2.0538306661715167 |                 State: (-72.73165893554688, 1.658215045928955, 163.15713500976562) | Terminated: False |                Episode Length: 1.470000000000001 | C_L: -0.5\n",
            "Action: [-0.5    0.224] | Reward: -2.069738307518283 |                 State: (-72.66897583007812, 1.6611452102661133, 163.28570556640625) | Terminated: False |                Episode Length: 1.480000000000001 | C_L: -0.5\n",
            "Action: [-0.5    0.224] | Reward: -2.0856684432952544 |                 State: (-72.6061019897461, 1.6640725135803223, 163.41427612304688) | Terminated: False |                Episode Length: 1.490000000000001 | C_L: -0.5\n",
            "Action: [-0.5    0.224] | Reward: -2.101620991608109 |                 State: (-72.54305267333984, 1.6669968366622925, 163.5428466796875) | Terminated: False |                Episode Length: 1.500000000000001 | C_L: -0.5\n",
            "Action: [-0.5    0.224] | Reward: -2.1175958702209643 |                 State: (-72.47982788085938, 1.669918179512024, 163.67141723632812) | Terminated: False |                Episode Length: 1.5100000000000011 | C_L: -0.5\n",
            "Action: [-0.5    0.224] | Reward: -2.133592996556638 |                 State: (-72.41641998291016, 1.6728365421295166, 163.79998779296875) | Terminated: False |                Episode Length: 1.5200000000000011 | C_L: -0.5\n",
            "Action: [-0.5    0.224] | Reward: -2.1496122876969297 |                 State: (-72.35283660888672, 1.67575204372406, 163.92855834960938) | Terminated: False |                Episode Length: 1.5300000000000011 | C_L: -0.5\n",
            "Action: [-0.5    0.224] | Reward: -2.1656536603829237 |                 State: (-72.28907775878906, 1.6786644458770752, 164.05712890625) | Terminated: False |                Episode Length: 1.5400000000000011 | C_L: -0.5\n",
            "Action: [-0.5    0.224] | Reward: -2.1817170310153107 |                 State: (-72.22515106201172, 1.6815739870071411, 164.18569946289062) | Terminated: False |                Episode Length: 1.5500000000000012 | C_L: -0.5\n",
            "Action: [-0.5    0.224] | Reward: -2.197802315654729 |                 State: (-72.16104125976562, 1.6844805479049683, 164.31427001953125) | Terminated: False |                Episode Length: 1.5600000000000012 | C_L: -0.5\n",
            "Action: [-0.5    0.224] | Reward: -2.2139094300221283 |                 State: (-72.09676361083984, 1.687384009361267, 164.44284057617188) | Terminated: False |                Episode Length: 1.5700000000000012 | C_L: -0.5\n",
            "Action: [-0.5    0.224] | Reward: -2.2300382894991517 |                 State: (-72.03231048583984, 1.6902844905853271, 164.5714111328125) | Terminated: False |                Episode Length: 1.5800000000000012 | C_L: -0.5\n",
            "Action: [-0.5    0.224] | Reward: -2.24618880912854 |                 State: (-71.96768188476562, 1.6931819915771484, 164.6999969482422) | Terminated: False |                Episode Length: 1.5900000000000012 | C_L: -0.5\n",
            "Action: [-0.5    0.224] | Reward: -2.262360903614554 |                 State: (-71.90287780761719, 1.696076512336731, 164.8285675048828) | Terminated: False |                Episode Length: 1.6000000000000012 | C_L: -0.5\n",
            "Action: [-0.5    0.224] | Reward: -2.278554487323422 |                 State: (-71.8379135131836, 1.6989679336547852, 164.95713806152344) | Terminated: False |                Episode Length: 1.6100000000000012 | C_L: -0.5\n",
            "Action: [-0.5    0.224] | Reward: -2.294769474283802 |                 State: (-71.77277374267578, 1.7018563747406006, 165.08570861816406) | Terminated: False |                Episode Length: 1.6200000000000012 | C_L: -0.5\n",
            "Action: [-0.5    0.224] | Reward: -2.3110057781872713 |                 State: (-71.70745849609375, 1.7047417163848877, 165.2142791748047) | Terminated: False |                Episode Length: 1.6300000000000012 | C_L: -0.5\n",
            "Action: [-0.5    0.224] | Reward: -2.3272633123888316 |                 State: (-71.64198303222656, 1.7076239585876465, 165.3428497314453) | Terminated: False |                Episode Length: 1.6400000000000012 | C_L: -0.5\n",
            "Action: [-0.5    0.224] | Reward: -2.343541989907439 |                 State: (-71.57632446289062, 1.7105032205581665, 165.47142028808594) | Terminated: False |                Episode Length: 1.6500000000000012 | C_L: -0.5\n",
            "Action: [-0.5    0.224] | Reward: -2.3598417234265523 |                 State: (-71.51050567626953, 1.7133792638778687, 165.59999084472656) | Terminated: False |                Episode Length: 1.6600000000000013 | C_L: -0.5\n",
            "Action: [-0.5    0.224] | Reward: -2.376162425294706 |                 State: (-71.44451904296875, 1.716252326965332, 165.7285614013672) | Terminated: False |                Episode Length: 1.6700000000000013 | C_L: -0.5\n",
            "Action: [-0.5    0.224] | Reward: -2.3925040075261013 |                 State: (-71.37837219238281, 1.719122290611267, 165.8571319580078) | Terminated: False |                Episode Length: 1.6800000000000013 | C_L: -0.5\n",
            "Action: [-0.5    0.224] | Reward: -2.4088663818012197 |                 State: (-71.31204986572266, 1.7219891548156738, 165.98570251464844) | Terminated: False |                Episode Length: 1.6900000000000013 | C_L: -0.5\n",
            "Action: [-0.5    0.224] | Reward: -2.425249459467459 |                 State: (-71.24555969238281, 1.7248529195785522, 166.11427307128906) | Terminated: False |                Episode Length: 1.7000000000000013 | C_L: -0.5\n",
            "Action: [-0.5    0.224] | Reward: -2.4416531515397915 |                 State: (-71.17890930175781, 1.7277134656906128, 166.2428436279297) | Terminated: False |                Episode Length: 1.7100000000000013 | C_L: -0.5\n",
            "Action: [-0.5    0.224] | Reward: -2.4580773687014394 |                 State: (-71.11209106445312, 1.7305710315704346, 166.3714141845703) | Terminated: False |                Episode Length: 1.7200000000000013 | C_L: -0.5\n",
            "Action: [-0.5    0.224] | Reward: -2.4745220213045793 |                 State: (-71.04512023925781, 1.7334253787994385, 166.49998474121094) | Terminated: False |                Episode Length: 1.7300000000000013 | C_L: -0.5\n",
            "Action: [-0.5    0.224] | Reward: -2.4909870193710617 |                 State: (-70.97796630859375, 1.7362765073776245, 166.62855529785156) | Terminated: False |                Episode Length: 1.7400000000000013 | C_L: -0.5\n",
            "Action: [-0.5    0.224] | Reward: -2.5074722725931564 |                 State: (-70.9106674194336, 1.7391245365142822, 166.7571258544922) | Terminated: False |                Episode Length: 1.7500000000000013 | C_L: -0.5\n",
            "Action: [-0.5    0.224] | Reward: -2.5239776903343194 |                 State: (-70.84319305419922, 1.7419694662094116, 166.88571166992188) | Terminated: False |                Episode Length: 1.7600000000000013 | C_L: -0.5\n",
            "Action: [-0.5    0.224] | Reward: -2.540503181629981 |                 State: (-70.77557373046875, 1.7448111772537231, 167.0142822265625) | Terminated: False |                Episode Length: 1.7700000000000014 | C_L: -0.5\n",
            "Action: [-0.5    0.224] | Reward: -2.5570486551883556 |                 State: (-70.70777893066406, 1.7476496696472168, 167.14285278320312) | Terminated: False |                Episode Length: 1.7800000000000014 | C_L: -0.5\n",
            "Action: [-0.5    0.224] | Reward: -2.573614019391276 |                 State: (-70.63982391357422, 1.7504849433898926, 167.27142333984375) | Terminated: False |                Episode Length: 1.7900000000000014 | C_L: -0.5\n",
            "Action: [-0.5    0.224] | Reward: -2.590199182295049 |                 State: (-70.57172393798828, 1.75331711769104, 167.39999389648438) | Terminated: False |                Episode Length: 1.8000000000000014 | C_L: -0.5\n",
            "Action: [-0.5    0.224] | Reward: -2.606804051631331 |                 State: (-70.50345611572266, 1.75614595413208, 167.528564453125) | Terminated: False |                Episode Length: 1.8100000000000014 | C_L: -0.5\n",
            "Action: [-0.5    0.224] | Reward: -2.6234285348080304 |                 State: (-70.43502044677734, 1.7589716911315918, 167.65713500976562) | Terminated: False |                Episode Length: 1.8200000000000014 | C_L: -0.5\n",
            "Action: [-0.5    0.224] | Reward: -2.6400725389102293 |                 State: (-70.36643981933594, 1.761794090270996, 167.78570556640625) | Terminated: False |                Episode Length: 1.8300000000000014 | C_L: -0.5\n",
            "Action: [-0.5    0.224] | Reward: -2.656735970701129 |                 State: (-70.2977066040039, 1.7646132707595825, 167.91427612304688) | Terminated: False |                Episode Length: 1.8400000000000014 | C_L: -0.5\n",
            "Action: [-0.5    0.224] | Reward: -2.6734187366230184 |                 State: (-70.22880554199219, 1.767429232597351, 168.0428466796875) | Terminated: False |                Episode Length: 1.8500000000000014 | C_L: -0.5\n",
            "Action: [-0.5    0.224] | Reward: -2.6901207427982636 |                 State: (-70.15975952148438, 1.7702419757843018, 168.17141723632812) | Terminated: False |                Episode Length: 1.8600000000000014 | C_L: -0.5\n",
            "Action: [-0.5    0.224] | Reward: -2.706841895030323 |                 State: (-70.0905532836914, 1.773051381111145, 168.29998779296875) | Terminated: False |                Episode Length: 1.8700000000000014 | C_L: -0.5\n",
            "Action: [-0.5    0.224] | Reward: -2.723582098804782 |                 State: (-70.02118682861328, 1.7758575677871704, 168.42855834960938) | Terminated: False |                Episode Length: 1.8800000000000014 | C_L: -0.5\n",
            "Action: [-0.5    0.224] | Reward: -2.7403412592904144 |                 State: (-69.95167541503906, 1.778660535812378, 168.55712890625) | Terminated: False |                Episode Length: 1.8900000000000015 | C_L: -0.5\n",
            "Action: [-0.5    0.224] | Reward: -2.757119281340263 |                 State: (-69.88201141357422, 1.7814600467681885, 168.68569946289062) | Terminated: False |                Episode Length: 1.9000000000000015 | C_L: -0.5\n",
            "Action: [-0.5    0.224] | Reward: -2.773916069492745 |                 State: (-69.81219482421875, 1.7842563390731812, 168.81427001953125) | Terminated: False |                Episode Length: 1.9100000000000015 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -2.790686767859967 |                 State: (-69.74222564697266, 1.787049412727356, 168.8571319580078) | Terminated: False |                Episode Length: 1.9200000000000015 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -2.8074760439692996 |                 State: (-69.6721420288086, 1.7898390293121338, 168.89999389648438) | Terminated: False |                Episode Length: 1.9300000000000015 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -2.824283804932486 |                 State: (-69.6019287109375, 1.7926253080368042, 168.94285583496094) | Terminated: False |                Episode Length: 1.9400000000000015 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -2.841109957558756 |                 State: (-69.53160858154297, 1.7954083681106567, 168.98570251464844) | Terminated: False |                Episode Length: 1.9500000000000015 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -2.8579544083551394 |                 State: (-69.46116638183594, 1.7981879711151123, 169.028564453125) | Terminated: False |                Episode Length: 1.9600000000000015 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -2.8748170635267845 |                 State: (-69.39060974121094, 1.80096435546875, 169.07142639160156) | Terminated: False |                Episode Length: 1.9700000000000015 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -2.8916978289772906 |                 State: (-69.31993103027344, 1.8037372827529907, 169.11427307128906) | Terminated: False |                Episode Length: 1.9800000000000015 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -2.9085966103090484 |                 State: (-69.2491455078125, 1.806506872177124, 169.15713500976562) | Terminated: False |                Episode Length: 1.9900000000000015 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -2.9255133128235915 |                 State: (-69.17823791503906, 1.8092730045318604, 169.1999969482422) | Terminated: False |                Episode Length: 2.0000000000000013 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -2.9424478415219566 |                 State: (-69.10720825195312, 1.8120357990264893, 169.2428436279297) | Terminated: False |                Episode Length: 2.010000000000001 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -2.9594001011050555 |                 State: (-69.03607177734375, 1.8147952556610107, 169.28570556640625) | Terminated: False |                Episode Length: 2.020000000000001 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -2.9763699959740575 |                 State: (-68.96481323242188, 1.8175512552261353, 169.3285675048828) | Terminated: False |                Episode Length: 2.0300000000000007 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -2.9933574302307795 |                 State: (-68.89344024658203, 1.8203039169311523, 169.3714141845703) | Terminated: False |                Episode Length: 2.0400000000000005 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -3.010362307678089 |                 State: (-68.82195281982422, 1.823053002357483, 169.41427612304688) | Terminated: False |                Episode Length: 2.0500000000000003 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -3.027384531820316 |                 State: (-68.7503433227539, 1.8257988691329956, 169.45713806152344) | Terminated: False |                Episode Length: 2.06 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -3.044424005863675 |                 State: (-68.67862701416016, 1.8285411596298218, 169.49998474121094) | Terminated: False |                Episode Length: 2.07 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -3.0614806327166995 |                 State: (-68.60679626464844, 1.831279993057251, 169.5428466796875) | Terminated: False |                Episode Length: 2.0799999999999996 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -3.0785543149906824 |                 State: (-68.53484344482422, 1.8340154886245728, 169.58570861816406) | Terminated: False |                Episode Length: 2.0899999999999994 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -3.095644955000132 |                 State: (-68.46278381347656, 1.836747407913208, 169.62855529785156) | Terminated: False |                Episode Length: 2.099999999999999 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -3.1127524547632337 |                 State: (-68.3906021118164, 1.8394758701324463, 169.67141723632812) | Terminated: False |                Episode Length: 2.109999999999999 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -3.1298767160023258 |                 State: (-68.31832122802734, 1.8422009944915771, 169.7142791748047) | Terminated: False |                Episode Length: 2.1199999999999988 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -3.147017640144384 |                 State: (-68.24591827392578, 1.844922423362732, 169.7571258544922) | Terminated: False |                Episode Length: 2.1299999999999986 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -3.1641751283215163 |                 State: (-68.17340087890625, 1.8476405143737793, 169.8000030517578) | Terminated: False |                Episode Length: 2.1399999999999983 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -3.1813490813714673 |                 State: (-68.10076904296875, 1.8503550291061401, 169.8428497314453) | Terminated: False |                Episode Length: 2.149999999999998 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -3.1985393998381375 |                 State: (-68.02802276611328, 1.853066086769104, 169.8856964111328) | Terminated: False |                Episode Length: 2.159999999999998 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -3.2157459839721065 |                 State: (-67.95516967773438, 1.8557735681533813, 169.92857360839844) | Terminated: False |                Episode Length: 2.1699999999999977 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -3.2329687337311728 |                 State: (-67.8822021484375, 1.8584775924682617, 169.97142028808594) | Terminated: False |                Episode Length: 2.1799999999999975 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -3.2502075487809 |                 State: (-67.80912017822266, 1.8611780405044556, 170.01426696777344) | Terminated: False |                Episode Length: 2.1899999999999973 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -3.267462328495175 |                 State: (-67.73593139648438, 1.863874912261963, 170.05714416503906) | Terminated: False |                Episode Length: 2.199999999999997 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -3.28473297195678 |                 State: (-67.66262817382812, 1.8665683269500732, 170.09999084472656) | Terminated: False |                Episode Length: 2.209999999999997 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -3.302019377957967 |                 State: (-67.5892105102539, 1.869258165359497, 170.14283752441406) | Terminated: False |                Episode Length: 2.2199999999999966 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -3.3193214450010533 |                 State: (-67.51569366455078, 1.8719443082809448, 170.1857147216797) | Terminated: False |                Episode Length: 2.2299999999999964 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -3.336639071299018 |                 State: (-67.44205474853516, 1.8746269941329956, 170.2285614013672) | Terminated: False |                Episode Length: 2.239999999999996 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -3.3539721547761174 |                 State: (-67.36830139160156, 1.8773061037063599, 170.27142333984375) | Terminated: False |                Episode Length: 2.249999999999996 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -3.3713205930685044 |                 State: (-67.29444885253906, 1.879981517791748, 170.3142852783203) | Terminated: False |                Episode Length: 2.259999999999996 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -3.3886842835248636 |                 State: (-67.2204818725586, 1.8826534748077393, 170.3571319580078) | Terminated: False |                Episode Length: 2.2699999999999956 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -3.4060631232070544 |                 State: (-67.14640808105469, 1.8853217363357544, 170.39999389648438) | Terminated: False |                Episode Length: 2.2799999999999954 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -3.423457008890765 |                 State: (-67.07221221923828, 1.8879863023757935, 170.44285583496094) | Terminated: False |                Episode Length: 2.289999999999995 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -3.440865837066179 |                 State: (-66.9979248046875, 1.890647292137146, 170.48570251464844) | Terminated: False |                Episode Length: 2.299999999999995 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -3.458289503938651 |                 State: (-66.92351531982422, 1.893304705619812, 170.528564453125) | Terminated: False |                Episode Length: 2.3099999999999947 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -3.4757279054293937 |                 State: (-66.84900665283203, 1.895958423614502, 170.57142639160156) | Terminated: False |                Episode Length: 2.3199999999999945 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -3.493180937176175 |                 State: (-66.77437591552734, 1.8986085653305054, 170.61427307128906) | Terminated: False |                Episode Length: 2.3299999999999943 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -3.5106484945340286 |                 State: (-66.69964599609375, 1.9012550115585327, 170.65713500976562) | Terminated: False |                Episode Length: 2.339999999999994 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -3.5281304725759717 |                 State: (-66.62480926513672, 1.903897762298584, 170.6999969482422) | Terminated: False |                Episode Length: 2.349999999999994 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -3.5456267660937364 |                 State: (-66.54986572265625, 1.9065368175506592, 170.7428436279297) | Terminated: False |                Episode Length: 2.3599999999999937 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -3.563137269598511 |                 State: (-66.47481536865234, 1.9091722965240479, 170.78570556640625) | Terminated: False |                Episode Length: 2.3699999999999934 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -3.580661877321692 |                 State: (-66.39964294433594, 1.911803960800171, 170.8285675048828) | Terminated: False |                Episode Length: 2.3799999999999932 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -3.5982004832156473 |                 State: (-66.32438659667969, 1.9144319295883179, 170.8714141845703) | Terminated: False |                Episode Length: 2.389999999999993 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -3.615752980954491 |                 State: (-66.24900817871094, 1.9170563220977783, 170.91427612304688) | Terminated: False |                Episode Length: 2.399999999999993 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -3.633319263934867 |                 State: (-66.17352294921875, 1.9196768999099731, 170.95713806152344) | Terminated: False |                Episode Length: 2.4099999999999926 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -3.650899225276747 |                 State: (-66.09793853759766, 1.9222936630249023, 170.99998474121094) | Terminated: False |                Episode Length: 2.4199999999999924 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -3.668492757824236 |                 State: (-66.02224731445312, 1.924906849861145, 171.0428466796875) | Terminated: False |                Episode Length: 2.429999999999992 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -3.6860997541463902 |                 State: (-65.94644165039062, 1.927516222000122, 171.08570861816406) | Terminated: False |                Episode Length: 2.439999999999992 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -3.703720106538048 |                 State: (-65.87053680419922, 1.930121898651123, 171.12857055664062) | Terminated: False |                Episode Length: 2.4499999999999917 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -3.7213537070206675 |                 State: (-65.79452514648438, 1.9327237606048584, 171.17141723632812) | Terminated: False |                Episode Length: 2.4599999999999915 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -3.739000447343179 |                 State: (-65.7184066772461, 1.9353218078613281, 171.2142791748047) | Terminated: False |                Episode Length: 2.4699999999999913 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -3.7566602189828457 |                 State: (-65.6421890258789, 1.9379161596298218, 171.25714111328125) | Terminated: False |                Episode Length: 2.479999999999991 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -3.774332913146139 |                 State: (-65.56586456298828, 1.9405066967010498, 171.29998779296875) | Terminated: False |                Episode Length: 2.489999999999991 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -3.79201842076962 |                 State: (-65.48943328857422, 1.9430934190750122, 171.3428497314453) | Terminated: False |                Episode Length: 2.4999999999999907 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -3.809716632520837 |                 State: (-65.41290283203125, 1.9456764459609985, 171.38571166992188) | Terminated: False |                Episode Length: 2.5099999999999905 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -3.827427438799229 |                 State: (-65.33626556396484, 1.9482555389404297, 171.42855834960938) | Terminated: False |                Episode Length: 2.5199999999999902 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -3.8451507297370457 |                 State: (-65.25952911376953, 1.9508308172225952, 171.47142028808594) | Terminated: False |                Episode Length: 2.52999999999999 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -3.8628863952002743 |                 State: (-65.18268585205078, 1.9534024000167847, 171.5142822265625) | Terminated: False |                Episode Length: 2.53999999999999 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -3.8806343247895785 |                 State: (-65.10574340820312, 1.955970048904419, 171.55712890625) | Terminated: False |                Episode Length: 2.5499999999999896 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -3.8983944078412502 |                 State: (-65.02869415283203, 1.9585338830947876, 171.59999084472656) | Terminated: False |                Episode Length: 2.5599999999999894 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -3.9161665334281697 |                 State: (-64.9515380859375, 1.961093783378601, 171.64285278320312) | Terminated: False |                Episode Length: 2.569999999999989 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -3.9339505903607797 |                 State: (-64.8742904663086, 1.9636499881744385, 171.68569946289062) | Terminated: False |                Episode Length: 2.579999999999989 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -3.9517464671880673 |                 State: (-64.79693603515625, 1.9662022590637207, 171.7285614013672) | Terminated: False |                Episode Length: 2.5899999999999888 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -3.9695540521985606 |                 State: (-64.71947479248047, 1.9687505960464478, 171.77142333984375) | Terminated: False |                Episode Length: 2.5999999999999885 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -3.987373233421333 |                 State: (-64.64191436767578, 1.9712951183319092, 171.81427001953125) | Terminated: False |                Episode Length: 2.6099999999999883 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -4.0052038986270215 |                 State: (-64.56425476074219, 1.9738357067108154, 171.85714721679688) | Terminated: False |                Episode Length: 2.619999999999988 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -4.023045935328853 |                 State: (-64.48650360107422, 1.9763723611831665, 171.89999389648438) | Terminated: False |                Episode Length: 2.629999999999988 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -4.040899230783686 |                 State: (-64.40863800048828, 1.978905200958252, 171.94284057617188) | Terminated: False |                Episode Length: 2.6399999999999877 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -4.0587636719930575 |                 State: (-64.33068084716797, 1.9814341068267822, 171.9857177734375) | Terminated: False |                Episode Length: 2.6499999999999875 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -4.076639145704248 |                 State: (-64.25262451171875, 1.9839589595794678, 172.028564453125) | Terminated: False |                Episode Length: 2.6599999999999873 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -4.09452553841135 |                 State: (-64.1744613647461, 1.9864799976348877, 172.0714111328125) | Terminated: False |                Episode Length: 2.669999999999987 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -4.112422736356355 |                 State: (-64.09619903564453, 1.9889971017837524, 172.11428833007812) | Terminated: False |                Episode Length: 2.679999999999987 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -4.130330625530246 |                 State: (-64.0178451538086, 1.991510272026062, 172.15713500976562) | Terminated: False |                Episode Length: 2.6899999999999866 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -4.148249091674104 |                 State: (-63.93938446044922, 1.9940193891525269, 172.19998168945312) | Terminated: False |                Episode Length: 2.6999999999999864 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -4.166178020280223 |                 State: (-63.86083221435547, 1.996524691581726, 172.24285888671875) | Terminated: False |                Episode Length: 2.709999999999986 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -4.184117296593243 |                 State: (-63.78217315673828, 1.9990259408950806, 172.28570556640625) | Terminated: False |                Episode Length: 2.719999999999986 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -4.202066805611282 |                 State: (-63.70342254638672, 2.00152325630188, 172.32855224609375) | Terminated: False |                Episode Length: 2.7299999999999858 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -4.22002643208709 |                 State: (-63.624576568603516, 2.004016399383545, 172.37142944335938) | Terminated: False |                Episode Length: 2.7399999999999856 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -4.23799606052921 |                 State: (-63.545631408691406, 2.0065057277679443, 172.41427612304688) | Terminated: False |                Episode Length: 2.7499999999999853 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -4.2559755752031485 |                 State: (-63.46658706665039, 2.008991003036499, 172.45713806152344) | Terminated: False |                Episode Length: 2.759999999999985 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -4.27396486013256 |                 State: (-63.38744354248047, 2.011472225189209, 172.5) | Terminated: False |                Episode Length: 2.769999999999985 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -4.291963799100441 |                 State: (-63.30820846557617, 2.013949394226074, 172.5428466796875) | Terminated: False |                Episode Length: 2.7799999999999847 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -4.309972275650334 |                 State: (-63.22886657714844, 2.0164225101470947, 172.58570861816406) | Terminated: False |                Episode Length: 2.7899999999999845 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -4.327990173087545 |                 State: (-63.14944076538086, 2.0188918113708496, 172.62857055664062) | Terminated: False |                Episode Length: 2.7999999999999843 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -4.346017374480371 |                 State: (-63.069908142089844, 2.0213568210601807, 172.67141723632812) | Terminated: False |                Episode Length: 2.809999999999984 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -4.364053762661337 |                 State: (-62.99028778076172, 2.023818016052246, 172.7142791748047) | Terminated: False |                Episode Length: 2.819999999999984 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -4.382099220228446 |                 State: (-62.91057586669922, 2.0262749195098877, 172.75714111328125) | Terminated: False |                Episode Length: 2.8299999999999836 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -4.40015362954644 |                 State: (-62.83076477050781, 2.0287277698516846, 172.79998779296875) | Terminated: False |                Episode Length: 2.8399999999999834 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -4.41821687274807 |                 State: (-62.750850677490234, 2.031176805496216, 172.8428497314453) | Terminated: False |                Episode Length: 2.849999999999983 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -4.4362888317353795 |                 State: (-62.67084884643555, 2.0336215496063232, 172.8856964111328) | Terminated: False |                Episode Length: 2.859999999999983 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -4.454369388180996 |                 State: (-62.590755462646484, 2.036062240600586, 172.92855834960938) | Terminated: False |                Episode Length: 2.869999999999983 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -4.472458423529435 |                 State: (-62.510562896728516, 2.038498640060425, 172.97142028808594) | Terminated: False |                Episode Length: 2.8799999999999826 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -4.490555818998419 |                 State: (-62.43028259277344, 2.040931224822998, 173.01426696777344) | Terminated: False |                Episode Length: 2.8899999999999824 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -4.508661455580198 |                 State: (-62.34990310668945, 2.0433595180511475, 173.05712890625) | Terminated: False |                Episode Length: 2.899999999999982 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -4.526775214042889 |                 State: (-62.269439697265625, 2.045783758163452, 173.09999084472656) | Terminated: False |                Episode Length: 2.909999999999982 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -4.544896974931825 |                 State: (-62.18887710571289, 2.048203706741333, 173.14283752441406) | Terminated: False |                Episode Length: 2.9199999999999817 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -4.563026618570911 |                 State: (-62.108219146728516, 2.050619602203369, 173.18569946289062) | Terminated: False |                Episode Length: 2.9299999999999815 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -4.581164025063996 |                 State: (-62.02747344970703, 2.0530314445495605, 173.2285614013672) | Terminated: False |                Episode Length: 2.9399999999999813 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -4.59930907429625 |                 State: (-61.94662857055664, 2.055438995361328, 173.2714080810547) | Terminated: False |                Episode Length: 2.949999999999981 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -4.61746164593556 |                 State: (-61.865699768066406, 2.057842493057251, 173.3142852783203) | Terminated: False |                Episode Length: 2.959999999999981 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -4.635621619433926 |                 State: (-61.7846794128418, 2.06024169921875, 173.3571319580078) | Terminated: False |                Episode Length: 2.9699999999999807 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -4.653788874028878 |                 State: (-61.70356369018555, 2.0626368522644043, 173.3999786376953) | Terminated: False |                Episode Length: 2.9799999999999804 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -4.671963288744899 |                 State: (-61.62236022949219, 2.0650277137756348, 173.44285583496094) | Terminated: False |                Episode Length: 2.9899999999999802 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -4.690144742394857 |                 State: (-61.54106521606445, 2.0674145221710205, 173.48570251464844) | Terminated: False |                Episode Length: 2.99999999999998 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -4.7083331135814515 |                 State: (-61.459686279296875, 2.0697970390319824, 173.52854919433594) | Terminated: False |                Episode Length: 3.00999999999998 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -4.72652828069867 |                 State: (-61.37820816040039, 2.0721752643585205, 173.57142639160156) | Terminated: False |                Episode Length: 3.0199999999999796 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -4.744730121933252 |                 State: (-61.2966423034668, 2.0745491981506348, 173.61427307128906) | Terminated: False |                Episode Length: 3.0299999999999794 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -4.762938515266167 |                 State: (-61.21499252319336, 2.0769190788269043, 173.65711975097656) | Terminated: False |                Episode Length: 3.039999999999979 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -4.781153338474104 |                 State: (-61.13325119018555, 2.07928466796875, 173.6999969482422) | Terminated: False |                Episode Length: 3.049999999999979 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -4.799374469130967 |                 State: (-61.05141830444336, 2.081645965576172, 173.7428436279297) | Terminated: False |                Episode Length: 3.0599999999999787 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -4.817601784609385 |                 State: (-60.96949768066406, 2.08400297164917, 173.78570556640625) | Terminated: False |                Episode Length: 3.0699999999999785 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -4.8358351620822315 |                 State: (-60.88748550415039, 2.0863559246063232, 173.8285675048828) | Terminated: False |                Episode Length: 3.0799999999999783 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -4.854074478524153 |                 State: (-60.80539321899414, 2.0887043476104736, 173.8714141845703) | Terminated: False |                Episode Length: 3.089999999999978 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -4.872319610713112 |                 State: (-60.72320556640625, 2.0910487174987793, 173.91427612304688) | Terminated: False |                Episode Length: 3.099999999999978 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -4.890570435231935 |                 State: (-60.64093780517578, 2.093388557434082, 173.95713806152344) | Terminated: False |                Episode Length: 3.1099999999999777 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -4.908826828469877 |                 State: (-60.55857849121094, 2.09572434425354, 173.99998474121094) | Terminated: False |                Episode Length: 3.1199999999999775 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -4.92708866662419 |                 State: (-60.476139068603516, 2.098055601119995, 174.0428466796875) | Terminated: False |                Episode Length: 3.1299999999999772 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -4.945355825701708 |                 State: (-60.39360046386719, 2.1003828048706055, 174.08570861816406) | Terminated: False |                Episode Length: 3.139999999999977 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -4.963628181520438 |                 State: (-60.31098937988281, 2.102705478668213, 174.12855529785156) | Terminated: False |                Episode Length: 3.149999999999977 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -4.981905609711162 |                 State: (-60.2282829284668, 2.1050238609313965, 174.17141723632812) | Terminated: False |                Episode Length: 3.1599999999999766 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -5.000187985719053 |                 State: (-60.1454963684082, 2.1073379516601562, 174.2142791748047) | Terminated: False |                Episode Length: 3.1699999999999764 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -5.018475184805298 |                 State: (-60.062625885009766, 2.109647750854492, 174.2571258544922) | Terminated: False |                Episode Length: 3.179999999999976 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -5.036767082048727 |                 State: (-59.97966384887695, 2.1119532585144043, 174.29998779296875) | Terminated: False |                Episode Length: 3.189999999999976 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -5.055063552347465 |                 State: (-59.8966178894043, 2.1142542362213135, 174.3428497314453) | Terminated: False |                Episode Length: 3.1999999999999758 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -5.0733644704205805 |                 State: (-59.81349182128906, 2.116550922393799, 174.3856964111328) | Terminated: False |                Episode Length: 3.2099999999999755 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -5.091669710809751 |                 State: (-59.730281829833984, 2.1188430786132812, 174.42855834960938) | Terminated: False |                Episode Length: 3.2199999999999753 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -5.109979147880938 |                 State: (-59.64698791503906, 2.121131181716919, 174.47142028808594) | Terminated: False |                Episode Length: 3.229999999999975 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -5.128292655826071 |                 State: (-59.563602447509766, 2.1234147548675537, 174.51426696777344) | Terminated: False |                Episode Length: 3.239999999999975 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -5.146610108664744 |                 State: (-59.480140686035156, 2.1256937980651855, 174.55712890625) | Terminated: False |                Episode Length: 3.2499999999999747 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -5.164931380245917 |                 State: (-59.39659881591797, 2.1279685497283936, 174.59999084472656) | Terminated: False |                Episode Length: 3.2599999999999745 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -5.1832563442496316 |                 State: (-59.31296920776367, 2.1302387714385986, 174.64285278320312) | Terminated: False |                Episode Length: 3.2699999999999743 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -5.201584874188739 |                 State: (-59.2292594909668, 2.13250470161438, 174.68569946289062) | Terminated: False |                Episode Length: 3.279999999999974 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -5.219916843410629 |                 State: (-59.14546585083008, 2.1347663402557373, 174.7285614013672) | Terminated: False |                Episode Length: 3.289999999999974 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -5.238252125098979 |                 State: (-59.06159210205078, 2.1370232105255127, 174.77142333984375) | Terminated: False |                Episode Length: 3.2999999999999736 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -5.256590592275505 |                 State: (-58.97763442993164, 2.1392757892608643, 174.81427001953125) | Terminated: False |                Episode Length: 3.3099999999999734 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -5.274932117801727 |                 State: (-58.89360427856445, 2.141524076461792, 174.8571319580078) | Terminated: False |                Episode Length: 3.319999999999973 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -5.293276574380743 |                 State: (-58.80948257446289, 2.143767833709717, 174.89999389648438) | Terminated: False |                Episode Length: 3.329999999999973 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -5.31162383455901 |                 State: (-58.72528839111328, 2.1460070610046387, 174.94284057617188) | Terminated: False |                Episode Length: 3.3399999999999728 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -5.3299737707281425 |                 State: (-58.64101028442383, 2.1482417583465576, 174.98570251464844) | Terminated: False |                Episode Length: 3.3499999999999726 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -5.348326255126709 |                 State: (-58.55664825439453, 2.1504719257354736, 175.028564453125) | Terminated: False |                Episode Length: 3.3599999999999723 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -5.366681159842048 |                 State: (-58.47221374511719, 2.152697801589966, 175.0714111328125) | Terminated: False |                Episode Length: 3.369999999999972 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -5.385038356812089 |                 State: (-58.387699127197266, 2.154919147491455, 175.11427307128906) | Terminated: False |                Episode Length: 3.379999999999972 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -5.403397717827184 |                 State: (-58.3031005859375, 2.1571359634399414, 175.15713500976562) | Terminated: False |                Episode Length: 3.3899999999999717 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -5.421759114531949 |                 State: (-58.21842575073242, 2.159348249435425, 175.19998168945312) | Terminated: False |                Episode Length: 3.3999999999999715 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -5.440122418427112 |                 State: (-58.1336784362793, 2.1615560054779053, 175.2428436279297) | Terminated: False |                Episode Length: 3.4099999999999713 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -5.458487500871376 |                 State: (-58.04884719848633, 2.163759231567383, 175.28570556640625) | Terminated: False |                Episode Length: 3.419999999999971 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -5.4768542330832855 |                 State: (-57.96393966674805, 2.1659579277038574, 175.32855224609375) | Terminated: False |                Episode Length: 3.429999999999971 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -5.4952224861431045 |                 State: (-57.87895202636719, 2.168152093887329, 175.37142944335938) | Terminated: False |                Episode Length: 3.4399999999999706 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -5.513592130994706 |                 State: (-57.793888092041016, 2.170341730117798, 175.41427612304688) | Terminated: False |                Episode Length: 3.4499999999999704 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -5.531963038447468 |                 State: (-57.7087516784668, 2.1725268363952637, 175.45712280273438) | Terminated: False |                Episode Length: 3.45999999999997 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -5.5503350791781765 |                 State: (-57.62353515625, 2.1747071743011475, 175.5) | Terminated: False |                Episode Length: 3.46999999999997 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -5.5687081237329465 |                 State: (-57.53824234008789, 2.1768832206726074, 175.5428466796875) | Terminated: False |                Episode Length: 3.47999999999997 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -5.58708204252914 |                 State: (-57.4528694152832, 2.1790544986724854, 175.585693359375) | Terminated: False |                Episode Length: 3.4899999999999696 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -5.605456705857302 |                 State: (-57.367431640625, 2.1812212467193604, 175.62857055664062) | Terminated: False |                Episode Length: 3.4999999999999694 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -5.6238319838831 |                 State: (-57.28190994262695, 2.1833834648132324, 175.67141723632812) | Terminated: False |                Episode Length: 3.509999999999969 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -5.64220774664928 |                 State: (-57.19631576538086, 2.1855411529541016, 175.71426391601562) | Terminated: False |                Episode Length: 3.519999999999969 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -5.660583864077619 |                 State: (-57.11064910888672, 2.1876940727233887, 175.75714111328125) | Terminated: False |                Episode Length: 3.5299999999999687 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -5.678960205970898 |                 State: (-57.024906158447266, 2.189842462539673, 175.79998779296875) | Terminated: False |                Episode Length: 3.5399999999999685 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -5.6973366420148785 |                 State: (-56.9390869140625, 2.191986083984375, 175.84283447265625) | Terminated: False |                Episode Length: 3.5499999999999683 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -5.715713041780288 |                 State: (-56.85319900512695, 2.194125175476074, 175.88571166992188) | Terminated: False |                Episode Length: 3.559999999999968 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -5.734089274724814 |                 State: (-56.76723098754883, 2.1962597370147705, 175.92855834960938) | Terminated: False |                Episode Length: 3.569999999999968 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -5.752465210195107 |                 State: (-56.68119430541992, 2.1983895301818848, 175.97142028808594) | Terminated: False |                Episode Length: 3.5799999999999677 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -5.770840717428793 |                 State: (-56.595088958740234, 2.200514793395996, 176.0142822265625) | Terminated: False |                Episode Length: 3.5899999999999674 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -5.789215665556493 |                 State: (-56.50890350341797, 2.2026352882385254, 176.05712890625) | Terminated: False |                Episode Length: 3.5999999999999672 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -5.807589923603851 |                 State: (-56.42264938354492, 2.2047510147094727, 176.09999084472656) | Terminated: False |                Episode Length: 3.609999999999967 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -5.825963360493572 |                 State: (-56.336326599121094, 2.206862211227417, 176.14285278320312) | Terminated: False |                Episode Length: 3.619999999999967 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -5.844335845047464 |                 State: (-56.24992752075195, 2.2089688777923584, 176.18569946289062) | Terminated: False |                Episode Length: 3.6299999999999666 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -5.862707245988497 |                 State: (-56.163455963134766, 2.2110705375671387, 176.2285614013672) | Terminated: False |                Episode Length: 3.6399999999999664 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -5.881077431942857 |                 State: (-56.07691955566406, 2.213167667388916, 176.27142333984375) | Terminated: False |                Episode Length: 3.649999999999966 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -5.899446271442022 |                 State: (-55.99030685424805, 2.2152602672576904, 176.31427001953125) | Terminated: False |                Episode Length: 3.659999999999966 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -5.917813632924837 |                 State: (-55.90362548828125, 2.2173478603363037, 176.3571319580078) | Terminated: False |                Episode Length: 3.6699999999999657 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -5.936179384739599 |                 State: (-55.81687545776367, 2.219430923461914, 176.39999389648438) | Terminated: False |                Episode Length: 3.6799999999999655 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -5.954543395146154 |                 State: (-55.73005676269531, 2.2215092182159424, 176.44284057617188) | Terminated: False |                Episode Length: 3.6899999999999653 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -5.972905532317993 |                 State: (-55.64316940307617, 2.2235827445983887, 176.48570251464844) | Terminated: False |                Episode Length: 3.699999999999965 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -5.991265664344366 |                 State: (-55.556209564208984, 2.225651502609253, 176.528564453125) | Terminated: False |                Episode Length: 3.709999999999965 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -6.009623659232396 |                 State: (-55.469181060791016, 2.2277157306671143, 176.5714111328125) | Terminated: False |                Episode Length: 3.7199999999999647 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -6.027979384909208 |                 State: (-55.38208770751953, 2.2297749519348145, 176.61427307128906) | Terminated: False |                Episode Length: 3.7299999999999645 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -6.046332709224055 |                 State: (-55.294925689697266, 2.2318296432495117, 176.65713500976562) | Terminated: False |                Episode Length: 3.7399999999999642 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -6.064683499950464 |                 State: (-55.20769500732422, 2.233879327774048, 176.6999969482422) | Terminated: False |                Episode Length: 3.749999999999964 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -6.083031624788379 |                 State: (-55.12039566040039, 2.235924482345581, 176.7428436279297) | Terminated: False |                Episode Length: 3.759999999999964 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -6.101376951366321 |                 State: (-55.03303146362305, 2.237964630126953, 176.78570556640625) | Terminated: False |                Episode Length: 3.7699999999999636 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -6.119719347243543 |                 State: (-54.94560241699219, 2.2400002479553223, 176.8285675048828) | Terminated: False |                Episode Length: 3.7799999999999634 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -6.1380586799122066 |                 State: (-54.85810089111328, 2.2420308589935303, 176.8714141845703) | Terminated: False |                Episode Length: 3.789999999999963 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -6.156394816799555 |                 State: (-54.77053451538086, 2.2440567016601562, 176.91427612304688) | Terminated: False |                Episode Length: 3.799999999999963 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -6.174727625270098 |                 State: (-54.68290710449219, 2.2460777759552, 176.95713806152344) | Terminated: False |                Episode Length: 3.8099999999999627 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -6.193056972627803 |                 State: (-54.595211029052734, 2.248094081878662, 176.99998474121094) | Terminated: False |                Episode Length: 3.8199999999999625 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -6.211382726118293 |                 State: (-54.507450103759766, 2.250105619430542, 177.0428466796875) | Terminated: False |                Episode Length: 3.8299999999999623 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -6.2297047529310525 |                 State: (-54.41962432861328, 2.2521121501922607, 177.08570861816406) | Terminated: False |                Episode Length: 3.839999999999962 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -6.248022920201638 |                 State: (-54.33173751831055, 2.2541139125823975, 177.12855529785156) | Terminated: False |                Episode Length: 3.849999999999962 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -6.266337095013898 |                 State: (-54.24378204345703, 2.256110906600952, 177.17141723632812) | Terminated: False |                Episode Length: 3.8599999999999617 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -6.284647144402199 |                 State: (-54.155765533447266, 2.258103132247925, 177.2142791748047) | Terminated: False |                Episode Length: 3.8699999999999615 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -6.302952935353656 |                 State: (-54.067684173583984, 2.2600903511047363, 177.2571258544922) | Terminated: False |                Episode Length: 3.8799999999999613 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -6.321254334810373 |                 State: (-53.97953796386719, 2.262072801589966, 177.29998779296875) | Terminated: False |                Episode Length: 3.889999999999961 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -6.339551209671687 |                 State: (-53.891334533691406, 2.264050245285034, 177.3428497314453) | Terminated: False |                Episode Length: 3.899999999999961 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -6.357843426796424 |                 State: (-53.803062438964844, 2.2660229206085205, 177.3856964111328) | Terminated: False |                Episode Length: 3.9099999999999606 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -6.376130853005151 |                 State: (-53.7147331237793, 2.267990827560425, 177.42855834960938) | Terminated: False |                Episode Length: 3.9199999999999604 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -6.3944133550824445 |                 State: (-53.62633514404297, 2.269953727722168, 177.47142028808594) | Terminated: False |                Episode Length: 3.92999999999996 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -6.4126907997791625 |                 State: (-53.537879943847656, 2.27191162109375, 177.51426696777344) | Terminated: False |                Episode Length: 3.93999999999996 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -6.430963053814718 |                 State: (-53.44936752319336, 2.27386474609375, 177.55714416503906) | Terminated: False |                Episode Length: 3.9499999999999598 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -6.449229983879366 |                 State: (-53.36079025268555, 2.275813102722168, 177.59999084472656) | Terminated: False |                Episode Length: 3.9599999999999596 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -6.467491456636491 |                 State: (-53.272151947021484, 2.2777562141418457, 177.64283752441406) | Terminated: False |                Episode Length: 3.9699999999999593 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -6.4857473387249005 |                 State: (-53.18345642089844, 2.2796947956085205, 177.6857147216797) | Terminated: False |                Episode Length: 3.979999999999959 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -6.503997496761129 |                 State: (-53.09469985961914, 2.281628131866455, 177.7285614013672) | Terminated: False |                Episode Length: 3.989999999999959 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -6.522241797341745 |                 State: (-53.005882263183594, 2.2835566997528076, 177.7714080810547) | Terminated: False |                Episode Length: 3.9999999999999587 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -6.54048010704566 |                 State: (-52.9170036315918, 2.285480260848999, 177.8142852783203) | Terminated: False |                Episode Length: 4.009999999999959 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -6.558712292436451 |                 State: (-52.82807159423828, 2.2873988151550293, 177.8571319580078) | Terminated: False |                Episode Length: 4.019999999999959 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -6.576938220064681 |                 State: (-52.739078521728516, 2.2893126010894775, 177.8999786376953) | Terminated: False |                Episode Length: 4.0299999999999585 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -6.5951577564702335 |                 State: (-52.6500244140625, 2.2912213802337646, 177.94285583496094) | Terminated: False |                Episode Length: 4.039999999999958 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -6.613370768184639 |                 State: (-52.560916900634766, 2.2931251525878906, 177.98570251464844) | Terminated: False |                Episode Length: 4.049999999999958 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -6.631577121733424 |                 State: (-52.47174835205078, 2.2950239181518555, 178.02854919433594) | Terminated: False |                Episode Length: 4.059999999999958 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -6.649776683638451 |                 State: (-52.38252258300781, 2.296917676925659, 178.07142639160156) | Terminated: False |                Episode Length: 4.069999999999958 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -6.667969320420269 |                 State: (-52.293243408203125, 2.298806667327881, 178.11427307128906) | Terminated: False |                Episode Length: 4.079999999999957 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -6.686154898600474 |                 State: (-52.20390319824219, 2.3006904125213623, 178.15713500976562) | Terminated: False |                Episode Length: 4.089999999999957 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -6.704333284704064 |                 State: (-52.11450958251953, 2.3025693893432617, 178.1999969482422) | Terminated: False |                Episode Length: 4.099999999999957 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -6.722504345261807 |                 State: (-52.025062561035156, 2.304443120956421, 178.2428436279297) | Terminated: False |                Episode Length: 4.109999999999957 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -6.740667946812613 |                 State: (-51.9355583190918, 2.306312084197998, 178.28570556640625) | Terminated: False |                Episode Length: 4.119999999999957 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -6.758823955905907 |                 State: (-51.84600067138672, 2.308176040649414, 178.3285675048828) | Terminated: False |                Episode Length: 4.129999999999956 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -6.776972239104009 |                 State: (-51.756385803222656, 2.31003475189209, 178.3714141845703) | Terminated: False |                Episode Length: 4.139999999999956 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -6.795112662984522 |                 State: (-51.66671371459961, 2.3118886947631836, 178.41427612304688) | Terminated: False |                Episode Length: 4.149999999999956 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -6.813245094142717 |                 State: (-51.576988220214844, 2.313737392425537, 178.45713806152344) | Terminated: False |                Episode Length: 4.159999999999956 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -6.831369399193928 |                 State: (-51.487213134765625, 2.3155810832977295, 178.49998474121094) | Terminated: False |                Episode Length: 4.1699999999999555 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -6.849485444775951 |                 State: (-51.39738082885742, 2.3174197673797607, 178.5428466796875) | Terminated: False |                Episode Length: 4.179999999999955 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -6.8675930975514445 |                 State: (-51.307498931884766, 2.319253444671631, 178.58570861816406) | Terminated: False |                Episode Length: 4.189999999999955 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -6.885692224210337 |                 State: (-51.217559814453125, 2.32108211517334, 178.62855529785156) | Terminated: False |                Episode Length: 4.199999999999955 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -6.903782691472238 |                 State: (-51.12757110595703, 2.3229055404663086, 178.67141723632812) | Terminated: False |                Episode Length: 4.209999999999955 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -6.921864366088852 |                 State: (-51.03752899169922, 2.3247241973876953, 178.7142791748047) | Terminated: False |                Episode Length: 4.2199999999999545 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -6.939937114846396 |                 State: (-50.94744110107422, 2.3265373706817627, 178.7571258544922) | Terminated: False |                Episode Length: 4.229999999999954 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -6.958000804568022 |                 State: (-50.857295989990234, 2.328345775604248, 178.79998779296875) | Terminated: False |                Episode Length: 4.239999999999954 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -6.976055302116246 |                 State: (-50.7671012878418, 2.330148935317993, 178.8428497314453) | Terminated: False |                Episode Length: 4.249999999999954 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -6.994100474395374 |                 State: (-50.67685317993164, 2.331947088241577, 178.88571166992188) | Terminated: False |                Episode Length: 4.259999999999954 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -7.012136188353937 |                 State: (-50.58655548095703, 2.333740234375, 178.92855834960938) | Terminated: False |                Episode Length: 4.269999999999953 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -7.030162310987127 |                 State: (-50.496212005615234, 2.3355281352996826, 178.97142028808594) | Terminated: False |                Episode Length: 4.279999999999953 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -7.048178709339241 |                 State: (-50.40581130981445, 2.337311029434204, 178.92855834960938) | Terminated: False |                Episode Length: 4.289999999999953 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -7.066185251532048 |                 State: (-50.315372467041016, 2.3390886783599854, 178.88571166992188) | Terminated: False |                Episode Length: 4.299999999999953 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -7.084181805751062 |                 State: (-50.224884033203125, 2.3408613204956055, 178.8428497314453) | Terminated: False |                Episode Length: 4.3099999999999525 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -7.102168240247986 |                 State: (-50.13434982299805, 2.3426289558410645, 178.79998779296875) | Terminated: False |                Episode Length: 4.319999999999952 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -7.120144423343155 |                 State: (-50.04377746582031, 2.344391345977783, 178.7571258544922) | Terminated: False |                Episode Length: 4.329999999999952 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -7.138110223427991 |                 State: (-49.953155517578125, 2.3461484909057617, 178.7142791748047) | Terminated: False |                Episode Length: 4.339999999999952 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -7.156065508967452 |                 State: (-49.862491607666016, 2.347900629043579, 178.67141723632812) | Terminated: False |                Episode Length: 4.349999999999952 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -7.174010148502487 |                 State: (-49.77178192138672, 2.3496475219726562, 178.62855529785156) | Terminated: False |                Episode Length: 4.3599999999999515 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -7.191944010652491 |                 State: (-49.681034088134766, 2.3513894081115723, 178.58570861816406) | Terminated: False |                Episode Length: 4.369999999999951 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -7.209866964117765 |                 State: (-49.590240478515625, 2.353126049041748, 178.5428466796875) | Terminated: False |                Episode Length: 4.379999999999951 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -7.227778877681978 |                 State: (-49.49940490722656, 2.3548574447631836, 178.49998474121094) | Terminated: False |                Episode Length: 4.389999999999951 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -7.245679620214623 |                 State: (-49.408531188964844, 2.356583833694458, 178.45713806152344) | Terminated: False |                Episode Length: 4.399999999999951 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -7.263569060673488 |                 State: (-49.31761169433594, 2.358304977416992, 178.41427612304688) | Terminated: False |                Episode Length: 4.40999999999995 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -7.281447068107118 |                 State: (-49.22665023803711, 2.360020875930786, 178.3714141845703) | Terminated: False |                Episode Length: 4.41999999999995 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -7.299313511657284 |                 State: (-49.13564682006836, 2.36173152923584, 178.3285675048828) | Terminated: False |                Episode Length: 4.42999999999995 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -7.31716826056145 |                 State: (-49.04460906982422, 2.3634371757507324, 178.28570556640625) | Terminated: False |                Episode Length: 4.43999999999995 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -7.3350111841552454 |                 State: (-48.95352554321289, 2.3651375770568848, 178.2428436279297) | Terminated: False |                Episode Length: 4.4499999999999496 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -7.352842151874934 |                 State: (-48.862403869628906, 2.366832733154297, 178.1999969482422) | Terminated: False |                Episode Length: 4.459999999999949 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -7.370661033259888 |                 State: (-48.771244049072266, 2.368522882461548, 178.15713500976562) | Terminated: False |                Episode Length: 4.469999999999949 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -7.388467697955065 |                 State: (-48.68003845214844, 2.3702075481414795, 178.11427307128906) | Terminated: False |                Episode Length: 4.479999999999949 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -7.406262015713476 |                 State: (-48.588802337646484, 2.37188720703125, 178.07142639160156) | Terminated: False |                Episode Length: 4.489999999999949 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -7.424043856398668 |                 State: (-48.49752426147461, 2.3735616207122803, 178.11427307128906) | Terminated: False |                Episode Length: 4.4999999999999485 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -7.441813087925298 |                 State: (-48.40620040893555, 2.375230550765991, 178.15713500976562) | Terminated: False |                Episode Length: 4.509999999999948 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -7.459569578305168 |                 State: (-48.31483459472656, 2.376894474029541, 178.1999969482422) | Terminated: False |                Episode Length: 4.519999999999948 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -7.477313195649726 |                 State: (-48.223419189453125, 2.3785531520843506, 178.2428436279297) | Terminated: False |                Episode Length: 4.529999999999948 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -7.49504380817257 |                 State: (-48.1319580078125, 2.38020658493042, 178.28570556640625) | Terminated: False |                Episode Length: 4.539999999999948 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -7.512761284191946 |                 State: (-48.04045867919922, 2.381854772567749, 178.3285675048828) | Terminated: False |                Episode Length: 4.549999999999947 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -7.53046549213326 |                 State: (-47.948909759521484, 2.383497714996338, 178.3714141845703) | Terminated: False |                Episode Length: 4.559999999999947 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -7.54815630053158 |                 State: (-47.85731887817383, 2.3851354122161865, 178.41427612304688) | Terminated: False |                Episode Length: 4.569999999999947 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -7.565833578034145 |                 State: (-47.76568603515625, 2.386767864227295, 178.45713806152344) | Terminated: False |                Episode Length: 4.579999999999947 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -7.583497193402872 |                 State: (-47.67401123046875, 2.388395071029663, 178.49998474121094) | Terminated: False |                Episode Length: 4.589999999999947 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -7.60114701551687 |                 State: (-47.58229064941406, 2.390017032623291, 178.5428466796875) | Terminated: False |                Episode Length: 4.599999999999946 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -7.618782913374945 |                 State: (-47.49053192138672, 2.3916335105895996, 178.58570861816406) | Terminated: False |                Episode Length: 4.609999999999946 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -7.636404756098116 |                 State: (-47.39873123168945, 2.393244981765747, 178.62855529785156) | Terminated: False |                Episode Length: 4.619999999999946 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -7.654012412932126 |                 State: (-47.306884765625, 2.394850969314575, 178.58570861816406) | Terminated: False |                Episode Length: 4.629999999999946 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -7.671605754777339 |                 State: (-47.215003967285156, 2.396451711654663, 178.5428466796875) | Terminated: False |                Episode Length: 4.6399999999999455 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -7.689184652676903 |                 State: (-47.12309265136719, 2.3980472087860107, 178.49998474121094) | Terminated: False |                Episode Length: 4.649999999999945 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -7.70674897781924 |                 State: (-47.0311393737793, 2.399637460708618, 178.45713806152344) | Terminated: False |                Episode Length: 4.659999999999945 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -7.724298601540541 |                 State: (-46.93915939331055, 2.4012222290039062, 178.41427612304688) | Terminated: False |                Episode Length: 4.669999999999945 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -7.741833395327254 |                 State: (-46.847137451171875, 2.402801752090454, 178.3714141845703) | Terminated: False |                Episode Length: 4.679999999999945 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -7.7593532308185775 |                 State: (-46.75508499145508, 2.4043760299682617, 178.3285675048828) | Terminated: False |                Episode Length: 4.689999999999944 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -7.776857979808951 |                 State: (-46.66299819946289, 2.405945062637329, 178.28570556640625) | Terminated: False |                Episode Length: 4.699999999999944 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -7.794347514250544 |                 State: (-46.57088088989258, 2.407508611679077, 178.2428436279297) | Terminated: False |                Episode Length: 4.709999999999944 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -7.811821706255744 |                 State: (-46.478729248046875, 2.409066915512085, 178.1999969482422) | Terminated: False |                Episode Length: 4.719999999999944 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -7.829280428099645 |                 State: (-46.386539459228516, 2.4106199741363525, 178.15713500976562) | Terminated: False |                Episode Length: 4.729999999999944 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -7.846723552222537 |                 State: (-46.29432678222656, 2.412167549133301, 178.11427307128906) | Terminated: False |                Episode Length: 4.739999999999943 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -7.864150951232386 |                 State: (-46.20207595825195, 2.413709878921509, 178.07142639160156) | Terminated: False |                Episode Length: 4.749999999999943 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -7.881562497907322 |                 State: (-46.10979461669922, 2.4152467250823975, 178.02854919433594) | Terminated: False |                Episode Length: 4.759999999999943 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -7.898958065198123 |                 State: (-46.017486572265625, 2.416778326034546, 177.98570251464844) | Terminated: False |                Episode Length: 4.769999999999943 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -7.916337526230692 |                 State: (-45.925140380859375, 2.418304681777954, 177.94285583496094) | Terminated: False |                Episode Length: 4.7799999999999425 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -7.933700754308542 |                 State: (-45.83277130126953, 2.419825553894043, 177.8999786376953) | Terminated: False |                Episode Length: 4.789999999999942 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -7.95104762291527 |                 State: (-45.7403678894043, 2.4213411808013916, 177.8571319580078) | Terminated: False |                Episode Length: 4.799999999999942 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -7.968378005717036 |                 State: (-45.64793395996094, 2.422851324081421, 177.8142852783203) | Terminated: False |                Episode Length: 4.809999999999942 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -7.985691776565039 |                 State: (-45.55547332763672, 2.424355983734131, 177.7714080810547) | Terminated: False |                Episode Length: 4.819999999999942 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -8.002988809497985 |                 State: (-45.462982177734375, 2.4258556365966797, 177.7285614013672) | Terminated: False |                Episode Length: 4.8299999999999415 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -8.020268978744562 |                 State: (-45.37046432495117, 2.42734956741333, 177.6857147216797) | Terminated: False |                Episode Length: 4.839999999999941 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -8.03753215872591 |                 State: (-45.27791976928711, 2.4288382530212402, 177.64283752441406) | Terminated: False |                Episode Length: 4.849999999999941 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -8.054778224058076 |                 State: (-45.185340881347656, 2.430321455001831, 177.59999084472656) | Terminated: False |                Episode Length: 4.859999999999941 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -8.072007049554495 |                 State: (-45.092742919921875, 2.4317994117736816, 177.55714416503906) | Terminated: False |                Episode Length: 4.869999999999941 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -8.08921851022844 |                 State: (-45.0001106262207, 2.433271884918213, 177.51426696777344) | Terminated: False |                Episode Length: 4.87999999999994 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -8.10641248129548 |                 State: (-44.90745544433594, 2.434739112854004, 177.47142028808594) | Terminated: False |                Episode Length: 4.88999999999994 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -8.123588838175948 |                 State: (-44.81477355957031, 2.4362008571624756, 177.42855834960938) | Terminated: False |                Episode Length: 4.89999999999994 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -8.140747456497378 |                 State: (-44.72206497192383, 2.437657117843628, 177.3856964111328) | Terminated: False |                Episode Length: 4.90999999999994 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -8.157888212096971 |                 State: (-44.629329681396484, 2.43910813331604, 177.3428497314453) | Terminated: False |                Episode Length: 4.9199999999999395 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -8.175010981024032 |                 State: (-44.53657150268555, 2.440553665161133, 177.29998779296875) | Terminated: False |                Episode Length: 4.929999999999939 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -8.192115639542424 |                 State: (-44.44378662109375, 2.4419937133789062, 177.2571258544922) | Terminated: False |                Episode Length: 4.939999999999939 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -8.209202064132999 |                 State: (-44.35097885131836, 2.4434282779693604, 177.2142791748047) | Terminated: False |                Episode Length: 4.949999999999939 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -8.226270131496046 |                 State: (-44.25814437866211, 2.444857597351074, 177.17141723632812) | Terminated: False |                Episode Length: 4.959999999999939 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -8.243319718553721 |                 State: (-44.165283203125, 2.4462814331054688, 177.12855529785156) | Terminated: False |                Episode Length: 4.9699999999999385 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -8.260350702452483 |                 State: (-44.07240295410156, 2.447699785232544, 177.17141723632812) | Terminated: False |                Episode Length: 4.979999999999938 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -8.277362957027922 |                 State: (-43.979488372802734, 2.4491126537323, 177.2142791748047) | Terminated: False |                Episode Length: 4.989999999999938 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -8.294356356317998 |                 State: (-43.886539459228516, 2.4505202770233154, 177.2571258544922) | Terminated: False |                Episode Length: 4.999999999999938 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -8.311330774565539 |                 State: (-43.793556213378906, 2.4519224166870117, 177.29998779296875) | Terminated: False |                Episode Length: 5.009999999999938 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -8.328286086220732 |                 State: (-43.700538635253906, 2.4533190727233887, 177.3428497314453) | Terminated: False |                Episode Length: 5.019999999999937 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -8.345222165943621 |                 State: (-43.607486724853516, 2.4547102451324463, 177.3856964111328) | Terminated: False |                Episode Length: 5.029999999999937 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -8.362138888606594 |                 State: (-43.514404296875, 2.4560959339141846, 177.42855834960938) | Terminated: False |                Episode Length: 5.039999999999937 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -8.379036129296876 |                 State: (-43.421287536621094, 2.4574761390686035, 177.47142028808594) | Terminated: False |                Episode Length: 5.049999999999937 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -8.395913763319008 |                 State: (-43.32814025878906, 2.4588510990142822, 177.51426696777344) | Terminated: False |                Episode Length: 5.0599999999999365 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -8.412771666197333 |                 State: (-43.234962463378906, 2.4602203369140625, 177.55714416503906) | Terminated: False |                Episode Length: 5.069999999999936 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -8.429609713678479 |                 State: (-43.14175033569336, 2.4615843296051025, 177.59999084472656) | Terminated: False |                Episode Length: 5.079999999999936 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -8.446427781733831 |                 State: (-43.04850769042969, 2.462942600250244, 177.64283752441406) | Terminated: False |                Episode Length: 5.089999999999936 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -8.46322574656201 |                 State: (-42.95523452758789, 2.4642956256866455, 177.6857147216797) | Terminated: False |                Episode Length: 5.099999999999936 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -8.480003484591338 |                 State: (-42.86193084716797, 2.4656431674957275, 177.7285614013672) | Terminated: False |                Episode Length: 5.1099999999999355 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -8.496760872482312 |                 State: (-42.76859664916992, 2.466984987258911, 177.7714080810547) | Terminated: False |                Episode Length: 5.119999999999935 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -8.513497787130065 |                 State: (-42.675235748291016, 2.4683215618133545, 177.8142852783203) | Terminated: False |                Episode Length: 5.129999999999935 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -8.530214105666829 |                 State: (-42.58184051513672, 2.4696524143218994, 177.8571319580078) | Terminated: False |                Episode Length: 5.139999999999935 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -8.54690970546439 |                 State: (-42.48842239379883, 2.470978021621704, 177.8999786376953) | Terminated: False |                Episode Length: 5.149999999999935 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -8.563584464136547 |                 State: (-42.39496994018555, 2.4722981452941895, 177.94285583496094) | Terminated: False |                Episode Length: 5.159999999999934 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -8.580238259541552 |                 State: (-42.30149841308594, 2.4736125469207764, 177.98570251464844) | Terminated: False |                Episode Length: 5.169999999999934 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -8.59687096978457 |                 State: (-42.20799255371094, 2.474921464920044, 178.02854919433594) | Terminated: False |                Episode Length: 5.179999999999934 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -8.613482473220111 |                 State: (-42.11445999145508, 2.4762251377105713, 178.07142639160156) | Terminated: False |                Episode Length: 5.189999999999934 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -8.630072648454474 |                 State: (-42.02090072631836, 2.4775230884552, 178.11427307128906) | Terminated: False |                Episode Length: 5.199999999999934 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -8.646641374348178 |                 State: (-41.927310943603516, 2.4788155555725098, 178.15713500976562) | Terminated: False |                Episode Length: 5.209999999999933 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -8.663188530018397 |                 State: (-41.833702087402344, 2.4801025390625, 178.1999969482422) | Terminated: False |                Episode Length: 5.219999999999933 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -8.67971399484138 |                 State: (-41.74006271362305, 2.481384038925171, 178.2428436279297) | Terminated: False |                Episode Length: 5.229999999999933 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -8.696217648454878 |                 State: (-41.64639663696289, 2.4826598167419434, 178.28570556640625) | Terminated: False |                Episode Length: 5.239999999999933 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -8.712699370760559 |                 State: (-41.55270767211914, 2.4839301109313965, 178.3285675048828) | Terminated: False |                Episode Length: 5.2499999999999325 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -8.729159041926417 |                 State: (-41.45899200439453, 2.4851951599121094, 178.3714141845703) | Terminated: False |                Episode Length: 5.259999999999932 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -8.745596542389187 |                 State: (-41.365257263183594, 2.486454486846924, 178.41427612304688) | Terminated: False |                Episode Length: 5.269999999999932 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -8.76201175285674 |                 State: (-41.27149200439453, 2.48770809173584, 178.45713806152344) | Terminated: False |                Episode Length: 5.279999999999932 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -8.778404554310487 |                 State: (-41.177703857421875, 2.4889564514160156, 178.49998474121094) | Terminated: False |                Episode Length: 5.289999999999932 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -8.794774828007773 |                 State: (-41.08389663696289, 2.490199089050293, 178.5428466796875) | Terminated: False |                Episode Length: 5.299999999999931 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -8.81112245548426 |                 State: (-40.99006271362305, 2.491436243057251, 178.58570861816406) | Terminated: False |                Episode Length: 5.309999999999931 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -8.827447318556308 |                 State: (-40.896209716796875, 2.4926679134368896, 178.62855529785156) | Terminated: False |                Episode Length: 5.319999999999931 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -8.843749299323363 |                 State: (-40.80233383178711, 2.493894100189209, 178.67141723632812) | Terminated: False |                Episode Length: 5.329999999999931 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -8.860028280170322 |                 State: (-40.708431243896484, 2.49511456489563, 178.7142791748047) | Terminated: False |                Episode Length: 5.339999999999931 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -8.8762841437699 |                 State: (-40.61450958251953, 2.4963295459747314, 178.7571258544922) | Terminated: False |                Episode Length: 5.34999999999993 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -8.892516773084987 |                 State: (-40.520565032958984, 2.4975388050079346, 178.79998779296875) | Terminated: False |                Episode Length: 5.35999999999993 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -8.908726051371017 |                 State: (-40.426605224609375, 2.4987425804138184, 178.8428497314453) | Terminated: False |                Episode Length: 5.36999999999993 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -8.924911862178305 |                 State: (-40.332618713378906, 2.499940872192383, 178.88571166992188) | Terminated: False |                Episode Length: 5.37999999999993 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -8.941074089354395 |                 State: (-40.23862075805664, 2.501133680343628, 178.92855834960938) | Terminated: False |                Episode Length: 5.3899999999999295 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -8.957212617046396 |                 State: (-40.144596099853516, 2.5023207664489746, 178.97142028808594) | Terminated: False |                Episode Length: 5.399999999999929 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -8.973327329703322 |                 State: (-40.05055236816406, 2.503502368927002, 179.0142822265625) | Terminated: False |                Episode Length: 5.409999999999929 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -8.989418112078408 |                 State: (-39.95649337768555, 2.504678249359131, 179.05712890625) | Terminated: False |                Episode Length: 5.419999999999929 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -9.005484849231433 |                 State: (-39.86241149902344, 2.5058486461639404, 179.09999084472656) | Terminated: False |                Episode Length: 5.429999999999929 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -9.021527426531033 |                 State: (-39.768314361572266, 2.5070133209228516, 179.14285278320312) | Terminated: False |                Episode Length: 5.4399999999999284 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -9.037545729657014 |                 State: (-39.674198150634766, 2.5081727504730225, 179.18569946289062) | Terminated: False |                Episode Length: 5.449999999999928 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -9.053539644602639 |                 State: (-39.58006286621094, 2.509326219558716, 179.2285614013672) | Terminated: False |                Episode Length: 5.459999999999928 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -9.069509057676933 |                 State: (-39.48591232299805, 2.510474443435669, 179.27142333984375) | Terminated: False |                Episode Length: 5.469999999999928 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -9.08545385550697 |                 State: (-39.39174270629883, 2.5116167068481445, 179.31427001953125) | Terminated: False |                Episode Length: 5.479999999999928 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -9.101373925040141 |                 State: (-39.29756164550781, 2.51275372505188, 179.3571319580078) | Terminated: False |                Episode Length: 5.489999999999927 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -9.117269153546443 |                 State: (-39.20336151123047, 2.513885021209717, 179.39999389648438) | Terminated: False |                Episode Length: 5.499999999999927 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -9.133139428620735 |                 State: (-39.10914993286133, 2.5150105953216553, 179.44284057617188) | Terminated: False |                Episode Length: 5.509999999999927 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -9.148984638185 |                 State: (-39.014915466308594, 2.5161306858062744, 179.48570251464844) | Terminated: False |                Episode Length: 5.519999999999927 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -9.164804670490597 |                 State: (-38.92067337036133, 2.517245054244995, 179.528564453125) | Terminated: False |                Episode Length: 5.5299999999999265 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -9.180599414120506 |                 State: (-38.826412200927734, 2.5183539390563965, 179.5714111328125) | Terminated: False |                Episode Length: 5.539999999999926 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -9.196368757991566 |                 State: (-38.732139587402344, 2.5194573402404785, 179.528564453125) | Terminated: False |                Episode Length: 5.549999999999926 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -9.212112591964104 |                 State: (-38.63785171508789, 2.520555019378662, 179.48570251464844) | Terminated: False |                Episode Length: 5.559999999999926 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -9.227830806240469 |                 State: (-38.543556213378906, 2.5216469764709473, 179.44284057617188) | Terminated: False |                Episode Length: 5.569999999999926 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -9.243523291367232 |                 State: (-38.44924545288086, 2.522733449935913, 179.39999389648438) | Terminated: False |                Episode Length: 5.5799999999999255 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -9.259189938237368 |                 State: (-38.35492706298828, 2.5238142013549805, 179.3571319580078) | Terminated: False |                Episode Length: 5.589999999999925 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -9.27483063809244 |                 State: (-38.260597229003906, 2.5248894691467285, 179.31427001953125) | Terminated: False |                Episode Length: 5.599999999999925 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -9.290445282524772 |                 State: (-38.166255950927734, 2.525959014892578, 179.27142333984375) | Terminated: False |                Episode Length: 5.609999999999925 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -9.306033763479602 |                 State: (-38.07190704345703, 2.5270228385925293, 179.2285614013672) | Terminated: False |                Episode Length: 5.619999999999925 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -9.321595973257253 |                 State: (-37.97754669189453, 2.528081178665161, 179.18569946289062) | Terminated: False |                Episode Length: 5.629999999999924 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -9.337131804515266 |                 State: (-37.8831787109375, 2.5291340351104736, 179.14285278320312) | Terminated: False |                Episode Length: 5.639999999999924 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -9.352641150270546 |                 State: (-37.78880310058594, 2.5301809310913086, 179.09999084472656) | Terminated: False |                Episode Length: 5.649999999999924 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -9.368123903901488 |                 State: (-37.69441604614258, 2.531222343444824, 179.05712890625) | Terminated: False |                Episode Length: 5.659999999999924 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -9.383579959150097 |                 State: (-37.60002136230469, 2.5322582721710205, 179.0142822265625) | Terminated: False |                Episode Length: 5.6699999999999235 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -9.399009210124104 |                 State: (-37.50562286376953, 2.5332884788513184, 178.97142028808594) | Terminated: False |                Episode Length: 5.679999999999923 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -9.414411551299068 |                 State: (-37.411216735839844, 2.5343129634857178, 178.92855834960938) | Terminated: False |                Episode Length: 5.689999999999923 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -9.429786877520469 |                 State: (-37.316802978515625, 2.535331964492798, 178.88571166992188) | Terminated: False |                Episode Length: 5.699999999999923 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -9.445135084005793 |                 State: (-37.222381591796875, 2.5363452434539795, 178.8428497314453) | Terminated: False |                Episode Length: 5.709999999999923 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -9.460456066346612 |                 State: (-37.127952575683594, 2.5373528003692627, 178.79998779296875) | Terminated: False |                Episode Length: 5.7199999999999225 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -9.475749720510649 |                 State: (-37.03351974487305, 2.5383548736572266, 178.8428497314453) | Terminated: False |                Episode Length: 5.729999999999922 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -9.491015941077546 |                 State: (-36.93907928466797, 2.539351224899292, 178.88571166992188) | Terminated: False |                Episode Length: 5.739999999999922 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -9.506254622997192 |                 State: (-36.84462356567383, 2.540342092514038, 178.92855834960938) | Terminated: False |                Episode Length: 5.749999999999922 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -9.521465661591822 |                 State: (-36.750160217285156, 2.5413272380828857, 178.97142028808594) | Terminated: False |                Episode Length: 5.759999999999922 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -9.536648952558103 |                 State: (-36.65568923950195, 2.542306661605835, 179.0142822265625) | Terminated: False |                Episode Length: 5.769999999999921 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -9.55180439196922 |                 State: (-36.56121063232422, 2.5432803630828857, 179.05712890625) | Terminated: False |                Episode Length: 5.779999999999921 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -9.566931876276946 |                 State: (-36.46672439575195, 2.544248580932617, 179.09999084472656) | Terminated: False |                Episode Length: 5.789999999999921 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -9.582031302313707 |                 State: (-36.372222900390625, 2.54521107673645, 179.14285278320312) | Terminated: False |                Episode Length: 5.799999999999921 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -9.597102567294634 |                 State: (-36.2777214050293, 2.5461678504943848, 179.18569946289062) | Terminated: False |                Episode Length: 5.809999999999921 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -9.612145568819608 |                 State: (-36.18320846557617, 2.547119140625, 179.2285614013672) | Terminated: False |                Episode Length: 5.81999999999992 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -9.627160204875297 |                 State: (-36.08869171142578, 2.548064708709717, 179.27142333984375) | Terminated: False |                Episode Length: 5.82999999999992 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -9.64214637383718 |                 State: (-35.99416732788086, 2.549004554748535, 179.31427001953125) | Terminated: False |                Episode Length: 5.83999999999992 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -9.657103974471562 |                 State: (-35.899635314941406, 2.549938917160034, 179.3571319580078) | Terminated: False |                Episode Length: 5.84999999999992 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -9.672032905937584 |                 State: (-35.80509948730469, 2.5508673191070557, 179.39999389648438) | Terminated: False |                Episode Length: 5.8599999999999195 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -9.686933067789218 |                 State: (-35.71055603027344, 2.551790237426758, 179.3571319580078) | Terminated: False |                Episode Length: 5.869999999999919 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -9.701804360885045 |                 State: (-35.61601257324219, 2.5527076721191406, 179.39999389648438) | Terminated: False |                Episode Length: 5.879999999999919 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -9.716646685512806 |                 State: (-35.521461486816406, 2.553619146347046, 179.3571319580078) | Terminated: False |                Episode Length: 5.889999999999919 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -9.731459943271872 |                 State: (-35.426910400390625, 2.554525136947632, 179.39999389648438) | Terminated: False |                Episode Length: 5.899999999999919 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -9.746244035190626 |                 State: (-35.33235549926758, 2.5554254055023193, 179.3571319580078) | Terminated: False |                Episode Length: 5.909999999999918 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -9.760998863616058 |                 State: (-35.237796783447266, 2.5563201904296875, 179.39999389648438) | Terminated: False |                Episode Length: 5.919999999999918 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -9.775724330324008 |                 State: (-35.14323806762695, 2.557209014892578, 179.3571319580078) | Terminated: False |                Episode Length: 5.929999999999918 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -9.790420338415844 |                 State: (-35.048675537109375, 2.5580923557281494, 179.39999389648438) | Terminated: False |                Episode Length: 5.939999999999918 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -9.805086790421612 |                 State: (-34.9541130065918, 2.5589699745178223, 179.3571319580078) | Terminated: False |                Episode Length: 5.949999999999918 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -9.819723590203742 |                 State: (-34.85955047607422, 2.559842109680176, 179.39999389648438) | Terminated: False |                Episode Length: 5.959999999999917 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -9.834330641053164 |                 State: (-34.76498031616211, 2.5607082843780518, 179.3571319580078) | Terminated: False |                Episode Length: 5.969999999999917 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -9.848907847599994 |                 State: (-34.670413970947266, 2.5615689754486084, 179.39999389648438) | Terminated: False |                Episode Length: 5.979999999999917 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -9.863455113902651 |                 State: (-34.575843811035156, 2.5624239444732666, 179.3571319580078) | Terminated: False |                Episode Length: 5.989999999999917 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -9.877972345365484 |                 State: (-34.48127746582031, 2.5632731914520264, 179.39999389648438) | Terminated: False |                Episode Length: 5.9999999999999165 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -9.892459446820933 |                 State: (-34.3867073059082, 2.564116954803467, 179.3571319580078) | Terminated: False |                Episode Length: 6.009999999999916 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -9.906916324454064 |                 State: (-34.29214096069336, 2.564954996109009, 179.39999389648438) | Terminated: False |                Episode Length: 6.019999999999916 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -9.921342883877802 |                 State: (-34.19757080078125, 2.5657873153686523, 179.3571319580078) | Terminated: False |                Episode Length: 6.029999999999916 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -9.935739032064333 |                 State: (-34.103004455566406, 2.5666139125823975, 179.39999389648438) | Terminated: False |                Episode Length: 6.039999999999916 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -9.950104675413458 |                 State: (-34.00843811035156, 2.567434787750244, 179.3571319580078) | Terminated: False |                Episode Length: 6.0499999999999154 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -9.964439721690816 |                 State: (-33.913875579833984, 2.5682501792907715, 179.39999389648438) | Terminated: False |                Episode Length: 6.059999999999915 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -9.978744078089399 |                 State: (-33.81930923461914, 2.5690598487854004, 179.3571319580078) | Terminated: False |                Episode Length: 6.069999999999915 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -9.993017653174556 |                 State: (-33.72475051879883, 2.569863796234131, 179.39999389648438) | Terminated: False |                Episode Length: 6.079999999999915 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -10.007260354938715 |                 State: (-33.63018798828125, 2.570662021636963, 179.3571319580078) | Terminated: False |                Episode Length: 6.089999999999915 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -10.021472092753122 |                 State: (-33.5356330871582, 2.5714545249938965, 179.39999389648438) | Terminated: False |                Episode Length: 6.099999999999914 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -10.035652775415803 |                 State: (-33.441078186035156, 2.5722415447235107, 179.3571319580078) | Terminated: False |                Episode Length: 6.109999999999914 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -10.049802313110007 |                 State: (-33.346527099609375, 2.5730228424072266, 179.39999389648438) | Terminated: False |                Episode Length: 6.119999999999914 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -10.063920615445454 |                 State: (-33.251983642578125, 2.573798418045044, 179.3571319580078) | Terminated: False |                Episode Length: 6.129999999999914 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -10.078007593423422 |                 State: (-33.157440185546875, 2.574568271636963, 179.39999389648438) | Terminated: False |                Episode Length: 6.1399999999999135 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -10.09206315747134 |                 State: (-33.062896728515625, 2.5753326416015625, 179.3571319580078) | Terminated: False |                Episode Length: 6.149999999999913 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -10.106087219414473 |                 State: (-32.968360900878906, 2.5760912895202637, 179.39999389648438) | Terminated: False |                Episode Length: 6.159999999999913 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -10.120079690503893 |                 State: (-32.87383270263672, 2.5768439769744873, 179.3571319580078) | Terminated: False |                Episode Length: 6.169999999999913 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -10.134040483394724 |                 State: (-32.77930450439453, 2.5775914192199707, 179.39999389648438) | Terminated: False |                Episode Length: 6.179999999999913 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -10.147969510167544 |                 State: (-32.684783935546875, 2.5783329010009766, 179.3571319580078) | Terminated: False |                Episode Length: 6.1899999999999125 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -10.16186668431313 |                 State: (-32.59027099609375, 2.579068660736084, 179.39999389648438) | Terminated: False |                Episode Length: 6.199999999999912 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -10.175731918747342 |                 State: (-32.495758056640625, 2.579798936843872, 179.3571319580078) | Terminated: False |                Episode Length: 6.209999999999912 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -10.189565127802332 |                 State: (-32.40125274658203, 2.5805234909057617, 179.39999389648438) | Terminated: False |                Episode Length: 6.219999999999912 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -10.203366225234937 |                 State: (-32.30675506591797, 2.581242322921753, 179.3571319580078) | Terminated: False |                Episode Length: 6.229999999999912 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -10.21713512622432 |                 State: (-32.21226501464844, 2.581955671310425, 179.39999389648438) | Terminated: False |                Episode Length: 6.239999999999911 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -10.23087174537392 |                 State: (-32.11777877807617, 2.582663059234619, 179.3571319580078) | Terminated: False |                Episode Length: 6.249999999999911 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -10.244575998715458 |                 State: (-32.0233039855957, 2.583364963531494, 179.39999389648438) | Terminated: False |                Episode Length: 6.259999999999911 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -10.258247801704512 |                 State: (-31.928831100463867, 2.5840611457824707, 179.3571319580078) | Terminated: False |                Episode Length: 6.269999999999911 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -10.27188707123084 |                 State: (-31.834369659423828, 2.584751605987549, 179.39999389648438) | Terminated: False |                Episode Length: 6.2799999999999105 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -10.285493723607608 |                 State: (-31.739913940429688, 2.5854365825653076, 179.3571319580078) | Terminated: False |                Episode Length: 6.28999999999991 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -10.299067676588004 |                 State: (-31.645465850830078, 2.586115598678589, 179.39999389648438) | Terminated: False |                Episode Length: 6.29999999999991 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -10.312608847348157 |                 State: (-31.551029205322266, 2.586789131164551, 179.3571319580078) | Terminated: False |                Episode Length: 6.30999999999991 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -10.326117154509987 |                 State: (-31.456602096557617, 2.5874569416046143, 179.39999389648438) | Terminated: False |                Episode Length: 6.31999999999991 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -10.339592516117877 |                 State: (-31.362180709838867, 2.5881192684173584, 179.3571319580078) | Terminated: False |                Episode Length: 6.3299999999999095 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -10.3530348516677 |                 State: (-31.267770767211914, 2.588775634765625, 179.39999389648438) | Terminated: False |                Episode Length: 6.339999999999909 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -10.366444080077303 |                 State: (-31.173370361328125, 2.5894265174865723, 179.3571319580078) | Terminated: False |                Episode Length: 6.349999999999909 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -10.379820121721648 |                 State: (-31.078977584838867, 2.590071678161621, 179.39999389648438) | Terminated: False |                Episode Length: 6.359999999999909 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -10.393162896397161 |                 State: (-30.98459815979004, 2.5907111167907715, 179.3571319580078) | Terminated: False |                Episode Length: 6.369999999999909 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -10.406472325362953 |                 State: (-30.890228271484375, 2.5913450717926025, 179.39999389648438) | Terminated: False |                Episode Length: 6.379999999999908 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -10.419748329299061 |                 State: (-30.795869827270508, 2.591973304748535, 179.3571319580078) | Terminated: False |                Episode Length: 6.389999999999908 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -10.432990830353711 |                 State: (-30.701520919799805, 2.5925958156585693, 179.39999389648438) | Terminated: False |                Episode Length: 6.399999999999908 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -10.446199750095502 |                 State: (-30.607181549072266, 2.593212604522705, 179.3571319580078) | Terminated: False |                Episode Length: 6.409999999999908 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -10.459375011566657 |                 State: (-30.51285743713379, 2.5938236713409424, 179.39999389648438) | Terminated: False |                Episode Length: 6.419999999999908 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -10.472516537229197 |                 State: (-30.418546676635742, 2.5944292545318604, 179.3571319580078) | Terminated: False |                Episode Length: 6.429999999999907 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -10.485624251024133 |                 State: (-30.32424545288086, 2.59502911567688, 179.39999389648438) | Terminated: False |                Episode Length: 6.439999999999907 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -10.498698076311687 |                 State: (-30.22995376586914, 2.595623254776001, 179.3571319580078) | Terminated: False |                Episode Length: 6.449999999999907 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -10.511737937936363 |                 State: (-30.13568115234375, 2.5962119102478027, 179.39999389648438) | Terminated: False |                Episode Length: 6.459999999999907 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -10.524743760161273 |                 State: (-30.041418075561523, 2.596794605255127, 179.3571319580078) | Terminated: False |                Episode Length: 6.4699999999999065 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -10.537715468739034 |                 State: (-29.947168350219727, 2.597371816635132, 179.39999389648438) | Terminated: False |                Episode Length: 6.479999999999906 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -10.550652988840241 |                 State: (-29.85293197631836, 2.5979435443878174, 179.3571319580078) | Terminated: False |                Episode Length: 6.489999999999906 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -10.563556247130153 |                 State: (-29.758712768554688, 2.5985093116760254, 179.39999389648438) | Terminated: False |                Episode Length: 6.499999999999906 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -10.576425169691364 |                 State: (-29.66450309753418, 2.599069595336914, 179.3571319580078) | Terminated: False |                Episode Length: 6.509999999999906 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -10.589259684106212 |                 State: (-29.5703125, 2.5996241569519043, 179.39999389648438) | Terminated: False |                Episode Length: 6.519999999999905 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -10.602059717373711 |                 State: (-29.476133346557617, 2.600173234939575, 179.3571319580078) | Terminated: False |                Episode Length: 6.529999999999905 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -10.614825197997629 |                 State: (-29.381973266601562, 2.6007165908813477, 179.39999389648438) | Terminated: False |                Episode Length: 6.539999999999905 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -10.627556053897731 |                 State: (-29.287822723388672, 2.6012542247772217, 179.3571319580078) | Terminated: False |                Episode Length: 6.549999999999905 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -10.640252214503475 |                 State: (-29.19369125366211, 2.6017861366271973, 179.39999389648438) | Terminated: False |                Episode Length: 6.559999999999905 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -10.652913608659617 |                 State: (-29.09957504272461, 2.6023125648498535, 179.3571319580078) | Terminated: False |                Episode Length: 6.569999999999904 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -10.665540166725473 |                 State: (-29.00547981262207, 2.6028332710266113, 179.39999389648438) | Terminated: False |                Episode Length: 6.579999999999904 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -10.678131818474942 |                 State: (-28.911394119262695, 2.6033482551574707, 179.3571319580078) | Terminated: False |                Episode Length: 6.589999999999904 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -10.690688495201277 |                 State: (-28.81732749938965, 2.6038577556610107, 179.39999389648438) | Terminated: False |                Episode Length: 6.599999999999904 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -10.703210127611577 |                 State: (-28.72327995300293, 2.6043615341186523, 179.3571319580078) | Terminated: False |                Episode Length: 6.6099999999999035 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -10.71569664793702 |                 State: (-28.629247665405273, 2.6048598289489746, 179.39999389648438) | Terminated: False |                Episode Length: 6.619999999999903 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -10.728147987821872 |                 State: (-28.535234451293945, 2.6053521633148193, 179.3571319580078) | Terminated: False |                Episode Length: 6.629999999999903 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -10.740564080439128 |                 State: (-28.441238403320312, 2.6058390140533447, 179.39999389648438) | Terminated: False |                Episode Length: 6.639999999999903 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -10.752944858374095 |                 State: (-28.347261428833008, 2.606320381164551, 179.3571319580078) | Terminated: False |                Episode Length: 6.649999999999903 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -10.765290255745388 |                 State: (-28.25330352783203, 2.6067960262298584, 179.39999389648438) | Terminated: False |                Episode Length: 6.659999999999902 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -10.777600206083141 |                 State: (-28.15936279296875, 2.6072659492492676, 179.3571319580078) | Terminated: False |                Episode Length: 6.669999999999902 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -10.789874644455297 |                 State: (-28.06544303894043, 2.6077303886413574, 179.39999389648438) | Terminated: False |                Episode Length: 6.679999999999902 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -10.802113505340504 |                 State: (-27.971538543701172, 2.608189105987549, 179.3571319580078) | Terminated: False |                Episode Length: 6.689999999999902 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -10.814316724759648 |                 State: (-27.87765884399414, 2.608642101287842, 179.39999389648438) | Terminated: False |                Episode Length: 6.699999999999902 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -10.826484238143488 |                 State: (-27.783796310424805, 2.6090896129608154, 179.3571319580078) | Terminated: False |                Episode Length: 6.709999999999901 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -10.838615982469376 |                 State: (-27.689956665039062, 2.6095314025878906, 179.39999389648438) | Terminated: False |                Episode Length: 6.719999999999901 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -10.850711894123686 |                 State: (-27.596132278442383, 2.6099677085876465, 179.3571319580078) | Terminated: False |                Episode Length: 6.729999999999901 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -10.862771911043662 |                 State: (-27.502334594726562, 2.610398292541504, 179.39999389648438) | Terminated: False |                Episode Length: 6.739999999999901 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -10.8747959705747 |                 State: (-27.40855598449707, 2.610823392868042, 179.3571319580078) | Terminated: False |                Episode Length: 6.7499999999999005 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -10.886784011617273 |                 State: (-27.31479835510254, 2.6112427711486816, 179.39999389648438) | Terminated: False |                Episode Length: 6.7599999999999 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -10.898735972479113 |                 State: (-27.22106170654297, 2.611656427383423, 179.3571319580078) | Terminated: False |                Episode Length: 6.7699999999999 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -10.910651793027155 |                 State: (-27.127347946166992, 2.6120645999908447, 179.39999389648438) | Terminated: False |                Episode Length: 6.7799999999999 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -10.92253141253469 |                 State: (-27.03365707397461, 2.612467050552368, 179.3571319580078) | Terminated: False |                Episode Length: 6.7899999999999 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -10.934374771838266 |                 State: (-26.939987182617188, 2.6128640174865723, 179.39999389648438) | Terminated: False |                Episode Length: 6.7999999999998995 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -10.946181811179853 |                 State: (-26.84634017944336, 2.613255500793457, 179.3571319580078) | Terminated: False |                Episode Length: 6.809999999999899 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -10.957952472368655 |                 State: (-26.75271987915039, 2.6136412620544434, 179.39999389648438) | Terminated: False |                Episode Length: 6.819999999999899 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -10.969686696618355 |                 State: (-26.65911865234375, 2.6140213012695312, 179.3571319580078) | Terminated: False |                Episode Length: 6.829999999999899 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -10.981384426713769 |                 State: (-26.565542221069336, 2.6143958568573, 179.39999389648438) | Terminated: False |                Episode Length: 6.839999999999899 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -10.993045604843223 |                 State: (-26.47199058532715, 2.614764928817749, 179.3571319580078) | Terminated: False |                Episode Length: 6.849999999999898 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -11.004670174770002 |                 State: (-26.378463745117188, 2.6151282787323, 179.39999389648438) | Terminated: False |                Episode Length: 6.859999999999898 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -11.016258079659918 |                 State: (-26.28495979309082, 2.615485906600952, 179.3571319580078) | Terminated: False |                Episode Length: 6.869999999999898 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -11.027809264257487 |                 State: (-26.191482543945312, 2.615838050842285, 179.39999389648438) | Terminated: False |                Episode Length: 6.879999999999898 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -11.039323672708745 |                 State: (-26.0980281829834, 2.616184711456299, 179.3571319580078) | Terminated: False |                Episode Length: 6.8899999999998975 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -11.050801250742103 |                 State: (-26.004602432250977, 2.616525650024414, 179.39999389648438) | Terminated: False |                Episode Length: 6.899999999999897 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -11.06224194348647 |                 State: (-25.91119956970215, 2.61686110496521, 179.3571319580078) | Terminated: False |                Episode Length: 6.909999999999897 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -11.07364569765672 |                 State: (-25.81782341003418, 2.6171910762786865, 179.39999389648438) | Terminated: False |                Episode Length: 6.919999999999897 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -11.085012459367189 |                 State: (-25.72447395324707, 2.6175153255462646, 179.3571319580078) | Terminated: False |                Episode Length: 6.929999999999897 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -11.096342176321684 |                 State: (-25.63115119934082, 2.6178338527679443, 179.39999389648438) | Terminated: False |                Episode Length: 6.9399999999998965 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -11.107634795622417 |                 State: (-25.537853240966797, 2.618147134780884, 179.3571319580078) | Terminated: False |                Episode Length: 6.949999999999896 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -11.118890265964508 |                 State: (-25.4445858001709, 2.618454694747925, 179.39999389648438) | Terminated: False |                Episode Length: 6.959999999999896 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -11.130108535440401 |                 State: (-25.351343154907227, 2.6187565326690674, 179.3571319580078) | Terminated: False |                Episode Length: 6.969999999999896 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -11.14128955373881 |                 State: (-25.25813102722168, 2.6190531253814697, 179.39999389648438) | Terminated: False |                Episode Length: 6.979999999999896 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -11.152433269944668 |                 State: (-25.164941787719727, 2.6193439960479736, 179.3571319580078) | Terminated: False |                Episode Length: 6.989999999999895 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -11.163539634742461 |                 State: (-25.07178497314453, 2.619629144668579, 179.39999389648438) | Terminated: False |                Episode Length: 6.999999999999895 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -11.174608598211782 |                 State: (-24.978656768798828, 2.6199090480804443, 179.3571319580078) | Terminated: False |                Episode Length: 7.009999999999895 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -11.185640112034973 |                 State: (-24.885557174682617, 2.620183229446411, 179.39999389648438) | Terminated: False |                Episode Length: 7.019999999999895 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -11.196634127288345 |                 State: (-24.792484283447266, 2.6204519271850586, 179.3571319580078) | Terminated: False |                Episode Length: 7.0299999999998946 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -11.207590596654088 |                 State: (-24.699443817138672, 2.6207149028778076, 179.39999389648438) | Terminated: False |                Episode Length: 7.039999999999894 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -11.218509472207202 |                 State: (-24.60643196105957, 2.6209726333618164, 179.3571319580078) | Terminated: False |                Episode Length: 7.049999999999894 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -11.229390707631612 |                 State: (-24.51344871520996, 2.6212246417999268, 179.39999389648438) | Terminated: False |                Episode Length: 7.059999999999894 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -11.24023425600288 |                 State: (-24.420495986938477, 2.6214711666107178, 179.3571319580078) | Terminated: False |                Episode Length: 7.069999999999894 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -11.251040072008458 |                 State: (-24.327577590942383, 2.6217119693756104, 179.39999389648438) | Terminated: False |                Episode Length: 7.0799999999998935 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -11.261808109726243 |                 State: (-24.234683990478516, 2.6219475269317627, 179.3571319580078) | Terminated: False |                Episode Length: 7.089999999999893 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -11.27253832484891 |                 State: (-24.141826629638672, 2.6221773624420166, 179.39999389648438) | Terminated: False |                Episode Length: 7.099999999999893 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -11.28323067245837 |                 State: (-24.04899787902832, 2.622401714324951, 179.3571319580078) | Terminated: False |                Episode Length: 7.109999999999893 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -11.293885109254116 |                 State: (-23.956201553344727, 2.6226205825805664, 179.39999389648438) | Terminated: False |                Episode Length: 7.119999999999893 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -11.304501591323653 |                 State: (-23.863435745239258, 2.6228339672088623, 179.3571319580078) | Terminated: False |                Episode Length: 7.129999999999892 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -11.315080076374796 |                 State: (-23.77070426940918, 2.623041868209839, 179.39999389648438) | Terminated: False |                Episode Length: 7.139999999999892 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -11.325620521502122 |                 State: (-23.67800521850586, 2.623244047164917, 179.3571319580078) | Terminated: False |                Episode Length: 7.149999999999892 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -11.33612288542317 |                 State: (-23.585338592529297, 2.623440980911255, 179.39999389648438) | Terminated: False |                Episode Length: 7.159999999999892 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -11.346587126240976 |                 State: (-23.492704391479492, 2.6236321926116943, 179.3571319580078) | Terminated: False |                Episode Length: 7.169999999999892 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -11.357013203684108 |                 State: (-23.40010643005371, 2.6238179206848145, 179.39999389648438) | Terminated: False |                Episode Length: 7.179999999999891 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -11.367401076865345 |                 State: (-23.307537078857422, 2.6239981651306152, 179.3571319580078) | Terminated: False |                Episode Length: 7.189999999999891 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -11.377750706525497 |                 State: (-23.21500587463379, 2.624173164367676, 179.39999389648438) | Terminated: False |                Episode Length: 7.199999999999891 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -11.388062052788277 |                 State: (-23.122507095336914, 2.624342441558838, 179.3571319580078) | Terminated: False |                Episode Length: 7.209999999999891 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -11.398335077407841 |                 State: (-23.030044555664062, 2.6245062351226807, 179.39999389648438) | Terminated: False |                Episode Length: 7.2199999999998905 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -11.408569741519935 |                 State: (-22.937612533569336, 2.624664545059204, 179.3571319580078) | Terminated: False |                Episode Length: 7.22999999999989 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -11.418766007893074 |                 State: (-22.8452205657959, 2.624817371368408, 179.39999389648438) | Terminated: False |                Episode Length: 7.23999999999989 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -11.42892383867603 |                 State: (-22.75286102294922, 2.624964714050293, 179.3571319580078) | Terminated: False |                Episode Length: 7.24999999999989 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -11.439043197652591 |                 State: (-22.660537719726562, 2.6251065731048584, 179.39999389648438) | Terminated: False |                Episode Length: 7.25999999999989 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -11.449124047985451 |                 State: (-22.56825065612793, 2.6252431869506836, 179.3571319580078) | Terminated: False |                Episode Length: 7.269999999999889 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -11.459166354474501 |                 State: (-22.47599983215332, 2.6253740787506104, 179.39999389648438) | Terminated: False |                Episode Length: 7.279999999999889 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -11.469170081297156 |                 State: (-22.383785247802734, 2.6254994869232178, 179.3571319580078) | Terminated: False |                Episode Length: 7.289999999999889 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -11.479135194270123 |                 State: (-22.291608810424805, 2.625619649887085, 179.39999389648438) | Terminated: False |                Episode Length: 7.299999999999889 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -11.489061658586246 |                 State: (-22.1994686126709, 2.625734329223633, 179.3571319580078) | Terminated: False |                Episode Length: 7.309999999999889 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -11.498949441079677 |                 State: (-22.107364654541016, 2.6258432865142822, 179.39999389648438) | Terminated: False |                Episode Length: 7.319999999999888 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -11.508798507959298 |                 State: (-22.01529884338379, 2.6259469985961914, 179.3571319580078) | Terminated: False |                Episode Length: 7.329999999999888 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -11.51860882707723 |                 State: (-21.923269271850586, 2.6260452270507812, 179.39999389648438) | Terminated: False |                Episode Length: 7.339999999999888 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -11.528380365658903 |                 State: (-21.831281661987305, 2.626138210296631, 179.3571319580078) | Terminated: False |                Episode Length: 7.349999999999888 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -11.538113092574841 |                 State: (-21.739330291748047, 2.626225471496582, 179.39999389648438) | Terminated: False |                Episode Length: 7.3599999999998875 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -11.54780697606744 |                 State: (-21.647417068481445, 2.626307487487793, 179.3571319580078) | Terminated: False |                Episode Length: 7.369999999999887 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -11.55746198602596 |                 State: (-21.555543899536133, 2.6263840198516846, 179.39999389648438) | Terminated: False |                Episode Length: 7.379999999999887 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -11.567078091710076 |                 State: (-21.463708877563477, 2.626455068588257, 179.3571319580078) | Terminated: False |                Episode Length: 7.389999999999887 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -11.57665526402803 |                 State: (-21.371917724609375, 2.6265206336975098, 179.39999389648438) | Terminated: False |                Episode Length: 7.399999999999887 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -11.586193473257 |                 State: (-21.280160903930664, 2.6265809535980225, 179.3571319580078) | Terminated: False |                Episode Length: 7.4099999999998865 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -11.595692691324349 |                 State: (-21.188447952270508, 2.626635789871216, 179.39999389648438) | Terminated: False |                Episode Length: 7.419999999999886 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -11.605152889524884 |                 State: (-21.096773147583008, 2.626685380935669, 179.3571319580078) | Terminated: False |                Episode Length: 7.429999999999886 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -11.614574040805136 |                 State: (-21.005138397216797, 2.6267292499542236, 179.39999389648438) | Terminated: False |                Episode Length: 7.439999999999886 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -11.623956117477578 |                 State: (-20.913545608520508, 2.626767873764038, 179.3571319580078) | Terminated: False |                Episode Length: 7.449999999999886 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -11.633299093507857 |                 State: (-20.821996688842773, 2.6268012523651123, 179.39999389648438) | Terminated: False |                Episode Length: 7.459999999999885 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -11.642602942226043 |                 State: (-20.730487823486328, 2.626829147338867, 179.3571319580078) | Terminated: False |                Episode Length: 7.469999999999885 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -11.651867638616766 |                 State: (-20.639019012451172, 2.6268515586853027, 179.39999389648438) | Terminated: False |                Episode Length: 7.479999999999885 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -11.66109315702753 |                 State: (-20.54759407043457, 2.626868486404419, 179.3571319580078) | Terminated: False |                Episode Length: 7.489999999999885 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -11.670279473461703 |                 State: (-20.45621109008789, 2.626880168914795, 179.39999389648438) | Terminated: False |                Episode Length: 7.4999999999998845 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -11.679426563283974 |                 State: (-20.3648681640625, 2.6268866062164307, 179.3571319580078) | Terminated: False |                Episode Length: 7.509999999999884 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -11.688534403516115 |                 State: (-20.27357292175293, 2.626887559890747, 179.39999389648438) | Terminated: False |                Episode Length: 7.519999999999884 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -11.697602970539656 |                 State: (-20.18231773376465, 2.6268832683563232, 179.3571319580078) | Terminated: False |                Episode Length: 7.529999999999884 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -11.706632242394344 |                 State: (-20.091108322143555, 2.62687349319458, 179.39999389648438) | Terminated: False |                Episode Length: 7.539999999999884 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -11.715622196478098 |                 State: (-19.999940872192383, 2.6268582344055176, 179.3571319580078) | Terminated: False |                Episode Length: 7.5499999999998835 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -11.724572811848125 |                 State: (-19.908817291259766, 2.626837730407715, 179.39999389648438) | Terminated: False |                Episode Length: 7.559999999999883 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -11.7334840669182 |                 State: (-19.817737579345703, 2.626811981201172, 179.3571319580078) | Terminated: False |                Episode Length: 7.569999999999883 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -11.74235594176237 |                 State: (-19.72670555114746, 2.6267807483673096, 179.39999389648438) | Terminated: False |                Episode Length: 7.579999999999883 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -11.751188415809636 |                 State: (-19.63571548461914, 2.626744270324707, 179.3571319580078) | Terminated: False |                Episode Length: 7.589999999999883 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -11.759981470150178 |                 State: (-19.54477310180664, 2.6267025470733643, 179.39999389648438) | Terminated: False |                Episode Length: 7.599999999999882 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -11.7687350852275 |                 State: (-19.453872680664062, 2.626655340194702, 179.3571319580078) | Terminated: False |                Episode Length: 7.609999999999882 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -11.77744924314711 |                 State: (-19.363021850585938, 2.6266028881073, 179.39999389648438) | Terminated: False |                Episode Length: 7.619999999999882 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -11.7861239253662 |                 State: (-19.272214889526367, 2.6265451908111572, 179.3571319580078) | Terminated: False |                Episode Length: 7.629999999999882 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -11.794759115004714 |                 State: (-19.181455612182617, 2.6264820098876953, 179.39999389648438) | Terminated: False |                Episode Length: 7.6399999999998816 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -11.803354794532618 |                 State: (-19.090740203857422, 2.626413583755493, 179.3571319580078) | Terminated: False |                Episode Length: 7.649999999999881 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -11.811910948083309 |                 State: (-19.00007438659668, 2.626339912414551, 179.39999389648438) | Terminated: False |                Episode Length: 7.659999999999881 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -11.820427559138528 |                 State: (-18.909452438354492, 2.626260757446289, 179.3571319580078) | Terminated: False |                Episode Length: 7.669999999999881 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -11.828904612844042 |                 State: (-18.81888198852539, 2.626176595687866, 179.39999389648438) | Terminated: False |                Episode Length: 7.679999999999881 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -11.837342093692275 |                 State: (-18.728355407714844, 2.626086950302124, 179.3571319580078) | Terminated: False |                Episode Length: 7.6899999999998805 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -11.845739987840195 |                 State: (-18.637880325317383, 2.6259920597076416, 179.39999389648438) | Terminated: False |                Episode Length: 7.69999999999988 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -11.854098280789728 |                 State: (-18.54745101928711, 2.625891923904419, 179.3571319580078) | Terminated: False |                Episode Length: 7.70999999999988 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -11.86241695970778 |                 State: (-18.457073211669922, 2.625786304473877, 179.39999389648438) | Terminated: False |                Episode Length: 7.71999999999988 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -11.8706960111045 |                 State: (-18.36673927307129, 2.625675678253174, 179.3571319580078) | Terminated: False |                Episode Length: 7.72999999999988 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -11.878935423155381 |                 State: (-18.276458740234375, 2.6255598068237305, 179.39999389648438) | Terminated: False |                Episode Length: 7.739999999999879 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -11.887135183377435 |                 State: (-18.18622398376465, 2.6254384517669678, 179.3571319580078) | Terminated: False |                Episode Length: 7.749999999999879 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -11.8952952809533 |                 State: (-18.09604263305664, 2.625312089920044, 179.39999389648438) | Terminated: False |                Episode Length: 7.759999999999879 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -11.903415704405395 |                 State: (-18.005908966064453, 2.625180244445801, 179.3571319580078) | Terminated: False |                Episode Length: 7.769999999999879 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -11.911496443921969 |                 State: (-17.91582679748535, 2.6250433921813965, 179.39999389648438) | Terminated: False |                Episode Length: 7.779999999999879 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -11.9195374890293 |                 State: (-17.825794219970703, 2.624901056289673, 179.3571319580078) | Terminated: False |                Episode Length: 7.789999999999878 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -11.927538830919636 |                 State: (-17.73581314086914, 2.624753713607788, 179.39999389648438) | Terminated: False |                Episode Length: 7.799999999999878 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -11.935500460121478 |                 State: (-17.64588165283203, 2.624600887298584, 179.3571319580078) | Terminated: False |                Episode Length: 7.809999999999878 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -11.943422368829358 |                 State: (-17.556001663208008, 2.6244430541992188, 179.39999389648438) | Terminated: False |                Episode Length: 7.819999999999878 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -11.951304548572288 |                 State: (-17.466175079345703, 2.6242799758911133, 179.3571319580078) | Terminated: False |                Episode Length: 7.8299999999998775 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -11.959146992545282 |                 State: (-17.37639808654785, 2.6241116523742676, 179.39999389648438) | Terminated: False |                Episode Length: 7.839999999999877 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -11.966949693276048 |                 State: (-17.286672592163086, 2.6239380836486816, 179.3571319580078) | Terminated: False |                Episode Length: 7.849999999999877 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -11.9747126449582 |                 State: (-17.197002410888672, 2.6237592697143555, 179.39999389648438) | Terminated: False |                Episode Length: 7.859999999999877 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -11.982435841116247 |                 State: (-17.10738182067871, 2.623575448989868, 179.3571319580078) | Terminated: False |                Episode Length: 7.869999999999877 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -11.990119276940433 |                 State: (-17.0178165435791, 2.6233863830566406, 179.39999389648438) | Terminated: False |                Episode Length: 7.879999999999876 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -11.997762946950079 |                 State: (-16.928302764892578, 2.623192071914673, 179.3571319580078) | Terminated: False |                Episode Length: 7.889999999999876 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -12.00536684733 |                 State: (-16.838844299316406, 2.622992515563965, 179.39999389648438) | Terminated: False |                Episode Length: 7.899999999999876 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.012930973592264 |                 State: (-16.749439239501953, 2.6227879524230957, 179.3571319580078) | Terminated: False |                Episode Length: 7.909999999999876 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -12.020455322914108 |                 State: (-16.66008949279785, 2.6225781440734863, 179.39999389648438) | Terminated: False |                Episode Length: 7.919999999999876 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.027939891798189 |                 State: (-16.570791244506836, 2.6223630905151367, 179.3571319580078) | Terminated: False |                Episode Length: 7.929999999999875 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -12.03538467841194 |                 State: (-16.481548309326172, 2.622142791748047, 179.39999389648438) | Terminated: False |                Episode Length: 7.939999999999875 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.042789680246367 |                 State: (-16.39236068725586, 2.621917486190796, 179.3571319580078) | Terminated: False |                Episode Length: 7.949999999999875 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -12.050154896456778 |                 State: (-16.3032283782959, 2.621687173843384, 179.39999389648438) | Terminated: False |                Episode Length: 7.959999999999875 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.057480325520201 |                 State: (-16.21415138244629, 2.6214516162872314, 179.3571319580078) | Terminated: False |                Episode Length: 7.9699999999998745 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -12.064765967577427 |                 State: (-16.12512969970703, 2.621210813522339, 179.39999389648438) | Terminated: False |                Episode Length: 7.979999999999874 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.072011822089097 |                 State: (-16.036163330078125, 2.620965003967285, 179.3571319580078) | Terminated: False |                Episode Length: 7.989999999999874 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -12.079217890178997 |                 State: (-15.947254180908203, 2.6207141876220703, 179.39999389648438) | Terminated: False |                Episode Length: 7.999999999999874 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.086384172288884 |                 State: (-15.858400344848633, 2.620457887649536, 179.3571319580078) | Terminated: False |                Episode Length: 8.009999999999874 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -12.093510670522978 |                 State: (-15.769606590270996, 2.62019681930542, 179.39999389648438) | Terminated: False |                Episode Length: 8.019999999999873 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.10059738630158 |                 State: (-15.680865287780762, 2.6199305057525635, 179.3571319580078) | Terminated: False |                Episode Length: 8.029999999999873 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -12.107644322706689 |                 State: (-15.592185974121094, 2.619659185409546, 179.39999389648438) | Terminated: False |                Episode Length: 8.039999999999873 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.114651482134493 |                 State: (-15.503560066223145, 2.619382619857788, 179.3571319580078) | Terminated: False |                Episode Length: 8.049999999999873 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -12.121618868642042 |                 State: (-15.414995193481445, 2.619101047515869, 179.39999389648438) | Terminated: False |                Episode Length: 8.059999999999873 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.128546485598669 |                 State: (-15.326485633850098, 2.618814468383789, 179.3571319580078) | Terminated: False |                Episode Length: 8.069999999999872 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -12.135434338033665 |                 State: (-15.238037109375, 2.6185226440429688, 179.39999389648438) | Terminated: False |                Episode Length: 8.079999999999872 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.14228243028669 |                 State: (-15.149645805358887, 2.6182258129119873, 179.3571319580078) | Terminated: False |                Episode Length: 8.089999999999872 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -12.149090768356379 |                 State: (-15.061314582824707, 2.6179239749908447, 179.39999389648438) | Terminated: False |                Episode Length: 8.099999999999872 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.15585935754982 |                 State: (-14.973040580749512, 2.617617130279541, 179.3571319580078) | Terminated: False |                Episode Length: 8.109999999999872 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -12.162588204832026 |                 State: (-14.884827613830566, 2.617305040359497, 179.39999389648438) | Terminated: False |                Episode Length: 8.119999999999871 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.16927731647453 |                 State: (-14.796673774719238, 2.616988182067871, 179.3571319580078) | Terminated: False |                Episode Length: 8.129999999999871 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -12.175926700405668 |                 State: (-14.70858097076416, 2.616666078567505, 179.39999389648438) | Terminated: False |                Episode Length: 8.139999999999871 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.182536363858361 |                 State: (-14.620546340942383, 2.6163389682769775, 179.3571319580078) | Terminated: False |                Episode Length: 8.14999999999987 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -12.189106315721142 |                 State: (-14.532575607299805, 2.616006851196289, 179.39999389648438) | Terminated: False |                Episode Length: 8.15999999999987 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.19563656418518 |                 State: (-14.444662094116211, 2.6156697273254395, 179.3571319580078) | Terminated: False |                Episode Length: 8.16999999999987 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -12.202127119096001 |                 State: (-14.356812477111816, 2.6153275966644287, 179.39999389648438) | Terminated: False |                Episode Length: 8.17999999999987 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.208577989599808 |                 State: (-14.269022941589355, 2.614980459213257, 179.3571319580078) | Terminated: False |                Episode Length: 8.18999999999987 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -12.214989186495831 |                 State: (-14.181295394897461, 2.614628314971924, 179.39999389648438) | Terminated: False |                Episode Length: 8.19999999999987 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.221360719882021 |                 State: (-14.093628883361816, 2.6142711639404297, 179.3571319580078) | Terminated: False |                Episode Length: 8.20999999999987 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -12.227692601507952 |                 State: (-14.006027221679688, 2.6139090061187744, 179.39999389648438) | Terminated: False |                Episode Length: 8.21999999999987 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.233984842419952 |                 State: (-13.918485641479492, 2.613542079925537, 179.3571319580078) | Terminated: False |                Episode Length: 8.229999999999869 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -12.240237455314507 |                 State: (-13.831007957458496, 2.6131699085235596, 179.39999389648438) | Terminated: False |                Episode Length: 8.239999999999869 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.246450452182883 |                 State: (-13.743592262268066, 2.61279296875, 179.3571319580078) | Terminated: False |                Episode Length: 8.249999999999869 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -12.252623846664962 |                 State: (-13.656241416931152, 2.6124107837677, 179.39999389648438) | Terminated: False |                Episode Length: 8.259999999999868 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.258757651693431 |                 State: (-13.568952560424805, 2.6120238304138184, 179.3571319580078) | Terminated: False |                Episode Length: 8.269999999999868 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -12.264851881847987 |                 State: (-13.481727600097656, 2.6116318702697754, 179.39999389648438) | Terminated: False |                Episode Length: 8.279999999999868 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.270906550999147 |                 State: (-13.394567489624023, 2.6112351417541504, 179.3571319580078) | Terminated: False |                Episode Length: 8.289999999999868 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -12.276921674662765 |                 State: (-13.30747127532959, 2.6108334064483643, 179.39999389648438) | Terminated: False |                Episode Length: 8.299999999999867 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.282897267643524 |                 State: (-13.220438957214355, 2.610426664352417, 179.3571319580078) | Terminated: False |                Episode Length: 8.309999999999867 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -12.288833346389707 |                 State: (-13.13347339630127, 2.6100149154663086, 179.39999389648438) | Terminated: False |                Episode Length: 8.319999999999867 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.294729926636425 |                 State: (-13.046571731567383, 2.609598398208618, 179.3571319580078) | Terminated: False |                Episode Length: 8.329999999999867 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -12.300587025760588 |                 State: (-12.959735870361328, 2.6091768741607666, 179.39999389648438) | Terminated: False |                Episode Length: 8.339999999999867 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.306404660423933 |                 State: (-12.872964859008789, 2.608750581741333, 179.3571319580078) | Terminated: False |                Episode Length: 8.349999999999866 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -12.312182848928119 |                 State: (-12.786261558532715, 2.6083192825317383, 179.39999389648438) | Terminated: False |                Episode Length: 8.359999999999866 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.31792160885763 |                 State: (-12.699623107910156, 2.6078829765319824, 179.3571319580078) | Terminated: False |                Episode Length: 8.369999999999866 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -12.323620959434935 |                 State: (-12.613051414489746, 2.6074421405792236, 179.39999389648438) | Terminated: False |                Episode Length: 8.379999999999866 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.329280919163319 |                 State: (-12.526546478271484, 2.6069960594177246, 179.3571319580078) | Terminated: False |                Episode Length: 8.389999999999866 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -12.334901508182048 |                 State: (-12.440109252929688, 2.6065454483032227, 179.39999389648438) | Terminated: False |                Episode Length: 8.399999999999865 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.340482745909187 |                 State: (-12.353738784790039, 2.6060895919799805, 179.3571319580078) | Terminated: False |                Episode Length: 8.409999999999865 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -12.34602465339672 |                 State: (-12.267436981201172, 2.6056292057037354, 179.39999389648438) | Terminated: False |                Episode Length: 8.419999999999865 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.35152725097341 |                 State: (-12.181200981140137, 2.605163812637329, 179.3571319580078) | Terminated: False |                Episode Length: 8.429999999999865 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -12.356990560599808 |                 State: (-12.0950345993042, 2.604693651199341, 179.39999389648438) | Terminated: False |                Episode Length: 8.439999999999864 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.362414603511223 |                 State: (-12.00893497467041, 2.6042187213897705, 179.3571319580078) | Terminated: False |                Episode Length: 8.449999999999864 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -12.367799402572558 |                 State: (-11.922906875610352, 2.603738784790039, 179.39999389648438) | Terminated: False |                Episode Length: 8.459999999999864 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.37314497992145 |                 State: (-11.836945533752441, 2.6032540798187256, 179.3571319580078) | Terminated: False |                Episode Length: 8.469999999999864 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -12.378451359322872 |                 State: (-11.751053810119629, 2.60276460647583, 179.39999389648438) | Terminated: False |                Episode Length: 8.479999999999864 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.383718563812506 |                 State: (-11.665230751037598, 2.6022703647613525, 179.3571319580078) | Terminated: False |                Episode Length: 8.489999999999863 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -12.388946618051046 |                 State: (-11.57947826385498, 2.601771116256714, 179.39999389648438) | Terminated: False |                Episode Length: 8.499999999999863 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.394135545967865 |                 State: (-11.493795394897461, 2.6012673377990723, 179.3571319580078) | Terminated: False |                Episode Length: 8.509999999999863 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -12.399285373114973 |                 State: (-11.408183097839355, 2.6007585525512695, 179.39999389648438) | Terminated: False |                Episode Length: 8.519999999999863 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.404396124311024 |                 State: (-11.322641372680664, 2.600245237350464, 179.3571319580078) | Terminated: False |                Episode Length: 8.529999999999863 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -12.409467825994861 |                 State: (-11.237171173095703, 2.599726915359497, 179.39999389648438) | Terminated: False |                Episode Length: 8.539999999999862 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.414500503869943 |                 State: (-11.151769638061523, 2.5992040634155273, 179.3571319580078) | Terminated: False |                Episode Length: 8.549999999999862 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -12.419494185257415 |                 State: (-11.066441535949707, 2.5986762046813965, 179.39999389648438) | Terminated: False |                Episode Length: 8.559999999999862 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.424448896740998 |                 State: (-10.981184005737305, 2.5981438159942627, 179.3571319580078) | Terminated: False |                Episode Length: 8.569999999999862 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -12.429364666519536 |                 State: (-10.895999908447266, 2.597606658935547, 179.39999389648438) | Terminated: False |                Episode Length: 8.579999999999862 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.434241522052416 |                 State: (-10.810885429382324, 2.59706449508667, 179.3571319580078) | Terminated: False |                Episode Length: 8.589999999999861 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -12.43907949241152 |                 State: (-10.725845336914062, 2.59651780128479, 179.39999389648438) | Terminated: False |                Episode Length: 8.599999999999861 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.443878605927237 |                 State: (-10.640875816345215, 2.5959665775299072, 179.3571319580078) | Terminated: False |                Episode Length: 8.60999999999986 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -12.448638892539767 |                 State: (-10.555980682373047, 2.5954103469848633, 179.39999389648438) | Terminated: False |                Episode Length: 8.61999999999986 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.453360381445783 |                 State: (-10.47115707397461, 2.5948495864868164, 179.3571319580078) | Terminated: False |                Episode Length: 8.62999999999986 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -12.458043103449022 |                 State: (-10.386409759521484, 2.5942840576171875, 179.39999389648438) | Terminated: False |                Episode Length: 8.63999999999986 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.462687088607659 |                 State: (-10.30173397064209, 2.5937137603759766, 179.3571319580078) | Terminated: False |                Episode Length: 8.64999999999986 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -12.467292368584129 |                 State: (-10.217132568359375, 2.5931389331817627, 179.39999389648438) | Terminated: False |                Episode Length: 8.65999999999986 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.471858974293273 |                 State: (-10.132604598999023, 2.592559337615967, 179.3571319580078) | Terminated: False |                Episode Length: 8.66999999999986 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -12.47638693825133 |                 State: (-10.048152923583984, 2.591974973678589, 179.39999389648438) | Terminated: False |                Episode Length: 8.67999999999986 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.48087629222491 |                 State: (-9.963774681091309, 2.591386079788208, 179.3571319580078) | Terminated: False |                Episode Length: 8.68999999999986 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -12.485327069579101 |                 State: (-9.879471778869629, 2.590792655944824, 179.39999389648438) | Terminated: False |                Episode Length: 8.699999999999859 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.489739302927331 |                 State: (-9.795244216918945, 2.5901944637298584, 179.3571319580078) | Terminated: False |                Episode Length: 8.709999999999859 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -12.494113026478535 |                 State: (-9.711091995239258, 2.5895915031433105, 179.39999389648438) | Terminated: False |                Episode Length: 8.719999999999859 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.498448273687947 |                 State: (-9.62701416015625, 2.5889840126037598, 179.3571319580078) | Terminated: False |                Episode Length: 8.729999999999858 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -12.502745079603283 |                 State: (-9.543015480041504, 2.588371992111206, 179.39999389648438) | Terminated: False |                Episode Length: 8.739999999999858 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.507003478516527 |                 State: (-9.459090232849121, 2.5877552032470703, 179.3571319580078) | Terminated: False |                Episode Length: 8.749999999999858 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.511223506309058 |                 State: (-9.375243186950684, 2.5871338844299316, 179.31427001953125) | Terminated: False |                Episode Length: 8.759999999999858 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.515405199317444 |                 State: (-9.291474342346191, 2.58650803565979, 179.27142333984375) | Terminated: False |                Episode Length: 8.769999999999857 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.51954859433209 |                 State: (-9.207784652709961, 2.5858776569366455, 179.2285614013672) | Terminated: False |                Episode Length: 8.779999999999857 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.523653728595878 |                 State: (-9.124173164367676, 2.585242509841919, 179.18569946289062) | Terminated: False |                Episode Length: 8.789999999999857 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.527720639802807 |                 State: (-9.040640830993652, 2.5846028327941895, 179.14285278320312) | Terminated: False |                Episode Length: 8.799999999999857 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.531749366096609 |                 State: (-8.957188606262207, 2.583958625793457, 179.09999084472656) | Terminated: False |                Episode Length: 8.809999999999857 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.535739946069372 |                 State: (-8.87381649017334, 2.5833096504211426, 179.05712890625) | Terminated: False |                Episode Length: 8.819999999999856 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.539692418760142 |                 State: (-8.79052448272705, 2.5826563835144043, 179.0142822265625) | Terminated: False |                Episode Length: 8.829999999999856 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.543606823653526 |                 State: (-8.707313537597656, 2.581998348236084, 178.97142028808594) | Terminated: False |                Episode Length: 8.839999999999856 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.547483200678279 |                 State: (-8.62418270111084, 2.58133602142334, 178.92855834960938) | Terminated: False |                Episode Length: 8.849999999999856 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.551321590205887 |                 State: (-8.541133880615234, 2.5806689262390137, 178.88571166992188) | Terminated: False |                Episode Length: 8.859999999999856 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.555122033049143 |                 State: (-8.458166122436523, 2.5799975395202637, 178.8428497314453) | Terminated: False |                Episode Length: 8.869999999999855 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.558884570460704 |                 State: (-8.375280380249023, 2.5793216228485107, 178.79998779296875) | Terminated: False |                Episode Length: 8.879999999999855 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.562609244131659 |                 State: (-8.292478561401367, 2.578640937805176, 178.7571258544922) | Terminated: False |                Episode Length: 8.889999999999855 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.566296096190069 |                 State: (-8.209757804870605, 2.577955961227417, 178.7142791748047) | Terminated: False |                Episode Length: 8.899999999999855 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.569945169199512 |                 State: (-8.127120971679688, 2.5772664546966553, 178.67141723632812) | Terminated: False |                Episode Length: 8.909999999999854 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.573556506157615 |                 State: (-8.044568061828613, 2.5765726566314697, 178.62855529785156) | Terminated: False |                Episode Length: 8.919999999999854 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.577130150494579 |                 State: (-7.962098121643066, 2.575874090194702, 178.58570861816406) | Terminated: False |                Episode Length: 8.929999999999854 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.580666146071692 |                 State: (-7.879712104797363, 2.5751712322235107, 178.5428466796875) | Terminated: False |                Episode Length: 8.939999999999854 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.584164537179847 |                 State: (-7.797411918640137, 2.5744638442993164, 178.49998474121094) | Terminated: False |                Episode Length: 8.949999999999854 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.587625368538035 |                 State: (-7.715195178985596, 2.573751926422119, 178.45713806152344) | Terminated: False |                Episode Length: 8.959999999999853 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.591048685291842 |                 State: (-7.633063793182373, 2.573035717010498, 178.41427612304688) | Terminated: False |                Episode Length: 8.969999999999853 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.594434533011936 |                 State: (-7.551018714904785, 2.572314977645874, 178.3714141845703) | Terminated: False |                Episode Length: 8.979999999999853 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.597782957692546 |                 State: (-7.469058990478516, 2.571589946746826, 178.3285675048828) | Terminated: False |                Episode Length: 8.989999999999853 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.601094005749932 |                 State: (-7.387185573577881, 2.5708603858947754, 178.28570556640625) | Terminated: False |                Episode Length: 8.999999999999853 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.604367724020847 |                 State: (-7.305398464202881, 2.5701262950897217, 178.2428436279297) | Terminated: False |                Episode Length: 9.009999999999852 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.607604159761 |                 State: (-7.22369909286499, 2.5693881511688232, 178.1999969482422) | Terminated: False |                Episode Length: 9.019999999999852 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.610803360643498 |                 State: (-7.142086029052734, 2.5686452388763428, 178.15713500976562) | Terminated: False |                Episode Length: 9.029999999999852 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.613965374757298 |                 State: (-7.060560703277588, 2.5678982734680176, 178.11427307128906) | Terminated: False |                Episode Length: 9.039999999999852 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.617090250605631 |                 State: (-6.979123592376709, 2.5671467781066895, 178.07142639160156) | Terminated: False |                Episode Length: 9.049999999999851 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.62017803710444 |                 State: (-6.897774696350098, 2.5663907527923584, 178.02854919433594) | Terminated: False |                Episode Length: 9.059999999999851 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.623228783580794 |                 State: (-6.816514492034912, 2.5656306743621826, 177.98570251464844) | Terminated: False |                Episode Length: 9.069999999999851 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.626242539771312 |                 State: (-6.735342979431152, 2.564866065979004, 177.94285583496094) | Terminated: False |                Episode Length: 9.07999999999985 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.629219355820558 |                 State: (-6.654261112213135, 2.5640971660614014, 177.8999786376953) | Terminated: False |                Episode Length: 9.08999999999985 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.632159282279455 |                 State: (-6.573268890380859, 2.563323974609375, 177.8571319580078) | Terminated: False |                Episode Length: 9.09999999999985 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.635062370103672 |                 State: (-6.492366313934326, 2.562546491622925, 177.8142852783203) | Terminated: False |                Episode Length: 9.10999999999985 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.637928670652013 |                 State: (-6.411554336547852, 2.5617644786834717, 177.7714080810547) | Terminated: False |                Episode Length: 9.11999999999985 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.640758235684801 |                 State: (-6.3308329582214355, 2.560978412628174, 177.7285614013672) | Terminated: False |                Episode Length: 9.12999999999985 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.643551117362255 |                 State: (-6.250202655792236, 2.560187816619873, 177.6857147216797) | Terminated: False |                Episode Length: 9.13999999999985 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.646307368242852 |                 State: (-6.169663429260254, 2.5593931674957275, 177.64283752441406) | Terminated: False |                Episode Length: 9.14999999999985 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.649027041281693 |                 State: (-6.089216232299805, 2.558593988418579, 177.59999084472656) | Terminated: False |                Episode Length: 9.15999999999985 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.651710189828865 |                 State: (-6.008861064910889, 2.557790756225586, 177.55714416503906) | Terminated: False |                Episode Length: 9.169999999999849 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.654356867627781 |                 State: (-5.928597927093506, 2.556983232498169, 177.51426696777344) | Terminated: False |                Episode Length: 9.179999999999849 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.656967128813536 |                 State: (-5.848427772521973, 2.556171417236328, 177.47142028808594) | Terminated: False |                Episode Length: 9.189999999999849 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.659541027911233 |                 State: (-5.768350601196289, 2.5553553104400635, 177.42855834960938) | Terminated: False |                Episode Length: 9.199999999999848 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.662078619834327 |                 State: (-5.688366889953613, 2.554534912109375, 177.3856964111328) | Terminated: False |                Episode Length: 9.209999999999848 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.664579959882946 |                 State: (-5.6084771156311035, 2.553710460662842, 177.3428497314453) | Terminated: False |                Episode Length: 9.219999999999848 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.667045103742211 |                 State: (-5.528680801391602, 2.5528817176818848, 177.29998779296875) | Terminated: False |                Episode Length: 9.229999999999848 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.669474107480557 |                 State: (-5.448979377746582, 2.552048683166504, 177.2571258544922) | Terminated: False |                Episode Length: 9.239999999999847 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.671867027548036 |                 State: (-5.369372844696045, 2.5512115955352783, 177.2142791748047) | Terminated: False |                Episode Length: 9.249999999999847 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.674223920774626 |                 State: (-5.289860725402832, 2.550370216369629, 177.17141723632812) | Terminated: False |                Episode Length: 9.259999999999847 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.67654484436853 |                 State: (-5.210444450378418, 2.5495245456695557, 177.12855529785156) | Terminated: False |                Episode Length: 9.269999999999847 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.67882985591447 |                 State: (-5.131124496459961, 2.548675060272217, 177.08570861816406) | Terminated: False |                Episode Length: 9.279999999999847 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.68107901337197 |                 State: (-5.051899433135986, 2.547821044921875, 177.0428466796875) | Terminated: False |                Episode Length: 9.289999999999846 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.683292375073647 |                 State: (-4.972771644592285, 2.5469629764556885, 176.99998474121094) | Terminated: False |                Episode Length: 9.299999999999846 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.685469999723479 |                 State: (-4.893740177154541, 2.5461008548736572, 176.95713806152344) | Terminated: False |                Episode Length: 9.309999999999846 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.68761194639509 |                 State: (-4.8148064613342285, 2.545234441757202, 176.91427612304688) | Terminated: False |                Episode Length: 9.319999999999846 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.689718274530014 |                 State: (-4.735969543457031, 2.5443639755249023, 176.8714141845703) | Terminated: False |                Episode Length: 9.329999999999846 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.69178904393595 |                 State: (-4.657230377197266, 2.543489456176758, 176.8285675048828) | Terminated: False |                Episode Length: 9.339999999999845 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.693824314785031 |                 State: (-4.578589916229248, 2.5426108837127686, 176.78570556640625) | Terminated: False |                Episode Length: 9.349999999999845 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.695824147612074 |                 State: (-4.500047206878662, 2.5417280197143555, 176.7428436279297) | Terminated: False |                Episode Length: 9.359999999999845 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.697788603312826 |                 State: (-4.421603202819824, 2.5408411026000977, 176.6999969482422) | Terminated: False |                Episode Length: 9.369999999999845 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.699717743142214 |                 State: (-4.343258857727051, 2.539950132369995, 176.65713500976562) | Terminated: False |                Episode Length: 9.379999999999844 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.701611628712579 |                 State: (-4.265014171600342, 2.539055109024048, 176.61427307128906) | Terminated: False |                Episode Length: 9.389999999999844 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.703470321991913 |                 State: (-4.186868667602539, 2.538156032562256, 176.5714111328125) | Terminated: False |                Episode Length: 9.399999999999844 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.705293885302096 |                 State: (-4.108823299407959, 2.537252902984619, 176.528564453125) | Terminated: False |                Episode Length: 9.409999999999844 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.707082381317115 |                 State: (-4.03087854385376, 2.5363457202911377, 176.48570251464844) | Terminated: False |                Episode Length: 9.419999999999844 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.708835873061288 |                 State: (-3.9530344009399414, 2.5354344844818115, 176.44284057617188) | Terminated: False |                Episode Length: 9.429999999999843 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.710554423907489 |                 State: (-3.875291585922241, 2.5345191955566406, 176.39999389648438) | Terminated: False |                Episode Length: 9.439999999999843 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.712238097575352 |                 State: (-3.79764986038208, 2.533599853515625, 176.3571319580078) | Terminated: False |                Episode Length: 9.449999999999843 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.713886958129489 |                 State: (-3.7201101779937744, 2.5326764583587646, 176.31427001953125) | Terminated: False |                Episode Length: 9.459999999999843 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.715501069977694 |                 State: (-3.642672538757324, 2.5317492485046387, 176.27142333984375) | Terminated: False |                Episode Length: 9.469999999999843 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.717080497869148 |                 State: (-3.5653374195098877, 2.530817985534668, 176.2285614013672) | Terminated: False |                Episode Length: 9.479999999999842 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.71862530689261 |                 State: (-3.488104820251465, 2.5298826694488525, 176.18569946289062) | Terminated: False |                Episode Length: 9.489999999999842 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.720135562474622 |                 State: (-3.410975694656372, 2.5289435386657715, 176.14285278320312) | Terminated: False |                Episode Length: 9.499999999999842 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.721611330377696 |                 State: (-3.333949327468872, 2.5280001163482666, 176.09999084472656) | Terminated: False |                Episode Length: 9.509999999999842 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.7230526766985 |                 State: (-3.2570271492004395, 2.527053117752075, 176.05712890625) | Terminated: False |                Episode Length: 9.519999999999841 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.724459667866048 |                 State: (-3.180209159851074, 2.52610182762146, 176.0142822265625) | Terminated: False |                Episode Length: 9.529999999999841 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.725832370639873 |                 State: (-3.1034953594207764, 2.525146961212158, 175.97142028808594) | Terminated: False |                Episode Length: 9.539999999999841 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -12.727170852108213 |                 State: (-3.026886224746704, 2.5241878032684326, 176.0142822265625) | Terminated: False |                Episode Length: 9.54999999999984 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -12.728475172370823 |                 State: (-2.9503657817840576, 2.5232250690460205, 176.05712890625) | Terminated: False |                Episode Length: 9.55999999999984 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -12.729745391865027 |                 State: (-2.873933792114258, 2.5222582817077637, 176.09999084472656) | Terminated: False |                Episode Length: 9.56999999999984 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -12.73098157136412 |                 State: (-2.797591209411621, 2.521287441253662, 176.14285278320312) | Terminated: False |                Episode Length: 9.57999999999984 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -12.732183771975777 |                 State: (-2.7213377952575684, 2.520313024520874, 176.18569946289062) | Terminated: False |                Episode Length: 9.58999999999984 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -12.733352055140445 |                 State: (-2.645174503326416, 2.519334554672241, 176.2285614013672) | Terminated: False |                Episode Length: 9.59999999999984 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -12.734486482629746 |                 State: (-2.569101095199585, 2.5183520317077637, 176.27142333984375) | Terminated: False |                Episode Length: 9.60999999999984 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -12.735587116544865 |                 State: (-2.4931180477142334, 2.5173659324645996, 176.31427001953125) | Terminated: False |                Episode Length: 9.61999999999984 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -12.736654019314935 |                 State: (-2.4172263145446777, 2.516375780105591, 176.3571319580078) | Terminated: False |                Episode Length: 9.62999999999984 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -12.737687253695423 |                 State: (-2.3414251804351807, 2.5153818130493164, 176.39999389648438) | Terminated: False |                Episode Length: 9.639999999999839 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -12.738686882766507 |                 State: (-2.2657158374786377, 2.5143840312957764, 176.44284057617188) | Terminated: False |                Episode Length: 9.649999999999839 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -12.739652969931447 |                 State: (-2.190098285675049, 2.5133824348449707, 176.48570251464844) | Terminated: False |                Episode Length: 9.659999999999838 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -12.74058557891496 |                 State: (-2.114572763442993, 2.5123770236968994, 176.528564453125) | Terminated: False |                Episode Length: 9.669999999999838 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -12.741484773761586 |                 State: (-2.039139747619629, 2.5113677978515625, 176.5714111328125) | Terminated: False |                Episode Length: 9.679999999999838 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -12.742350618834047 |                 State: (-1.9637998342514038, 2.51035475730896, 176.61427307128906) | Terminated: False |                Episode Length: 9.689999999999838 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -12.743183178811613 |                 State: (-1.8885530233383179, 2.509338140487671, 176.65713500976562) | Terminated: False |                Episode Length: 9.699999999999838 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -12.74398251868845 |                 State: (-1.8133997917175293, 2.508317470550537, 176.6999969482422) | Terminated: False |                Episode Length: 9.709999999999837 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -12.744748703771974 |                 State: (-1.7383402585983276, 2.5072929859161377, 176.7428436279297) | Terminated: False |                Episode Length: 9.719999999999837 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -12.745481799681203 |                 State: (-1.6633751392364502, 2.5062649250030518, 176.78570556640625) | Terminated: False |                Episode Length: 9.729999999999837 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -12.746181872345097 |                 State: (-1.5885043144226074, 2.5052330493927, 176.8285675048828) | Terminated: False |                Episode Length: 9.739999999999837 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -12.746848988000902 |                 State: (-1.5137284994125366, 2.504197359085083, 176.8714141845703) | Terminated: False |                Episode Length: 9.749999999999837 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -12.747483213192485 |                 State: (-1.439047932624817, 2.5031578540802, 176.91427612304688) | Terminated: False |                Episode Length: 9.759999999999836 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -12.74808461476867 |                 State: (-1.3644628524780273, 2.502114772796631, 176.95713806152344) | Terminated: False |                Episode Length: 9.769999999999836 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -12.74865325988157 |                 State: (-1.2899737358093262, 2.501067876815796, 176.99998474121094) | Terminated: False |                Episode Length: 9.779999999999836 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -12.749189215984915 |                 State: (-1.2155808210372925, 2.5000171661376953, 177.0428466796875) | Terminated: False |                Episode Length: 9.789999999999836 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -12.749692550832378 |                 State: (-1.1412845849990845, 2.498962879180908, 177.08570861816406) | Terminated: False |                Episode Length: 9.799999999999836 | C_L: -0.5\n",
            "Action: [-0.5    0.075] | Reward: -12.750163332475895 |                 State: (-1.0670851469039917, 2.4979047775268555, 177.12855529785156) | Terminated: False |                Episode Length: 9.809999999999835 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.750601629263981 |                 State: (-0.9929828643798828, 2.496843099594116, 177.08570861816406) | Terminated: False |                Episode Length: 9.819999999999835 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.751007514949789 |                 State: (-0.9189900755882263, 2.4957778453826904, 177.0428466796875) | Terminated: False |                Episode Length: 9.829999999999835 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.751381063569049 |                 State: (-0.8451067805290222, 2.494708776473999, 176.99998474121094) | Terminated: False |                Episode Length: 9.839999999999835 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.751722349438223 |                 State: (-0.7713335156440735, 2.493635892868042, 176.95713806152344) | Terminated: False |                Episode Length: 9.849999999999834 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.752031447152662 |                 State: (-0.6976704597473145, 2.4925596714019775, 176.91427612304688) | Terminated: False |                Episode Length: 9.859999999999834 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.752308431584758 |                 State: (-0.6241180896759033, 2.4914796352386475, 176.8714141845703) | Terminated: False |                Episode Length: 9.869999999999834 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.752553377882093 |                 State: (-0.5506766438484192, 2.490396022796631, 176.8285675048828) | Terminated: False |                Episode Length: 9.879999999999834 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.752766361465584 |                 State: (-0.4773464798927307, 2.4893085956573486, 176.78570556640625) | Terminated: False |                Episode Length: 9.889999999999834 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.752947458027638 |                 State: (-0.404127836227417, 2.488217830657959, 176.7428436279297) | Terminated: False |                Episode Length: 9.899999999999833 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.753096743530294 |                 State: (-0.33102115988731384, 2.4871232509613037, 176.6999969482422) | Terminated: False |                Episode Length: 9.909999999999833 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.753214294203369 |                 State: (-0.25802668929100037, 2.486025094985962, 176.65713500976562) | Terminated: False |                Episode Length: 9.919999999999833 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.753300186542603 |                 State: (-0.18514475226402283, 2.4849236011505127, 176.61427307128906) | Terminated: False |                Episode Length: 9.929999999999833 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.753354497307798 |                 State: (-0.11237572133541107, 2.483818292617798, 176.5714111328125) | Terminated: False |                Episode Length: 9.939999999999833 | C_L: -0.5\n",
            "Action: [-0.5   -0.075] | Reward: -12.753377303520967 |                 State: (-0.039719875901937485, 2.4827094078063965, 176.528564453125) | Terminated: True |                Episode Length: 9.949999999999832 | C_L: -0.5\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x500 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from utils.utils import get_optimal_action\n",
        "\n",
        "\n",
        "\n",
        "# generate a list of random initial states allowing for a wide range of values\n",
        "np.random.seed(0)\n",
        "initial_states = np.random.rand(5, 3)\n",
        "initial_states[:, 0] = initial_states[:, 0] * np.deg2rad(90) - np.deg2rad(90)  # Flight path angle\n",
        "initial_states[:, 1] = initial_states[:, 1] * 3.3 + 0.7  # Airspeed\n",
        "initial_states[:, 2] = initial_states[:, 2] * np.deg2rad(230) - np.deg2rad(30)  # Bank angle\n",
        "\n",
        "initial_states = [np.array([np.deg2rad(-80.),  1.2, np.deg2rad(150)])]  # Example state\n",
        "\n",
        "#initial_states  = [np.array([np.deg2rad(-80.),  1.2, np.deg2rad(150)])]  # Example state\n",
        "fig, ax1 = plt.subplots(figsize=(10, 5))  # Main figure\n",
        "\n",
        "ax2 = ax1.twinx()  # Create secondary y-axis\n",
        "\n",
        "# Loop through each initial state\n",
        "for initial_state in initial_states:\n",
        "    state = np.array(initial_state)  # Convert list to numpy array\n",
        "    glider.airplane.flight_path_angle = state[0]\n",
        "    glider.airplane.airspeed_norm = state[1]\n",
        "    glider.airplane.bank_angle = state[2]\n",
        "\n",
        "    # Storage for plotting\n",
        "    flight_path_angles = []\n",
        "    time_steps = []\n",
        "    cl_values = []\n",
        "    height_lost_values = []\n",
        "\n",
        "    total_height_lost = 0\n",
        "    episode_length = 0\n",
        "    terminated = False\n",
        "\n",
        "    # Run simulation\n",
        "    while episode_length < 150:\n",
        "\n",
        "        if not terminated:\n",
        "            try:\n",
        "                action = get_optimal_action(state, pi)\n",
        "                #action[0] = 1.0\n",
        "                state, reward, terminated, _, _ = glider.step(action)\n",
        "                state = state[0]\n",
        "            except:\n",
        "                terminated = True\n",
        "            \n",
        "\n",
        "        total_height_lost += reward # Update height lost\n",
        "        episode_length += 0.01\n",
        "\n",
        "        # Convert to readable format\n",
        "        flight_path_angle = float(np.rad2deg(state[0]))\n",
        "        V_norm = float(state[1])\n",
        "        bank_angle = float(np.rad2deg(state[2]))\n",
        "        C_L = float(action[0])  # Extract lift coefficient\n",
        "\n",
        "        # Store values\n",
        "        flight_path_angles.append(flight_path_angle)\n",
        "        time_steps.append(episode_length)\n",
        "        cl_values.append(C_L)\n",
        "        height_lost_values.append(float(np.rad2deg(state[2])))\n",
        "\n",
        "        print(f\"Action: {np.round(action,3)} | Reward: {total_height_lost} | \\\n",
        "                State: {flight_path_angle, V_norm, bank_angle} | Terminated: {terminated} |\\\n",
        "                Episode Length: {episode_length} | C_L: {C_L}\")\n",
        "\n",
        "        if terminated:\n",
        "            break\n",
        "\n",
        "    # Plot the flight path angle on primary axis\n",
        "    ax1.plot(time_steps, flight_path_angles,label=f\"V_norm={round(initial_state[1],2)}, Bank_angle={round(np.rad2deg(initial_state[2]),1)}°\") \n",
        "    # Plot height lost on secondary axis\n",
        "    ax2.plot(time_steps, height_lost_values, linestyle=\"dashed\", alpha=0.7)\n",
        "\n",
        "    # Select 5 evenly spaced indices for C_L annotations\n",
        "    num_points = 5\n",
        "    if len(time_steps) > num_points:\n",
        "        indices = np.linspace(0, len(time_steps) - 1, num_points, dtype=int)\n",
        "    else:\n",
        "        indices = range(len(time_steps))  # If fewer than 5 points exist\n",
        "\n",
        "    # Plot markers and add annotations for C_L\n",
        "    for i in indices:\n",
        "        ax1.scatter(time_steps[i], flight_path_angles[i], color=\"black\", marker=\"x\")  # Mark point\n",
        "        ax1.text(time_steps[i], flight_path_angles[i], f\"{cl_values[i]:.2f}\", fontsize=7, \n",
        "                 verticalalignment='bottom', \n",
        "                 horizontalalignment='right')\n",
        "\n",
        "# Graph settings\n",
        "ax1.set_xlabel(\"Time (seconds)\")\n",
        "ax1.set_ylabel(\"Flight Path Angle (γ) [°]\", color=\"blue\")\n",
        "ax2.set_ylabel(\"Bank Angle (μ) [°])\", color=\"red\")\n",
        "ax1.set_title(\"Airplane trajectories\")\n",
        "ax1.legend()\n",
        "ax1.grid()\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "bc4b24f4",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.colors as mcolors\n",
        "from utils.utils import get_optimal_action\n",
        "\n",
        "\n",
        "vel_norm = 1.2  # Airspeed (V) in normalized units\n",
        "# Example discretization\n",
        "flight_path_bins = np.linspace(np.deg2rad(-90), np.deg2rad(0),    40,      dtype=np.float32) \n",
        "bank_bins        = np.linspace( np.deg2rad(-30), np.deg2rad(200), 40,      dtype=np.float32) \n",
        "\n",
        "\n",
        "# Prepare a 2D array to store the policy (CL values)\n",
        "policy_values = np.zeros((len(flight_path_bins), len(bank_bins)))\n",
        "\n",
        "# Fill in the 2D array by evaluating your policy at each (γ, μ)\n",
        "for i, mu_rad in enumerate(bank_bins):\n",
        "    for j, gamma_rad in enumerate(flight_path_bins):\n",
        "        # Convert angles to radians if your policy needs it\n",
        "        state = np.array([gamma_rad,  vel_norm, mu_rad])\n",
        "        action = get_optimal_action(state, pi)  # Replace with your actual policy call\n",
        "        cl = float(action[0])  # If the first element of `action` is the lift coefficient\n",
        "        policy_values[i, j] = cl\n",
        "        #print(f\"State: {float(np.rad2deg(state)[0]), vel_norm ,float(np.rad2deg(state)[2]) } | CL: {cl}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "e08a7e16",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x600 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Calculate edges (as before)\n",
        "gamma_centers = flight_path_bins\n",
        "gamma_step = gamma_centers[1] - gamma_centers[0]\n",
        "gamma_edges = np.linspace(gamma_centers[0] - gamma_step/2, gamma_centers[-1] + gamma_step/2, len(gamma_centers)+1)\n",
        "gamma_edges_deg = np.rad2deg(gamma_edges)\n",
        "\n",
        "mu_centers = bank_bins\n",
        "mu_step = mu_centers[1] - mu_centers[0]\n",
        "mu_edges = np.linspace(mu_centers[0] - mu_step/2, mu_centers[-1] + mu_step/2, len(mu_centers)+1)\n",
        "mu_edges_deg = np.rad2deg(mu_edges)\n",
        "\n",
        "# Plot with inverted axes (swap x and y)\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.pcolormesh(\n",
        "    mu_edges_deg,  # Now x-axis (bank angles)\n",
        "    gamma_edges_deg,  # Now y-axis (flight path angles)\n",
        "    policy_values.T,  # Transpose the array to align with swapped axes\n",
        "    cmap='gray',\n",
        "    shading='flat'\n",
        ")\n",
        "plt.xlabel('Bank Angle (degrees)')  # Updated label\n",
        "plt.ylabel('Flight Path Angle (degrees)')  # Updated label\n",
        "cbar = plt.colorbar(label='Lift Coefficient (CL)')\n",
        "plt.title('Optimal Policy: Lift Coefficient (CL)')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "81f11551",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "np.float32(-0.5)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "state = np.array([np.deg2rad(-80.),  1.2, np.deg2rad(150)])  # Example state\n",
        "get_optimal_action(state, pi)[0]  # Replace with your actual policy call"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3dd56bb",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Normalize the policy values (0 to 1) for grayscale plotting\n",
        "vmin, vmax = policy_values.min(), policy_values.max()\n",
        "norm_values = (policy_values - vmin) / (vmax - vmin + 1e-8)\n",
        "\n",
        "# Create a mesh for plotting\n",
        "X, Y = np.meshgrid(bank_angles, flight_path_angles)\n",
        "\n",
        "# Plot using pcolormesh (grayscale)\n",
        "fig, ax = plt.subplots(figsize=(6, 4))\n",
        "c = ax.pcolormesh(X, Y, norm_values, cmap='gray', shading='auto', norm=mcolors.Normalize(vmin=0, vmax=1))\n",
        "\n",
        "# Labels and title\n",
        "ax.set_xlabel(\"Bank Angle (deg)\")\n",
        "ax.set_ylabel(\"Flight Path Angle (deg)\")\n",
        "ax.set_title(\"Optimal Policy (CL)\")\n",
        "\n",
        "# Optional: colorbar\n",
        "plt.colorbar(c, ax=ax, label=\"Normalized CL\")\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8323f6d",
      "metadata": {},
      "outputs": [],
      "source": [
        "-192769.51 + -125086.89"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e954bd11",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from utils.utils import get_optimal_action\n",
        "\n",
        "# initial state\n",
        "state = np.array([np.deg2rad(-60), 1.2, np.deg2rad(30)])\n",
        "glider.airplane.flight_path_angle = state[0]\n",
        "glider.airplane.airspeed_norm     = state[1]\n",
        "glider.airplane.bank_angle        = state[2]\n",
        "\n",
        "total_height_lost = 0\n",
        "episode_length    = 0\n",
        "terminated        = False\n",
        "\n",
        "time_history = []\n",
        "height_lost_history = []\n",
        "\n",
        "while episode_length < 20:\n",
        "    action = get_optimal_action(state, pi)\n",
        "    prev_state = state.copy()\n",
        "    state, reward, terminated, _, _ = glider.step(action)\n",
        "    state = state[0] \n",
        "    total_height_lost += reward\n",
        "    episode_length += 0.01\n",
        "\n",
        "    time_history.append(episode_length)  # for plotting!\n",
        "    height_lost_history.append(total_height_lost)\n",
        "\n",
        "    #print(f\"Action: {np.round(action,3)} | Lost Height: {total_height_lost:.3f} | State: {state} | Terminated: {terminated} | Time: {episode_length:.2f}\")\n",
        "    if terminated:\n",
        "        break\n",
        "\n",
        "# Plotting the results\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(time_history, height_lost_history, label=\"Height Lost\")\n",
        "plt.xlabel(\"Time (s)\")\n",
        "plt.ylabel(\"Height Lost (m)\")\n",
        "plt.title(\"Height Lost Over Time\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5cd13daf",
      "metadata": {},
      "outputs": [],
      "source": [
        "STALL_AIRSPEED = 27.331231856346\n",
        "from utils.utils import get_optimal_action\n",
        "from tqdm import tqdm\n",
        "with open(glider.__class__.__name__ + \".pkl\", \"rb\") as f:\n",
        "    pi: PolicyIteration = pickle.load(f)\n",
        "\n",
        "prom_episode_lenght = 0\n",
        "dict_result = {}\n",
        "dict_episode_length = {}\n",
        "state_spaces = [v for v in pi.states_space if v[0] > -np.pi/2]\n",
        "for state in tqdm(state_spaces):\n",
        "    initial_state = state.copy()\n",
        "    prev_state = state.copy()\n",
        "    glider.reset()\n",
        "    glider.airplane.flight_path_angle = state[0]\n",
        "    glider.airplane.airspeed_norm = state[1]\n",
        "    glider.airplane.bank_angle = state[2]\n",
        "    done = False\n",
        "    episode_length = 0\n",
        "    total_reward = 0\n",
        "    while not done:\n",
        "        action = get_optimal_action(state, pi)\n",
        "        prev_state  = state.copy()\n",
        "        state, reward, done, _, _ = glider.step(action)\n",
        "        done  = bool(done)\n",
        "        if done:\n",
        "            break\n",
        "        state = state[0]\n",
        "        # check if our state is in the state space\n",
        "        index = pi.triangulation.find_simplex(state)\n",
        "        if not done:\n",
        "            total_reward -= reward#*STALL_AIRSPEED\n",
        "        if (index ==-1) or episode_length > 70: \n",
        "            done = True\n",
        "        episode_length += 1\n",
        "        \n",
        "    dict_result[tuple(initial_state)] = total_reward\n",
        "    dict_episode_length[tuple(initial_state)] = episode_length\n",
        "    prom_episode_lenght += episode_length / len(pi.states_space)\n",
        "    #print(f\"Initial state: {initial_state} - Total reward: {total_reward}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab055601",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "epsilon = 1*1e-1\n",
        "#dict_result = dict_episode_length\n",
        "# Your dictionary with keys as coordinates (x, y) and values as the color intensity (z)\n",
        "# Extracting the x, y and z values\n",
        "x = [np.degrees(coord[0]) for coord in dict_result.keys() if 0.05 >= coord[0] >= -np.pi/2 - epsilon and coord[1] > 0.7]\n",
        "#convert x to grad\n",
        "y = [coord[1] for coord in dict_result.keys() if 0.05 >= coord[0] >= -np.pi/2 - epsilon and coord[1] > 0.7]\n",
        "#convert y to Vs\n",
        "keys_list = list(dict_result.keys())\n",
        "values_list = list(dict_result.values())\n",
        "z = [v for e,v in zip(keys_list, values_list) if 0.05 >= e[0] >= -np.pi/2 - epsilon and e[1] > 0.7]\n",
        "\n",
        "# Creating a 2D scatter plot\n",
        "cmap = plt.get_cmap('viridis', 2048)\n",
        "plt.tricontourf(y, x, z, cmap=cmap, levels=18)   # Change 'viridis' to any other colormap you like\n",
        "plt.colorbar(label='', shrink=0.8,  )  # Add color bar for the z values\n",
        "\n",
        "# Add labels and a title\n",
        "plt.ylabel('Flight Path Angle (γ) [deg]')\n",
        "plt.xlabel('V/Vs')\n",
        "\n",
        "x_min, x_max = min(x), max(x)\n",
        "y_min, y_max = min(y), max(y)\n",
        "\n",
        "# Set the minor ticks for the grid, keeping the dense grid with smaller squares\n",
        "ax = plt.gca()  # Get current axes\n",
        "ax.set_yticks(np.linspace(x_min, x_max, 60), minor=True)  # 20 minor ticks for grid\n",
        "ax.set_xticks(np.linspace(y_min, y_max, 60), minor=True)  # 20 minor ticks for grid\n",
        "# put line x = 1\n",
        "plt.axvline(x=1, color='r', linestyle='--', linewidth=0.5)\n",
        "# put line y = 0\n",
        "#plt.axhline(y=0, color='k', linestyle='--')\n",
        "\n",
        "# Show the plot\n",
        "vals = np.round(np.linspace(-90, 0,6))\n",
        "plt.yticks(vals)  # Only 5 labels on x-axis\n",
        "plt.xticks(np.linspace(round(y_min), round(y_max), 6))  # Only 5 labels on y-axis\n",
        "# Enable the minor grid lines\n",
        "ax.grid(which='minor', color='gray', linestyle='-', linewidth=0.5)\n",
        "\n",
        "# Habilitar la cuadrícula en las marcas menores\n",
        "ax.grid(which='minor', color='gray', linestyle='-', linewidth=0.5)\n",
        "\n",
        "# Guardar la imagen sin borde blanco\n",
        "plt.savefig('output.png', bbox_inches='tight')\n",
        "\n",
        "# set size of the plot\n",
        "plt.gcf().set_size_inches(9, 5)\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8416867",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.interpolate import griddata\n",
        "\n",
        "# Your dictionary with keys as coordinates (x, y) and values as the color intensity (z)\n",
        "# Extracting the x, y and z values\n",
        "x = [np.degrees(coord[0]) for coord in dict_result.keys() if 5 >= coord[0] >= -np.pi/2 and coord[1] > 0.7]\n",
        "y = [coord[1] for coord in dict_result.keys() if 5 >= coord[0] >= -np.pi/2 and coord[1] > 0.7]\n",
        "keys_list = list(dict_result.keys())\n",
        "values_list = list(dict_result.values())\n",
        "z = [v for e,v in zip(keys_list, values_list) if 5 >= e[0] >= -np.pi/2 and e[1] > 0.7]\n",
        "\n",
        "# Create a grid for interpolation\n",
        "x_grid = np.linspace(min(x), max(x), 100)\n",
        "y_grid = np.linspace(min(y), max(y), 100)\n",
        "X, Y = np.meshgrid(x_grid, y_grid)\n",
        "\n",
        "# Interpolate the scattered data into the grid\n",
        "Z = griddata((y, x), z, (Y, X), method='linear')\n",
        "\n",
        "# Create the scatter plot\n",
        "cmap = plt.get_cmap('viridis', 2048)\n",
        "plt.scatter(y, x, c=z, cmap=cmap)\n",
        "\n",
        "# Add color bar\n",
        "plt.colorbar(label='', shrink=0.8)\n",
        "contour_levels = np.linspace(np.min(z), np.max(z), 10)  # 10 levels\n",
        "contour_levels = contour_levels[contour_levels != 0]    # Remove zero from levels\n",
        "\n",
        "# Add contour lines on top of the scatter plot\n",
        "contour = plt.contour(Y, X, Z, levels=contour_levels, colors='black', linewidths=0.75)\n",
        "plt.clabel(contour, inline=True, fontsize=8)  # Optional: add labels to the contours\n",
        "\n",
        "# Add labels and a title\n",
        "plt.ylabel('Flight Path Angle (γ) [deg]')\n",
        "plt.xlabel('V/Vs')\n",
        "\n",
        "# Plot vertical line at x=1\n",
        "plt.axvline(x=1, color='k', linestyle='--')\n",
        "\n",
        "# Configure the minor ticks and grid\n",
        "x_min, x_max = min(x), max(x)\n",
        "y_min, y_max = min(y), max(y)\n",
        "ax = plt.gca()  # Get current axes\n",
        "ax.set_yticks(np.linspace(x_min, x_max, 60), minor=True)\n",
        "ax.set_xticks(np.linspace(y_min, y_max, 60), minor=True)\n",
        "plt.yticks(np.linspace(x_min, x_max, 6))  # Major ticks on y-axis\n",
        "plt.xticks(np.linspace(y_min, y_max, 4))  # Major ticks on x-axis\n",
        "\n",
        "# Set size of the plot\n",
        "plt.gcf().set_size_inches(9, 5)\n",
        "\n",
        "# Enable the minor grid lines\n",
        "ax.grid(which='minor', color='white', linestyle='-', linewidth=0.25)\n",
        "\n",
        "# Habilitar la cuadrícula en las marcas menores\n",
        "ax.grid(which='minor', color='white', linestyle='-', linewidth=0.25)\n",
        "\n",
        "# Save the image\n",
        "plt.savefig('output_with_contours.png', bbox_inches='tight')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "204e0318",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "3c8fe4a4",
      "metadata": {},
      "source": [
        "# CartPoleEnv \n",
        "\n",
        "### Observation Space\n",
        "\n",
        "The observation is a `ndarray` with shape `(4,)` with the values corresponding to the following positions and velocities:\n",
        "\n",
        "| Num | Observation           | Min                 | Max               |\n",
        "|-----|-----------------------|---------------------|-------------------|\n",
        "| 0   | Cart Position         | -4.8                | 4.8               |\n",
        "| 1   | Cart Velocity         | -Inf                | Inf               |\n",
        "| 2   | Pole Angle            | ~ -0.418 rad (-24°) | ~ 0.418 rad (24°) |\n",
        "| 3   | Pole Angular Velocity | -Inf                | Inf               |\n",
        "\n",
        "### Action Space\n",
        "\n",
        "The action is a `ndarray` with shape `(1,)` which can take values `{0, 1}` indicating the direction\n",
        "of the fixed force the cart is pushed with.\n",
        "\n",
        "- 0: Push cart to the left\n",
        "- 1: Push cart to the right"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1c04b7b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train cartpole environment:\n",
        "from classic_control.cartpole import CartPoleEnv\n",
        "# CartPole environment:\n",
        "env = CartPoleEnv(sutton_barto_reward=True)\n",
        "# position thresholds:\n",
        "x_lim         = 2.4\n",
        "theta_lim     = 0.418 \n",
        "# velocity thresholds:\n",
        "x_dot_lim     = 3.1\n",
        "theta_dot_lim = 3.1\n",
        "\n",
        "bins_space = {\n",
        "    \"x_space\"         : np.linspace(-x_lim, x_lim, 10,  dtype=np.float32),                     # position space          (0)\n",
        "    \"x_dot_space\"     : np.linspace(-x_dot_lim, x_dot_lim, 10,  dtype=np.float32),             # velocity space          (1)\n",
        "    \"theta_space\"     : np.linspace(-theta_lim, theta_lim, 10, dtype=np.float32),              # angle space             (2)\n",
        "    \"theta_dot_space\" : np.linspace(-theta_dot_lim, theta_dot_lim, 10, dtype=np.float32),      # angular velocity space  (3)\n",
        "}\n",
        "\n",
        "pi = PolicyIteration(\n",
        "    env=env, \n",
        "    bins_space=bins_space,\n",
        "    action_space=np.array([0, 1], dtype=np.int32),\n",
        "    gamma=0.99,\n",
        "    theta=1e-3\n",
        ")\n",
        "\n",
        "pi.run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0462a904",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test cartpole environment:\n",
        "\n",
        "with open(env.__class__.__name__ + \".pkl\", \"rb\") as f:\n",
        "    pi = pickle.load(f)\n",
        "\n",
        "test_enviroment(CartPoleEnv(sutton_barto_reward=True, render_mode=\"human\"), pi)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "063b6002",
      "metadata": {},
      "source": [
        "## Observation Space\n",
        "\n",
        "The observation is a `ndarray` with shape `(2,)` where the elements correspond to the following:\n",
        "\n",
        "| Num | Observation                          | Min   | Max  | Unit         |\n",
        "|-----|--------------------------------------|-------|------|--------------|\n",
        "| 0   | position of the car along the x-axis | -1.2  | 0.6  | position (m) |\n",
        "| 1   | velocity of the car                  | -0.07 | 0.07 | velocity (v) |\n",
        "\n",
        "## Action Space\n",
        "\n",
        "There are 3 discrete deterministic actions:\n",
        "\n",
        "- 0: Accelerate to the left\n",
        "- 1: Don't accelerate\n",
        "- 2: Accelerate to the right\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d617686",
      "metadata": {},
      "outputs": [],
      "source": [
        "from classic_control.continuous_mountain_car import Continuous_MountainCarEnv\n",
        "\n",
        "env=Continuous_MountainCarEnv()\n",
        "\n",
        "bins_space = {\n",
        "    \"x_space\":     np.linspace(env.min_position, env.max_position, 100,      dtype=np.float32),    # position space    (0)\n",
        "    \"x_dot_space\": np.linspace(-abs(env.max_speed), abs(env.max_speed), 100, dtype=np.float32),    # velocity space    (1)\n",
        "}\n",
        "\n",
        "pi = PolicyIteration(\n",
        "    env=env, \n",
        "    bins_space=bins_space,\n",
        "    action_space=np.linspace(-1.0, +1.0, 9, dtype=np.float32),\n",
        "    gamma=0.99,\n",
        "    theta=1e-3,\n",
        ")\n",
        "pi.run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f556b5a",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test mountain car environment:\n",
        "with open(env.__class__.__name__ + \".pkl\", \"rb\") as f:\n",
        "    pi: PolicyIteration = pickle.load(f)\n",
        "\n",
        "test_enviroment(Continuous_MountainCarEnv(render_mode=\"human\"), pi)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "DynamicProgramming",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
