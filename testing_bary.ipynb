{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "b149d005",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nicoRomeroCuruchet/DynamicProgramming/blob/main/testing_bary.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "beeb377e",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import gymnasium as gym\n",
        "from itertools import product\n",
        "from scipy.spatial import KDTree\n",
        "from scipy.optimize import minimize\n",
        "from PolicyIteration import PolicyIteration\n",
        "from classic_control.cartpole import CartPoleEnv \n",
        "from classic_control.continuous_mountain_car import Continuous_MountainCarEnv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1c04b7b",
      "metadata": {},
      "outputs": [],
      "source": [
        "env=CartPoleEnv(sutton_barto_reward=True)\n",
        "# position thresholds:\n",
        "x_lim = 2.5#env.x_threshold  \n",
        "theta_lim = 0.25#env.theta_threshold_radians \n",
        "# velocity thresholds:\n",
        "x_dot_lim = 2.5\n",
        "theta_dot_lim = 2.5\n",
        "\n",
        "bins_space = {\n",
        "    \"x_space\": np.linspace(-x_lim, x_lim, 12),                         # position space         (0)\n",
        "    \"x_dot_space\": np.linspace(-x_dot_lim, x_dot_lim, 12),             # velocity space         (1)\n",
        "    \"theta_space\": np.linspace(-theta_lim, theta_lim, 20),             # angle space            (2)\n",
        "    \"theta_dot_space\": np.linspace(-theta_dot_lim, theta_dot_lim, 12), # angular velocity space (3)\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df921921",
      "metadata": {},
      "outputs": [],
      "source": [
        "pi = PolicyIteration(\n",
        "    env=env, \n",
        "    bins_space=bins_space,\n",
        "    action_space=[0, 1],\n",
        "    gamma=0.99,\n",
        "    theta=1e-2\n",
        ")\n",
        "\n",
        "pi.run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5ab6bee",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5ab6bee",
        "outputId": "cc2eb18d-5a89-40d3-fd6c-0cf0e33ae32e"
      },
      "outputs": [],
      "source": [
        "def get_optimal_action(state:np.array, optimal_policy:PolicyIteration):\n",
        "    \"\"\"\n",
        "    Aproximate the optimal action for a given state using the provided optimal policy\n",
        "    with barycentric interpolation.\n",
        "\n",
        "    Parameters:\n",
        "    state (np.array): The state for which to determine the optimal action.\n",
        "    optimal_policy (PolicyIteration): The optimal policy used to determine the action.\n",
        "\n",
        "    Returns:\n",
        "    action: The optimal action for the given state.\n",
        "    \"\"\"\n",
        "    _, neighbors  = optimal_policy.kd_tree.query([state], k=optimal_policy.num_simplex_points)\n",
        "    simplex       = optimal_policy.points[neighbors[0]]\n",
        "    lambdas       = optimal_policy.barycentric_coordinates(state, simplex)\n",
        "\n",
        "    actions = optimal_policy.action_space\n",
        "    probabilities = np.zeros(len(actions))\n",
        "\n",
        "    for i, l in enumerate(lambdas):\n",
        "        for j, action in enumerate(actions):\n",
        "            if optimal_policy.policy[tuple(simplex[i])][action] > 0:\n",
        "                probabilities[j] += l\n",
        "\n",
        "    argmax = lambda x: max(enumerate(x), key=lambda x: x[1])[0]\n",
        "    action = actions[argmax(probabilities)]\n",
        "\n",
        "    return action\n",
        "\n",
        "with open(env.__class__.__name__ + \".pkl\", \"rb\") as f:\n",
        "    pi = pickle.load(f)\n",
        "\n",
        "num_episodes = 10000\n",
        "task = CartPoleEnv(render_mode=\"human\") # Continuous_MountainCarEnv(render_mode=\"human\")  | CartPoleEnv(render_mode=\"human\")\n",
        "max_velocity = -1\n",
        "max_theta_dot = -1\n",
        "for episode in range(0, num_episodes):\n",
        "    observation, _ = task.reset(options={\"low\":-0.05, \"high\":0.05})\n",
        "    total_reward = 0\n",
        "    for timestep in range(1, 1000):\n",
        "        action = get_optimal_action(observation, pi)\n",
        "        observation, reward, terminated, done, info = task.step(action)\n",
        "        total_reward += reward\n",
        "        max_velocity = max(max_velocity, abs(observation[1]))\n",
        "        max_theta_dot = max(max_theta_dot, abs(observation[3]))\n",
        "        if terminated:\n",
        "            print(f\"Episode {episode} finished after {timestep} timesteps\")\n",
        "            print(f\"Total reward: {total_reward}\")\n",
        "            print(f\"Max velocity: {max_velocity}\")\n",
        "            print(f\"Max theta_dot: {max_theta_dot}\")\n",
        "            break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1135fe0",
      "metadata": {},
      "outputs": [],
      "source": [
        "#requirements:\n",
        "#numpy\n",
        "#tqdm \n",
        "#gymnasium\n",
        "#scipy\n",
        "#loguru"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
